My SLURM_ARRAY_TASK_ID:  18
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_18
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_18.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6931
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6929
Epoch=010, loss=0.6928
Epoch=011, loss=0.6928
Epoch=012, loss=0.6927
Epoch=013, loss=0.6927
Epoch=014, loss=0.6926
Epoch=015, loss=0.6926
Epoch=016, loss=0.6925
Epoch=017, loss=0.6924
Epoch=018, loss=0.6923
Epoch=019, loss=0.6923
Epoch=020, loss=0.6921
Epoch=021, loss=0.6921
Epoch=022, loss=0.6919
Epoch=023, loss=0.6918
Epoch=024, loss=0.6917
Epoch=025, loss=0.6916
Epoch=026, loss=0.6915
Epoch=027, loss=0.6913
Epoch=028, loss=0.6911
Epoch=029, loss=0.6910
Epoch=030, loss=0.6907
Epoch=031, loss=0.6905
Epoch=032, loss=0.6903
Epoch=033, loss=0.6901
Epoch=034, loss=0.6898
Epoch=035, loss=0.6895
Epoch=036, loss=0.6893
Epoch=037, loss=0.6890
Epoch=038, loss=0.6887
Epoch=039, loss=0.6885
Epoch=040, loss=0.6880
Epoch=041, loss=0.6877
Epoch=042, loss=0.6873
Epoch=043, loss=0.6869
Epoch=044, loss=0.6865
Epoch=045, loss=0.6861
Epoch=046, loss=0.6856
Epoch=047, loss=0.6852
Epoch=048, loss=0.6846
Epoch=049, loss=0.6841
Epoch=050, loss=0.6834
Epoch=051, loss=0.6828
Epoch=052, loss=0.6821
Epoch=053, loss=0.6817
Epoch=054, loss=0.6810
Epoch=055, loss=0.6801
Epoch=056, loss=0.6797
Epoch=057, loss=0.6785
Epoch=058, loss=0.6780
Epoch=059, loss=0.6770
Epoch=060, loss=0.6763
Epoch=061, loss=0.6750
Epoch=062, loss=0.6745
Epoch=063, loss=0.6735
Epoch=064, loss=0.6722
Epoch=065, loss=0.6713
Epoch=066, loss=0.6704
Epoch=067, loss=0.6693
Epoch=068, loss=0.6681
Epoch=069, loss=0.6665
Epoch=070, loss=0.6651
Epoch=071, loss=0.6647
Epoch=072, loss=0.6629
Epoch=073, loss=0.6616
Epoch=074, loss=0.6604
Epoch=075, loss=0.6579
Epoch=076, loss=0.6569
Epoch=077, loss=0.6550
Epoch=078, loss=0.6542
Epoch=079, loss=0.6523
Epoch=080, loss=0.6497
Epoch=081, loss=0.6487
Epoch=082, loss=0.6468
Epoch=083, loss=0.6457
Epoch=084, loss=0.6428
Epoch=085, loss=0.6416
Epoch=086, loss=0.6397
Epoch=087, loss=0.6371
Epoch=088, loss=0.6348
Epoch=089, loss=0.6323
Epoch=090, loss=0.6299
Epoch=091, loss=0.6286
Epoch=092, loss=0.6258
Epoch=093, loss=0.6221
Epoch=094, loss=0.6219
Epoch=095, loss=0.6201
Epoch=096, loss=0.6173
Epoch=097, loss=0.6137
Epoch=098, loss=0.6120
Epoch=099, loss=0.6082
Epoch=100, loss=0.6049
Epoch=101, loss=0.6040
Epoch=102, loss=0.6004
Epoch=103, loss=0.5972
Epoch=104, loss=0.5932
Epoch=105, loss=0.5927
Epoch=106, loss=0.5889
Epoch=107, loss=0.5858
Epoch=108, loss=0.5820
Epoch=109, loss=0.5780
Epoch=110, loss=0.5754
Epoch=111, loss=0.5734
Epoch=112, loss=0.5701
Epoch=113, loss=0.5670
Epoch=114, loss=0.5630
Epoch=115, loss=0.5579
Epoch=116, loss=0.5552
Epoch=117, loss=0.5533
Epoch=118, loss=0.5471
Epoch=119, loss=0.5439
Epoch=120, loss=0.5424
Epoch=121, loss=0.5379
Epoch=122, loss=0.5345
Epoch=123, loss=0.5311
Epoch=124, loss=0.5252
Epoch=125, loss=0.5220
Epoch=126, loss=0.5213
Epoch=127, loss=0.5151
Epoch=128, loss=0.5126
Epoch=129, loss=0.5090
Epoch=130, loss=0.5034
Epoch=131, loss=0.4995
Epoch=132, loss=0.4971
Epoch=133, loss=0.4853
Epoch=134, loss=0.4879
Epoch=135, loss=0.4863
Epoch=136, loss=0.4815
Epoch=137, loss=0.4782
Epoch=138, loss=0.4729
Epoch=139, loss=0.4688
Epoch=140, loss=0.4612
Epoch=141, loss=0.4572
Epoch=142, loss=0.4569
Epoch=143, loss=0.4492
Epoch=144, loss=0.4459
Epoch=145, loss=0.4393
Epoch=146, loss=0.4412
Epoch=147, loss=0.4337
Epoch=148, loss=0.4311
Epoch=149, loss=0.4241
Epoch=150, loss=0.4187
Epoch=151, loss=0.4194
Epoch=152, loss=0.4146
Epoch=153, loss=0.4128
Epoch=154, loss=0.4059
Epoch=155, loss=0.4018
Epoch=156, loss=0.3959
Epoch=157, loss=0.3930
Epoch=158, loss=0.3902
Epoch=159, loss=0.3838
Epoch=160, loss=0.3844
Epoch=161, loss=0.3758
Epoch=162, loss=0.3684
Epoch=163, loss=0.3706
Epoch=164, loss=0.3633
Epoch=165, loss=0.3603
Epoch=166, loss=0.3576
Epoch=167, loss=0.3528
Epoch=168, loss=0.3513
Epoch=169, loss=0.3458
Epoch=170, loss=0.3386
Epoch=171, loss=0.3350
Epoch=172, loss=0.3349
Epoch=173, loss=0.3312
Epoch=174, loss=0.3310
Epoch=175, loss=0.3239
Epoch=176, loss=0.3227
Epoch=177, loss=0.3165
Epoch=178, loss=0.3104
Epoch=179, loss=0.3125
Epoch=180, loss=0.3041
Epoch=181, loss=0.3061
Epoch=182, loss=0.3071
Epoch=183, loss=0.3025
Epoch=184, loss=0.2948
Epoch=185, loss=0.2897
Epoch=186, loss=0.2869
Epoch=187, loss=0.2816
Epoch=188, loss=0.2833
Epoch=189, loss=0.2787
Epoch=190, loss=0.2695
Epoch=191, loss=0.2726
Epoch=192, loss=0.2693
Epoch=193, loss=0.2636
Epoch=194, loss=0.2623
Epoch=195, loss=0.2529
Epoch=196, loss=0.2607
Epoch=197, loss=0.2559
Epoch=198, loss=0.2484
Epoch=199, loss=0.2440
Epoch=200, loss=0.2482
Epoch=201, loss=0.2500
Epoch=202, loss=0.2449
Epoch=203, loss=0.2381
Epoch=204, loss=0.2363
Epoch=205, loss=0.2370
Epoch=206, loss=0.2344
Epoch=207, loss=0.2326
Epoch=208, loss=0.2284
Epoch=209, loss=0.2285
Epoch=210, loss=0.2229
Epoch=211, loss=0.2262
Epoch=212, loss=0.2177
Epoch=213, loss=0.2213
Epoch=214, loss=0.2190
Epoch=215, loss=0.2058
Epoch=216, loss=0.2173
Epoch=217, loss=0.2112
Epoch=218, loss=0.2110
Epoch=219, loss=0.2013
Epoch=220, loss=0.2051
Epoch=221, loss=0.2029
Epoch=222, loss=0.2002
Epoch=223, loss=0.2133
Epoch=224, loss=0.1981
Epoch=225, loss=0.1942
Epoch=226, loss=0.1883
Epoch=227, loss=0.1959
Epoch=228, loss=0.1994
Epoch=229, loss=0.1889
Epoch=230, loss=0.1833
Epoch=231, loss=0.1887
Epoch=232, loss=0.1835
Epoch=233, loss=0.1797
Epoch=234, loss=0.1730
Epoch=235, loss=0.1768
Epoch=236, loss=0.1796
Epoch=237, loss=0.1811
Epoch=238, loss=0.1711
Epoch=239, loss=0.1786
Epoch=240, loss=0.1759
Epoch=241, loss=0.1794
Epoch=242, loss=0.1679
Epoch=243, loss=0.1660
Epoch=244, loss=0.1693
Epoch=245, loss=0.1733
Epoch=246, loss=0.1614
Epoch=247, loss=0.1611
Epoch=248, loss=0.1639
Epoch=249, loss=0.1601
Epoch=250, loss=0.1563
Epoch=251, loss=0.1622
Epoch=252, loss=0.1617
Epoch=253, loss=0.1522
Epoch=254, loss=0.1566
Epoch=255, loss=0.1559
Epoch=256, loss=0.1526
Epoch=257, loss=0.1457
Epoch=258, loss=0.1489
Epoch=259, loss=0.1477
Epoch=260, loss=0.1491
Epoch=261, loss=0.1435
Epoch=262, loss=0.1519
Epoch=263, loss=0.1446
Epoch=264, loss=0.1503
Epoch=265, loss=0.1542
Epoch=266, loss=0.1448
Epoch=267, loss=0.1446
Epoch=268, loss=0.1438
Epoch=269, loss=0.1419
Epoch=270, loss=0.1421
Epoch=271, loss=0.1457
Epoch=272, loss=0.1351
Epoch=273, loss=0.1366
Epoch=274, loss=0.1350
Epoch=275, loss=0.1300
Epoch=276, loss=0.1341
Epoch=277, loss=0.1338
Epoch=278, loss=0.1273
Epoch=279, loss=0.1356
Epoch=280, loss=0.1395
Epoch=281, loss=0.1274
Epoch=282, loss=0.1255
Epoch=283, loss=0.1281
Epoch=284, loss=0.1337
Epoch=285, loss=0.1362
Epoch=286, loss=0.1342
Epoch=287, loss=0.1189
Epoch=288, loss=0.1302
Epoch=289, loss=0.1249
Epoch=290, loss=0.1196
Epoch=291, loss=0.1248
Epoch=292, loss=0.1290
Epoch=293, loss=0.1227
Epoch=294, loss=0.1278
Epoch=295, loss=0.1151
Epoch=296, loss=0.1165
Epoch=297, loss=0.1358
Epoch=298, loss=0.1215
Epoch=299, loss=0.1178
Epoch=300, loss=0.1214
Epoch=301, loss=0.1158
Epoch=302, loss=0.1239
Epoch=303, loss=0.1116
Epoch=304, loss=0.1132
Epoch=305, loss=0.1196
Epoch=306, loss=0.1128
Epoch=307, loss=0.1106
Epoch=308, loss=0.1128
Epoch=309, loss=0.1162
Epoch=310, loss=0.1101
Epoch=311, loss=0.1154
Epoch=312, loss=0.1114
Epoch=313, loss=0.1072
Epoch=314, loss=0.1143
Epoch=315, loss=0.1141
Epoch=316, loss=0.1175
Epoch=317, loss=0.1152
Epoch=318, loss=0.1157
Epoch=319, loss=0.1080
Epoch=320, loss=0.1175
Epoch=321, loss=0.1118
Epoch=322, loss=0.1119
Epoch=323, loss=0.1053
Epoch=324, loss=0.1075
Epoch=325, loss=0.1108
Epoch=326, loss=0.1012
Epoch=327, loss=0.1031
Epoch=328, loss=0.1061
Epoch=329, loss=0.1087
Epoch=330, loss=0.0956
Epoch=331, loss=0.1022
Epoch=332, loss=0.0962
Epoch=333, loss=0.1084
Epoch=334, loss=0.1052
Epoch=335, loss=0.1109
Epoch=336, loss=0.0993
Epoch=337, loss=0.0971
Epoch=338, loss=0.0997
Epoch=339, loss=0.1000
Epoch=340, loss=0.1047
Epoch=341, loss=0.0936
Epoch=342, loss=0.0985
Epoch=343, loss=0.0993
Epoch=344, loss=0.0943
Epoch=345, loss=0.0942
Epoch=346, loss=0.0974
Epoch=347, loss=0.1012
Epoch=348, loss=0.0975
Epoch=349, loss=0.0937
Epoch=350, loss=0.0945
Epoch=351, loss=0.0966
Epoch=352, loss=0.0898
Epoch=353, loss=0.0972
Epoch=354, loss=0.0964
Epoch=355, loss=0.0949
Epoch=356, loss=0.0912
Epoch=357, loss=0.0944
Epoch=358, loss=0.1076
Epoch=359, loss=0.0999
Epoch=360, loss=0.0896
Epoch=361, loss=0.0924
Epoch=362, loss=0.0902
Epoch=363, loss=0.0828
Epoch=364, loss=0.0872
Epoch=365, loss=0.0876
Epoch=366, loss=0.1013
Epoch=367, loss=0.0886
Epoch=368, loss=0.0853
Epoch=369, loss=0.0815
Epoch=370, loss=0.0854
Epoch=371, loss=0.0857
Epoch=372, loss=0.0848
Epoch=373, loss=0.0886
Epoch=374, loss=0.0791
Epoch=375, loss=0.0832
Epoch=376, loss=0.0948
Epoch=377, loss=0.0915
Epoch=378, loss=0.0899
Epoch=379, loss=0.0905
Epoch=380, loss=0.0862
Epoch=381, loss=0.0899
Epoch=382, loss=0.0948
Epoch=383, loss=0.0808
Epoch=384, loss=0.0752
Epoch=385, loss=0.0801
Epoch=386, loss=0.0807
Epoch=387, loss=0.0807
Epoch=388, loss=0.0833
Epoch=389, loss=0.0770
Epoch=390, loss=0.0861
Epoch=391, loss=0.0889
Epoch=392, loss=0.0872
Epoch=393, loss=0.0814
Epoch=394, loss=0.0888
Epoch=395, loss=0.0858
Epoch=396, loss=0.0778
Epoch=397, loss=0.0808
Epoch=398, loss=0.0844
Epoch=399, loss=0.0843
Epoch=400, loss=0.0827
Epoch=401, loss=0.0773
Epoch=402, loss=0.0782
Epoch=403, loss=0.0778
Epoch=404, loss=0.0772
Early stopping!
Loading 384th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7625+-0.0095, F1Ma=0.7154+-0.0184, acc=0.7625+-0.0095
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738]]
=== train DGI model ===
Epoch=000, loss=0.6933
Epoch=001, loss=0.6932
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6927
Epoch=009, loss=0.6926
Epoch=010, loss=0.6925
Epoch=011, loss=0.6924
Epoch=012, loss=0.6923
Epoch=013, loss=0.6922
Epoch=014, loss=0.6920
Epoch=015, loss=0.6918
Epoch=016, loss=0.6916
Epoch=017, loss=0.6914
Epoch=018, loss=0.6912
Epoch=019, loss=0.6910
Epoch=020, loss=0.6906
Epoch=021, loss=0.6903
Epoch=022, loss=0.6900
Epoch=023, loss=0.6896
Epoch=024, loss=0.6892
Epoch=025, loss=0.6888
Epoch=026, loss=0.6882
Epoch=027, loss=0.6878
Epoch=028, loss=0.6871
Epoch=029, loss=0.6866
Epoch=030, loss=0.6858
Epoch=031, loss=0.6851
Epoch=032, loss=0.6845
Epoch=033, loss=0.6836
Epoch=034, loss=0.6826
Epoch=035, loss=0.6816
Epoch=036, loss=0.6807
Epoch=037, loss=0.6797
Epoch=038, loss=0.6786
Epoch=039, loss=0.6772
Epoch=040, loss=0.6758
Epoch=041, loss=0.6746
Epoch=042, loss=0.6730
Epoch=043, loss=0.6711
Epoch=044, loss=0.6694
Epoch=045, loss=0.6677
Epoch=046, loss=0.6650
Epoch=047, loss=0.6633
Epoch=048, loss=0.6620
Epoch=049, loss=0.6595
Epoch=050, loss=0.6570
Epoch=051, loss=0.6539
Epoch=052, loss=0.6517
Epoch=053, loss=0.6490
Epoch=054, loss=0.6461
Epoch=055, loss=0.6430
Epoch=056, loss=0.6402
Epoch=057, loss=0.6369
Epoch=058, loss=0.6337
Epoch=059, loss=0.6306
Epoch=060, loss=0.6262
Epoch=061, loss=0.6227
Epoch=062, loss=0.6198
Epoch=063, loss=0.6154
Epoch=064, loss=0.6115
Epoch=065, loss=0.6091
Epoch=066, loss=0.6004
Epoch=067, loss=0.5993
Epoch=068, loss=0.5916
Epoch=069, loss=0.5867
Epoch=070, loss=0.5845
Epoch=071, loss=0.5790
Epoch=072, loss=0.5741
Epoch=073, loss=0.5687
Epoch=074, loss=0.5646
Epoch=075, loss=0.5561
Epoch=076, loss=0.5528
Epoch=077, loss=0.5471
Epoch=078, loss=0.5410
Epoch=079, loss=0.5352
Epoch=080, loss=0.5259
Epoch=081, loss=0.5234
Epoch=082, loss=0.5169
Epoch=083, loss=0.5113
Epoch=084, loss=0.5033
Epoch=085, loss=0.4978
Epoch=086, loss=0.4910
Epoch=087, loss=0.4873
Epoch=088, loss=0.4747
Epoch=089, loss=0.4727
Epoch=090, loss=0.4655
Epoch=091, loss=0.4598
Epoch=092, loss=0.4516
Epoch=093, loss=0.4461
Epoch=094, loss=0.4394
Epoch=095, loss=0.4334
Epoch=096, loss=0.4224
Epoch=097, loss=0.4209
Epoch=098, loss=0.4057
Epoch=099, loss=0.4019
Epoch=100, loss=0.3959
Epoch=101, loss=0.3876
Epoch=102, loss=0.3818
Epoch=103, loss=0.3743
Epoch=104, loss=0.3680
Epoch=105, loss=0.3667
Epoch=106, loss=0.3511
Epoch=107, loss=0.3452
Epoch=108, loss=0.3471
Epoch=109, loss=0.3338
Epoch=110, loss=0.3358
Epoch=111, loss=0.3295
Epoch=112, loss=0.3142
Epoch=113, loss=0.3153
Epoch=114, loss=0.3082
Epoch=115, loss=0.2974
Epoch=116, loss=0.2929
Epoch=117, loss=0.2884
Epoch=118, loss=0.2821
Epoch=119, loss=0.2785
Epoch=120, loss=0.2744
Epoch=121, loss=0.2728
Epoch=122, loss=0.2618
Epoch=123, loss=0.2595
Epoch=124, loss=0.2541
Epoch=125, loss=0.2467
Epoch=126, loss=0.2434
Epoch=127, loss=0.2393
Epoch=128, loss=0.2333
Epoch=129, loss=0.2309
Epoch=130, loss=0.2185
Epoch=131, loss=0.2138
Epoch=132, loss=0.2169
Epoch=133, loss=0.2088
Epoch=134, loss=0.2018
Epoch=135, loss=0.2115
Epoch=136, loss=0.2001
Epoch=137, loss=0.1970
Epoch=138, loss=0.1915
Epoch=139, loss=0.1939
Epoch=140, loss=0.1842
Epoch=141, loss=0.1889
Epoch=142, loss=0.1825
Epoch=143, loss=0.1796
Epoch=144, loss=0.1737
Epoch=145, loss=0.1697
Epoch=146, loss=0.1636
Epoch=147, loss=0.1601
Epoch=148, loss=0.1625
Epoch=149, loss=0.1545
Epoch=150, loss=0.1609
Epoch=151, loss=0.1644
Epoch=152, loss=0.1548
Epoch=153, loss=0.1474
Epoch=154, loss=0.1537
Epoch=155, loss=0.1371
Epoch=156, loss=0.1439
Epoch=157, loss=0.1375
Epoch=158, loss=0.1404
Epoch=159, loss=0.1383
Epoch=160, loss=0.1383
Epoch=161, loss=0.1328
Epoch=162, loss=0.1416
Epoch=163, loss=0.1302
Epoch=164, loss=0.1337
Epoch=165, loss=0.1289
Epoch=166, loss=0.1267
Epoch=167, loss=0.1199
Epoch=168, loss=0.1151
Epoch=169, loss=0.1119
Epoch=170, loss=0.1232
Epoch=171, loss=0.1214
Epoch=172, loss=0.1115
Epoch=173, loss=0.1160
Epoch=174, loss=0.1115
Epoch=175, loss=0.1220
Epoch=176, loss=0.1153
Epoch=177, loss=0.1072
Epoch=178, loss=0.1107
Epoch=179, loss=0.1135
Epoch=180, loss=0.1032
Epoch=181, loss=0.1038
Epoch=182, loss=0.1003
Epoch=183, loss=0.0971
Epoch=184, loss=0.1049
Epoch=185, loss=0.0997
Epoch=186, loss=0.0899
Epoch=187, loss=0.1040
Epoch=188, loss=0.0950
Epoch=189, loss=0.0979
Epoch=190, loss=0.0941
Epoch=191, loss=0.0913
Epoch=192, loss=0.0961
Epoch=193, loss=0.0904
Epoch=194, loss=0.0942
Epoch=195, loss=0.0860
Epoch=196, loss=0.0836
Epoch=197, loss=0.0877
Epoch=198, loss=0.0889
Epoch=199, loss=0.0856
Epoch=200, loss=0.0798
Epoch=201, loss=0.0861
Epoch=202, loss=0.0892
Epoch=203, loss=0.0734
Epoch=204, loss=0.0801
Epoch=205, loss=0.0830
Epoch=206, loss=0.0780
Epoch=207, loss=0.0812
Epoch=208, loss=0.0833
Epoch=209, loss=0.0795
Epoch=210, loss=0.0768
Epoch=211, loss=0.0787
Epoch=212, loss=0.0747
Epoch=213, loss=0.0678
Epoch=214, loss=0.0748
Epoch=215, loss=0.0711
Epoch=216, loss=0.0711
Epoch=217, loss=0.0714
Epoch=218, loss=0.0718
Epoch=219, loss=0.0770
Epoch=220, loss=0.0698
Epoch=221, loss=0.0707
Epoch=222, loss=0.0656
Epoch=223, loss=0.0693
Epoch=224, loss=0.0738
Epoch=225, loss=0.0704
Epoch=226, loss=0.0653
Epoch=227, loss=0.0683
Epoch=228, loss=0.0644
Epoch=229, loss=0.0590
Epoch=230, loss=0.0677
Epoch=231, loss=0.0690
Epoch=232, loss=0.0677
Epoch=233, loss=0.0634
Epoch=234, loss=0.0649
Epoch=235, loss=0.0643
Epoch=236, loss=0.0629
Epoch=237, loss=0.0654
Epoch=238, loss=0.0602
Epoch=239, loss=0.0618
Epoch=240, loss=0.0545
Epoch=241, loss=0.0628
Epoch=242, loss=0.0614
Epoch=243, loss=0.0548
Epoch=244, loss=0.0586
Epoch=245, loss=0.0526
Epoch=246, loss=0.0580
Epoch=247, loss=0.0663
Epoch=248, loss=0.0547
Epoch=249, loss=0.0580
Epoch=250, loss=0.0596
Epoch=251, loss=0.0576
Epoch=252, loss=0.0582
Epoch=253, loss=0.0532
Epoch=254, loss=0.0539
Epoch=255, loss=0.0587
Epoch=256, loss=0.0543
Epoch=257, loss=0.0618
Epoch=258, loss=0.0507
Epoch=259, loss=0.0505
Epoch=260, loss=0.0517
Epoch=261, loss=0.0560
Epoch=262, loss=0.0494
Epoch=263, loss=0.0536
Epoch=264, loss=0.0554
Epoch=265, loss=0.0524
Epoch=266, loss=0.0460
Epoch=267, loss=0.0476
Epoch=268, loss=0.0467
Epoch=269, loss=0.0539
Epoch=270, loss=0.0434
Epoch=271, loss=0.0494
Epoch=272, loss=0.0520
Epoch=273, loss=0.0512
Epoch=274, loss=0.0584
Epoch=275, loss=0.0444
Epoch=276, loss=0.0501
Epoch=277, loss=0.0498
Epoch=278, loss=0.0461
Epoch=279, loss=0.0504
Epoch=280, loss=0.0461
Epoch=281, loss=0.0446
Epoch=282, loss=0.0470
Epoch=283, loss=0.0427
Epoch=284, loss=0.0464
Epoch=285, loss=0.0462
Epoch=286, loss=0.0443
Epoch=287, loss=0.0369
Epoch=288, loss=0.0457
Epoch=289, loss=0.0377
Epoch=290, loss=0.0425
Epoch=291, loss=0.0465
Epoch=292, loss=0.0444
Epoch=293, loss=0.0433
Epoch=294, loss=0.0402
Epoch=295, loss=0.0351
Epoch=296, loss=0.0340
Epoch=297, loss=0.0427
Epoch=298, loss=0.0399
Epoch=299, loss=0.0375
Epoch=300, loss=0.0408
Epoch=301, loss=0.0436
Epoch=302, loss=0.0364
Epoch=303, loss=0.0353
Epoch=304, loss=0.0365
Epoch=305, loss=0.0409
Epoch=306, loss=0.0414
Epoch=307, loss=0.0412
Epoch=308, loss=0.0369
Epoch=309, loss=0.0343
Epoch=310, loss=0.0415
Epoch=311, loss=0.0408
Epoch=312, loss=0.0380
Epoch=313, loss=0.0393
Epoch=314, loss=0.0404
Epoch=315, loss=0.0336
Epoch=316, loss=0.0374
Epoch=317, loss=0.0342
Epoch=318, loss=0.0371
Epoch=319, loss=0.0368
Epoch=320, loss=0.0323
Epoch=321, loss=0.0323
Epoch=322, loss=0.0339
Epoch=323, loss=0.0372
Epoch=324, loss=0.0349
Epoch=325, loss=0.0415
Epoch=326, loss=0.0378
Epoch=327, loss=0.0343
Epoch=328, loss=0.0344
Epoch=329, loss=0.0345
Epoch=330, loss=0.0269
Epoch=331, loss=0.0329
Epoch=332, loss=0.0330
Epoch=333, loss=0.0349
Epoch=334, loss=0.0365
Epoch=335, loss=0.0340
Epoch=336, loss=0.0307
Epoch=337, loss=0.0403
Epoch=338, loss=0.0376
Epoch=339, loss=0.0295
Epoch=340, loss=0.0399
Epoch=341, loss=0.0316
Epoch=342, loss=0.0335
Epoch=343, loss=0.0287
Epoch=344, loss=0.0362
Epoch=345, loss=0.0263
Epoch=346, loss=0.0318
Epoch=347, loss=0.0359
Epoch=348, loss=0.0284
Epoch=349, loss=0.0357
Epoch=350, loss=0.0320
Epoch=351, loss=0.0297
Epoch=352, loss=0.0380
Epoch=353, loss=0.0264
Epoch=354, loss=0.0285
Epoch=355, loss=0.0311
Epoch=356, loss=0.0309
Epoch=357, loss=0.0303
Epoch=358, loss=0.0329
Epoch=359, loss=0.0337
Epoch=360, loss=0.0263
Epoch=361, loss=0.0356
Epoch=362, loss=0.0261
Epoch=363, loss=0.0228
Epoch=364, loss=0.0239
Epoch=365, loss=0.0316
Epoch=366, loss=0.0305
Epoch=367, loss=0.0238
Epoch=368, loss=0.0297
Epoch=369, loss=0.0245
Epoch=370, loss=0.0292
Epoch=371, loss=0.0352
Epoch=372, loss=0.0314
Epoch=373, loss=0.0296
Epoch=374, loss=0.0308
Epoch=375, loss=0.0260
Epoch=376, loss=0.0240
Epoch=377, loss=0.0326
Epoch=378, loss=0.0325
Epoch=379, loss=0.0261
Epoch=380, loss=0.0262
Epoch=381, loss=0.0257
Epoch=382, loss=0.0395
Epoch=383, loss=0.0298
Early stopping!
Loading 363th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7703+-0.0038, F1Ma=0.7501+-0.0054, acc=0.7703+-0.0038
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7406136605914446, 0.7557005618857826, 0.7479665429249376, 0.7646731834599356, 0.8357142806053162, 0.7379999756813049, 0.7490328550338745, 0.8285714387893677, 0.7360000014305115, 0.75, 0.7703070345899728, 0.003768114929977733, 0.7501466989028345, 0.005368346347229234, 0.7703070345899727, 0.0037681149299777198]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6927
Epoch=003, loss=0.6925
Epoch=004, loss=0.6922
Epoch=005, loss=0.6918
Epoch=006, loss=0.6915
Epoch=007, loss=0.6909
Epoch=008, loss=0.6904
Epoch=009, loss=0.6897
Epoch=010, loss=0.6891
Epoch=011, loss=0.6881
Epoch=012, loss=0.6872
Epoch=013, loss=0.6860
Epoch=014, loss=0.6847
Epoch=015, loss=0.6833
Epoch=016, loss=0.6816
Epoch=017, loss=0.6800
Epoch=018, loss=0.6780
Epoch=019, loss=0.6754
Epoch=020, loss=0.6730
Epoch=021, loss=0.6699
Epoch=022, loss=0.6669
Epoch=023, loss=0.6635
Epoch=024, loss=0.6601
Epoch=025, loss=0.6567
Epoch=026, loss=0.6517
Epoch=027, loss=0.6472
Epoch=028, loss=0.6412
Epoch=029, loss=0.6359
Epoch=030, loss=0.6297
Epoch=031, loss=0.6234
Epoch=032, loss=0.6171
Epoch=033, loss=0.6102
Epoch=034, loss=0.6014
Epoch=035, loss=0.5941
Epoch=036, loss=0.5843
Epoch=037, loss=0.5751
Epoch=038, loss=0.5653
Epoch=039, loss=0.5574
Epoch=040, loss=0.5464
Epoch=041, loss=0.5367
Epoch=042, loss=0.5236
Epoch=043, loss=0.5091
Epoch=044, loss=0.5003
Epoch=045, loss=0.4880
Epoch=046, loss=0.4757
Epoch=047, loss=0.4616
Epoch=048, loss=0.4480
Epoch=049, loss=0.4330
Epoch=050, loss=0.4236
Epoch=051, loss=0.4125
Epoch=052, loss=0.3974
Epoch=053, loss=0.3838
Epoch=054, loss=0.3664
Epoch=055, loss=0.3583
Epoch=056, loss=0.3453
Epoch=057, loss=0.3349
Epoch=058, loss=0.3241
Epoch=059, loss=0.3109
Epoch=060, loss=0.2985
Epoch=061, loss=0.2882
Epoch=062, loss=0.2759
Epoch=063, loss=0.2689
Epoch=064, loss=0.2547
Epoch=065, loss=0.2449
Epoch=066, loss=0.2413
Epoch=067, loss=0.2298
Epoch=068, loss=0.2219
Epoch=069, loss=0.2151
Epoch=070, loss=0.2066
Epoch=071, loss=0.1962
Epoch=072, loss=0.1871
Epoch=073, loss=0.1954
Epoch=074, loss=0.1792
Epoch=075, loss=0.1759
Epoch=076, loss=0.1756
Epoch=077, loss=0.1598
Epoch=078, loss=0.1513
Epoch=079, loss=0.1469
Epoch=080, loss=0.1467
Epoch=081, loss=0.1437
Epoch=082, loss=0.1487
Epoch=083, loss=0.1392
Epoch=084, loss=0.1411
Epoch=085, loss=0.1275
Epoch=086, loss=0.1222
Epoch=087, loss=0.1259
Epoch=088, loss=0.1231
Epoch=089, loss=0.1155
Epoch=090, loss=0.1265
Epoch=091, loss=0.1112
Epoch=092, loss=0.1184
Epoch=093, loss=0.1156
Epoch=094, loss=0.1064
Epoch=095, loss=0.1114
Epoch=096, loss=0.1002
Epoch=097, loss=0.1026
Epoch=098, loss=0.0932
Epoch=099, loss=0.0944
Epoch=100, loss=0.1012
Epoch=101, loss=0.0863
Epoch=102, loss=0.1060
Epoch=103, loss=0.0918
Epoch=104, loss=0.0871
Epoch=105, loss=0.1060
Epoch=106, loss=0.0911
Epoch=107, loss=0.0977
Epoch=108, loss=0.0859
Epoch=109, loss=0.0837
Epoch=110, loss=0.0813
Epoch=111, loss=0.0834
Epoch=112, loss=0.0821
Epoch=113, loss=0.0875
Epoch=114, loss=0.0802
Epoch=115, loss=0.0741
Epoch=116, loss=0.0879
Epoch=117, loss=0.0706
Epoch=118, loss=0.0707
Epoch=119, loss=0.0748
Epoch=120, loss=0.0744
Epoch=121, loss=0.0776
Epoch=122, loss=0.0762
Epoch=123, loss=0.0721
Epoch=124, loss=0.0665
Epoch=125, loss=0.0656
Epoch=126, loss=0.0671
Epoch=127, loss=0.0691
Epoch=128, loss=0.0703
Epoch=129, loss=0.0671
Epoch=130, loss=0.0554
Epoch=131, loss=0.0682
Epoch=132, loss=0.0654
Epoch=133, loss=0.0573
Epoch=134, loss=0.0601
Epoch=135, loss=0.0596
Epoch=136, loss=0.0505
Epoch=137, loss=0.0599
Epoch=138, loss=0.0604
Epoch=139, loss=0.0631
Epoch=140, loss=0.0661
Epoch=141, loss=0.0574
Epoch=142, loss=0.0581
Epoch=143, loss=0.0607
Epoch=144, loss=0.0591
Epoch=145, loss=0.0565
Epoch=146, loss=0.0621
Epoch=147, loss=0.0573
Epoch=148, loss=0.0708
Epoch=149, loss=0.0613
Epoch=150, loss=0.0574
Epoch=151, loss=0.0611
Epoch=152, loss=0.0571
Epoch=153, loss=0.0631
Epoch=154, loss=0.0505
Epoch=155, loss=0.0547
Epoch=156, loss=0.0677
Epoch=157, loss=0.0523
Epoch=158, loss=0.0552
Epoch=159, loss=0.0439
Epoch=160, loss=0.0575
Epoch=161, loss=0.0548
Epoch=162, loss=0.0489
Epoch=163, loss=0.0606
Epoch=164, loss=0.0500
Epoch=165, loss=0.0453
Epoch=166, loss=0.0529
Epoch=167, loss=0.0440
Epoch=168, loss=0.0473
Epoch=169, loss=0.0511
Epoch=170, loss=0.0402
Epoch=171, loss=0.0495
Epoch=172, loss=0.0456
Epoch=173, loss=0.0520
Epoch=174, loss=0.0445
Epoch=175, loss=0.0412
Epoch=176, loss=0.0395
Epoch=177, loss=0.0513
Epoch=178, loss=0.0502
Epoch=179, loss=0.0424
Epoch=180, loss=0.0417
Epoch=181, loss=0.0488
Epoch=182, loss=0.0428
Epoch=183, loss=0.0420
Epoch=184, loss=0.0438
Epoch=185, loss=0.0324
Epoch=186, loss=0.0421
Epoch=187, loss=0.0416
Epoch=188, loss=0.0396
Epoch=189, loss=0.0513
Epoch=190, loss=0.0456
Epoch=191, loss=0.0424
Epoch=192, loss=0.0397
Epoch=193, loss=0.0409
Epoch=194, loss=0.0399
Epoch=195, loss=0.0435
Epoch=196, loss=0.0368
Epoch=197, loss=0.0390
Epoch=198, loss=0.0446
Epoch=199, loss=0.0481
Epoch=200, loss=0.0375
Epoch=201, loss=0.0346
Epoch=202, loss=0.0341
Epoch=203, loss=0.0559
Epoch=204, loss=0.0496
Epoch=205, loss=0.0427
Early stopping!
Loading 185th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7845+-0.0149, F1Ma=0.7613+-0.0189, acc=0.7845+-0.0149
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7406136605914446, 0.7557005618857826, 0.7479665429249376, 0.7646731834599356, 0.8357142806053162, 0.7379999756813049, 0.7490328550338745, 0.8285714387893677, 0.7360000014305115, 0.75, 0.7703070345899728, 0.003768114929977733, 0.7501466989028345, 0.005368346347229234, 0.7703070345899727, 0.0037681149299777198], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7841551773237248, 0.7833132717286768, 0.7979865264340419, 0.796547786301411, 0.8571428656578064, 0.7919999957084656, 0.7722437381744385, 0.8500000238418579, 0.7879999876022339, 0.7693423628807068, 0.7845316750874465, 0.01493675790927936, 0.7612918249982277, 0.018875132868058274, 0.7845316750874465, 0.014936757909279369]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6928
Epoch=002, loss=0.6922
Epoch=003, loss=0.6914
Epoch=004, loss=0.6904
Epoch=005, loss=0.6891
Epoch=006, loss=0.6874
Epoch=007, loss=0.6854
Epoch=008, loss=0.6831
Epoch=009, loss=0.6800
Epoch=010, loss=0.6762
Epoch=011, loss=0.6723
Epoch=012, loss=0.6678
Epoch=013, loss=0.6618
Epoch=014, loss=0.6555
Epoch=015, loss=0.6479
Epoch=016, loss=0.6399
Epoch=017, loss=0.6307
Epoch=018, loss=0.6199
Epoch=019, loss=0.6086
Epoch=020, loss=0.5960
Epoch=021, loss=0.5814
Epoch=022, loss=0.5651
Epoch=023, loss=0.5509
Epoch=024, loss=0.5364
Epoch=025, loss=0.5161
Epoch=026, loss=0.4959
Epoch=027, loss=0.4760
Epoch=028, loss=0.4533
Epoch=029, loss=0.4404
Epoch=030, loss=0.4143
Epoch=031, loss=0.3971
Epoch=032, loss=0.3700
Epoch=033, loss=0.3513
Epoch=034, loss=0.3394
Epoch=035, loss=0.3230
Epoch=036, loss=0.3027
Epoch=037, loss=0.2943
Epoch=038, loss=0.2652
Epoch=039, loss=0.2413
Epoch=040, loss=0.2368
Epoch=041, loss=0.2210
Epoch=042, loss=0.1990
Epoch=043, loss=0.1957
Epoch=044, loss=0.1821
Epoch=045, loss=0.1637
Epoch=046, loss=0.1838
Epoch=047, loss=0.1615
Epoch=048, loss=0.1472
Epoch=049, loss=0.1319
Epoch=050, loss=0.1396
Epoch=051, loss=0.1412
Epoch=052, loss=0.1286
Epoch=053, loss=0.1280
Epoch=054, loss=0.1166
Epoch=055, loss=0.1114
Epoch=056, loss=0.1104
Epoch=057, loss=0.1106
Epoch=058, loss=0.1079
Epoch=059, loss=0.1176
Epoch=060, loss=0.0950
Epoch=061, loss=0.0970
Epoch=062, loss=0.0908
Epoch=063, loss=0.0940
Epoch=064, loss=0.0917
Epoch=065, loss=0.0939
Epoch=066, loss=0.0775
Epoch=067, loss=0.0735
Epoch=068, loss=0.0888
Epoch=069, loss=0.0887
Epoch=070, loss=0.0750
Epoch=071, loss=0.0820
Epoch=072, loss=0.0715
Epoch=073, loss=0.0788
Epoch=074, loss=0.0793
Epoch=075, loss=0.0632
Epoch=076, loss=0.0748
Epoch=077, loss=0.0644
Epoch=078, loss=0.0605
Epoch=079, loss=0.0734
Epoch=080, loss=0.0667
Epoch=081, loss=0.0831
Epoch=082, loss=0.0627
Epoch=083, loss=0.0573
Epoch=084, loss=0.0682
Epoch=085, loss=0.0682
Epoch=086, loss=0.0636
Epoch=087, loss=0.0614
Epoch=088, loss=0.0748
Epoch=089, loss=0.0702
Epoch=090, loss=0.0675
Epoch=091, loss=0.0633
Epoch=092, loss=0.0505
Epoch=093, loss=0.0529
Epoch=094, loss=0.0578
Epoch=095, loss=0.0737
Epoch=096, loss=0.0617
Epoch=097, loss=0.0605
Epoch=098, loss=0.0550
Epoch=099, loss=0.0532
Epoch=100, loss=0.0569
Epoch=101, loss=0.0520
Epoch=102, loss=0.0534
Epoch=103, loss=0.0506
Epoch=104, loss=0.0636
Epoch=105, loss=0.0566
Epoch=106, loss=0.0502
Epoch=107, loss=0.0488
Epoch=108, loss=0.0412
Epoch=109, loss=0.0447
Epoch=110, loss=0.0602
Epoch=111, loss=0.0405
Epoch=112, loss=0.0473
Epoch=113, loss=0.0541
Epoch=114, loss=0.0615
Epoch=115, loss=0.0625
Epoch=116, loss=0.0588
Epoch=117, loss=0.0581
Epoch=118, loss=0.0499
Epoch=119, loss=0.0392
Epoch=120, loss=0.0458
Epoch=121, loss=0.0470
Epoch=122, loss=0.0468
Epoch=123, loss=0.0497
Epoch=124, loss=0.0426
Epoch=125, loss=0.0457
Epoch=126, loss=0.0534
Epoch=127, loss=0.0554
Epoch=128, loss=0.0494
Epoch=129, loss=0.0438
Epoch=130, loss=0.0387
Epoch=131, loss=0.0507
Epoch=132, loss=0.0464
Epoch=133, loss=0.0435
Epoch=134, loss=0.0410
Epoch=135, loss=0.0400
Epoch=136, loss=0.0368
Epoch=137, loss=0.0454
Epoch=138, loss=0.0479
Epoch=139, loss=0.0388
Epoch=140, loss=0.0456
Epoch=141, loss=0.0390
Epoch=142, loss=0.0414
Epoch=143, loss=0.0287
Epoch=144, loss=0.0415
Epoch=145, loss=0.0488
Epoch=146, loss=0.0368
Epoch=147, loss=0.0288
Epoch=148, loss=0.0421
Epoch=149, loss=0.0531
Epoch=150, loss=0.0382
Epoch=151, loss=0.0398
Epoch=152, loss=0.0367
Epoch=153, loss=0.0352
Epoch=154, loss=0.0482
Epoch=155, loss=0.0443
Epoch=156, loss=0.0357
Epoch=157, loss=0.0350
Epoch=158, loss=0.0297
Epoch=159, loss=0.0359
Epoch=160, loss=0.0350
Epoch=161, loss=0.0385
Epoch=162, loss=0.0360
Epoch=163, loss=0.0479
Early stopping!
Loading 143th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7988+-0.0152, F1Ma=0.7762+-0.0183, acc=0.7988+-0.0152
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7406136605914446, 0.7557005618857826, 0.7479665429249376, 0.7646731834599356, 0.8357142806053162, 0.7379999756813049, 0.7490328550338745, 0.8285714387893677, 0.7360000014305115, 0.75, 0.7703070345899728, 0.003768114929977733, 0.7501466989028345, 0.005368346347229234, 0.7703070345899727, 0.0037681149299777198], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7841551773237248, 0.7833132717286768, 0.7979865264340419, 0.796547786301411, 0.8571428656578064, 0.7919999957084656, 0.7722437381744385, 0.8500000238418579, 0.7879999876022339, 0.7693423628807068, 0.7845316750874465, 0.01493675790927936, 0.7612918249982277, 0.018875132868058274, 0.7845316750874465, 0.014936757909279369], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7932253388715719, 0.7968518080598719, 0.8146628547973025, 0.8170599211159619, 0.8642857074737549, 0.800000011920929, 0.7620889544487, 0.8642857074737549, 0.800000011920929, 0.761605441570282, 0.7988340458608627, 0.015243063681934262, 0.7761681825626688, 0.018292998073328123, 0.7988340458608627, 0.015243063681934262]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6920
Epoch=002, loss=0.6897
Epoch=003, loss=0.6864
Epoch=004, loss=0.6818
Epoch=005, loss=0.6759
Epoch=006, loss=0.6689
Epoch=007, loss=0.6597
Epoch=008, loss=0.6484
Epoch=009, loss=0.6359
Epoch=010, loss=0.6214
Epoch=011, loss=0.6039
Epoch=012, loss=0.5812
Epoch=013, loss=0.5592
Epoch=014, loss=0.5380
Epoch=015, loss=0.5091
Epoch=016, loss=0.4864
Epoch=017, loss=0.4624
Epoch=018, loss=0.4337
Epoch=019, loss=0.4053
Epoch=020, loss=0.3767
Epoch=021, loss=0.3653
Epoch=022, loss=0.3333
Epoch=023, loss=0.3066
Epoch=024, loss=0.2940
Epoch=025, loss=0.2706
Epoch=026, loss=0.2431
Epoch=027, loss=0.2370
Epoch=028, loss=0.2191
Epoch=029, loss=0.2012
Epoch=030, loss=0.1950
Epoch=031, loss=0.1891
Epoch=032, loss=0.1673
Epoch=033, loss=0.1623
Epoch=034, loss=0.1557
Epoch=035, loss=0.1384
Epoch=036, loss=0.1510
Epoch=037, loss=0.1376
Epoch=038, loss=0.1438
Epoch=039, loss=0.1349
Epoch=040, loss=0.1137
Epoch=041, loss=0.1146
Epoch=042, loss=0.1196
Epoch=043, loss=0.1009
Epoch=044, loss=0.1074
Epoch=045, loss=0.1019
Epoch=046, loss=0.1058
Epoch=047, loss=0.0913
Epoch=048, loss=0.0873
Epoch=049, loss=0.0972
Epoch=050, loss=0.0929
Epoch=051, loss=0.1056
Epoch=052, loss=0.0952
Epoch=053, loss=0.0745
Epoch=054, loss=0.1104
Epoch=055, loss=0.0952
Epoch=056, loss=0.0794
Epoch=057, loss=0.0781
Epoch=058, loss=0.0839
Epoch=059, loss=0.0759
Epoch=060, loss=0.0736
Epoch=061, loss=0.0591
Epoch=062, loss=0.0813
Epoch=063, loss=0.0846
Epoch=064, loss=0.0747
Epoch=065, loss=0.0751
Epoch=066, loss=0.0634
Epoch=067, loss=0.0657
Epoch=068, loss=0.0757
Epoch=069, loss=0.0608
Epoch=070, loss=0.0842
Epoch=071, loss=0.0755
Epoch=072, loss=0.0817
Epoch=073, loss=0.0622
Epoch=074, loss=0.0653
Epoch=075, loss=0.0675
Epoch=076, loss=0.0668
Epoch=077, loss=0.0595
Epoch=078, loss=0.0596
Epoch=079, loss=0.0589
Epoch=080, loss=0.0625
Epoch=081, loss=0.0604
Epoch=082, loss=0.0663
Epoch=083, loss=0.0532
Epoch=084, loss=0.0594
Epoch=085, loss=0.0641
Epoch=086, loss=0.0577
Epoch=087, loss=0.0477
Epoch=088, loss=0.0611
Epoch=089, loss=0.0502
Epoch=090, loss=0.0503
Epoch=091, loss=0.0582
Epoch=092, loss=0.0529
Epoch=093, loss=0.0558
Epoch=094, loss=0.0641
Epoch=095, loss=0.0468
Epoch=096, loss=0.0378
Epoch=097, loss=0.0443
Epoch=098, loss=0.0609
Epoch=099, loss=0.0550
Epoch=100, loss=0.0472
Epoch=101, loss=0.0583
Epoch=102, loss=0.0427
Epoch=103, loss=0.0359
Epoch=104, loss=0.0385
Epoch=105, loss=0.0512
Epoch=106, loss=0.0443
Epoch=107, loss=0.0414
Epoch=108, loss=0.0458
Epoch=109, loss=0.0431
Epoch=110, loss=0.0407
Epoch=111, loss=0.0432
Epoch=112, loss=0.0381
Epoch=113, loss=0.0411
Epoch=114, loss=0.0397
Epoch=115, loss=0.0395
Epoch=116, loss=0.0399
Epoch=117, loss=0.0451
Epoch=118, loss=0.0463
Epoch=119, loss=0.0383
Epoch=120, loss=0.0292
Epoch=121, loss=0.0331
Epoch=122, loss=0.0360
Epoch=123, loss=0.0320
Epoch=124, loss=0.0304
Epoch=125, loss=0.0338
Epoch=126, loss=0.0409
Epoch=127, loss=0.0325
Epoch=128, loss=0.0332
Epoch=129, loss=0.0291
Epoch=130, loss=0.0336
Epoch=131, loss=0.0342
Epoch=132, loss=0.0305
Epoch=133, loss=0.0322
Epoch=134, loss=0.0284
Epoch=135, loss=0.0347
Epoch=136, loss=0.0329
Epoch=137, loss=0.0391
Epoch=138, loss=0.0332
Epoch=139, loss=0.0291
Epoch=140, loss=0.0366
Epoch=141, loss=0.0294
Epoch=142, loss=0.0249
Epoch=143, loss=0.0389
Epoch=144, loss=0.0331
Epoch=145, loss=0.0432
Epoch=146, loss=0.0372
Epoch=147, loss=0.0278
Epoch=148, loss=0.0387
Epoch=149, loss=0.0190
Epoch=150, loss=0.0295
Epoch=151, loss=0.0280
Epoch=152, loss=0.0219
Epoch=153, loss=0.0245
Epoch=154, loss=0.0298
Epoch=155, loss=0.0212
Epoch=156, loss=0.0335
Epoch=157, loss=0.0198
Epoch=158, loss=0.0272
Epoch=159, loss=0.0242
Epoch=160, loss=0.0269
Epoch=161, loss=0.0332
Epoch=162, loss=0.0225
Epoch=163, loss=0.0222
Epoch=164, loss=0.0292
Epoch=165, loss=0.0243
Epoch=166, loss=0.0251
Epoch=167, loss=0.0190
Epoch=168, loss=0.0209
Epoch=169, loss=0.0241
Epoch=170, loss=0.0283
Epoch=171, loss=0.0236
Epoch=172, loss=0.0344
Epoch=173, loss=0.0268
Epoch=174, loss=0.0243
Epoch=175, loss=0.0220
Epoch=176, loss=0.0306
Epoch=177, loss=0.0198
Epoch=178, loss=0.0216
Epoch=179, loss=0.0179
Epoch=180, loss=0.0191
Epoch=181, loss=0.0206
Epoch=182, loss=0.0198
Epoch=183, loss=0.0170
Epoch=184, loss=0.0264
Epoch=185, loss=0.0166
Epoch=186, loss=0.0228
Epoch=187, loss=0.0190
Epoch=188, loss=0.0216
Epoch=189, loss=0.0213
Epoch=190, loss=0.0244
Epoch=191, loss=0.0138
Epoch=192, loss=0.0187
Epoch=193, loss=0.0186
Epoch=194, loss=0.0148
Epoch=195, loss=0.0193
Epoch=196, loss=0.0151
Epoch=197, loss=0.0212
Epoch=198, loss=0.0148
Epoch=199, loss=0.0208
Epoch=200, loss=0.0188
Epoch=201, loss=0.0109
Epoch=202, loss=0.0083
Epoch=203, loss=0.0209
Epoch=204, loss=0.0235
Epoch=205, loss=0.0206
Epoch=206, loss=0.0122
Epoch=207, loss=0.0247
Epoch=208, loss=0.0181
Epoch=209, loss=0.0271
Epoch=210, loss=0.0221
Epoch=211, loss=0.0206
Epoch=212, loss=0.0245
Epoch=213, loss=0.0147
Epoch=214, loss=0.0092
Epoch=215, loss=0.0190
Epoch=216, loss=0.0128
Epoch=217, loss=0.0109
Epoch=218, loss=0.0136
Epoch=219, loss=0.0167
Epoch=220, loss=0.0139
Epoch=221, loss=0.0107
Epoch=222, loss=0.0160
Early stopping!
Loading 202th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8017+-0.0121, F1Ma=0.7787+-0.0191, acc=0.8017+-0.0121
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7406136605914446, 0.7557005618857826, 0.7479665429249376, 0.7646731834599356, 0.8357142806053162, 0.7379999756813049, 0.7490328550338745, 0.8285714387893677, 0.7360000014305115, 0.75, 0.7703070345899728, 0.003768114929977733, 0.7501466989028345, 0.005368346347229234, 0.7703070345899727, 0.0037681149299777198], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7841551773237248, 0.7833132717286768, 0.7979865264340419, 0.796547786301411, 0.8571428656578064, 0.7919999957084656, 0.7722437381744385, 0.8500000238418579, 0.7879999876022339, 0.7693423628807068, 0.7845316750874465, 0.01493675790927936, 0.7612918249982277, 0.018875132868058274, 0.7845316750874465, 0.014936757909279369], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7932253388715719, 0.7968518080598719, 0.8146628547973025, 0.8170599211159619, 0.8642857074737549, 0.800000011920929, 0.7620889544487, 0.8642857074737549, 0.800000011920929, 0.761605441570282, 0.7988340458608627, 0.015243063681934262, 0.7761681825626688, 0.018292998073328123, 0.7988340458608627, 0.015243063681934262], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7450525376047356, 0.7513937052406279, 0.7503069539011051, 0.7590781044776795, 0.9285714030265808, 0.7979999780654907, 0.7983558773994446, 0.9285714030265808, 0.7979999780654907, 0.7998065948486328, 0.8017100660707346, 0.012105476698047579, 0.7786529662131652, 0.019129072169908033, 0.8017100660707346, 0.012105476698047563]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6908
Epoch=002, loss=0.6860
Epoch=003, loss=0.6753
Epoch=004, loss=0.6677
Epoch=005, loss=0.6521
Epoch=006, loss=0.6379
Epoch=007, loss=0.6261
Epoch=008, loss=0.5984
Epoch=009, loss=0.5766
Epoch=010, loss=0.5607
Epoch=011, loss=0.5325
Epoch=012, loss=0.4911
Epoch=013, loss=0.4772
Epoch=014, loss=0.4502
Epoch=015, loss=0.3872
Epoch=016, loss=0.3836
Epoch=017, loss=0.3642
Epoch=018, loss=0.3114
Epoch=019, loss=0.2784
Epoch=020, loss=0.2827
Epoch=021, loss=0.2512
Epoch=022, loss=0.2252
Epoch=023, loss=0.2155
Epoch=024, loss=0.1999
Epoch=025, loss=0.1960
Epoch=026, loss=0.1812
Epoch=027, loss=0.1508
Epoch=028, loss=0.1523
Epoch=029, loss=0.1358
Epoch=030, loss=0.1256
Epoch=031, loss=0.1136
Epoch=032, loss=0.1002
Epoch=033, loss=0.0976
Epoch=034, loss=0.1085
Epoch=035, loss=0.0869
Epoch=036, loss=0.0790
Epoch=037, loss=0.0757
Epoch=038, loss=0.0825
Epoch=039, loss=0.0665
Epoch=040, loss=0.0698
Epoch=041, loss=0.0604
Epoch=042, loss=0.0535
Epoch=043, loss=0.0585
Epoch=044, loss=0.0508
Epoch=045, loss=0.0554
Epoch=046, loss=0.0477
Epoch=047, loss=0.0423
Epoch=048, loss=0.0456
Epoch=049, loss=0.0393
Epoch=050, loss=0.0402
Epoch=051, loss=0.0377
Epoch=052, loss=0.0426
Epoch=053, loss=0.0337
Epoch=054, loss=0.0304
Epoch=055, loss=0.0349
Epoch=056, loss=0.0368
Epoch=057, loss=0.0317
Epoch=058, loss=0.0370
Epoch=059, loss=0.0270
Epoch=060, loss=0.0240
Epoch=061, loss=0.0223
Epoch=062, loss=0.0241
Epoch=063, loss=0.0231
Epoch=064, loss=0.0248
Epoch=065, loss=0.0226
Epoch=066, loss=0.0216
Epoch=067, loss=0.0212
Epoch=068, loss=0.0218
Epoch=069, loss=0.0213
Epoch=070, loss=0.0180
Epoch=071, loss=0.0174
Epoch=072, loss=0.0122
Epoch=073, loss=0.0164
Epoch=074, loss=0.0133
Epoch=075, loss=0.0183
Epoch=076, loss=0.0207
Epoch=077, loss=0.0194
Epoch=078, loss=0.0224
Epoch=079, loss=0.0121
Epoch=080, loss=0.0156
Epoch=081, loss=0.0175
Epoch=082, loss=0.0108
Epoch=083, loss=0.0161
Epoch=084, loss=0.0178
Epoch=085, loss=0.0154
Epoch=086, loss=0.0157
Epoch=087, loss=0.0142
Epoch=088, loss=0.0140
Epoch=089, loss=0.0137
Epoch=090, loss=0.0130
Epoch=091, loss=0.0130
Epoch=092, loss=0.0116
Epoch=093, loss=0.0116
Epoch=094, loss=0.0129
Epoch=095, loss=0.0137
Epoch=096, loss=0.0102
Epoch=097, loss=0.0104
Epoch=098, loss=0.0107
Epoch=099, loss=0.0096
Epoch=100, loss=0.0177
Epoch=101, loss=0.0089
Epoch=102, loss=0.0140
Epoch=103, loss=0.0086
Epoch=104, loss=0.0068
Epoch=105, loss=0.0125
Epoch=106, loss=0.0084
Epoch=107, loss=0.0093
Epoch=108, loss=0.0106
Epoch=109, loss=0.0066
Epoch=110, loss=0.0066
Epoch=111, loss=0.0128
Epoch=112, loss=0.0116
Epoch=113, loss=0.0088
Epoch=114, loss=0.0083
Epoch=115, loss=0.0056
Epoch=116, loss=0.0088
Epoch=117, loss=0.0146
Epoch=118, loss=0.0080
Epoch=119, loss=0.0090
Epoch=120, loss=0.0080
Epoch=121, loss=0.0117
Epoch=122, loss=0.0068
Epoch=123, loss=0.0068
Epoch=124, loss=0.0035
Epoch=125, loss=0.0072
Epoch=126, loss=0.0112
Epoch=127, loss=0.0077
Epoch=128, loss=0.0092
Epoch=129, loss=0.0100
Epoch=130, loss=0.0115
Epoch=131, loss=0.0098
Epoch=132, loss=0.0088
Epoch=133, loss=0.0046
Epoch=134, loss=0.0030
Epoch=135, loss=0.0049
Epoch=136, loss=0.0060
Epoch=137, loss=0.0104
Epoch=138, loss=0.0097
Epoch=139, loss=0.0047
Epoch=140, loss=0.0040
Epoch=141, loss=0.0105
Epoch=142, loss=0.0052
Epoch=143, loss=0.0045
Epoch=144, loss=0.0028
Epoch=145, loss=0.0117
Epoch=146, loss=0.0057
Epoch=147, loss=0.0038
Epoch=148, loss=0.0064
Epoch=149, loss=0.0055
Epoch=150, loss=0.0050
Epoch=151, loss=0.0037
Epoch=152, loss=0.0027
Epoch=153, loss=0.0069
Epoch=154, loss=0.0109
Epoch=155, loss=0.0045
Epoch=156, loss=0.0031
Epoch=157, loss=0.0083
Epoch=158, loss=0.0044
Epoch=159, loss=0.0020
Epoch=160, loss=0.0055
Epoch=161, loss=0.0040
Epoch=162, loss=0.0033
Epoch=163, loss=0.0024
Epoch=164, loss=0.0041
Epoch=165, loss=0.0086
Epoch=166, loss=0.0064
Epoch=167, loss=0.0060
Epoch=168, loss=0.0024
Epoch=169, loss=0.0065
Epoch=170, loss=0.0064
Epoch=171, loss=0.0078
Epoch=172, loss=0.0060
Epoch=173, loss=0.0030
Epoch=174, loss=0.0059
Epoch=175, loss=0.0027
Epoch=176, loss=0.0051
Epoch=177, loss=0.0034
Epoch=178, loss=0.0063
Epoch=179, loss=0.0058
Early stopping!
Loading 159th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8180+-0.0124, F1Ma=0.8016+-0.0162, acc=0.8180+-0.0124
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7503714351362, 0.7658283890188521, 0.7550921941892995, 0.7783976847457192, 0.7857142686843872, 0.7020000219345093, 0.7011605501174927, 0.7785714268684387, 0.7039999961853027, 0.7059961557388306, 0.7624562767197823, 0.009476720189119738, 0.7154385068271771, 0.018398139958308832, 0.7624562767197823, 0.009476720189119738], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7406136605914446, 0.7557005618857826, 0.7479665429249376, 0.7646731834599356, 0.8357142806053162, 0.7379999756813049, 0.7490328550338745, 0.8285714387893677, 0.7360000014305115, 0.75, 0.7703070345899728, 0.003768114929977733, 0.7501466989028345, 0.005368346347229234, 0.7703070345899727, 0.0037681149299777198], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7841551773237248, 0.7833132717286768, 0.7979865264340419, 0.796547786301411, 0.8571428656578064, 0.7919999957084656, 0.7722437381744385, 0.8500000238418579, 0.7879999876022339, 0.7693423628807068, 0.7845316750874465, 0.01493675790927936, 0.7612918249982277, 0.018875132868058274, 0.7845316750874465, 0.014936757909279369], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7932253388715719, 0.7968518080598719, 0.8146628547973025, 0.8170599211159619, 0.8642857074737549, 0.800000011920929, 0.7620889544487, 0.8642857074737549, 0.800000011920929, 0.761605441570282, 0.7988340458608627, 0.015243063681934262, 0.7761681825626688, 0.018292998073328123, 0.7988340458608627, 0.015243063681934262], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7450525376047356, 0.7513937052406279, 0.7503069539011051, 0.7590781044776795, 0.9285714030265808, 0.7979999780654907, 0.7983558773994446, 0.9285714030265808, 0.7979999780654907, 0.7998065948486328, 0.8017100660707346, 0.012105476698047579, 0.7786529662131652, 0.019129072169908033, 0.8017100660707346, 0.012105476698047563], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8926663914228793, 0.8822553906123767, 0.8976160213733532, 0.8900371675809283, 0.9285714030265808, 0.8059999942779541, 0.7814313173294067, 0.9285714030265808, 0.8059999942779541, 0.7809478044509888, 0.8179556937427128, 0.012418856015839315, 0.8015513194484913, 0.016194149372536538, 0.8179556937427128, 0.012418856015839287]]
