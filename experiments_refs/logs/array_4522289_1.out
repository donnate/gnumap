My SLURM_ARRAY_TASK_ID:  1
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_1
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_1.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6928
Epoch=007, loss=0.6927
Epoch=008, loss=0.6927
Epoch=009, loss=0.6926
Epoch=010, loss=0.6925
Epoch=011, loss=0.6925
Epoch=012, loss=0.6923
Epoch=013, loss=0.6923
Epoch=014, loss=0.6922
Epoch=015, loss=0.6921
Epoch=016, loss=0.6920
Epoch=017, loss=0.6919
Epoch=018, loss=0.6918
Epoch=019, loss=0.6916
Epoch=020, loss=0.6915
Epoch=021, loss=0.6914
Epoch=022, loss=0.6912
Epoch=023, loss=0.6910
Epoch=024, loss=0.6908
Epoch=025, loss=0.6907
Epoch=026, loss=0.6905
Epoch=027, loss=0.6903
Epoch=028, loss=0.6901
Epoch=029, loss=0.6898
Epoch=030, loss=0.6896
Epoch=031, loss=0.6893
Epoch=032, loss=0.6890
Epoch=033, loss=0.6889
Epoch=034, loss=0.6885
Epoch=035, loss=0.6882
Epoch=036, loss=0.6879
Epoch=037, loss=0.6874
Epoch=038, loss=0.6870
Epoch=039, loss=0.6867
Epoch=040, loss=0.6863
Epoch=041, loss=0.6859
Epoch=042, loss=0.6854
Epoch=043, loss=0.6850
Epoch=044, loss=0.6844
Epoch=045, loss=0.6839
Epoch=046, loss=0.6833
Epoch=047, loss=0.6829
Epoch=048, loss=0.6820
Epoch=049, loss=0.6816
Epoch=050, loss=0.6807
Epoch=051, loss=0.6802
Epoch=052, loss=0.6796
Epoch=053, loss=0.6790
Epoch=054, loss=0.6778
Epoch=055, loss=0.6771
Epoch=056, loss=0.6765
Epoch=057, loss=0.6755
Epoch=058, loss=0.6745
Epoch=059, loss=0.6738
Epoch=060, loss=0.6720
Epoch=061, loss=0.6715
Epoch=062, loss=0.6707
Epoch=063, loss=0.6693
Epoch=064, loss=0.6679
Epoch=065, loss=0.6673
Epoch=066, loss=0.6662
Epoch=067, loss=0.6647
Epoch=068, loss=0.6634
Epoch=069, loss=0.6620
Epoch=070, loss=0.6606
Epoch=071, loss=0.6594
Epoch=072, loss=0.6575
Epoch=073, loss=0.6561
Epoch=074, loss=0.6541
Epoch=075, loss=0.6531
Epoch=076, loss=0.6516
Epoch=077, loss=0.6499
Epoch=078, loss=0.6480
Epoch=079, loss=0.6462
Epoch=080, loss=0.6444
Epoch=081, loss=0.6420
Epoch=082, loss=0.6398
Epoch=083, loss=0.6389
Epoch=084, loss=0.6367
Epoch=085, loss=0.6336
Epoch=086, loss=0.6313
Epoch=087, loss=0.6303
Epoch=088, loss=0.6267
Epoch=089, loss=0.6260
Epoch=090, loss=0.6231
Epoch=091, loss=0.6205
Epoch=092, loss=0.6191
Epoch=093, loss=0.6154
Epoch=094, loss=0.6119
Epoch=095, loss=0.6094
Epoch=096, loss=0.6069
Epoch=097, loss=0.6041
Epoch=098, loss=0.6009
Epoch=099, loss=0.5983
Epoch=100, loss=0.5967
Epoch=101, loss=0.5929
Epoch=102, loss=0.5893
Epoch=103, loss=0.5868
Epoch=104, loss=0.5830
Epoch=105, loss=0.5805
Epoch=106, loss=0.5767
Epoch=107, loss=0.5749
Epoch=108, loss=0.5718
Epoch=109, loss=0.5657
Epoch=110, loss=0.5645
Epoch=111, loss=0.5597
Epoch=112, loss=0.5573
Epoch=113, loss=0.5515
Epoch=114, loss=0.5514
Epoch=115, loss=0.5463
Epoch=116, loss=0.5435
Epoch=117, loss=0.5410
Epoch=118, loss=0.5355
Epoch=119, loss=0.5302
Epoch=120, loss=0.5292
Epoch=121, loss=0.5255
Epoch=122, loss=0.5220
Epoch=123, loss=0.5153
Epoch=124, loss=0.5100
Epoch=125, loss=0.5127
Epoch=126, loss=0.5059
Epoch=127, loss=0.5024
Epoch=128, loss=0.4938
Epoch=129, loss=0.4932
Epoch=130, loss=0.4879
Epoch=131, loss=0.4839
Epoch=132, loss=0.4807
Epoch=133, loss=0.4788
Epoch=134, loss=0.4735
Epoch=135, loss=0.4680
Epoch=136, loss=0.4607
Epoch=137, loss=0.4612
Epoch=138, loss=0.4599
Epoch=139, loss=0.4507
Epoch=140, loss=0.4478
Epoch=141, loss=0.4433
Epoch=142, loss=0.4426
Epoch=143, loss=0.4362
Epoch=144, loss=0.4300
Epoch=145, loss=0.4274
Epoch=146, loss=0.4214
Epoch=147, loss=0.4189
Epoch=148, loss=0.4162
Epoch=149, loss=0.4129
Epoch=150, loss=0.4079
Epoch=151, loss=0.3977
Epoch=152, loss=0.4002
Epoch=153, loss=0.3920
Epoch=154, loss=0.3880
Epoch=155, loss=0.3872
Epoch=156, loss=0.3883
Epoch=157, loss=0.3794
Epoch=158, loss=0.3763
Epoch=159, loss=0.3746
Epoch=160, loss=0.3682
Epoch=161, loss=0.3586
Epoch=162, loss=0.3618
Epoch=163, loss=0.3543
Epoch=164, loss=0.3504
Epoch=165, loss=0.3494
Epoch=166, loss=0.3430
Epoch=167, loss=0.3383
Epoch=168, loss=0.3362
Epoch=169, loss=0.3352
Epoch=170, loss=0.3324
Epoch=171, loss=0.3281
Epoch=172, loss=0.3217
Epoch=173, loss=0.3204
Epoch=174, loss=0.3149
Epoch=175, loss=0.3077
Epoch=176, loss=0.3098
Epoch=177, loss=0.3068
Epoch=178, loss=0.3007
Epoch=179, loss=0.2953
Epoch=180, loss=0.3017
Epoch=181, loss=0.2930
Epoch=182, loss=0.2908
Epoch=183, loss=0.2848
Epoch=184, loss=0.2835
Epoch=185, loss=0.2804
Epoch=186, loss=0.2763
Epoch=187, loss=0.2789
Epoch=188, loss=0.2741
Epoch=189, loss=0.2664
Epoch=190, loss=0.2678
Epoch=191, loss=0.2626
Epoch=192, loss=0.2575
Epoch=193, loss=0.2609
Epoch=194, loss=0.2553
Epoch=195, loss=0.2512
Epoch=196, loss=0.2532
Epoch=197, loss=0.2450
Epoch=198, loss=0.2374
Epoch=199, loss=0.2449
Epoch=200, loss=0.2414
Epoch=201, loss=0.2317
Epoch=202, loss=0.2345
Epoch=203, loss=0.2281
Epoch=204, loss=0.2263
Epoch=205, loss=0.2383
Epoch=206, loss=0.2246
Epoch=207, loss=0.2277
Epoch=208, loss=0.2242
Epoch=209, loss=0.2225
Epoch=210, loss=0.2208
Epoch=211, loss=0.2152
Epoch=212, loss=0.2141
Epoch=213, loss=0.2188
Epoch=214, loss=0.2132
Epoch=215, loss=0.2092
Epoch=216, loss=0.2019
Epoch=217, loss=0.1993
Epoch=218, loss=0.2047
Epoch=219, loss=0.2014
Epoch=220, loss=0.2058
Epoch=221, loss=0.2000
Epoch=222, loss=0.1947
Epoch=223, loss=0.1946
Epoch=224, loss=0.1955
Epoch=225, loss=0.1966
Epoch=226, loss=0.1925
Epoch=227, loss=0.1875
Epoch=228, loss=0.1801
Epoch=229, loss=0.1986
Epoch=230, loss=0.1818
Epoch=231, loss=0.1829
Epoch=232, loss=0.1815
Epoch=233, loss=0.1756
Epoch=234, loss=0.1755
Epoch=235, loss=0.1752
Epoch=236, loss=0.1747
Epoch=237, loss=0.1659
Epoch=238, loss=0.1740
Epoch=239, loss=0.1695
Epoch=240, loss=0.1699
Epoch=241, loss=0.1663
Epoch=242, loss=0.1722
Epoch=243, loss=0.1619
Epoch=244, loss=0.1660
Epoch=245, loss=0.1538
Epoch=246, loss=0.1738
Epoch=247, loss=0.1574
Epoch=248, loss=0.1563
Epoch=249, loss=0.1680
Epoch=250, loss=0.1538
Epoch=251, loss=0.1540
Epoch=252, loss=0.1573
Epoch=253, loss=0.1495
Epoch=254, loss=0.1456
Epoch=255, loss=0.1507
Epoch=256, loss=0.1563
Epoch=257, loss=0.1493
Epoch=258, loss=0.1453
Epoch=259, loss=0.1512
Epoch=260, loss=0.1500
Epoch=261, loss=0.1432
Epoch=262, loss=0.1458
Epoch=263, loss=0.1477
Epoch=264, loss=0.1408
Epoch=265, loss=0.1456
Epoch=266, loss=0.1503
Epoch=267, loss=0.1402
Epoch=268, loss=0.1499
Epoch=269, loss=0.1368
Epoch=270, loss=0.1367
Epoch=271, loss=0.1398
Epoch=272, loss=0.1385
Epoch=273, loss=0.1381
Epoch=274, loss=0.1498
Epoch=275, loss=0.1324
Epoch=276, loss=0.1369
Epoch=277, loss=0.1395
Epoch=278, loss=0.1327
Epoch=279, loss=0.1289
Epoch=280, loss=0.1315
Epoch=281, loss=0.1248
Epoch=282, loss=0.1384
Epoch=283, loss=0.1250
Epoch=284, loss=0.1254
Epoch=285, loss=0.1299
Epoch=286, loss=0.1320
Epoch=287, loss=0.1221
Epoch=288, loss=0.1297
Epoch=289, loss=0.1302
Epoch=290, loss=0.1145
Epoch=291, loss=0.1193
Epoch=292, loss=0.1226
Epoch=293, loss=0.1250
Epoch=294, loss=0.1174
Epoch=295, loss=0.1195
Epoch=296, loss=0.1252
Epoch=297, loss=0.1245
Epoch=298, loss=0.1178
Epoch=299, loss=0.1337
Epoch=300, loss=0.1169
Epoch=301, loss=0.1227
Epoch=302, loss=0.1265
Epoch=303, loss=0.1176
Epoch=304, loss=0.1161
Epoch=305, loss=0.1092
Epoch=306, loss=0.1117
Epoch=307, loss=0.1037
Epoch=308, loss=0.1069
Epoch=309, loss=0.1183
Epoch=310, loss=0.1101
Epoch=311, loss=0.1000
Epoch=312, loss=0.1121
Epoch=313, loss=0.1090
Epoch=314, loss=0.1199
Epoch=315, loss=0.1118
Epoch=316, loss=0.1144
Epoch=317, loss=0.1081
Epoch=318, loss=0.1057
Epoch=319, loss=0.1036
Epoch=320, loss=0.1054
Epoch=321, loss=0.1082
Epoch=322, loss=0.1083
Epoch=323, loss=0.1082
Epoch=324, loss=0.1074
Epoch=325, loss=0.0998
Epoch=326, loss=0.1081
Epoch=327, loss=0.1139
Epoch=328, loss=0.1085
Epoch=329, loss=0.0990
Epoch=330, loss=0.1072
Epoch=331, loss=0.0973
Epoch=332, loss=0.0990
Epoch=333, loss=0.0905
Epoch=334, loss=0.0980
Epoch=335, loss=0.0965
Epoch=336, loss=0.0966
Epoch=337, loss=0.1005
Epoch=338, loss=0.0949
Epoch=339, loss=0.1067
Epoch=340, loss=0.0973
Epoch=341, loss=0.1051
Epoch=342, loss=0.1024
Epoch=343, loss=0.0909
Epoch=344, loss=0.1060
Epoch=345, loss=0.0939
Epoch=346, loss=0.0880
Epoch=347, loss=0.0972
Epoch=348, loss=0.0917
Epoch=349, loss=0.1067
Epoch=350, loss=0.0925
Epoch=351, loss=0.0971
Epoch=352, loss=0.0975
Epoch=353, loss=0.0922
Epoch=354, loss=0.0929
Epoch=355, loss=0.0876
Epoch=356, loss=0.0896
Epoch=357, loss=0.0973
Epoch=358, loss=0.0877
Epoch=359, loss=0.0856
Epoch=360, loss=0.0862
Epoch=361, loss=0.0989
Epoch=362, loss=0.0871
Epoch=363, loss=0.0909
Epoch=364, loss=0.0890
Epoch=365, loss=0.1014
Epoch=366, loss=0.0979
Epoch=367, loss=0.0884
Epoch=368, loss=0.0840
Epoch=369, loss=0.0899
Epoch=370, loss=0.0896
Epoch=371, loss=0.0943
Epoch=372, loss=0.1016
Epoch=373, loss=0.0876
Epoch=374, loss=0.0935
Epoch=375, loss=0.0884
Epoch=376, loss=0.0879
Epoch=377, loss=0.0875
Epoch=378, loss=0.0834
Epoch=379, loss=0.0842
Epoch=380, loss=0.0896
Epoch=381, loss=0.0938
Epoch=382, loss=0.0786
Epoch=383, loss=0.0829
Epoch=384, loss=0.0839
Epoch=385, loss=0.0849
Epoch=386, loss=0.0813
Epoch=387, loss=0.0788
Epoch=388, loss=0.0814
Epoch=389, loss=0.0810
Epoch=390, loss=0.0748
Epoch=391, loss=0.0823
Epoch=392, loss=0.0845
Epoch=393, loss=0.0869
Epoch=394, loss=0.0774
Epoch=395, loss=0.0877
Epoch=396, loss=0.0808
Epoch=397, loss=0.0803
Epoch=398, loss=0.0857
Epoch=399, loss=0.0753
Epoch=400, loss=0.0786
Epoch=401, loss=0.0961
Epoch=402, loss=0.0858
Epoch=403, loss=0.0769
Epoch=404, loss=0.0845
Epoch=405, loss=0.0793
Epoch=406, loss=0.0903
Epoch=407, loss=0.0916
Epoch=408, loss=0.0775
Epoch=409, loss=0.0798
Epoch=410, loss=0.0862
Early stopping!
Loading 390th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7299+-0.0217, F1Ma=0.6706+-0.0379, acc=0.7299+-0.0217
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6927
Epoch=009, loss=0.6926
Epoch=010, loss=0.6925
Epoch=011, loss=0.6924
Epoch=012, loss=0.6923
Epoch=013, loss=0.6922
Epoch=014, loss=0.6920
Epoch=015, loss=0.6919
Epoch=016, loss=0.6917
Epoch=017, loss=0.6915
Epoch=018, loss=0.6912
Epoch=019, loss=0.6910
Epoch=020, loss=0.6907
Epoch=021, loss=0.6904
Epoch=022, loss=0.6900
Epoch=023, loss=0.6897
Epoch=024, loss=0.6892
Epoch=025, loss=0.6888
Epoch=026, loss=0.6883
Epoch=027, loss=0.6877
Epoch=028, loss=0.6872
Epoch=029, loss=0.6865
Epoch=030, loss=0.6859
Epoch=031, loss=0.6851
Epoch=032, loss=0.6842
Epoch=033, loss=0.6834
Epoch=034, loss=0.6821
Epoch=035, loss=0.6812
Epoch=036, loss=0.6800
Epoch=037, loss=0.6789
Epoch=038, loss=0.6778
Epoch=039, loss=0.6762
Epoch=040, loss=0.6744
Epoch=041, loss=0.6725
Epoch=042, loss=0.6714
Epoch=043, loss=0.6693
Epoch=044, loss=0.6675
Epoch=045, loss=0.6656
Epoch=046, loss=0.6631
Epoch=047, loss=0.6610
Epoch=048, loss=0.6584
Epoch=049, loss=0.6558
Epoch=050, loss=0.6530
Epoch=051, loss=0.6501
Epoch=052, loss=0.6465
Epoch=053, loss=0.6435
Epoch=054, loss=0.6406
Epoch=055, loss=0.6368
Epoch=056, loss=0.6336
Epoch=057, loss=0.6298
Epoch=058, loss=0.6255
Epoch=059, loss=0.6223
Epoch=060, loss=0.6177
Epoch=061, loss=0.6133
Epoch=062, loss=0.6088
Epoch=063, loss=0.6038
Epoch=064, loss=0.5993
Epoch=065, loss=0.5934
Epoch=066, loss=0.5868
Epoch=067, loss=0.5851
Epoch=068, loss=0.5784
Epoch=069, loss=0.5714
Epoch=070, loss=0.5669
Epoch=071, loss=0.5583
Epoch=072, loss=0.5551
Epoch=073, loss=0.5469
Epoch=074, loss=0.5447
Epoch=075, loss=0.5338
Epoch=076, loss=0.5253
Epoch=077, loss=0.5219
Epoch=078, loss=0.5143
Epoch=079, loss=0.5055
Epoch=080, loss=0.5004
Epoch=081, loss=0.4934
Epoch=082, loss=0.4862
Epoch=083, loss=0.4770
Epoch=084, loss=0.4707
Epoch=085, loss=0.4656
Epoch=086, loss=0.4560
Epoch=087, loss=0.4516
Epoch=088, loss=0.4413
Epoch=089, loss=0.4331
Epoch=090, loss=0.4263
Epoch=091, loss=0.4201
Epoch=092, loss=0.4147
Epoch=093, loss=0.4090
Epoch=094, loss=0.3990
Epoch=095, loss=0.3843
Epoch=096, loss=0.3872
Epoch=097, loss=0.3762
Epoch=098, loss=0.3677
Epoch=099, loss=0.3623
Epoch=100, loss=0.3521
Epoch=101, loss=0.3497
Epoch=102, loss=0.3421
Epoch=103, loss=0.3410
Epoch=104, loss=0.3301
Epoch=105, loss=0.3218
Epoch=106, loss=0.3131
Epoch=107, loss=0.3144
Epoch=108, loss=0.3002
Epoch=109, loss=0.2953
Epoch=110, loss=0.2861
Epoch=111, loss=0.2789
Epoch=112, loss=0.2780
Epoch=113, loss=0.2801
Epoch=114, loss=0.2730
Epoch=115, loss=0.2620
Epoch=116, loss=0.2562
Epoch=117, loss=0.2522
Epoch=118, loss=0.2445
Epoch=119, loss=0.2473
Epoch=120, loss=0.2380
Epoch=121, loss=0.2343
Epoch=122, loss=0.2391
Epoch=123, loss=0.2244
Epoch=124, loss=0.2220
Epoch=125, loss=0.2219
Epoch=126, loss=0.2112
Epoch=127, loss=0.2081
Epoch=128, loss=0.1990
Epoch=129, loss=0.2005
Epoch=130, loss=0.1976
Epoch=131, loss=0.1874
Epoch=132, loss=0.1935
Epoch=133, loss=0.1875
Epoch=134, loss=0.1849
Epoch=135, loss=0.1806
Epoch=136, loss=0.1880
Epoch=137, loss=0.1746
Epoch=138, loss=0.1729
Epoch=139, loss=0.1760
Epoch=140, loss=0.1608
Epoch=141, loss=0.1612
Epoch=142, loss=0.1585
Epoch=143, loss=0.1576
Epoch=144, loss=0.1594
Epoch=145, loss=0.1590
Epoch=146, loss=0.1613
Epoch=147, loss=0.1430
Epoch=148, loss=0.1529
Epoch=149, loss=0.1520
Epoch=150, loss=0.1388
Epoch=151, loss=0.1431
Epoch=152, loss=0.1401
Epoch=153, loss=0.1378
Epoch=154, loss=0.1365
Epoch=155, loss=0.1349
Epoch=156, loss=0.1344
Epoch=157, loss=0.1320
Epoch=158, loss=0.1303
Epoch=159, loss=0.1348
Epoch=160, loss=0.1282
Epoch=161, loss=0.1323
Epoch=162, loss=0.1177
Epoch=163, loss=0.1203
Epoch=164, loss=0.1326
Epoch=165, loss=0.1110
Epoch=166, loss=0.1225
Epoch=167, loss=0.1169
Epoch=168, loss=0.1182
Epoch=169, loss=0.1138
Epoch=170, loss=0.1107
Epoch=171, loss=0.1100
Epoch=172, loss=0.1143
Epoch=173, loss=0.1101
Epoch=174, loss=0.1169
Epoch=175, loss=0.1024
Epoch=176, loss=0.1132
Epoch=177, loss=0.1065
Epoch=178, loss=0.1050
Epoch=179, loss=0.1072
Epoch=180, loss=0.1074
Epoch=181, loss=0.0990
Epoch=182, loss=0.1048
Epoch=183, loss=0.0984
Epoch=184, loss=0.1015
Epoch=185, loss=0.0988
Epoch=186, loss=0.1007
Epoch=187, loss=0.0984
Epoch=188, loss=0.0989
Epoch=189, loss=0.1034
Epoch=190, loss=0.1032
Epoch=191, loss=0.0980
Epoch=192, loss=0.0981
Epoch=193, loss=0.0894
Epoch=194, loss=0.0893
Epoch=195, loss=0.0959
Epoch=196, loss=0.0981
Epoch=197, loss=0.0942
Epoch=198, loss=0.0916
Epoch=199, loss=0.0854
Epoch=200, loss=0.0870
Epoch=201, loss=0.0886
Epoch=202, loss=0.0915
Epoch=203, loss=0.0900
Epoch=204, loss=0.0816
Epoch=205, loss=0.0797
Epoch=206, loss=0.0877
Epoch=207, loss=0.0887
Epoch=208, loss=0.0846
Epoch=209, loss=0.0892
Epoch=210, loss=0.0697
Epoch=211, loss=0.0875
Epoch=212, loss=0.0873
Epoch=213, loss=0.0862
Epoch=214, loss=0.0804
Epoch=215, loss=0.0829
Epoch=216, loss=0.0752
Epoch=217, loss=0.0780
Epoch=218, loss=0.0870
Epoch=219, loss=0.0712
Epoch=220, loss=0.0756
Epoch=221, loss=0.0838
Epoch=222, loss=0.0824
Epoch=223, loss=0.0774
Epoch=224, loss=0.0727
Epoch=225, loss=0.0711
Epoch=226, loss=0.0698
Epoch=227, loss=0.0775
Epoch=228, loss=0.0856
Epoch=229, loss=0.0787
Epoch=230, loss=0.0788
Early stopping!
Loading 210th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7663+-0.0107, F1Ma=0.7300+-0.0155, acc=0.7663+-0.0107
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7748559438359689, 0.7672299145824544, 0.7873718624990549, 0.7813062591274433, 0.8714285492897034, 0.7540000081062317, 0.728723406791687, 0.8857142925262451, 0.7580000162124634, 0.728723406791687, 0.7662650602409639, 0.010699142600726885, 0.7299780622065406, 0.015452996967309495, 0.7662650602409639, 0.010699142600726885]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6923
Epoch=005, loss=0.6920
Epoch=006, loss=0.6916
Epoch=007, loss=0.6911
Epoch=008, loss=0.6907
Epoch=009, loss=0.6900
Epoch=010, loss=0.6893
Epoch=011, loss=0.6885
Epoch=012, loss=0.6876
Epoch=013, loss=0.6864
Epoch=014, loss=0.6851
Epoch=015, loss=0.6838
Epoch=016, loss=0.6820
Epoch=017, loss=0.6803
Epoch=018, loss=0.6786
Epoch=019, loss=0.6761
Epoch=020, loss=0.6737
Epoch=021, loss=0.6710
Epoch=022, loss=0.6680
Epoch=023, loss=0.6645
Epoch=024, loss=0.6608
Epoch=025, loss=0.6572
Epoch=026, loss=0.6524
Epoch=027, loss=0.6480
Epoch=028, loss=0.6433
Epoch=029, loss=0.6372
Epoch=030, loss=0.6317
Epoch=031, loss=0.6250
Epoch=032, loss=0.6181
Epoch=033, loss=0.6112
Epoch=034, loss=0.6044
Epoch=035, loss=0.5958
Epoch=036, loss=0.5878
Epoch=037, loss=0.5790
Epoch=038, loss=0.5686
Epoch=039, loss=0.5591
Epoch=040, loss=0.5488
Epoch=041, loss=0.5401
Epoch=042, loss=0.5277
Epoch=043, loss=0.5143
Epoch=044, loss=0.5049
Epoch=045, loss=0.4910
Epoch=046, loss=0.4766
Epoch=047, loss=0.4728
Epoch=048, loss=0.4535
Epoch=049, loss=0.4457
Epoch=050, loss=0.4306
Epoch=051, loss=0.4182
Epoch=052, loss=0.4076
Epoch=053, loss=0.3936
Epoch=054, loss=0.3788
Epoch=055, loss=0.3653
Epoch=056, loss=0.3557
Epoch=057, loss=0.3388
Epoch=058, loss=0.3350
Epoch=059, loss=0.3116
Epoch=060, loss=0.3052
Epoch=061, loss=0.2919
Epoch=062, loss=0.2882
Epoch=063, loss=0.2666
Epoch=064, loss=0.2596
Epoch=065, loss=0.2495
Epoch=066, loss=0.2459
Epoch=067, loss=0.2345
Epoch=068, loss=0.2213
Epoch=069, loss=0.2190
Epoch=070, loss=0.2123
Epoch=071, loss=0.2066
Epoch=072, loss=0.1938
Epoch=073, loss=0.1848
Epoch=074, loss=0.1921
Epoch=075, loss=0.1790
Epoch=076, loss=0.1786
Epoch=077, loss=0.1618
Epoch=078, loss=0.1715
Epoch=079, loss=0.1559
Epoch=080, loss=0.1486
Epoch=081, loss=0.1515
Epoch=082, loss=0.1488
Epoch=083, loss=0.1399
Epoch=084, loss=0.1451
Epoch=085, loss=0.1353
Epoch=086, loss=0.1220
Epoch=087, loss=0.1277
Epoch=088, loss=0.1248
Epoch=089, loss=0.1252
Epoch=090, loss=0.1128
Epoch=091, loss=0.1232
Epoch=092, loss=0.1179
Epoch=093, loss=0.1140
Epoch=094, loss=0.1294
Epoch=095, loss=0.1091
Epoch=096, loss=0.1039
Epoch=097, loss=0.1117
Epoch=098, loss=0.1047
Epoch=099, loss=0.0983
Epoch=100, loss=0.0993
Epoch=101, loss=0.1066
Epoch=102, loss=0.1010
Epoch=103, loss=0.0916
Epoch=104, loss=0.1056
Epoch=105, loss=0.0955
Epoch=106, loss=0.0835
Epoch=107, loss=0.0917
Epoch=108, loss=0.0913
Epoch=109, loss=0.0800
Epoch=110, loss=0.0794
Epoch=111, loss=0.0881
Epoch=112, loss=0.0772
Epoch=113, loss=0.0879
Epoch=114, loss=0.0826
Epoch=115, loss=0.0870
Epoch=116, loss=0.0780
Epoch=117, loss=0.0787
Epoch=118, loss=0.0794
Epoch=119, loss=0.0825
Epoch=120, loss=0.0697
Epoch=121, loss=0.0759
Epoch=122, loss=0.0755
Epoch=123, loss=0.0805
Epoch=124, loss=0.0686
Epoch=125, loss=0.0818
Epoch=126, loss=0.0770
Epoch=127, loss=0.0725
Epoch=128, loss=0.0728
Epoch=129, loss=0.0649
Epoch=130, loss=0.0667
Epoch=131, loss=0.0726
Epoch=132, loss=0.0786
Epoch=133, loss=0.0665
Epoch=134, loss=0.0676
Epoch=135, loss=0.0755
Epoch=136, loss=0.0572
Epoch=137, loss=0.0647
Epoch=138, loss=0.0767
Epoch=139, loss=0.0740
Epoch=140, loss=0.0650
Epoch=141, loss=0.0691
Epoch=142, loss=0.0834
Epoch=143, loss=0.0673
Epoch=144, loss=0.0654
Epoch=145, loss=0.0628
Epoch=146, loss=0.0870
Epoch=147, loss=0.0619
Epoch=148, loss=0.0616
Epoch=149, loss=0.0656
Epoch=150, loss=0.0861
Epoch=151, loss=0.0646
Epoch=152, loss=0.0517
Epoch=153, loss=0.0623
Epoch=154, loss=0.0569
Epoch=155, loss=0.0588
Epoch=156, loss=0.0559
Epoch=157, loss=0.0653
Epoch=158, loss=0.0502
Epoch=159, loss=0.0598
Epoch=160, loss=0.0414
Epoch=161, loss=0.0494
Epoch=162, loss=0.0572
Epoch=163, loss=0.0637
Epoch=164, loss=0.0556
Epoch=165, loss=0.0504
Epoch=166, loss=0.0522
Epoch=167, loss=0.0546
Epoch=168, loss=0.0504
Epoch=169, loss=0.0635
Epoch=170, loss=0.0540
Epoch=171, loss=0.0469
Epoch=172, loss=0.0625
Epoch=173, loss=0.0630
Epoch=174, loss=0.0471
Epoch=175, loss=0.0430
Epoch=176, loss=0.0605
Epoch=177, loss=0.0532
Epoch=178, loss=0.0543
Epoch=179, loss=0.0456
Epoch=180, loss=0.0505
Early stopping!
Loading 160th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7946+-0.0047, F1Ma=0.7808+-0.0084, acc=0.7946+-0.0047
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7748559438359689, 0.7672299145824544, 0.7873718624990549, 0.7813062591274433, 0.8714285492897034, 0.7540000081062317, 0.728723406791687, 0.8857142925262451, 0.7580000162124634, 0.728723406791687, 0.7662650602409639, 0.010699142600726885, 0.7299780622065406, 0.015452996967309495, 0.7662650602409639, 0.010699142600726885], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7698493020405375, 0.7710581465719396, 0.7749100742090311, 0.7843498828315028, 0.8857142925262451, 0.7979999780654907, 0.790135383605957, 0.8928571343421936, 0.7979999780654907, 0.7877175807952881, 0.794636610959969, 0.004674169103264022, 0.7807909079767287, 0.00836841658519763, 0.794636610959969, 0.004674169103264038]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6927
Epoch=002, loss=0.6922
Epoch=003, loss=0.6914
Epoch=004, loss=0.6904
Epoch=005, loss=0.6891
Epoch=006, loss=0.6874
Epoch=007, loss=0.6854
Epoch=008, loss=0.6831
Epoch=009, loss=0.6796
Epoch=010, loss=0.6762
Epoch=011, loss=0.6723
Epoch=012, loss=0.6672
Epoch=013, loss=0.6616
Epoch=014, loss=0.6550
Epoch=015, loss=0.6476
Epoch=016, loss=0.6398
Epoch=017, loss=0.6300
Epoch=018, loss=0.6194
Epoch=019, loss=0.6078
Epoch=020, loss=0.5950
Epoch=021, loss=0.5832
Epoch=022, loss=0.5669
Epoch=023, loss=0.5498
Epoch=024, loss=0.5321
Epoch=025, loss=0.5118
Epoch=026, loss=0.4972
Epoch=027, loss=0.4754
Epoch=028, loss=0.4571
Epoch=029, loss=0.4319
Epoch=030, loss=0.4137
Epoch=031, loss=0.3955
Epoch=032, loss=0.3723
Epoch=033, loss=0.3626
Epoch=034, loss=0.3324
Epoch=035, loss=0.3173
Epoch=036, loss=0.2942
Epoch=037, loss=0.2803
Epoch=038, loss=0.2603
Epoch=039, loss=0.2469
Epoch=040, loss=0.2419
Epoch=041, loss=0.2201
Epoch=042, loss=0.2032
Epoch=043, loss=0.1895
Epoch=044, loss=0.1738
Epoch=045, loss=0.1696
Epoch=046, loss=0.1666
Epoch=047, loss=0.1566
Epoch=048, loss=0.1504
Epoch=049, loss=0.1331
Epoch=050, loss=0.1453
Epoch=051, loss=0.1268
Epoch=052, loss=0.1246
Epoch=053, loss=0.1050
Epoch=054, loss=0.1134
Epoch=055, loss=0.1066
Epoch=056, loss=0.1156
Epoch=057, loss=0.1065
Epoch=058, loss=0.0945
Epoch=059, loss=0.1075
Epoch=060, loss=0.1066
Epoch=061, loss=0.0971
Epoch=062, loss=0.0891
Epoch=063, loss=0.0962
Epoch=064, loss=0.0937
Epoch=065, loss=0.0773
Epoch=066, loss=0.0739
Epoch=067, loss=0.0864
Epoch=068, loss=0.0838
Epoch=069, loss=0.0773
Epoch=070, loss=0.0739
Epoch=071, loss=0.0766
Epoch=072, loss=0.0776
Epoch=073, loss=0.0737
Epoch=074, loss=0.0758
Epoch=075, loss=0.0686
Epoch=076, loss=0.0641
Epoch=077, loss=0.0789
Epoch=078, loss=0.0708
Epoch=079, loss=0.0656
Epoch=080, loss=0.0677
Epoch=081, loss=0.0631
Epoch=082, loss=0.0662
Epoch=083, loss=0.0771
Epoch=084, loss=0.0649
Epoch=085, loss=0.0611
Epoch=086, loss=0.0638
Epoch=087, loss=0.0509
Epoch=088, loss=0.0678
Epoch=089, loss=0.0666
Epoch=090, loss=0.0600
Epoch=091, loss=0.0579
Epoch=092, loss=0.0635
Epoch=093, loss=0.0684
Epoch=094, loss=0.0551
Epoch=095, loss=0.0708
Epoch=096, loss=0.0564
Epoch=097, loss=0.0512
Epoch=098, loss=0.0522
Epoch=099, loss=0.0592
Epoch=100, loss=0.0615
Epoch=101, loss=0.0739
Epoch=102, loss=0.0485
Epoch=103, loss=0.0721
Epoch=104, loss=0.0532
Epoch=105, loss=0.0452
Epoch=106, loss=0.0439
Epoch=107, loss=0.0615
Epoch=108, loss=0.0464
Epoch=109, loss=0.0516
Epoch=110, loss=0.0499
Epoch=111, loss=0.0525
Epoch=112, loss=0.0396
Epoch=113, loss=0.0549
Epoch=114, loss=0.0475
Epoch=115, loss=0.0485
Epoch=116, loss=0.0384
Epoch=117, loss=0.0440
Epoch=118, loss=0.0449
Epoch=119, loss=0.0326
Epoch=120, loss=0.0519
Epoch=121, loss=0.0465
Epoch=122, loss=0.0513
Epoch=123, loss=0.0448
Epoch=124, loss=0.0402
Epoch=125, loss=0.0429
Epoch=126, loss=0.0481
Epoch=127, loss=0.0509
Epoch=128, loss=0.0517
Epoch=129, loss=0.0360
Epoch=130, loss=0.0413
Epoch=131, loss=0.0480
Epoch=132, loss=0.0449
Epoch=133, loss=0.0460
Epoch=134, loss=0.0398
Epoch=135, loss=0.0503
Epoch=136, loss=0.0452
Epoch=137, loss=0.0431
Epoch=138, loss=0.0429
Epoch=139, loss=0.0396
Early stopping!
Loading 119th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8054+-0.0090, F1Ma=0.7812+-0.0231, acc=0.8054+-0.0090
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7748559438359689, 0.7672299145824544, 0.7873718624990549, 0.7813062591274433, 0.8714285492897034, 0.7540000081062317, 0.728723406791687, 0.8857142925262451, 0.7580000162124634, 0.728723406791687, 0.7662650602409639, 0.010699142600726885, 0.7299780622065406, 0.015452996967309495, 0.7662650602409639, 0.010699142600726885], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7698493020405375, 0.7710581465719396, 0.7749100742090311, 0.7843498828315028, 0.8857142925262451, 0.7979999780654907, 0.790135383605957, 0.8928571343421936, 0.7979999780654907, 0.7877175807952881, 0.794636610959969, 0.004674169103264022, 0.7807909079767287, 0.00836841658519763, 0.794636610959969, 0.004674169103264038], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7656682674893001, 0.7654361170956279, 0.7756157981341523, 0.7763232960027796, 0.8928571343421936, 0.7860000133514404, 0.7620889544487, 0.8714285492897034, 0.7860000133514404, 0.759671151638031, 0.8053633890400309, 0.00895552635102481, 0.7811791170584563, 0.023122045078831775, 0.8053633890400309, 0.008955526351024836]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6920
Epoch=002, loss=0.6897
Epoch=003, loss=0.6867
Epoch=004, loss=0.6825
Epoch=005, loss=0.6773
Epoch=006, loss=0.6682
Epoch=007, loss=0.6597
Epoch=008, loss=0.6496
Epoch=009, loss=0.6344
Epoch=010, loss=0.6192
Epoch=011, loss=0.6025
Epoch=012, loss=0.5835
Epoch=013, loss=0.5595
Epoch=014, loss=0.5348
Epoch=015, loss=0.5068
Epoch=016, loss=0.4773
Epoch=017, loss=0.4578
Epoch=018, loss=0.4289
Epoch=019, loss=0.3916
Epoch=020, loss=0.3756
Epoch=021, loss=0.3498
Epoch=022, loss=0.3271
Epoch=023, loss=0.2878
Epoch=024, loss=0.2794
Epoch=025, loss=0.2632
Epoch=026, loss=0.2429
Epoch=027, loss=0.2409
Epoch=028, loss=0.2204
Epoch=029, loss=0.2217
Epoch=030, loss=0.1778
Epoch=031, loss=0.1756
Epoch=032, loss=0.1823
Epoch=033, loss=0.1415
Epoch=034, loss=0.1570
Epoch=035, loss=0.1391
Epoch=036, loss=0.1452
Epoch=037, loss=0.1252
Epoch=038, loss=0.1175
Epoch=039, loss=0.1333
Epoch=040, loss=0.1068
Epoch=041, loss=0.1112
Epoch=042, loss=0.1093
Epoch=043, loss=0.1162
Epoch=044, loss=0.0886
Epoch=045, loss=0.1036
Epoch=046, loss=0.1058
Epoch=047, loss=0.1053
Epoch=048, loss=0.0947
Epoch=049, loss=0.1020
Epoch=050, loss=0.0957
Epoch=051, loss=0.0992
Epoch=052, loss=0.0944
Epoch=053, loss=0.1075
Epoch=054, loss=0.1084
Epoch=055, loss=0.0904
Epoch=056, loss=0.0867
Epoch=057, loss=0.0820
Epoch=058, loss=0.0940
Epoch=059, loss=0.0959
Epoch=060, loss=0.0835
Epoch=061, loss=0.0911
Epoch=062, loss=0.0823
Epoch=063, loss=0.0709
Epoch=064, loss=0.0798
Epoch=065, loss=0.0942
Epoch=066, loss=0.0667
Epoch=067, loss=0.0763
Epoch=068, loss=0.0745
Epoch=069, loss=0.0802
Epoch=070, loss=0.0642
Epoch=071, loss=0.0570
Epoch=072, loss=0.0784
Epoch=073, loss=0.0650
Epoch=074, loss=0.0705
Epoch=075, loss=0.0638
Epoch=076, loss=0.0784
Epoch=077, loss=0.0678
Epoch=078, loss=0.0578
Epoch=079, loss=0.0649
Epoch=080, loss=0.0583
Epoch=081, loss=0.0608
Epoch=082, loss=0.0533
Epoch=083, loss=0.0668
Epoch=084, loss=0.0643
Epoch=085, loss=0.0661
Epoch=086, loss=0.0763
Epoch=087, loss=0.0577
Epoch=088, loss=0.0697
Epoch=089, loss=0.0631
Epoch=090, loss=0.0657
Epoch=091, loss=0.0551
Epoch=092, loss=0.0638
Epoch=093, loss=0.0567
Epoch=094, loss=0.0476
Epoch=095, loss=0.0607
Epoch=096, loss=0.0615
Epoch=097, loss=0.0615
Epoch=098, loss=0.0590
Epoch=099, loss=0.0558
Epoch=100, loss=0.0692
Epoch=101, loss=0.0535
Epoch=102, loss=0.0591
Epoch=103, loss=0.0482
Epoch=104, loss=0.0513
Epoch=105, loss=0.0504
Epoch=106, loss=0.0522
Epoch=107, loss=0.0450
Epoch=108, loss=0.0499
Epoch=109, loss=0.0479
Epoch=110, loss=0.0407
Epoch=111, loss=0.0477
Epoch=112, loss=0.0428
Epoch=113, loss=0.0383
Epoch=114, loss=0.0485
Epoch=115, loss=0.0414
Epoch=116, loss=0.0476
Epoch=117, loss=0.0495
Epoch=118, loss=0.0463
Epoch=119, loss=0.0421
Epoch=120, loss=0.0590
Epoch=121, loss=0.0427
Epoch=122, loss=0.0375
Epoch=123, loss=0.0394
Epoch=124, loss=0.0525
Epoch=125, loss=0.0329
Epoch=126, loss=0.0433
Epoch=127, loss=0.0374
Epoch=128, loss=0.0493
Epoch=129, loss=0.0388
Epoch=130, loss=0.0391
Epoch=131, loss=0.0427
Epoch=132, loss=0.0457
Epoch=133, loss=0.0315
Epoch=134, loss=0.0260
Epoch=135, loss=0.0632
Epoch=136, loss=0.0380
Epoch=137, loss=0.0320
Epoch=138, loss=0.0319
Epoch=139, loss=0.0411
Epoch=140, loss=0.0487
Epoch=141, loss=0.0433
Epoch=142, loss=0.0327
Epoch=143, loss=0.0541
Epoch=144, loss=0.0634
Epoch=145, loss=0.0463
Epoch=146, loss=0.0389
Epoch=147, loss=0.0396
Epoch=148, loss=0.0549
Epoch=149, loss=0.0386
Epoch=150, loss=0.0418
Epoch=151, loss=0.0384
Epoch=152, loss=0.0592
Epoch=153, loss=0.0393
Epoch=154, loss=0.0381
Early stopping!
Loading 134th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8043+-0.0104, F1Ma=0.7880+-0.0134, acc=0.8043+-0.0104
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7748559438359689, 0.7672299145824544, 0.7873718624990549, 0.7813062591274433, 0.8714285492897034, 0.7540000081062317, 0.728723406791687, 0.8857142925262451, 0.7580000162124634, 0.728723406791687, 0.7662650602409639, 0.010699142600726885, 0.7299780622065406, 0.015452996967309495, 0.7662650602409639, 0.010699142600726885], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7698493020405375, 0.7710581465719396, 0.7749100742090311, 0.7843498828315028, 0.8857142925262451, 0.7979999780654907, 0.790135383605957, 0.8928571343421936, 0.7979999780654907, 0.7877175807952881, 0.794636610959969, 0.004674169103264022, 0.7807909079767287, 0.00836841658519763, 0.794636610959969, 0.004674169103264038], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7656682674893001, 0.7654361170956279, 0.7756157981341523, 0.7763232960027796, 0.8928571343421936, 0.7860000133514404, 0.7620889544487, 0.8714285492897034, 0.7860000133514404, 0.759671151638031, 0.8053633890400309, 0.00895552635102481, 0.7811791170584563, 0.023122045078831775, 0.8053633890400309, 0.008955526351024836], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7978776241496436, 0.7964526457119644, 0.78691638251677, 0.7900659897861533, 0.8999999761581421, 0.7960000038146973, 0.7587040662765503, 0.9214285612106323, 0.7960000038146973, 0.7707930207252502, 0.8042751651768365, 0.010386812647331595, 0.788006231643324, 0.013431109141802263, 0.8042751651768365, 0.010386812647331567]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6915
Epoch=002, loss=0.6868
Epoch=003, loss=0.6772
Epoch=004, loss=0.6714
Epoch=005, loss=0.6553
Epoch=006, loss=0.6427
Epoch=007, loss=0.6298
Epoch=008, loss=0.6011
Epoch=009, loss=0.5859
Epoch=010, loss=0.5729
Epoch=011, loss=0.5304
Epoch=012, loss=0.5063
Epoch=013, loss=0.4873
Epoch=014, loss=0.4401
Epoch=015, loss=0.4009
Epoch=016, loss=0.4005
Epoch=017, loss=0.3594
Epoch=018, loss=0.3050
Epoch=019, loss=0.3110
Epoch=020, loss=0.2913
Epoch=021, loss=0.2556
Epoch=022, loss=0.2190
Epoch=023, loss=0.2144
Epoch=024, loss=0.1886
Epoch=025, loss=0.1684
Epoch=026, loss=0.1674
Epoch=027, loss=0.1488
Epoch=028, loss=0.1492
Epoch=029, loss=0.1295
Epoch=030, loss=0.1263
Epoch=031, loss=0.1102
Epoch=032, loss=0.1071
Epoch=033, loss=0.0996
Epoch=034, loss=0.0934
Epoch=035, loss=0.1025
Epoch=036, loss=0.1157
Epoch=037, loss=0.1026
Epoch=038, loss=0.1191
Epoch=039, loss=0.0686
Epoch=040, loss=0.1097
Epoch=041, loss=0.0666
Epoch=042, loss=0.1176
Epoch=043, loss=0.0700
Epoch=044, loss=0.0787
Epoch=045, loss=0.0622
Epoch=046, loss=0.0584
Epoch=047, loss=0.0706
Epoch=048, loss=0.0557
Epoch=049, loss=0.0561
Epoch=050, loss=0.0511
Epoch=051, loss=0.0403
Epoch=052, loss=0.0497
Epoch=053, loss=0.0403
Epoch=054, loss=0.0375
Epoch=055, loss=0.0444
Epoch=056, loss=0.0336
Epoch=057, loss=0.0472
Epoch=058, loss=0.0386
Epoch=059, loss=0.0315
Epoch=060, loss=0.0308
Epoch=061, loss=0.0306
Epoch=062, loss=0.0234
Epoch=063, loss=0.0252
Epoch=064, loss=0.0316
Epoch=065, loss=0.0297
Epoch=066, loss=0.0210
Epoch=067, loss=0.0230
Epoch=068, loss=0.0235
Epoch=069, loss=0.0239
Epoch=070, loss=0.0258
Epoch=071, loss=0.0209
Epoch=072, loss=0.0320
Epoch=073, loss=0.0234
Epoch=074, loss=0.0132
Epoch=075, loss=0.0328
Epoch=076, loss=0.0222
Epoch=077, loss=0.0234
Epoch=078, loss=0.0172
Epoch=079, loss=0.0176
Epoch=080, loss=0.0215
Epoch=081, loss=0.0205
Epoch=082, loss=0.0251
Epoch=083, loss=0.0256
Epoch=084, loss=0.0199
Epoch=085, loss=0.0128
Epoch=086, loss=0.0249
Epoch=087, loss=0.0141
Epoch=088, loss=0.0101
Epoch=089, loss=0.0142
Epoch=090, loss=0.0171
Epoch=091, loss=0.0161
Epoch=092, loss=0.0184
Epoch=093, loss=0.0158
Epoch=094, loss=0.0167
Epoch=095, loss=0.0128
Epoch=096, loss=0.0218
Epoch=097, loss=0.0124
Epoch=098, loss=0.0082
Epoch=099, loss=0.0099
Epoch=100, loss=0.0134
Epoch=101, loss=0.0081
Epoch=102, loss=0.0114
Epoch=103, loss=0.0082
Epoch=104, loss=0.0099
Epoch=105, loss=0.0079
Epoch=106, loss=0.0129
Epoch=107, loss=0.0108
Epoch=108, loss=0.0078
Epoch=109, loss=0.0092
Epoch=110, loss=0.0056
Epoch=111, loss=0.0054
Epoch=112, loss=0.0165
Epoch=113, loss=0.0069
Epoch=114, loss=0.0067
Epoch=115, loss=0.0061
Epoch=116, loss=0.0063
Epoch=117, loss=0.0099
Epoch=118, loss=0.0102
Epoch=119, loss=0.0087
Epoch=120, loss=0.0086
Epoch=121, loss=0.0081
Epoch=122, loss=0.0067
Epoch=123, loss=0.0108
Epoch=124, loss=0.0049
Epoch=125, loss=0.0067
Epoch=126, loss=0.0112
Epoch=127, loss=0.0058
Epoch=128, loss=0.0053
Epoch=129, loss=0.0077
Epoch=130, loss=0.0056
Epoch=131, loss=0.0125
Epoch=132, loss=0.0076
Epoch=133, loss=0.0095
Epoch=134, loss=0.0101
Epoch=135, loss=0.0064
Epoch=136, loss=0.0085
Epoch=137, loss=0.0077
Epoch=138, loss=0.0058
Epoch=139, loss=0.0057
Epoch=140, loss=0.0077
Epoch=141, loss=0.0084
Epoch=142, loss=0.0043
Epoch=143, loss=0.0070
Epoch=144, loss=0.0034
Epoch=145, loss=0.0063
Epoch=146, loss=0.0070
Epoch=147, loss=0.0098
Epoch=148, loss=0.0071
Epoch=149, loss=0.0083
Epoch=150, loss=0.0048
Epoch=151, loss=0.0062
Epoch=152, loss=0.0041
Epoch=153, loss=0.0061
Epoch=154, loss=0.0036
Epoch=155, loss=0.0038
Epoch=156, loss=0.0039
Epoch=157, loss=0.0028
Epoch=158, loss=0.0022
Epoch=159, loss=0.0028
Epoch=160, loss=0.0064
Epoch=161, loss=0.0065
Epoch=162, loss=0.0029
Epoch=163, loss=0.0032
Epoch=164, loss=0.0038
Epoch=165, loss=0.0122
Epoch=166, loss=0.0034
Epoch=167, loss=0.0043
Epoch=168, loss=0.0026
Epoch=169, loss=0.0046
Epoch=170, loss=0.0037
Epoch=171, loss=0.0059
Epoch=172, loss=0.0040
Epoch=173, loss=0.0028
Epoch=174, loss=0.0032
Epoch=175, loss=0.0035
Epoch=176, loss=0.0047
Epoch=177, loss=0.0060
Epoch=178, loss=0.0035
Early stopping!
Loading 158th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8189+-0.0125, F1Ma=0.8007+-0.0204, acc=0.8189+-0.0125
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7500244760438612, 0.7554412497721005, 0.7598810351097653, 0.7667580309021561, 0.8357142806053162, 0.7540000081062317, 0.7055125832557678, 0.8071428537368774, 0.7519999742507935, 0.7030947804450989, 0.7298872910998835, 0.021725577362802305, 0.6706062064826355, 0.03791658358063721, 0.7298872910998833, 0.02172557736280226], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7748559438359689, 0.7672299145824544, 0.7873718624990549, 0.7813062591274433, 0.8714285492897034, 0.7540000081062317, 0.728723406791687, 0.8857142925262451, 0.7580000162124634, 0.728723406791687, 0.7662650602409639, 0.010699142600726885, 0.7299780622065406, 0.015452996967309495, 0.7662650602409639, 0.010699142600726885], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7698493020405375, 0.7710581465719396, 0.7749100742090311, 0.7843498828315028, 0.8857142925262451, 0.7979999780654907, 0.790135383605957, 0.8928571343421936, 0.7979999780654907, 0.7877175807952881, 0.794636610959969, 0.004674169103264022, 0.7807909079767287, 0.00836841658519763, 0.794636610959969, 0.004674169103264038], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7656682674893001, 0.7654361170956279, 0.7756157981341523, 0.7763232960027796, 0.8928571343421936, 0.7860000133514404, 0.7620889544487, 0.8714285492897034, 0.7860000133514404, 0.759671151638031, 0.8053633890400309, 0.00895552635102481, 0.7811791170584563, 0.023122045078831775, 0.8053633890400309, 0.008955526351024836], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7978776241496436, 0.7964526457119644, 0.78691638251677, 0.7900659897861533, 0.8999999761581421, 0.7960000038146973, 0.7587040662765503, 0.9214285612106323, 0.7960000038146973, 0.7707930207252502, 0.8042751651768365, 0.010386812647331595, 0.788006231643324, 0.013431109141802263, 0.8042751651768365, 0.010386812647331567], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9160243815156918, 0.9068912051520674, 0.9241562818430916, 0.9060786644375384, 0.9428571462631226, 0.8100000023841858, 0.8007736802101135, 0.9428571462631226, 0.8100000023841858, 0.8007736802101135, 0.8188884570540225, 0.012511918762868324, 0.8007387094564964, 0.02035683240306831, 0.8188884570540225, 0.012511918762868324]]
