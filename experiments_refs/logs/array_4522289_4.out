My SLURM_ARRAY_TASK_ID:  4
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_4
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_4.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6927
Epoch=009, loss=0.6927
Epoch=010, loss=0.6926
Epoch=011, loss=0.6925
Epoch=012, loss=0.6925
Epoch=013, loss=0.6924
Epoch=014, loss=0.6923
Epoch=015, loss=0.6923
Epoch=016, loss=0.6921
Epoch=017, loss=0.6920
Epoch=018, loss=0.6919
Epoch=019, loss=0.6918
Epoch=020, loss=0.6916
Epoch=021, loss=0.6915
Epoch=022, loss=0.6913
Epoch=023, loss=0.6912
Epoch=024, loss=0.6910
Epoch=025, loss=0.6908
Epoch=026, loss=0.6906
Epoch=027, loss=0.6904
Epoch=028, loss=0.6902
Epoch=029, loss=0.6899
Epoch=030, loss=0.6897
Epoch=031, loss=0.6894
Epoch=032, loss=0.6891
Epoch=033, loss=0.6888
Epoch=034, loss=0.6885
Epoch=035, loss=0.6881
Epoch=036, loss=0.6879
Epoch=037, loss=0.6874
Epoch=038, loss=0.6871
Epoch=039, loss=0.6867
Epoch=040, loss=0.6863
Epoch=041, loss=0.6859
Epoch=042, loss=0.6855
Epoch=043, loss=0.6848
Epoch=044, loss=0.6844
Epoch=045, loss=0.6839
Epoch=046, loss=0.6833
Epoch=047, loss=0.6826
Epoch=048, loss=0.6820
Epoch=049, loss=0.6813
Epoch=050, loss=0.6807
Epoch=051, loss=0.6800
Epoch=052, loss=0.6795
Epoch=053, loss=0.6787
Epoch=054, loss=0.6777
Epoch=055, loss=0.6773
Epoch=056, loss=0.6763
Epoch=057, loss=0.6752
Epoch=058, loss=0.6744
Epoch=059, loss=0.6733
Epoch=060, loss=0.6724
Epoch=061, loss=0.6715
Epoch=062, loss=0.6703
Epoch=063, loss=0.6693
Epoch=064, loss=0.6681
Epoch=065, loss=0.6668
Epoch=066, loss=0.6661
Epoch=067, loss=0.6648
Epoch=068, loss=0.6632
Epoch=069, loss=0.6617
Epoch=070, loss=0.6606
Epoch=071, loss=0.6589
Epoch=072, loss=0.6578
Epoch=073, loss=0.6560
Epoch=074, loss=0.6547
Epoch=075, loss=0.6535
Epoch=076, loss=0.6507
Epoch=077, loss=0.6506
Epoch=078, loss=0.6477
Epoch=079, loss=0.6458
Epoch=080, loss=0.6449
Epoch=081, loss=0.6426
Epoch=082, loss=0.6398
Epoch=083, loss=0.6387
Epoch=084, loss=0.6375
Epoch=085, loss=0.6351
Epoch=086, loss=0.6335
Epoch=087, loss=0.6305
Epoch=088, loss=0.6277
Epoch=089, loss=0.6251
Epoch=090, loss=0.6240
Epoch=091, loss=0.6223
Epoch=092, loss=0.6208
Epoch=093, loss=0.6171
Epoch=094, loss=0.6146
Epoch=095, loss=0.6125
Epoch=096, loss=0.6086
Epoch=097, loss=0.6065
Epoch=098, loss=0.6055
Epoch=099, loss=0.6015
Epoch=100, loss=0.5995
Epoch=101, loss=0.5976
Epoch=102, loss=0.5943
Epoch=103, loss=0.5899
Epoch=104, loss=0.5868
Epoch=105, loss=0.5836
Epoch=106, loss=0.5816
Epoch=107, loss=0.5819
Epoch=108, loss=0.5781
Epoch=109, loss=0.5723
Epoch=110, loss=0.5702
Epoch=111, loss=0.5677
Epoch=112, loss=0.5628
Epoch=113, loss=0.5619
Epoch=114, loss=0.5559
Epoch=115, loss=0.5558
Epoch=116, loss=0.5526
Epoch=117, loss=0.5489
Epoch=118, loss=0.5430
Epoch=119, loss=0.5408
Epoch=120, loss=0.5369
Epoch=121, loss=0.5373
Epoch=122, loss=0.5304
Epoch=123, loss=0.5291
Epoch=124, loss=0.5218
Epoch=125, loss=0.5199
Epoch=126, loss=0.5155
Epoch=127, loss=0.5156
Epoch=128, loss=0.5105
Epoch=129, loss=0.5059
Epoch=130, loss=0.5046
Epoch=131, loss=0.4976
Epoch=132, loss=0.4959
Epoch=133, loss=0.4902
Epoch=134, loss=0.4871
Epoch=135, loss=0.4830
Epoch=136, loss=0.4797
Epoch=137, loss=0.4785
Epoch=138, loss=0.4676
Epoch=139, loss=0.4689
Epoch=140, loss=0.4665
Epoch=141, loss=0.4626
Epoch=142, loss=0.4554
Epoch=143, loss=0.4528
Epoch=144, loss=0.4512
Epoch=145, loss=0.4496
Epoch=146, loss=0.4421
Epoch=147, loss=0.4423
Epoch=148, loss=0.4414
Epoch=149, loss=0.4369
Epoch=150, loss=0.4253
Epoch=151, loss=0.4238
Epoch=152, loss=0.4235
Epoch=153, loss=0.4169
Epoch=154, loss=0.4173
Epoch=155, loss=0.4167
Epoch=156, loss=0.4080
Epoch=157, loss=0.4061
Epoch=158, loss=0.4008
Epoch=159, loss=0.3970
Epoch=160, loss=0.3907
Epoch=161, loss=0.3920
Epoch=162, loss=0.3882
Epoch=163, loss=0.3775
Epoch=164, loss=0.3833
Epoch=165, loss=0.3772
Epoch=166, loss=0.3819
Epoch=167, loss=0.3710
Epoch=168, loss=0.3714
Epoch=169, loss=0.3690
Epoch=170, loss=0.3586
Epoch=171, loss=0.3566
Epoch=172, loss=0.3547
Epoch=173, loss=0.3545
Epoch=174, loss=0.3514
Epoch=175, loss=0.3440
Epoch=176, loss=0.3518
Epoch=177, loss=0.3494
Epoch=178, loss=0.3367
Epoch=179, loss=0.3360
Epoch=180, loss=0.3345
Epoch=181, loss=0.3182
Epoch=182, loss=0.3217
Epoch=183, loss=0.3226
Epoch=184, loss=0.3183
Epoch=185, loss=0.3205
Epoch=186, loss=0.3128
Epoch=187, loss=0.3090
Epoch=188, loss=0.3095
Epoch=189, loss=0.3036
Epoch=190, loss=0.3039
Epoch=191, loss=0.2991
Epoch=192, loss=0.2934
Epoch=193, loss=0.2922
Epoch=194, loss=0.2920
Epoch=195, loss=0.2924
Epoch=196, loss=0.2856
Epoch=197, loss=0.2797
Epoch=198, loss=0.2765
Epoch=199, loss=0.2823
Epoch=200, loss=0.2786
Epoch=201, loss=0.2805
Epoch=202, loss=0.2738
Epoch=203, loss=0.2742
Epoch=204, loss=0.2749
Epoch=205, loss=0.2652
Epoch=206, loss=0.2594
Epoch=207, loss=0.2700
Epoch=208, loss=0.2612
Epoch=209, loss=0.2593
Epoch=210, loss=0.2537
Epoch=211, loss=0.2548
Epoch=212, loss=0.2583
Epoch=213, loss=0.2511
Epoch=214, loss=0.2511
Epoch=215, loss=0.2502
Epoch=216, loss=0.2454
Epoch=217, loss=0.2427
Epoch=218, loss=0.2452
Epoch=219, loss=0.2307
Epoch=220, loss=0.2400
Epoch=221, loss=0.2425
Epoch=222, loss=0.2350
Epoch=223, loss=0.2347
Epoch=224, loss=0.2330
Epoch=225, loss=0.2363
Epoch=226, loss=0.2217
Epoch=227, loss=0.2183
Epoch=228, loss=0.2205
Epoch=229, loss=0.2181
Epoch=230, loss=0.2204
Epoch=231, loss=0.2200
Epoch=232, loss=0.2152
Epoch=233, loss=0.2143
Epoch=234, loss=0.2130
Epoch=235, loss=0.2159
Epoch=236, loss=0.2062
Epoch=237, loss=0.1950
Epoch=238, loss=0.2017
Epoch=239, loss=0.2012
Epoch=240, loss=0.2072
Epoch=241, loss=0.1999
Epoch=242, loss=0.2013
Epoch=243, loss=0.2009
Epoch=244, loss=0.1935
Epoch=245, loss=0.1983
Epoch=246, loss=0.1974
Epoch=247, loss=0.1946
Epoch=248, loss=0.1903
Epoch=249, loss=0.1993
Epoch=250, loss=0.1880
Epoch=251, loss=0.1944
Epoch=252, loss=0.1880
Epoch=253, loss=0.1841
Epoch=254, loss=0.1927
Epoch=255, loss=0.1988
Epoch=256, loss=0.1877
Epoch=257, loss=0.1936
Epoch=258, loss=0.1841
Epoch=259, loss=0.1888
Epoch=260, loss=0.1776
Epoch=261, loss=0.1710
Epoch=262, loss=0.1755
Epoch=263, loss=0.1841
Epoch=264, loss=0.1828
Epoch=265, loss=0.1772
Epoch=266, loss=0.1725
Epoch=267, loss=0.1729
Epoch=268, loss=0.1731
Epoch=269, loss=0.1744
Epoch=270, loss=0.1757
Epoch=271, loss=0.1708
Epoch=272, loss=0.1644
Epoch=273, loss=0.1694
Epoch=274, loss=0.1681
Epoch=275, loss=0.1648
Epoch=276, loss=0.1635
Epoch=277, loss=0.1795
Epoch=278, loss=0.1592
Epoch=279, loss=0.1577
Epoch=280, loss=0.1602
Epoch=281, loss=0.1542
Epoch=282, loss=0.1643
Epoch=283, loss=0.1585
Epoch=284, loss=0.1642
Epoch=285, loss=0.1642
Epoch=286, loss=0.1607
Epoch=287, loss=0.1599
Epoch=288, loss=0.1653
Epoch=289, loss=0.1524
Epoch=290, loss=0.1550
Epoch=291, loss=0.1551
Epoch=292, loss=0.1622
Epoch=293, loss=0.1441
Epoch=294, loss=0.1545
Epoch=295, loss=0.1503
Epoch=296, loss=0.1467
Epoch=297, loss=0.1502
Epoch=298, loss=0.1432
Epoch=299, loss=0.1455
Epoch=300, loss=0.1454
Epoch=301, loss=0.1541
Epoch=302, loss=0.1421
Epoch=303, loss=0.1436
Epoch=304, loss=0.1459
Epoch=305, loss=0.1448
Epoch=306, loss=0.1439
Epoch=307, loss=0.1429
Epoch=308, loss=0.1450
Epoch=309, loss=0.1532
Epoch=310, loss=0.1339
Epoch=311, loss=0.1416
Epoch=312, loss=0.1331
Epoch=313, loss=0.1381
Epoch=314, loss=0.1281
Epoch=315, loss=0.1411
Epoch=316, loss=0.1359
Epoch=317, loss=0.1465
Epoch=318, loss=0.1371
Epoch=319, loss=0.1400
Epoch=320, loss=0.1455
Epoch=321, loss=0.1316
Epoch=322, loss=0.1322
Epoch=323, loss=0.1381
Epoch=324, loss=0.1316
Epoch=325, loss=0.1286
Epoch=326, loss=0.1328
Epoch=327, loss=0.1238
Epoch=328, loss=0.1249
Epoch=329, loss=0.1318
Epoch=330, loss=0.1321
Epoch=331, loss=0.1288
Epoch=332, loss=0.1299
Epoch=333, loss=0.1333
Epoch=334, loss=0.1182
Epoch=335, loss=0.1261
Epoch=336, loss=0.1262
Epoch=337, loss=0.1392
Epoch=338, loss=0.1166
Epoch=339, loss=0.1344
Epoch=340, loss=0.1256
Epoch=341, loss=0.1235
Epoch=342, loss=0.1179
Epoch=343, loss=0.1345
Epoch=344, loss=0.1230
Epoch=345, loss=0.1206
Epoch=346, loss=0.1084
Epoch=347, loss=0.1052
Epoch=348, loss=0.1284
Epoch=349, loss=0.1293
Epoch=350, loss=0.1263
Epoch=351, loss=0.1244
Epoch=352, loss=0.1155
Epoch=353, loss=0.1224
Epoch=354, loss=0.1224
Epoch=355, loss=0.1205
Epoch=356, loss=0.1145
Epoch=357, loss=0.1310
Epoch=358, loss=0.1108
Epoch=359, loss=0.1244
Epoch=360, loss=0.1137
Epoch=361, loss=0.1090
Epoch=362, loss=0.1152
Epoch=363, loss=0.1124
Epoch=364, loss=0.1252
Epoch=365, loss=0.1211
Epoch=366, loss=0.1150
Epoch=367, loss=0.1121
Early stopping!
Loading 347th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.5949+-0.0244, F1Ma=0.5544+-0.0228, acc=0.5949+-0.0244
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6924
Epoch=009, loss=0.6923
Epoch=010, loss=0.6922
Epoch=011, loss=0.6920
Epoch=012, loss=0.6918
Epoch=013, loss=0.6916
Epoch=014, loss=0.6914
Epoch=015, loss=0.6911
Epoch=016, loss=0.6908
Epoch=017, loss=0.6905
Epoch=018, loss=0.6902
Epoch=019, loss=0.6898
Epoch=020, loss=0.6894
Epoch=021, loss=0.6889
Epoch=022, loss=0.6885
Epoch=023, loss=0.6879
Epoch=024, loss=0.6872
Epoch=025, loss=0.6865
Epoch=026, loss=0.6858
Epoch=027, loss=0.6851
Epoch=028, loss=0.6844
Epoch=029, loss=0.6835
Epoch=030, loss=0.6825
Epoch=031, loss=0.6815
Epoch=032, loss=0.6805
Epoch=033, loss=0.6794
Epoch=034, loss=0.6778
Epoch=035, loss=0.6763
Epoch=036, loss=0.6751
Epoch=037, loss=0.6739
Epoch=038, loss=0.6722
Epoch=039, loss=0.6704
Epoch=040, loss=0.6687
Epoch=041, loss=0.6667
Epoch=042, loss=0.6649
Epoch=043, loss=0.6626
Epoch=044, loss=0.6607
Epoch=045, loss=0.6578
Epoch=046, loss=0.6554
Epoch=047, loss=0.6534
Epoch=048, loss=0.6501
Epoch=049, loss=0.6477
Epoch=050, loss=0.6450
Epoch=051, loss=0.6418
Epoch=052, loss=0.6380
Epoch=053, loss=0.6344
Epoch=054, loss=0.6304
Epoch=055, loss=0.6281
Epoch=056, loss=0.6239
Epoch=057, loss=0.6192
Epoch=058, loss=0.6158
Epoch=059, loss=0.6118
Epoch=060, loss=0.6063
Epoch=061, loss=0.6008
Epoch=062, loss=0.5981
Epoch=063, loss=0.5916
Epoch=064, loss=0.5888
Epoch=065, loss=0.5824
Epoch=066, loss=0.5774
Epoch=067, loss=0.5756
Epoch=068, loss=0.5662
Epoch=069, loss=0.5610
Epoch=070, loss=0.5559
Epoch=071, loss=0.5485
Epoch=072, loss=0.5445
Epoch=073, loss=0.5390
Epoch=074, loss=0.5297
Epoch=075, loss=0.5259
Epoch=076, loss=0.5207
Epoch=077, loss=0.5096
Epoch=078, loss=0.5064
Epoch=079, loss=0.4953
Epoch=080, loss=0.4911
Epoch=081, loss=0.4853
Epoch=082, loss=0.4779
Epoch=083, loss=0.4727
Epoch=084, loss=0.4623
Epoch=085, loss=0.4555
Epoch=086, loss=0.4501
Epoch=087, loss=0.4415
Epoch=088, loss=0.4339
Epoch=089, loss=0.4269
Epoch=090, loss=0.4201
Epoch=091, loss=0.4109
Epoch=092, loss=0.4103
Epoch=093, loss=0.4022
Epoch=094, loss=0.3879
Epoch=095, loss=0.3880
Epoch=096, loss=0.3763
Epoch=097, loss=0.3730
Epoch=098, loss=0.3646
Epoch=099, loss=0.3555
Epoch=100, loss=0.3496
Epoch=101, loss=0.3439
Epoch=102, loss=0.3355
Epoch=103, loss=0.3308
Epoch=104, loss=0.3251
Epoch=105, loss=0.3195
Epoch=106, loss=0.3148
Epoch=107, loss=0.3063
Epoch=108, loss=0.3020
Epoch=109, loss=0.2914
Epoch=110, loss=0.2852
Epoch=111, loss=0.2806
Epoch=112, loss=0.2813
Epoch=113, loss=0.2742
Epoch=114, loss=0.2616
Epoch=115, loss=0.2638
Epoch=116, loss=0.2581
Epoch=117, loss=0.2539
Epoch=118, loss=0.2494
Epoch=119, loss=0.2350
Epoch=120, loss=0.2368
Epoch=121, loss=0.2357
Epoch=122, loss=0.2262
Epoch=123, loss=0.2216
Epoch=124, loss=0.2285
Epoch=125, loss=0.2171
Epoch=126, loss=0.2171
Epoch=127, loss=0.2116
Epoch=128, loss=0.2009
Epoch=129, loss=0.1979
Epoch=130, loss=0.2049
Epoch=131, loss=0.1873
Epoch=132, loss=0.1919
Epoch=133, loss=0.1939
Epoch=134, loss=0.1761
Epoch=135, loss=0.1814
Epoch=136, loss=0.1734
Epoch=137, loss=0.1656
Epoch=138, loss=0.1677
Epoch=139, loss=0.1742
Epoch=140, loss=0.1653
Epoch=141, loss=0.1612
Epoch=142, loss=0.1636
Epoch=143, loss=0.1623
Epoch=144, loss=0.1608
Epoch=145, loss=0.1627
Epoch=146, loss=0.1534
Epoch=147, loss=0.1539
Epoch=148, loss=0.1539
Epoch=149, loss=0.1470
Epoch=150, loss=0.1422
Epoch=151, loss=0.1430
Epoch=152, loss=0.1362
Epoch=153, loss=0.1451
Epoch=154, loss=0.1404
Epoch=155, loss=0.1473
Epoch=156, loss=0.1357
Epoch=157, loss=0.1318
Epoch=158, loss=0.1365
Epoch=159, loss=0.1367
Epoch=160, loss=0.1246
Epoch=161, loss=0.1264
Epoch=162, loss=0.1162
Epoch=163, loss=0.1232
Epoch=164, loss=0.1239
Epoch=165, loss=0.1262
Epoch=166, loss=0.1256
Epoch=167, loss=0.1259
Epoch=168, loss=0.1110
Epoch=169, loss=0.1106
Epoch=170, loss=0.1161
Epoch=171, loss=0.1084
Epoch=172, loss=0.1157
Epoch=173, loss=0.1123
Epoch=174, loss=0.1074
Epoch=175, loss=0.0979
Epoch=176, loss=0.1177
Epoch=177, loss=0.0976
Epoch=178, loss=0.0990
Epoch=179, loss=0.1002
Epoch=180, loss=0.0971
Epoch=181, loss=0.0995
Epoch=182, loss=0.1023
Epoch=183, loss=0.0967
Epoch=184, loss=0.1034
Epoch=185, loss=0.0929
Epoch=186, loss=0.1040
Epoch=187, loss=0.0946
Epoch=188, loss=0.0895
Epoch=189, loss=0.0955
Epoch=190, loss=0.0911
Epoch=191, loss=0.1016
Epoch=192, loss=0.0933
Epoch=193, loss=0.0857
Epoch=194, loss=0.0989
Epoch=195, loss=0.0948
Epoch=196, loss=0.0904
Epoch=197, loss=0.0915
Epoch=198, loss=0.0833
Epoch=199, loss=0.0877
Epoch=200, loss=0.0960
Epoch=201, loss=0.0835
Epoch=202, loss=0.0869
Epoch=203, loss=0.0896
Epoch=204, loss=0.0879
Epoch=205, loss=0.0828
Epoch=206, loss=0.0814
Epoch=207, loss=0.0823
Epoch=208, loss=0.0827
Epoch=209, loss=0.0816
Epoch=210, loss=0.0701
Epoch=211, loss=0.0826
Epoch=212, loss=0.0787
Epoch=213, loss=0.0805
Epoch=214, loss=0.0784
Epoch=215, loss=0.0795
Epoch=216, loss=0.0857
Epoch=217, loss=0.0831
Epoch=218, loss=0.0680
Epoch=219, loss=0.0811
Epoch=220, loss=0.0768
Epoch=221, loss=0.0741
Epoch=222, loss=0.0770
Epoch=223, loss=0.0634
Epoch=224, loss=0.0808
Epoch=225, loss=0.0780
Epoch=226, loss=0.0647
Epoch=227, loss=0.0743
Epoch=228, loss=0.0699
Epoch=229, loss=0.0729
Epoch=230, loss=0.0695
Epoch=231, loss=0.0690
Epoch=232, loss=0.0688
Epoch=233, loss=0.0733
Epoch=234, loss=0.0637
Epoch=235, loss=0.0713
Epoch=236, loss=0.0627
Epoch=237, loss=0.0646
Epoch=238, loss=0.0666
Epoch=239, loss=0.0696
Epoch=240, loss=0.0637
Epoch=241, loss=0.0655
Epoch=242, loss=0.0587
Epoch=243, loss=0.0669
Epoch=244, loss=0.0705
Epoch=245, loss=0.0631
Epoch=246, loss=0.0678
Epoch=247, loss=0.0587
Epoch=248, loss=0.0694
Epoch=249, loss=0.0611
Epoch=250, loss=0.0659
Epoch=251, loss=0.0619
Epoch=252, loss=0.0649
Epoch=253, loss=0.0558
Epoch=254, loss=0.0707
Epoch=255, loss=0.0634
Epoch=256, loss=0.0635
Epoch=257, loss=0.0633
Epoch=258, loss=0.0625
Epoch=259, loss=0.0634
Epoch=260, loss=0.0581
Epoch=261, loss=0.0557
Epoch=262, loss=0.0647
Epoch=263, loss=0.0651
Epoch=264, loss=0.0595
Epoch=265, loss=0.0572
Epoch=266, loss=0.0630
Epoch=267, loss=0.0549
Epoch=268, loss=0.0565
Epoch=269, loss=0.0629
Epoch=270, loss=0.0550
Epoch=271, loss=0.0640
Epoch=272, loss=0.0566
Epoch=273, loss=0.0600
Epoch=274, loss=0.0563
Epoch=275, loss=0.0593
Epoch=276, loss=0.0513
Epoch=277, loss=0.0568
Epoch=278, loss=0.0546
Epoch=279, loss=0.0558
Epoch=280, loss=0.0499
Epoch=281, loss=0.0496
Epoch=282, loss=0.0562
Epoch=283, loss=0.0557
Epoch=284, loss=0.0588
Epoch=285, loss=0.0520
Epoch=286, loss=0.0561
Epoch=287, loss=0.0512
Epoch=288, loss=0.0570
Epoch=289, loss=0.0560
Epoch=290, loss=0.0526
Epoch=291, loss=0.0465
Epoch=292, loss=0.0530
Epoch=293, loss=0.0599
Epoch=294, loss=0.0477
Epoch=295, loss=0.0581
Epoch=296, loss=0.0514
Epoch=297, loss=0.0602
Epoch=298, loss=0.0573
Epoch=299, loss=0.0498
Epoch=300, loss=0.0496
Epoch=301, loss=0.0515
Epoch=302, loss=0.0553
Epoch=303, loss=0.0527
Epoch=304, loss=0.0439
Epoch=305, loss=0.0539
Epoch=306, loss=0.0415
Epoch=307, loss=0.0465
Epoch=308, loss=0.0476
Epoch=309, loss=0.0589
Epoch=310, loss=0.0481
Epoch=311, loss=0.0482
Epoch=312, loss=0.0435
Epoch=313, loss=0.0494
Epoch=314, loss=0.0521
Epoch=315, loss=0.0430
Epoch=316, loss=0.0492
Epoch=317, loss=0.0415
Epoch=318, loss=0.0452
Epoch=319, loss=0.0442
Epoch=320, loss=0.0426
Epoch=321, loss=0.0419
Epoch=322, loss=0.0449
Epoch=323, loss=0.0432
Epoch=324, loss=0.0445
Epoch=325, loss=0.0453
Epoch=326, loss=0.0462
Epoch=327, loss=0.0434
Epoch=328, loss=0.0431
Epoch=329, loss=0.0489
Epoch=330, loss=0.0580
Epoch=331, loss=0.0473
Epoch=332, loss=0.0431
Epoch=333, loss=0.0459
Epoch=334, loss=0.0487
Epoch=335, loss=0.0518
Epoch=336, loss=0.0468
Epoch=337, loss=0.0361
Epoch=338, loss=0.0553
Epoch=339, loss=0.0423
Epoch=340, loss=0.0420
Epoch=341, loss=0.0475
Epoch=342, loss=0.0439
Epoch=343, loss=0.0470
Epoch=344, loss=0.0436
Epoch=345, loss=0.0496
Epoch=346, loss=0.0440
Epoch=347, loss=0.0445
Epoch=348, loss=0.0418
Epoch=349, loss=0.0401
Epoch=350, loss=0.0397
Epoch=351, loss=0.0385
Epoch=352, loss=0.0435
Epoch=353, loss=0.0434
Epoch=354, loss=0.0462
Epoch=355, loss=0.0407
Epoch=356, loss=0.0487
Epoch=357, loss=0.0420
Early stopping!
Loading 337th epoch
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7643+-0.0035, F1Ma=0.7200+-0.0206, acc=0.7643+-0.0035
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9395365756495435, 0.9317892008354953, 0.9355702861422467, 0.9310174839770823, 0.800000011920929, 0.7039999961853027, 0.7238878011703491, 0.8285714387893677, 0.7020000219345093, 0.7330754399299622, 0.7643218033424019, 0.0035245344885362325, 0.7199604670003616, 0.020559404463299, 0.7643218033424019, 0.003524534488536219]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6927
Epoch=004, loss=0.6925
Epoch=005, loss=0.6922
Epoch=006, loss=0.6919
Epoch=007, loss=0.6914
Epoch=008, loss=0.6911
Epoch=009, loss=0.6905
Epoch=010, loss=0.6900
Epoch=011, loss=0.6892
Epoch=012, loss=0.6884
Epoch=013, loss=0.6874
Epoch=014, loss=0.6865
Epoch=015, loss=0.6852
Epoch=016, loss=0.6839
Epoch=017, loss=0.6821
Epoch=018, loss=0.6807
Epoch=019, loss=0.6786
Epoch=020, loss=0.6764
Epoch=021, loss=0.6739
Epoch=022, loss=0.6715
Epoch=023, loss=0.6684
Epoch=024, loss=0.6654
Epoch=025, loss=0.6615
Epoch=026, loss=0.6576
Epoch=027, loss=0.6541
Epoch=028, loss=0.6493
Epoch=029, loss=0.6448
Epoch=030, loss=0.6388
Epoch=031, loss=0.6326
Epoch=032, loss=0.6277
Epoch=033, loss=0.6196
Epoch=034, loss=0.6137
Epoch=035, loss=0.6060
Epoch=036, loss=0.5970
Epoch=037, loss=0.5875
Epoch=038, loss=0.5800
Epoch=039, loss=0.5714
Epoch=040, loss=0.5595
Epoch=041, loss=0.5508
Epoch=042, loss=0.5401
Epoch=043, loss=0.5307
Epoch=044, loss=0.5190
Epoch=045, loss=0.5074
Epoch=046, loss=0.4974
Epoch=047, loss=0.4821
Epoch=048, loss=0.4720
Epoch=049, loss=0.4594
Epoch=050, loss=0.4480
Epoch=051, loss=0.4340
Epoch=052, loss=0.4238
Epoch=053, loss=0.4033
Epoch=054, loss=0.3934
Epoch=055, loss=0.3788
Epoch=056, loss=0.3668
Epoch=057, loss=0.3567
Epoch=058, loss=0.3455
Epoch=059, loss=0.3345
Epoch=060, loss=0.3138
Epoch=061, loss=0.3095
Epoch=062, loss=0.3003
Epoch=063, loss=0.2903
Epoch=064, loss=0.2736
Epoch=065, loss=0.2624
Epoch=066, loss=0.2506
Epoch=067, loss=0.2427
Epoch=068, loss=0.2392
Epoch=069, loss=0.2319
Epoch=070, loss=0.2247
Epoch=071, loss=0.2084
Epoch=072, loss=0.2022
Epoch=073, loss=0.1906
Epoch=074, loss=0.1895
Epoch=075, loss=0.1961
Epoch=076, loss=0.1707
Epoch=077, loss=0.1730
Epoch=078, loss=0.1673
Epoch=079, loss=0.1672
Epoch=080, loss=0.1541
Epoch=081, loss=0.1577
Epoch=082, loss=0.1519
Epoch=083, loss=0.1380
Epoch=084, loss=0.1370
Epoch=085, loss=0.1523
Epoch=086, loss=0.1319
Epoch=087, loss=0.1341
Epoch=088, loss=0.1230
Epoch=089, loss=0.1297
Epoch=090, loss=0.1173
Epoch=091, loss=0.1171
Epoch=092, loss=0.1209
Epoch=093, loss=0.1185
Epoch=094, loss=0.1183
Epoch=095, loss=0.1136
Epoch=096, loss=0.1085
Epoch=097, loss=0.1115
Epoch=098, loss=0.0955
Epoch=099, loss=0.1097
Epoch=100, loss=0.1026
Epoch=101, loss=0.0925
Epoch=102, loss=0.0995
Epoch=103, loss=0.0909
Epoch=104, loss=0.1000
Epoch=105, loss=0.0909
Epoch=106, loss=0.0936
Epoch=107, loss=0.0932
Epoch=108, loss=0.0890
Epoch=109, loss=0.0854
Epoch=110, loss=0.1000
Epoch=111, loss=0.0809
Epoch=112, loss=0.0863
Epoch=113, loss=0.0820
Epoch=114, loss=0.0740
Epoch=115, loss=0.0866
Epoch=116, loss=0.0860
Epoch=117, loss=0.0773
Epoch=118, loss=0.0756
Epoch=119, loss=0.0760
Epoch=120, loss=0.0697
Epoch=121, loss=0.0794
Epoch=122, loss=0.0820
Epoch=123, loss=0.0651
Epoch=124, loss=0.0748
Epoch=125, loss=0.0762
Epoch=126, loss=0.0700
Epoch=127, loss=0.0717
Epoch=128, loss=0.0663
Epoch=129, loss=0.0689
Epoch=130, loss=0.0759
Epoch=131, loss=0.0607
Epoch=132, loss=0.0652
Epoch=133, loss=0.0642
Epoch=134, loss=0.0597
Epoch=135, loss=0.0707
Epoch=136, loss=0.0656
Epoch=137, loss=0.0726
Epoch=138, loss=0.0633
Epoch=139, loss=0.0731
Epoch=140, loss=0.0582
Epoch=141, loss=0.0591
Epoch=142, loss=0.0708
Epoch=143, loss=0.0546
Epoch=144, loss=0.0664
Epoch=145, loss=0.0645
Epoch=146, loss=0.0703
Epoch=147, loss=0.0544
Epoch=148, loss=0.0587
Epoch=149, loss=0.0639
Epoch=150, loss=0.0610
Epoch=151, loss=0.0613
Epoch=152, loss=0.0523
Epoch=153, loss=0.0491
Epoch=154, loss=0.0505
Epoch=155, loss=0.0567
Epoch=156, loss=0.0557
Epoch=157, loss=0.0572
Epoch=158, loss=0.0655
Epoch=159, loss=0.0502
Epoch=160, loss=0.0653
Epoch=161, loss=0.0601
Epoch=162, loss=0.0533
Epoch=163, loss=0.0471
Epoch=164, loss=0.0499
Epoch=165, loss=0.0519
Epoch=166, loss=0.0560
Epoch=167, loss=0.0536
Epoch=168, loss=0.0446
Epoch=169, loss=0.0501
Epoch=170, loss=0.0513
Epoch=171, loss=0.0537
Epoch=172, loss=0.0516
Epoch=173, loss=0.0608
Epoch=174, loss=0.0500
Epoch=175, loss=0.0544
Epoch=176, loss=0.0651
Epoch=177, loss=0.0493
Epoch=178, loss=0.0540
Epoch=179, loss=0.0419
Epoch=180, loss=0.0442
Epoch=181, loss=0.0458
Epoch=182, loss=0.0477
Epoch=183, loss=0.0509
Epoch=184, loss=0.0497
Epoch=185, loss=0.0599
Epoch=186, loss=0.0462
Epoch=187, loss=0.0394
Epoch=188, loss=0.0478
Epoch=189, loss=0.0457
Epoch=190, loss=0.0437
Epoch=191, loss=0.0475
Epoch=192, loss=0.0442
Epoch=193, loss=0.0584
Epoch=194, loss=0.0525
Epoch=195, loss=0.0477
Epoch=196, loss=0.0464
Epoch=197, loss=0.0580
Epoch=198, loss=0.0525
Epoch=199, loss=0.0529
Epoch=200, loss=0.0392
Epoch=201, loss=0.0372
Epoch=202, loss=0.0411
Epoch=203, loss=0.0351
Epoch=204, loss=0.0355
Epoch=205, loss=0.0468
Epoch=206, loss=0.0446
Epoch=207, loss=0.0474
Epoch=208, loss=0.0526
Epoch=209, loss=0.0486
Epoch=210, loss=0.0404
Epoch=211, loss=0.0420
Epoch=212, loss=0.0504
Epoch=213, loss=0.0366
Epoch=214, loss=0.0415
Epoch=215, loss=0.0446
Epoch=216, loss=0.0305
Epoch=217, loss=0.0399
Epoch=218, loss=0.0385
Epoch=219, loss=0.0313
Epoch=220, loss=0.0346
Epoch=221, loss=0.0339
Epoch=222, loss=0.0398
Epoch=223, loss=0.0380
Epoch=224, loss=0.0399
Epoch=225, loss=0.0423
Epoch=226, loss=0.0422
Epoch=227, loss=0.0417
Epoch=228, loss=0.0410
Epoch=229, loss=0.0367
Epoch=230, loss=0.0370
Epoch=231, loss=0.0325
Epoch=232, loss=0.0402
Epoch=233, loss=0.0371
Epoch=234, loss=0.0440
Epoch=235, loss=0.0434
Epoch=236, loss=0.0287
Epoch=237, loss=0.0479
Epoch=238, loss=0.0333
Epoch=239, loss=0.0391
Epoch=240, loss=0.0385
Epoch=241, loss=0.0385
Epoch=242, loss=0.0442
Epoch=243, loss=0.0400
Epoch=244, loss=0.0374
Epoch=245, loss=0.0384
Epoch=246, loss=0.0315
Epoch=247, loss=0.0416
Epoch=248, loss=0.0403
Epoch=249, loss=0.0344
Epoch=250, loss=0.0309
Epoch=251, loss=0.0322
Epoch=252, loss=0.0406
Epoch=253, loss=0.0400
Epoch=254, loss=0.0298
Epoch=255, loss=0.0320
Epoch=256, loss=0.0378
Early stopping!
Loading 236th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7796+-0.0141, F1Ma=0.7529+-0.0176, acc=0.7796+-0.0141
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9395365756495435, 0.9317892008354953, 0.9355702861422467, 0.9310174839770823, 0.800000011920929, 0.7039999961853027, 0.7238878011703491, 0.8285714387893677, 0.7020000219345093, 0.7330754399299622, 0.7643218033424019, 0.0035245344885362325, 0.7199604670003616, 0.020559404463299, 0.7643218033424019, 0.003524534488536219], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7506554416451396, 0.7505414071258979, 0.7701248339208365, 0.7832705639238036, 0.8714285492897034, 0.7379999756813049, 0.740812361240387, 0.8714285492897034, 0.7360000014305115, 0.7393617033958435, 0.7796346677030703, 0.014131099077106721, 0.7529280942210523, 0.017625979206232566, 0.7796346677030704, 0.014131099077106739]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6928
Epoch=002, loss=0.6922
Epoch=003, loss=0.6915
Epoch=004, loss=0.6905
Epoch=005, loss=0.6894
Epoch=006, loss=0.6876
Epoch=007, loss=0.6857
Epoch=008, loss=0.6835
Epoch=009, loss=0.6802
Epoch=010, loss=0.6769
Epoch=011, loss=0.6729
Epoch=012, loss=0.6678
Epoch=013, loss=0.6624
Epoch=014, loss=0.6562
Epoch=015, loss=0.6488
Epoch=016, loss=0.6416
Epoch=017, loss=0.6313
Epoch=018, loss=0.6219
Epoch=019, loss=0.6105
Epoch=020, loss=0.5974
Epoch=021, loss=0.5838
Epoch=022, loss=0.5711
Epoch=023, loss=0.5548
Epoch=024, loss=0.5355
Epoch=025, loss=0.5194
Epoch=026, loss=0.4996
Epoch=027, loss=0.4814
Epoch=028, loss=0.4586
Epoch=029, loss=0.4398
Epoch=030, loss=0.4203
Epoch=031, loss=0.3980
Epoch=032, loss=0.3792
Epoch=033, loss=0.3553
Epoch=034, loss=0.3353
Epoch=035, loss=0.3200
Epoch=036, loss=0.3005
Epoch=037, loss=0.2862
Epoch=038, loss=0.2609
Epoch=039, loss=0.2534
Epoch=040, loss=0.2413
Epoch=041, loss=0.2271
Epoch=042, loss=0.2024
Epoch=043, loss=0.1953
Epoch=044, loss=0.1808
Epoch=045, loss=0.1842
Epoch=046, loss=0.1720
Epoch=047, loss=0.1637
Epoch=048, loss=0.1463
Epoch=049, loss=0.1501
Epoch=050, loss=0.1447
Epoch=051, loss=0.1423
Epoch=052, loss=0.1359
Epoch=053, loss=0.1297
Epoch=054, loss=0.1200
Epoch=055, loss=0.1213
Epoch=056, loss=0.1153
Epoch=057, loss=0.1194
Epoch=058, loss=0.1208
Epoch=059, loss=0.1041
Epoch=060, loss=0.1012
Epoch=061, loss=0.0918
Epoch=062, loss=0.1072
Epoch=063, loss=0.0975
Epoch=064, loss=0.0893
Epoch=065, loss=0.0989
Epoch=066, loss=0.1035
Epoch=067, loss=0.0924
Epoch=068, loss=0.0852
Epoch=069, loss=0.0943
Epoch=070, loss=0.0768
Epoch=071, loss=0.0743
Epoch=072, loss=0.0721
Epoch=073, loss=0.0801
Epoch=074, loss=0.0740
Epoch=075, loss=0.0780
Epoch=076, loss=0.0777
Epoch=077, loss=0.0755
Epoch=078, loss=0.0697
Epoch=079, loss=0.0719
Epoch=080, loss=0.0671
Epoch=081, loss=0.0661
Epoch=082, loss=0.0788
Epoch=083, loss=0.0776
Epoch=084, loss=0.0683
Epoch=085, loss=0.0663
Epoch=086, loss=0.0595
Epoch=087, loss=0.0741
Epoch=088, loss=0.0866
Epoch=089, loss=0.0696
Epoch=090, loss=0.0751
Epoch=091, loss=0.0607
Epoch=092, loss=0.0536
Epoch=093, loss=0.0708
Epoch=094, loss=0.0690
Epoch=095, loss=0.0527
Epoch=096, loss=0.0636
Epoch=097, loss=0.0613
Epoch=098, loss=0.0663
Epoch=099, loss=0.0617
Epoch=100, loss=0.0645
Epoch=101, loss=0.0365
Epoch=102, loss=0.0559
Epoch=103, loss=0.0634
Epoch=104, loss=0.0623
Epoch=105, loss=0.0561
Epoch=106, loss=0.0655
Epoch=107, loss=0.0497
Epoch=108, loss=0.0622
Epoch=109, loss=0.0590
Epoch=110, loss=0.0547
Epoch=111, loss=0.0447
Epoch=112, loss=0.0515
Epoch=113, loss=0.0547
Epoch=114, loss=0.0551
Epoch=115, loss=0.0528
Epoch=116, loss=0.0569
Epoch=117, loss=0.0472
Epoch=118, loss=0.0603
Epoch=119, loss=0.0525
Epoch=120, loss=0.0465
Epoch=121, loss=0.0385
Early stopping!
Loading 101th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8044+-0.0181, F1Ma=0.7765+-0.0291, acc=0.8044+-0.0181
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9395365756495435, 0.9317892008354953, 0.9355702861422467, 0.9310174839770823, 0.800000011920929, 0.7039999961853027, 0.7238878011703491, 0.8285714387893677, 0.7020000219345093, 0.7330754399299622, 0.7643218033424019, 0.0035245344885362325, 0.7199604670003616, 0.020559404463299, 0.7643218033424019, 0.003524534488536219], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7506554416451396, 0.7505414071258979, 0.7701248339208365, 0.7832705639238036, 0.8714285492897034, 0.7379999756813049, 0.740812361240387, 0.8714285492897034, 0.7360000014305115, 0.7393617033958435, 0.7796346677030703, 0.014131099077106721, 0.7529280942210523, 0.017625979206232566, 0.7796346677030704, 0.014131099077106739], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.776197608357879, 0.7669230848848191, 0.7821041374865426, 0.7884115674767584, 0.9071428775787354, 0.7680000066757202, 0.7732108235359192, 0.8999999761581421, 0.7680000066757202, 0.7727272510528564, 0.8044306257287215, 0.018101977795639615, 0.7764631394863425, 0.029125177697378143, 0.8044306257287213, 0.01810197779563966]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6913
Epoch=002, loss=0.6884
Epoch=003, loss=0.6843
Epoch=004, loss=0.6792
Epoch=005, loss=0.6720
Epoch=006, loss=0.6631
Epoch=007, loss=0.6530
Epoch=008, loss=0.6409
Epoch=009, loss=0.6250
Epoch=010, loss=0.6110
Epoch=011, loss=0.5879
Epoch=012, loss=0.5714
Epoch=013, loss=0.5530
Epoch=014, loss=0.5239
Epoch=015, loss=0.4987
Epoch=016, loss=0.4742
Epoch=017, loss=0.4401
Epoch=018, loss=0.4208
Epoch=019, loss=0.3901
Epoch=020, loss=0.3530
Epoch=021, loss=0.3344
Epoch=022, loss=0.3125
Epoch=023, loss=0.2894
Epoch=024, loss=0.2696
Epoch=025, loss=0.2544
Epoch=026, loss=0.2326
Epoch=027, loss=0.2286
Epoch=028, loss=0.2069
Epoch=029, loss=0.2014
Epoch=030, loss=0.2051
Epoch=031, loss=0.1626
Epoch=032, loss=0.1842
Epoch=033, loss=0.1692
Epoch=034, loss=0.1349
Epoch=035, loss=0.1396
Epoch=036, loss=0.1280
Epoch=037, loss=0.1289
Epoch=038, loss=0.1225
Epoch=039, loss=0.1323
Epoch=040, loss=0.1248
Epoch=041, loss=0.1179
Epoch=042, loss=0.1085
Epoch=043, loss=0.1159
Epoch=044, loss=0.1082
Epoch=045, loss=0.1044
Epoch=046, loss=0.1027
Epoch=047, loss=0.1030
Epoch=048, loss=0.1048
Epoch=049, loss=0.0994
Epoch=050, loss=0.0817
Epoch=051, loss=0.0949
Epoch=052, loss=0.0870
Epoch=053, loss=0.0752
Epoch=054, loss=0.0933
Epoch=055, loss=0.0749
Epoch=056, loss=0.0770
Epoch=057, loss=0.0696
Epoch=058, loss=0.0921
Epoch=059, loss=0.0785
Epoch=060, loss=0.0847
Epoch=061, loss=0.0809
Epoch=062, loss=0.0753
Epoch=063, loss=0.0696
Epoch=064, loss=0.0699
Epoch=065, loss=0.0693
Epoch=066, loss=0.0640
Epoch=067, loss=0.0606
Epoch=068, loss=0.0692
Epoch=069, loss=0.0725
Epoch=070, loss=0.0804
Epoch=071, loss=0.0706
Epoch=072, loss=0.0643
Epoch=073, loss=0.0554
Epoch=074, loss=0.0591
Epoch=075, loss=0.0661
Epoch=076, loss=0.0554
Epoch=077, loss=0.0484
Epoch=078, loss=0.0624
Epoch=079, loss=0.0664
Epoch=080, loss=0.0597
Epoch=081, loss=0.0704
Epoch=082, loss=0.0522
Epoch=083, loss=0.0578
Epoch=084, loss=0.0627
Epoch=085, loss=0.0583
Epoch=086, loss=0.0595
Epoch=087, loss=0.0677
Epoch=088, loss=0.0513
Epoch=089, loss=0.0582
Epoch=090, loss=0.0580
Epoch=091, loss=0.0522
Epoch=092, loss=0.0616
Epoch=093, loss=0.0569
Epoch=094, loss=0.0448
Epoch=095, loss=0.0642
Epoch=096, loss=0.0598
Epoch=097, loss=0.0552
Epoch=098, loss=0.0457
Epoch=099, loss=0.0472
Epoch=100, loss=0.0410
Epoch=101, loss=0.0406
Epoch=102, loss=0.0432
Epoch=103, loss=0.0525
Epoch=104, loss=0.0447
Epoch=105, loss=0.0445
Epoch=106, loss=0.0395
Epoch=107, loss=0.0481
Epoch=108, loss=0.0406
Epoch=109, loss=0.0436
Epoch=110, loss=0.0499
Epoch=111, loss=0.0464
Epoch=112, loss=0.0515
Epoch=113, loss=0.0408
Epoch=114, loss=0.0403
Epoch=115, loss=0.0331
Epoch=116, loss=0.0396
Epoch=117, loss=0.0481
Epoch=118, loss=0.0390
Epoch=119, loss=0.0336
Epoch=120, loss=0.0390
Epoch=121, loss=0.0243
Epoch=122, loss=0.0355
Epoch=123, loss=0.0340
Epoch=124, loss=0.0440
Epoch=125, loss=0.0306
Epoch=126, loss=0.0328
Epoch=127, loss=0.0260
Epoch=128, loss=0.0284
Epoch=129, loss=0.0380
Epoch=130, loss=0.0382
Epoch=131, loss=0.0416
Epoch=132, loss=0.0348
Epoch=133, loss=0.0334
Epoch=134, loss=0.0428
Epoch=135, loss=0.0342
Epoch=136, loss=0.0311
Epoch=137, loss=0.0330
Epoch=138, loss=0.0177
Epoch=139, loss=0.0355
Epoch=140, loss=0.0430
Epoch=141, loss=0.0327
Epoch=142, loss=0.0277
Epoch=143, loss=0.0287
Epoch=144, loss=0.0285
Epoch=145, loss=0.0410
Epoch=146, loss=0.0336
Epoch=147, loss=0.0372
Epoch=148, loss=0.0240
Epoch=149, loss=0.0264
Epoch=150, loss=0.0258
Epoch=151, loss=0.0186
Epoch=152, loss=0.0269
Epoch=153, loss=0.0350
Epoch=154, loss=0.0256
Epoch=155, loss=0.0319
Epoch=156, loss=0.0331
Epoch=157, loss=0.0293
Epoch=158, loss=0.0265
Early stopping!
Loading 138th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8064+-0.0036, F1Ma=0.7896+-0.0088, acc=0.8064+-0.0036
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9395365756495435, 0.9317892008354953, 0.9355702861422467, 0.9310174839770823, 0.800000011920929, 0.7039999961853027, 0.7238878011703491, 0.8285714387893677, 0.7020000219345093, 0.7330754399299622, 0.7643218033424019, 0.0035245344885362325, 0.7199604670003616, 0.020559404463299, 0.7643218033424019, 0.003524534488536219], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7506554416451396, 0.7505414071258979, 0.7701248339208365, 0.7832705639238036, 0.8714285492897034, 0.7379999756813049, 0.740812361240387, 0.8714285492897034, 0.7360000014305115, 0.7393617033958435, 0.7796346677030703, 0.014131099077106721, 0.7529280942210523, 0.017625979206232566, 0.7796346677030704, 0.014131099077106739], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.776197608357879, 0.7669230848848191, 0.7821041374865426, 0.7884115674767584, 0.9071428775787354, 0.7680000066757202, 0.7732108235359192, 0.8999999761581421, 0.7680000066757202, 0.7727272510528564, 0.8044306257287215, 0.018101977795639615, 0.7764631394863425, 0.029125177697378143, 0.8044306257287213, 0.01810197779563966], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9251638504818555, 0.9179337693990133, 0.9307670426926968, 0.9268574911698199, 0.8714285492897034, 0.7699999809265137, 0.7529013752937317, 0.8714285492897034, 0.7680000066757202, 0.7519342303276062, 0.8063738826272833, 0.0035907685852937907, 0.7896418454581531, 0.008827197437765952, 0.8063738826272833, 0.0035907685852937907]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6916
Epoch=002, loss=0.6871
Epoch=003, loss=0.6775
Epoch=004, loss=0.6720
Epoch=005, loss=0.6560
Epoch=006, loss=0.6460
Epoch=007, loss=0.6305
Epoch=008, loss=0.6078
Epoch=009, loss=0.5950
Epoch=010, loss=0.5671
Epoch=011, loss=0.5323
Epoch=012, loss=0.5216
Epoch=013, loss=0.4953
Epoch=014, loss=0.4472
Epoch=015, loss=0.4123
Epoch=016, loss=0.4018
Epoch=017, loss=0.3595
Epoch=018, loss=0.3321
Epoch=019, loss=0.3219
Epoch=020, loss=0.2964
Epoch=021, loss=0.2625
Epoch=022, loss=0.2660
Epoch=023, loss=0.2245
Epoch=024, loss=0.2169
Epoch=025, loss=0.2124
Epoch=026, loss=0.1869
Epoch=027, loss=0.1946
Epoch=028, loss=0.1540
Epoch=029, loss=0.1350
Epoch=030, loss=0.1325
Epoch=031, loss=0.1405
Epoch=032, loss=0.1064
Epoch=033, loss=0.1129
Epoch=034, loss=0.1088
Epoch=035, loss=0.1121
Epoch=036, loss=0.0978
Epoch=037, loss=0.1093
Epoch=038, loss=0.0791
Epoch=039, loss=0.1050
Epoch=040, loss=0.0769
Epoch=041, loss=0.0934
Epoch=042, loss=0.0555
Epoch=043, loss=0.0725
Epoch=044, loss=0.0579
Epoch=045, loss=0.0715
Epoch=046, loss=0.0637
Epoch=047, loss=0.0548
Epoch=048, loss=0.0504
Epoch=049, loss=0.0525
Epoch=050, loss=0.0513
Epoch=051, loss=0.0494
Epoch=052, loss=0.0487
Epoch=053, loss=0.0406
Epoch=054, loss=0.0545
Epoch=055, loss=0.0466
Epoch=056, loss=0.0442
Epoch=057, loss=0.0442
Epoch=058, loss=0.0399
Epoch=059, loss=0.0408
Epoch=060, loss=0.0402
Epoch=061, loss=0.0346
Epoch=062, loss=0.0412
Epoch=063, loss=0.0321
Epoch=064, loss=0.0348
Epoch=065, loss=0.0371
Epoch=066, loss=0.0304
Epoch=067, loss=0.0273
Epoch=068, loss=0.0298
Epoch=069, loss=0.0229
Epoch=070, loss=0.0241
Epoch=071, loss=0.0211
Epoch=072, loss=0.0316
Epoch=073, loss=0.0189
Epoch=074, loss=0.0224
Epoch=075, loss=0.0206
Epoch=076, loss=0.0242
Epoch=077, loss=0.0202
Epoch=078, loss=0.0200
Epoch=079, loss=0.0221
Epoch=080, loss=0.0154
Epoch=081, loss=0.0169
Epoch=082, loss=0.0186
Epoch=083, loss=0.0143
Epoch=084, loss=0.0192
Epoch=085, loss=0.0213
Epoch=086, loss=0.0226
Epoch=087, loss=0.0162
Epoch=088, loss=0.0165
Epoch=089, loss=0.0148
Epoch=090, loss=0.0163
Epoch=091, loss=0.0141
Epoch=092, loss=0.0167
Epoch=093, loss=0.0145
Epoch=094, loss=0.0223
Epoch=095, loss=0.0107
Epoch=096, loss=0.0116
Epoch=097, loss=0.0206
Epoch=098, loss=0.0130
Epoch=099, loss=0.0057
Epoch=100, loss=0.0140
Epoch=101, loss=0.0088
Epoch=102, loss=0.0162
Epoch=103, loss=0.0124
Epoch=104, loss=0.0132
Epoch=105, loss=0.0080
Epoch=106, loss=0.0126
Epoch=107, loss=0.0088
Epoch=108, loss=0.0106
Epoch=109, loss=0.0092
Epoch=110, loss=0.0083
Epoch=111, loss=0.0090
Epoch=112, loss=0.0144
Epoch=113, loss=0.0072
Epoch=114, loss=0.0060
Epoch=115, loss=0.0073
Epoch=116, loss=0.0102
Epoch=117, loss=0.0132
Epoch=118, loss=0.0112
Epoch=119, loss=0.0093
Early stopping!
Loading 99th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8008+-0.0165, F1Ma=0.7785+-0.0264, acc=0.8008+-0.0165
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8003086960355363, 0.7971679569463426, 0.8156296245620731, 0.8200957153246607, 0.7285714149475098, 0.578000009059906, 0.5933268666267395, 0.7357142567634583, 0.5860000252723694, 0.6189554929733276, 0.5948698017877964, 0.024404831033893983, 0.5544316445245667, 0.02276658081838738, 0.5948698017877964, 0.024404831033893983], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9395365756495435, 0.9317892008354953, 0.9355702861422467, 0.9310174839770823, 0.800000011920929, 0.7039999961853027, 0.7238878011703491, 0.8285714387893677, 0.7020000219345093, 0.7330754399299622, 0.7643218033424019, 0.0035245344885362325, 0.7199604670003616, 0.020559404463299, 0.7643218033424019, 0.003524534488536219], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7506554416451396, 0.7505414071258979, 0.7701248339208365, 0.7832705639238036, 0.8714285492897034, 0.7379999756813049, 0.740812361240387, 0.8714285492897034, 0.7360000014305115, 0.7393617033958435, 0.7796346677030703, 0.014131099077106721, 0.7529280942210523, 0.017625979206232566, 0.7796346677030704, 0.014131099077106739], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.776197608357879, 0.7669230848848191, 0.7821041374865426, 0.7884115674767584, 0.9071428775787354, 0.7680000066757202, 0.7732108235359192, 0.8999999761581421, 0.7680000066757202, 0.7727272510528564, 0.8044306257287215, 0.018101977795639615, 0.7764631394863425, 0.029125177697378143, 0.8044306257287213, 0.01810197779563966], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9251638504818555, 0.9179337693990133, 0.9307670426926968, 0.9268574911698199, 0.8714285492897034, 0.7699999809265137, 0.7529013752937317, 0.8714285492897034, 0.7680000066757202, 0.7519342303276062, 0.8063738826272833, 0.0035907685852937907, 0.7896418454581531, 0.008827197437765952, 0.8063738826272833, 0.0035907685852937907], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9129769651135451, 0.9046481939067655, 0.9178479741042527, 0.9091333731205523, 0.9142857193946838, 0.7900000214576721, 0.7862669229507446, 0.9142857193946838, 0.7900000214576721, 0.7862669229507446, 0.8007773027594247, 0.01654322343651523, 0.7784546959890226, 0.026358964681899997, 0.8007773027594247, 0.01654322343651523]]
