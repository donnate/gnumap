My SLURM_ARRAY_TASK_ID:  13
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_13
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_13.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6931
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6929
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6928
Epoch=010, loss=0.6928
Epoch=011, loss=0.6927
Epoch=012, loss=0.6926
Epoch=013, loss=0.6926
Epoch=014, loss=0.6925
Epoch=015, loss=0.6924
Epoch=016, loss=0.6923
Epoch=017, loss=0.6922
Epoch=018, loss=0.6921
Epoch=019, loss=0.6920
Epoch=020, loss=0.6919
Epoch=021, loss=0.6918
Epoch=022, loss=0.6917
Epoch=023, loss=0.6916
Epoch=024, loss=0.6914
Epoch=025, loss=0.6912
Epoch=026, loss=0.6910
Epoch=027, loss=0.6909
Epoch=028, loss=0.6907
Epoch=029, loss=0.6905
Epoch=030, loss=0.6903
Epoch=031, loss=0.6901
Epoch=032, loss=0.6898
Epoch=033, loss=0.6895
Epoch=034, loss=0.6893
Epoch=035, loss=0.6892
Epoch=036, loss=0.6888
Epoch=037, loss=0.6884
Epoch=038, loss=0.6882
Epoch=039, loss=0.6878
Epoch=040, loss=0.6874
Epoch=041, loss=0.6871
Epoch=042, loss=0.6865
Epoch=043, loss=0.6862
Epoch=044, loss=0.6858
Epoch=045, loss=0.6854
Epoch=046, loss=0.6849
Epoch=047, loss=0.6845
Epoch=048, loss=0.6841
Epoch=049, loss=0.6834
Epoch=050, loss=0.6829
Epoch=051, loss=0.6821
Epoch=052, loss=0.6818
Epoch=053, loss=0.6808
Epoch=054, loss=0.6806
Epoch=055, loss=0.6797
Epoch=056, loss=0.6790
Epoch=057, loss=0.6784
Epoch=058, loss=0.6776
Epoch=059, loss=0.6768
Epoch=060, loss=0.6758
Epoch=061, loss=0.6749
Epoch=062, loss=0.6738
Epoch=063, loss=0.6730
Epoch=064, loss=0.6722
Epoch=065, loss=0.6710
Epoch=066, loss=0.6700
Epoch=067, loss=0.6696
Epoch=068, loss=0.6676
Epoch=069, loss=0.6664
Epoch=070, loss=0.6656
Epoch=071, loss=0.6642
Epoch=072, loss=0.6633
Epoch=073, loss=0.6621
Epoch=074, loss=0.6601
Epoch=075, loss=0.6590
Epoch=076, loss=0.6579
Epoch=077, loss=0.6561
Epoch=078, loss=0.6554
Epoch=079, loss=0.6535
Epoch=080, loss=0.6521
Epoch=081, loss=0.6495
Epoch=082, loss=0.6485
Epoch=083, loss=0.6476
Epoch=084, loss=0.6454
Epoch=085, loss=0.6441
Epoch=086, loss=0.6420
Epoch=087, loss=0.6403
Epoch=088, loss=0.6381
Epoch=089, loss=0.6350
Epoch=090, loss=0.6341
Epoch=091, loss=0.6325
Epoch=092, loss=0.6300
Epoch=093, loss=0.6295
Epoch=094, loss=0.6250
Epoch=095, loss=0.6242
Epoch=096, loss=0.6222
Epoch=097, loss=0.6195
Epoch=098, loss=0.6164
Epoch=099, loss=0.6138
Epoch=100, loss=0.6129
Epoch=101, loss=0.6097
Epoch=102, loss=0.6070
Epoch=103, loss=0.6050
Epoch=104, loss=0.6009
Epoch=105, loss=0.5982
Epoch=106, loss=0.5980
Epoch=107, loss=0.5948
Epoch=108, loss=0.5906
Epoch=109, loss=0.5871
Epoch=110, loss=0.5870
Epoch=111, loss=0.5860
Epoch=112, loss=0.5817
Epoch=113, loss=0.5765
Epoch=114, loss=0.5716
Epoch=115, loss=0.5718
Epoch=116, loss=0.5696
Epoch=117, loss=0.5648
Epoch=118, loss=0.5614
Epoch=119, loss=0.5599
Epoch=120, loss=0.5543
Epoch=121, loss=0.5522
Epoch=122, loss=0.5487
Epoch=123, loss=0.5488
Epoch=124, loss=0.5455
Epoch=125, loss=0.5396
Epoch=126, loss=0.5344
Epoch=127, loss=0.5326
Epoch=128, loss=0.5322
Epoch=129, loss=0.5243
Epoch=130, loss=0.5244
Epoch=131, loss=0.5204
Epoch=132, loss=0.5154
Epoch=133, loss=0.5129
Epoch=134, loss=0.5091
Epoch=135, loss=0.5037
Epoch=136, loss=0.5042
Epoch=137, loss=0.4960
Epoch=138, loss=0.4950
Epoch=139, loss=0.4895
Epoch=140, loss=0.4880
Epoch=141, loss=0.4833
Epoch=142, loss=0.4805
Epoch=143, loss=0.4750
Epoch=144, loss=0.4705
Epoch=145, loss=0.4666
Epoch=146, loss=0.4665
Epoch=147, loss=0.4621
Epoch=148, loss=0.4561
Epoch=149, loss=0.4540
Epoch=150, loss=0.4486
Epoch=151, loss=0.4452
Epoch=152, loss=0.4423
Epoch=153, loss=0.4402
Epoch=154, loss=0.4356
Epoch=155, loss=0.4279
Epoch=156, loss=0.4300
Epoch=157, loss=0.4248
Epoch=158, loss=0.4213
Epoch=159, loss=0.4160
Epoch=160, loss=0.4123
Epoch=161, loss=0.4129
Epoch=162, loss=0.4114
Epoch=163, loss=0.4004
Epoch=164, loss=0.3995
Epoch=165, loss=0.3984
Epoch=166, loss=0.3960
Epoch=167, loss=0.3910
Epoch=168, loss=0.3839
Epoch=169, loss=0.3815
Epoch=170, loss=0.3778
Epoch=171, loss=0.3737
Epoch=172, loss=0.3738
Epoch=173, loss=0.3677
Epoch=174, loss=0.3674
Epoch=175, loss=0.3572
Epoch=176, loss=0.3558
Epoch=177, loss=0.3481
Epoch=178, loss=0.3523
Epoch=179, loss=0.3514
Epoch=180, loss=0.3479
Epoch=181, loss=0.3416
Epoch=182, loss=0.3315
Epoch=183, loss=0.3342
Epoch=184, loss=0.3265
Epoch=185, loss=0.3287
Epoch=186, loss=0.3241
Epoch=187, loss=0.3188
Epoch=188, loss=0.3165
Epoch=189, loss=0.3132
Epoch=190, loss=0.3103
Epoch=191, loss=0.3107
Epoch=192, loss=0.2959
Epoch=193, loss=0.3012
Epoch=194, loss=0.3010
Epoch=195, loss=0.2932
Epoch=196, loss=0.3021
Epoch=197, loss=0.2927
Epoch=198, loss=0.2890
Epoch=199, loss=0.2830
Epoch=200, loss=0.2793
Epoch=201, loss=0.2768
Epoch=202, loss=0.2796
Epoch=203, loss=0.2770
Epoch=204, loss=0.2723
Epoch=205, loss=0.2663
Epoch=206, loss=0.2667
Epoch=207, loss=0.2622
Epoch=208, loss=0.2694
Epoch=209, loss=0.2570
Epoch=210, loss=0.2604
Epoch=211, loss=0.2620
Epoch=212, loss=0.2565
Epoch=213, loss=0.2504
Epoch=214, loss=0.2536
Epoch=215, loss=0.2475
Epoch=216, loss=0.2463
Epoch=217, loss=0.2431
Epoch=218, loss=0.2314
Epoch=219, loss=0.2381
Epoch=220, loss=0.2357
Epoch=221, loss=0.2423
Epoch=222, loss=0.2325
Epoch=223, loss=0.2291
Epoch=224, loss=0.2289
Epoch=225, loss=0.2256
Epoch=226, loss=0.2338
Epoch=227, loss=0.2229
Epoch=228, loss=0.2165
Epoch=229, loss=0.2176
Epoch=230, loss=0.2179
Epoch=231, loss=0.2173
Epoch=232, loss=0.2106
Epoch=233, loss=0.2066
Epoch=234, loss=0.2118
Epoch=235, loss=0.2042
Epoch=236, loss=0.2091
Epoch=237, loss=0.1979
Epoch=238, loss=0.1934
Epoch=239, loss=0.1937
Epoch=240, loss=0.1932
Epoch=241, loss=0.1951
Epoch=242, loss=0.1969
Epoch=243, loss=0.2034
Epoch=244, loss=0.1872
Epoch=245, loss=0.1962
Epoch=246, loss=0.1904
Epoch=247, loss=0.1926
Epoch=248, loss=0.1908
Epoch=249, loss=0.1901
Epoch=250, loss=0.1791
Epoch=251, loss=0.1843
Epoch=252, loss=0.1852
Epoch=253, loss=0.1769
Epoch=254, loss=0.1791
Epoch=255, loss=0.1805
Epoch=256, loss=0.1699
Epoch=257, loss=0.1695
Epoch=258, loss=0.1719
Epoch=259, loss=0.1689
Epoch=260, loss=0.1730
Epoch=261, loss=0.1693
Epoch=262, loss=0.1721
Epoch=263, loss=0.1698
Epoch=264, loss=0.1703
Epoch=265, loss=0.1687
Epoch=266, loss=0.1593
Epoch=267, loss=0.1499
Epoch=268, loss=0.1563
Epoch=269, loss=0.1658
Epoch=270, loss=0.1620
Epoch=271, loss=0.1594
Epoch=272, loss=0.1567
Epoch=273, loss=0.1587
Epoch=274, loss=0.1505
Epoch=275, loss=0.1587
Epoch=276, loss=0.1500
Epoch=277, loss=0.1468
Epoch=278, loss=0.1516
Epoch=279, loss=0.1498
Epoch=280, loss=0.1490
Epoch=281, loss=0.1519
Epoch=282, loss=0.1486
Epoch=283, loss=0.1499
Epoch=284, loss=0.1472
Epoch=285, loss=0.1345
Epoch=286, loss=0.1464
Epoch=287, loss=0.1422
Epoch=288, loss=0.1463
Epoch=289, loss=0.1370
Epoch=290, loss=0.1390
Epoch=291, loss=0.1419
Epoch=292, loss=0.1380
Epoch=293, loss=0.1317
Epoch=294, loss=0.1298
Epoch=295, loss=0.1377
Epoch=296, loss=0.1317
Epoch=297, loss=0.1303
Epoch=298, loss=0.1360
Epoch=299, loss=0.1333
Epoch=300, loss=0.1297
Epoch=301, loss=0.1309
Epoch=302, loss=0.1288
Epoch=303, loss=0.1291
Epoch=304, loss=0.1323
Epoch=305, loss=0.1226
Epoch=306, loss=0.1269
Epoch=307, loss=0.1268
Epoch=308, loss=0.1294
Epoch=309, loss=0.1231
Epoch=310, loss=0.1232
Epoch=311, loss=0.1221
Epoch=312, loss=0.1151
Epoch=313, loss=0.1218
Epoch=314, loss=0.1228
Epoch=315, loss=0.1250
Epoch=316, loss=0.1104
Epoch=317, loss=0.1197
Epoch=318, loss=0.1152
Epoch=319, loss=0.1199
Epoch=320, loss=0.1156
Epoch=321, loss=0.1157
Epoch=322, loss=0.1111
Epoch=323, loss=0.1180
Epoch=324, loss=0.1179
Epoch=325, loss=0.1171
Epoch=326, loss=0.1143
Epoch=327, loss=0.1097
Epoch=328, loss=0.1103
Epoch=329, loss=0.1129
Epoch=330, loss=0.1102
Epoch=331, loss=0.1093
Epoch=332, loss=0.1014
Epoch=333, loss=0.1099
Epoch=334, loss=0.1173
Epoch=335, loss=0.1078
Epoch=336, loss=0.0994
Epoch=337, loss=0.1014
Epoch=338, loss=0.1102
Epoch=339, loss=0.1116
Epoch=340, loss=0.1015
Epoch=341, loss=0.1077
Epoch=342, loss=0.0984
Epoch=343, loss=0.1041
Epoch=344, loss=0.1005
Epoch=345, loss=0.1055
Epoch=346, loss=0.0954
Epoch=347, loss=0.0972
Epoch=348, loss=0.0935
Epoch=349, loss=0.0953
Epoch=350, loss=0.1030
Epoch=351, loss=0.0958
Epoch=352, loss=0.1009
Epoch=353, loss=0.0981
Epoch=354, loss=0.0950
Epoch=355, loss=0.0982
Epoch=356, loss=0.0906
Epoch=357, loss=0.1061
Epoch=358, loss=0.0944
Epoch=359, loss=0.0940
Epoch=360, loss=0.0926
Epoch=361, loss=0.0952
Epoch=362, loss=0.0933
Epoch=363, loss=0.0984
Epoch=364, loss=0.0949
Epoch=365, loss=0.0871
Epoch=366, loss=0.0989
Epoch=367, loss=0.0898
Epoch=368, loss=0.0972
Epoch=369, loss=0.0898
Epoch=370, loss=0.0929
Epoch=371, loss=0.0884
Epoch=372, loss=0.1023
Epoch=373, loss=0.0878
Epoch=374, loss=0.0888
Epoch=375, loss=0.0927
Epoch=376, loss=0.0897
Epoch=377, loss=0.0936
Epoch=378, loss=0.0805
Epoch=379, loss=0.0857
Epoch=380, loss=0.0763
Epoch=381, loss=0.0816
Epoch=382, loss=0.0952
Epoch=383, loss=0.0898
Epoch=384, loss=0.0868
Epoch=385, loss=0.0810
Epoch=386, loss=0.0860
Epoch=387, loss=0.0865
Epoch=388, loss=0.0749
Epoch=389, loss=0.0839
Epoch=390, loss=0.0892
Epoch=391, loss=0.0888
Epoch=392, loss=0.0843
Epoch=393, loss=0.0884
Epoch=394, loss=0.0819
Epoch=395, loss=0.0904
Epoch=396, loss=0.1037
Epoch=397, loss=0.0866
Epoch=398, loss=0.0846
Epoch=399, loss=0.0863
Epoch=400, loss=0.0828
Epoch=401, loss=0.0861
Epoch=402, loss=0.0781
Epoch=403, loss=0.0900
Epoch=404, loss=0.0841
Epoch=405, loss=0.0797
Epoch=406, loss=0.0861
Epoch=407, loss=0.0789
Epoch=408, loss=0.0809
Early stopping!
Loading 388th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.6752+-0.0125, F1Ma=0.5862+-0.0286, acc=0.6752+-0.0125
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6924
Epoch=009, loss=0.6923
Epoch=010, loss=0.6922
Epoch=011, loss=0.6920
Epoch=012, loss=0.6918
Epoch=013, loss=0.6916
Epoch=014, loss=0.6913
Epoch=015, loss=0.6910
Epoch=016, loss=0.6907
Epoch=017, loss=0.6904
Epoch=018, loss=0.6901
Epoch=019, loss=0.6896
Epoch=020, loss=0.6891
Epoch=021, loss=0.6887
Epoch=022, loss=0.6882
Epoch=023, loss=0.6877
Epoch=024, loss=0.6870
Epoch=025, loss=0.6862
Epoch=026, loss=0.6855
Epoch=027, loss=0.6849
Epoch=028, loss=0.6839
Epoch=029, loss=0.6830
Epoch=030, loss=0.6821
Epoch=031, loss=0.6809
Epoch=032, loss=0.6799
Epoch=033, loss=0.6786
Epoch=034, loss=0.6774
Epoch=035, loss=0.6761
Epoch=036, loss=0.6740
Epoch=037, loss=0.6725
Epoch=038, loss=0.6708
Epoch=039, loss=0.6695
Epoch=040, loss=0.6675
Epoch=041, loss=0.6652
Epoch=042, loss=0.6627
Epoch=043, loss=0.6609
Epoch=044, loss=0.6587
Epoch=045, loss=0.6558
Epoch=046, loss=0.6533
Epoch=047, loss=0.6511
Epoch=048, loss=0.6486
Epoch=049, loss=0.6447
Epoch=050, loss=0.6413
Epoch=051, loss=0.6381
Epoch=052, loss=0.6354
Epoch=053, loss=0.6319
Epoch=054, loss=0.6275
Epoch=055, loss=0.6249
Epoch=056, loss=0.6191
Epoch=057, loss=0.6160
Epoch=058, loss=0.6113
Epoch=059, loss=0.6068
Epoch=060, loss=0.6023
Epoch=061, loss=0.5984
Epoch=062, loss=0.5907
Epoch=063, loss=0.5857
Epoch=064, loss=0.5812
Epoch=065, loss=0.5757
Epoch=066, loss=0.5700
Epoch=067, loss=0.5658
Epoch=068, loss=0.5607
Epoch=069, loss=0.5520
Epoch=070, loss=0.5442
Epoch=071, loss=0.5414
Epoch=072, loss=0.5337
Epoch=073, loss=0.5293
Epoch=074, loss=0.5207
Epoch=075, loss=0.5138
Epoch=076, loss=0.5066
Epoch=077, loss=0.5022
Epoch=078, loss=0.4929
Epoch=079, loss=0.4861
Epoch=080, loss=0.4796
Epoch=081, loss=0.4753
Epoch=082, loss=0.4668
Epoch=083, loss=0.4602
Epoch=084, loss=0.4508
Epoch=085, loss=0.4420
Epoch=086, loss=0.4336
Epoch=087, loss=0.4290
Epoch=088, loss=0.4229
Epoch=089, loss=0.4134
Epoch=090, loss=0.4081
Epoch=091, loss=0.3975
Epoch=092, loss=0.3902
Epoch=093, loss=0.3838
Epoch=094, loss=0.3778
Epoch=095, loss=0.3717
Epoch=096, loss=0.3599
Epoch=097, loss=0.3591
Epoch=098, loss=0.3455
Epoch=099, loss=0.3431
Epoch=100, loss=0.3326
Epoch=101, loss=0.3266
Epoch=102, loss=0.3195
Epoch=103, loss=0.3222
Epoch=104, loss=0.3102
Epoch=105, loss=0.3023
Epoch=106, loss=0.3031
Epoch=107, loss=0.2946
Epoch=108, loss=0.2876
Epoch=109, loss=0.2768
Epoch=110, loss=0.2691
Epoch=111, loss=0.2760
Epoch=112, loss=0.2670
Epoch=113, loss=0.2507
Epoch=114, loss=0.2523
Epoch=115, loss=0.2482
Epoch=116, loss=0.2403
Epoch=117, loss=0.2322
Epoch=118, loss=0.2268
Epoch=119, loss=0.2309
Epoch=120, loss=0.2263
Epoch=121, loss=0.2180
Epoch=122, loss=0.2123
Epoch=123, loss=0.2164
Epoch=124, loss=0.2050
Epoch=125, loss=0.2087
Epoch=126, loss=0.1994
Epoch=127, loss=0.1995
Epoch=128, loss=0.2009
Epoch=129, loss=0.1927
Epoch=130, loss=0.1860
Epoch=131, loss=0.1905
Epoch=132, loss=0.1778
Epoch=133, loss=0.1684
Epoch=134, loss=0.1694
Epoch=135, loss=0.1678
Epoch=136, loss=0.1668
Epoch=137, loss=0.1683
Epoch=138, loss=0.1663
Epoch=139, loss=0.1654
Epoch=140, loss=0.1578
Epoch=141, loss=0.1606
Epoch=142, loss=0.1544
Epoch=143, loss=0.1521
Epoch=144, loss=0.1465
Epoch=145, loss=0.1506
Epoch=146, loss=0.1444
Epoch=147, loss=0.1455
Epoch=148, loss=0.1443
Epoch=149, loss=0.1439
Epoch=150, loss=0.1474
Epoch=151, loss=0.1368
Epoch=152, loss=0.1351
Epoch=153, loss=0.1332
Epoch=154, loss=0.1341
Epoch=155, loss=0.1318
Epoch=156, loss=0.1302
Epoch=157, loss=0.1250
Epoch=158, loss=0.1300
Epoch=159, loss=0.1181
Epoch=160, loss=0.1205
Epoch=161, loss=0.1200
Epoch=162, loss=0.1165
Epoch=163, loss=0.1240
Epoch=164, loss=0.1219
Epoch=165, loss=0.1093
Epoch=166, loss=0.1218
Epoch=167, loss=0.1142
Epoch=168, loss=0.1212
Epoch=169, loss=0.1075
Epoch=170, loss=0.1133
Epoch=171, loss=0.1105
Epoch=172, loss=0.1129
Epoch=173, loss=0.1094
Epoch=174, loss=0.1041
Epoch=175, loss=0.0987
Epoch=176, loss=0.1015
Epoch=177, loss=0.1032
Epoch=178, loss=0.0958
Epoch=179, loss=0.1008
Epoch=180, loss=0.0993
Epoch=181, loss=0.1000
Epoch=182, loss=0.1056
Epoch=183, loss=0.0980
Epoch=184, loss=0.0999
Epoch=185, loss=0.0971
Epoch=186, loss=0.1006
Epoch=187, loss=0.0899
Epoch=188, loss=0.0868
Epoch=189, loss=0.0945
Epoch=190, loss=0.0936
Epoch=191, loss=0.0909
Epoch=192, loss=0.0877
Epoch=193, loss=0.0915
Epoch=194, loss=0.0917
Epoch=195, loss=0.0872
Epoch=196, loss=0.0857
Epoch=197, loss=0.0872
Epoch=198, loss=0.0851
Epoch=199, loss=0.0848
Epoch=200, loss=0.0993
Epoch=201, loss=0.0793
Epoch=202, loss=0.0779
Epoch=203, loss=0.0824
Epoch=204, loss=0.0893
Epoch=205, loss=0.0786
Epoch=206, loss=0.0786
Epoch=207, loss=0.0777
Epoch=208, loss=0.0705
Epoch=209, loss=0.0790
Epoch=210, loss=0.0734
Epoch=211, loss=0.0679
Epoch=212, loss=0.0804
Epoch=213, loss=0.0847
Epoch=214, loss=0.0830
Epoch=215, loss=0.0790
Epoch=216, loss=0.0705
Epoch=217, loss=0.0689
Epoch=218, loss=0.0740
Epoch=219, loss=0.0771
Epoch=220, loss=0.0849
Epoch=221, loss=0.0693
Epoch=222, loss=0.0756
Epoch=223, loss=0.0792
Epoch=224, loss=0.0734
Epoch=225, loss=0.0638
Epoch=226, loss=0.0656
Epoch=227, loss=0.0766
Epoch=228, loss=0.0742
Epoch=229, loss=0.0707
Epoch=230, loss=0.0687
Epoch=231, loss=0.0714
Epoch=232, loss=0.0660
Epoch=233, loss=0.0705
Epoch=234, loss=0.0637
Epoch=235, loss=0.0679
Epoch=236, loss=0.0582
Epoch=237, loss=0.0649
Epoch=238, loss=0.0604
Epoch=239, loss=0.0624
Epoch=240, loss=0.0686
Epoch=241, loss=0.0712
Epoch=242, loss=0.0610
Epoch=243, loss=0.0615
Epoch=244, loss=0.0729
Epoch=245, loss=0.0581
Epoch=246, loss=0.0603
Epoch=247, loss=0.0639
Epoch=248, loss=0.0646
Epoch=249, loss=0.0778
Epoch=250, loss=0.0589
Epoch=251, loss=0.0722
Epoch=252, loss=0.0514
Epoch=253, loss=0.0652
Epoch=254, loss=0.0629
Epoch=255, loss=0.0609
Epoch=256, loss=0.0583
Epoch=257, loss=0.0588
Epoch=258, loss=0.0668
Epoch=259, loss=0.0632
Epoch=260, loss=0.0645
Epoch=261, loss=0.0624
Epoch=262, loss=0.0563
Epoch=263, loss=0.0621
Epoch=264, loss=0.0619
Epoch=265, loss=0.0608
Epoch=266, loss=0.0575
Epoch=267, loss=0.0509
Epoch=268, loss=0.0667
Epoch=269, loss=0.0503
Epoch=270, loss=0.0587
Epoch=271, loss=0.0584
Epoch=272, loss=0.0545
Epoch=273, loss=0.0609
Epoch=274, loss=0.0504
Epoch=275, loss=0.0522
Epoch=276, loss=0.0573
Epoch=277, loss=0.0541
Epoch=278, loss=0.0559
Epoch=279, loss=0.0551
Epoch=280, loss=0.0577
Epoch=281, loss=0.0561
Epoch=282, loss=0.0487
Epoch=283, loss=0.0605
Epoch=284, loss=0.0558
Epoch=285, loss=0.0480
Epoch=286, loss=0.0610
Epoch=287, loss=0.0573
Epoch=288, loss=0.0482
Epoch=289, loss=0.0465
Epoch=290, loss=0.0514
Epoch=291, loss=0.0573
Epoch=292, loss=0.0539
Epoch=293, loss=0.0483
Epoch=294, loss=0.0537
Epoch=295, loss=0.0509
Epoch=296, loss=0.0535
Epoch=297, loss=0.0557
Epoch=298, loss=0.0542
Epoch=299, loss=0.0526
Epoch=300, loss=0.0482
Epoch=301, loss=0.0462
Epoch=302, loss=0.0460
Epoch=303, loss=0.0490
Epoch=304, loss=0.0412
Epoch=305, loss=0.0459
Epoch=306, loss=0.0471
Epoch=307, loss=0.0484
Epoch=308, loss=0.0496
Epoch=309, loss=0.0445
Epoch=310, loss=0.0491
Epoch=311, loss=0.0564
Epoch=312, loss=0.0498
Epoch=313, loss=0.0518
Epoch=314, loss=0.0414
Epoch=315, loss=0.0467
Epoch=316, loss=0.0451
Epoch=317, loss=0.0424
Epoch=318, loss=0.0479
Epoch=319, loss=0.0419
Epoch=320, loss=0.0412
Epoch=321, loss=0.0438
Epoch=322, loss=0.0480
Epoch=323, loss=0.0366
Epoch=324, loss=0.0452
Epoch=325, loss=0.0472
Epoch=326, loss=0.0369
Epoch=327, loss=0.0341
Epoch=328, loss=0.0443
Epoch=329, loss=0.0540
Epoch=330, loss=0.0475
Epoch=331, loss=0.0415
Epoch=332, loss=0.0424
Epoch=333, loss=0.0493
Epoch=334, loss=0.0377
Epoch=335, loss=0.0383
Epoch=336, loss=0.0449
Epoch=337, loss=0.0445
Epoch=338, loss=0.0461
Epoch=339, loss=0.0463
Epoch=340, loss=0.0366
Epoch=341, loss=0.0476
Epoch=342, loss=0.0377
Epoch=343, loss=0.0427
Epoch=344, loss=0.0380
Epoch=345, loss=0.0490
Epoch=346, loss=0.0360
Epoch=347, loss=0.0395
Early stopping!
Loading 327th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7782+-0.0177, F1Ma=0.7467+-0.0260, acc=0.7782+-0.0177
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7949274913335939, 0.7936294776105425, 0.7968865332752432, 0.8041397451550721, 0.8500000238418579, 0.75, 0.7282398343086243, 0.8642857074737549, 0.75, 0.7325918674468994, 0.7782355227361057, 0.017661372400592245, 0.7466764967358541, 0.025961118195880793, 0.7782355227361057, 0.017661372400592245]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6923
Epoch=005, loss=0.6920
Epoch=006, loss=0.6916
Epoch=007, loss=0.6912
Epoch=008, loss=0.6907
Epoch=009, loss=0.6900
Epoch=010, loss=0.6894
Epoch=011, loss=0.6885
Epoch=012, loss=0.6874
Epoch=013, loss=0.6864
Epoch=014, loss=0.6853
Epoch=015, loss=0.6838
Epoch=016, loss=0.6824
Epoch=017, loss=0.6805
Epoch=018, loss=0.6784
Epoch=019, loss=0.6764
Epoch=020, loss=0.6740
Epoch=021, loss=0.6713
Epoch=022, loss=0.6683
Epoch=023, loss=0.6650
Epoch=024, loss=0.6622
Epoch=025, loss=0.6583
Epoch=026, loss=0.6534
Epoch=027, loss=0.6490
Epoch=028, loss=0.6443
Epoch=029, loss=0.6387
Epoch=030, loss=0.6335
Epoch=031, loss=0.6264
Epoch=032, loss=0.6193
Epoch=033, loss=0.6126
Epoch=034, loss=0.6053
Epoch=035, loss=0.5976
Epoch=036, loss=0.5899
Epoch=037, loss=0.5799
Epoch=038, loss=0.5699
Epoch=039, loss=0.5600
Epoch=040, loss=0.5513
Epoch=041, loss=0.5383
Epoch=042, loss=0.5315
Epoch=043, loss=0.5181
Epoch=044, loss=0.5071
Epoch=045, loss=0.4992
Epoch=046, loss=0.4872
Epoch=047, loss=0.4728
Epoch=048, loss=0.4628
Epoch=049, loss=0.4474
Epoch=050, loss=0.4348
Epoch=051, loss=0.4246
Epoch=052, loss=0.4072
Epoch=053, loss=0.3960
Epoch=054, loss=0.3844
Epoch=055, loss=0.3715
Epoch=056, loss=0.3523
Epoch=057, loss=0.3477
Epoch=058, loss=0.3337
Epoch=059, loss=0.3201
Epoch=060, loss=0.3126
Epoch=061, loss=0.2982
Epoch=062, loss=0.2870
Epoch=063, loss=0.2704
Epoch=064, loss=0.2632
Epoch=065, loss=0.2475
Epoch=066, loss=0.2375
Epoch=067, loss=0.2358
Epoch=068, loss=0.2236
Epoch=069, loss=0.2159
Epoch=070, loss=0.2128
Epoch=071, loss=0.2075
Epoch=072, loss=0.1947
Epoch=073, loss=0.1831
Epoch=074, loss=0.1759
Epoch=075, loss=0.1730
Epoch=076, loss=0.1743
Epoch=077, loss=0.1636
Epoch=078, loss=0.1614
Epoch=079, loss=0.1581
Epoch=080, loss=0.1566
Epoch=081, loss=0.1515
Epoch=082, loss=0.1458
Epoch=083, loss=0.1357
Epoch=084, loss=0.1347
Epoch=085, loss=0.1292
Epoch=086, loss=0.1261
Epoch=087, loss=0.1199
Epoch=088, loss=0.1202
Epoch=089, loss=0.1116
Epoch=090, loss=0.1122
Epoch=091, loss=0.1177
Epoch=092, loss=0.1219
Epoch=093, loss=0.1182
Epoch=094, loss=0.1051
Epoch=095, loss=0.1092
Epoch=096, loss=0.1154
Epoch=097, loss=0.1176
Epoch=098, loss=0.0991
Epoch=099, loss=0.1136
Epoch=100, loss=0.1061
Epoch=101, loss=0.1013
Epoch=102, loss=0.0963
Epoch=103, loss=0.0908
Epoch=104, loss=0.0986
Epoch=105, loss=0.1014
Epoch=106, loss=0.0894
Epoch=107, loss=0.0874
Epoch=108, loss=0.1061
Epoch=109, loss=0.0888
Epoch=110, loss=0.0870
Epoch=111, loss=0.0764
Epoch=112, loss=0.0879
Epoch=113, loss=0.0862
Epoch=114, loss=0.0951
Epoch=115, loss=0.0757
Epoch=116, loss=0.0869
Epoch=117, loss=0.0800
Epoch=118, loss=0.0717
Epoch=119, loss=0.0689
Epoch=120, loss=0.0964
Epoch=121, loss=0.0774
Epoch=122, loss=0.0698
Epoch=123, loss=0.0807
Epoch=124, loss=0.0766
Epoch=125, loss=0.0727
Epoch=126, loss=0.0678
Epoch=127, loss=0.0800
Epoch=128, loss=0.0614
Epoch=129, loss=0.0754
Epoch=130, loss=0.0709
Epoch=131, loss=0.0700
Epoch=132, loss=0.0770
Epoch=133, loss=0.0649
Epoch=134, loss=0.0641
Epoch=135, loss=0.0672
Epoch=136, loss=0.0753
Epoch=137, loss=0.0703
Epoch=138, loss=0.0680
Epoch=139, loss=0.0674
Epoch=140, loss=0.0706
Epoch=141, loss=0.0608
Epoch=142, loss=0.0619
Epoch=143, loss=0.0675
Epoch=144, loss=0.0609
Epoch=145, loss=0.0713
Epoch=146, loss=0.0630
Epoch=147, loss=0.0722
Epoch=148, loss=0.0717
Epoch=149, loss=0.0650
Epoch=150, loss=0.0569
Epoch=151, loss=0.0757
Epoch=152, loss=0.0774
Epoch=153, loss=0.0686
Epoch=154, loss=0.0660
Epoch=155, loss=0.0575
Epoch=156, loss=0.0809
Epoch=157, loss=0.0666
Epoch=158, loss=0.0575
Epoch=159, loss=0.0536
Epoch=160, loss=0.0608
Epoch=161, loss=0.0579
Epoch=162, loss=0.0624
Epoch=163, loss=0.0499
Epoch=164, loss=0.0559
Epoch=165, loss=0.0581
Epoch=166, loss=0.0554
Epoch=167, loss=0.0580
Epoch=168, loss=0.0571
Epoch=169, loss=0.0606
Epoch=170, loss=0.0578
Epoch=171, loss=0.0497
Epoch=172, loss=0.0609
Epoch=173, loss=0.0546
Epoch=174, loss=0.0570
Epoch=175, loss=0.0482
Epoch=176, loss=0.0523
Epoch=177, loss=0.0512
Epoch=178, loss=0.0575
Epoch=179, loss=0.0470
Epoch=180, loss=0.0633
Epoch=181, loss=0.0580
Epoch=182, loss=0.0605
Epoch=183, loss=0.0430
Epoch=184, loss=0.0503
Epoch=185, loss=0.0559
Epoch=186, loss=0.0457
Epoch=187, loss=0.0522
Epoch=188, loss=0.0532
Epoch=189, loss=0.0504
Epoch=190, loss=0.0631
Epoch=191, loss=0.0549
Epoch=192, loss=0.0459
Epoch=193, loss=0.0661
Epoch=194, loss=0.0458
Epoch=195, loss=0.0463
Epoch=196, loss=0.0577
Epoch=197, loss=0.0429
Epoch=198, loss=0.0460
Epoch=199, loss=0.0447
Epoch=200, loss=0.0504
Epoch=201, loss=0.0537
Epoch=202, loss=0.0511
Epoch=203, loss=0.0479
Epoch=204, loss=0.0575
Epoch=205, loss=0.0512
Epoch=206, loss=0.0463
Epoch=207, loss=0.0502
Epoch=208, loss=0.0387
Epoch=209, loss=0.0480
Epoch=210, loss=0.0481
Epoch=211, loss=0.0393
Epoch=212, loss=0.0431
Epoch=213, loss=0.0511
Epoch=214, loss=0.0435
Epoch=215, loss=0.0453
Epoch=216, loss=0.0486
Epoch=217, loss=0.0467
Epoch=218, loss=0.0351
Epoch=219, loss=0.0486
Epoch=220, loss=0.0477
Epoch=221, loss=0.0359
Epoch=222, loss=0.0446
Epoch=223, loss=0.0426
Epoch=224, loss=0.0483
Epoch=225, loss=0.0504
Epoch=226, loss=0.0402
Epoch=227, loss=0.0378
Epoch=228, loss=0.0406
Epoch=229, loss=0.0404
Epoch=230, loss=0.0403
Epoch=231, loss=0.0395
Epoch=232, loss=0.0504
Epoch=233, loss=0.0398
Epoch=234, loss=0.0442
Epoch=235, loss=0.0382
Epoch=236, loss=0.0420
Epoch=237, loss=0.0397
Epoch=238, loss=0.0413
Early stopping!
Loading 218th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8012+-0.0059, F1Ma=0.7809+-0.0059, acc=0.8012+-0.0059
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7949274913335939, 0.7936294776105425, 0.7968865332752432, 0.8041397451550721, 0.8500000238418579, 0.75, 0.7282398343086243, 0.8642857074737549, 0.75, 0.7325918674468994, 0.7782355227361057, 0.017661372400592245, 0.7466764967358541, 0.025961118195880793, 0.7782355227361057, 0.017661372400592245], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7702552419444524, 0.7630099050530339, 0.7734716216167559, 0.7727307424902319, 0.8928571343421936, 0.7900000214576721, 0.7717601656913757, 0.8928571343421936, 0.7900000214576721, 0.7707930207252502, 0.8011659541391373, 0.005892139497317471, 0.780946215483067, 0.005941583424789998, 0.8011659541391373, 0.005892139497317451]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6920
Epoch=003, loss=0.6911
Epoch=004, loss=0.6901
Epoch=005, loss=0.6886
Epoch=006, loss=0.6868
Epoch=007, loss=0.6846
Epoch=008, loss=0.6821
Epoch=009, loss=0.6787
Epoch=010, loss=0.6745
Epoch=011, loss=0.6703
Epoch=012, loss=0.6644
Epoch=013, loss=0.6592
Epoch=014, loss=0.6517
Epoch=015, loss=0.6439
Epoch=016, loss=0.6344
Epoch=017, loss=0.6246
Epoch=018, loss=0.6145
Epoch=019, loss=0.6006
Epoch=020, loss=0.5888
Epoch=021, loss=0.5730
Epoch=022, loss=0.5610
Epoch=023, loss=0.5401
Epoch=024, loss=0.5224
Epoch=025, loss=0.5034
Epoch=026, loss=0.4872
Epoch=027, loss=0.4652
Epoch=028, loss=0.4445
Epoch=029, loss=0.4245
Epoch=030, loss=0.4040
Epoch=031, loss=0.3835
Epoch=032, loss=0.3629
Epoch=033, loss=0.3409
Epoch=034, loss=0.3265
Epoch=035, loss=0.3093
Epoch=036, loss=0.2923
Epoch=037, loss=0.2692
Epoch=038, loss=0.2568
Epoch=039, loss=0.2524
Epoch=040, loss=0.2280
Epoch=041, loss=0.2262
Epoch=042, loss=0.2023
Epoch=043, loss=0.1928
Epoch=044, loss=0.1862
Epoch=045, loss=0.1848
Epoch=046, loss=0.1756
Epoch=047, loss=0.1630
Epoch=048, loss=0.1533
Epoch=049, loss=0.1520
Epoch=050, loss=0.1460
Epoch=051, loss=0.1337
Epoch=052, loss=0.1384
Epoch=053, loss=0.1235
Epoch=054, loss=0.1182
Epoch=055, loss=0.1128
Epoch=056, loss=0.1172
Epoch=057, loss=0.1124
Epoch=058, loss=0.1095
Epoch=059, loss=0.1028
Epoch=060, loss=0.1094
Epoch=061, loss=0.1012
Epoch=062, loss=0.1026
Epoch=063, loss=0.1023
Epoch=064, loss=0.0897
Epoch=065, loss=0.0839
Epoch=066, loss=0.0839
Epoch=067, loss=0.0920
Epoch=068, loss=0.0837
Epoch=069, loss=0.0885
Epoch=070, loss=0.0858
Epoch=071, loss=0.0771
Epoch=072, loss=0.0868
Epoch=073, loss=0.0757
Epoch=074, loss=0.0752
Epoch=075, loss=0.0684
Epoch=076, loss=0.0981
Epoch=077, loss=0.0827
Epoch=078, loss=0.0909
Epoch=079, loss=0.0821
Epoch=080, loss=0.0599
Epoch=081, loss=0.0669
Epoch=082, loss=0.0724
Epoch=083, loss=0.0749
Epoch=084, loss=0.0596
Epoch=085, loss=0.0670
Epoch=086, loss=0.0791
Epoch=087, loss=0.0790
Epoch=088, loss=0.0649
Epoch=089, loss=0.0655
Epoch=090, loss=0.0605
Epoch=091, loss=0.0598
Epoch=092, loss=0.0712
Epoch=093, loss=0.0638
Epoch=094, loss=0.0527
Epoch=095, loss=0.0753
Epoch=096, loss=0.0672
Epoch=097, loss=0.0693
Epoch=098, loss=0.0701
Epoch=099, loss=0.0563
Epoch=100, loss=0.0714
Epoch=101, loss=0.0541
Epoch=102, loss=0.0590
Epoch=103, loss=0.0604
Epoch=104, loss=0.0735
Epoch=105, loss=0.0695
Epoch=106, loss=0.0632
Epoch=107, loss=0.0620
Epoch=108, loss=0.0592
Epoch=109, loss=0.0585
Epoch=110, loss=0.0468
Epoch=111, loss=0.0485
Epoch=112, loss=0.0544
Epoch=113, loss=0.0672
Epoch=114, loss=0.0668
Epoch=115, loss=0.0561
Epoch=116, loss=0.0514
Epoch=117, loss=0.0607
Epoch=118, loss=0.0557
Epoch=119, loss=0.0560
Epoch=120, loss=0.0519
Epoch=121, loss=0.0511
Epoch=122, loss=0.0475
Epoch=123, loss=0.0482
Epoch=124, loss=0.0491
Epoch=125, loss=0.0507
Epoch=126, loss=0.0507
Epoch=127, loss=0.0464
Epoch=128, loss=0.0496
Epoch=129, loss=0.0449
Epoch=130, loss=0.0422
Epoch=131, loss=0.0417
Epoch=132, loss=0.0484
Epoch=133, loss=0.0553
Epoch=134, loss=0.0448
Epoch=135, loss=0.0429
Epoch=136, loss=0.0480
Epoch=137, loss=0.0458
Epoch=138, loss=0.0553
Epoch=139, loss=0.0601
Epoch=140, loss=0.0576
Epoch=141, loss=0.0399
Epoch=142, loss=0.0527
Epoch=143, loss=0.0449
Epoch=144, loss=0.0493
Epoch=145, loss=0.0487
Epoch=146, loss=0.0419
Epoch=147, loss=0.0464
Epoch=148, loss=0.0348
Epoch=149, loss=0.0399
Epoch=150, loss=0.0418
Epoch=151, loss=0.0406
Epoch=152, loss=0.0424
Epoch=153, loss=0.0492
Epoch=154, loss=0.0496
Epoch=155, loss=0.0448
Epoch=156, loss=0.0527
Epoch=157, loss=0.0352
Epoch=158, loss=0.0483
Epoch=159, loss=0.0480
Epoch=160, loss=0.0481
Epoch=161, loss=0.0417
Epoch=162, loss=0.0294
Epoch=163, loss=0.0392
Epoch=164, loss=0.0427
Epoch=165, loss=0.0462
Epoch=166, loss=0.0534
Epoch=167, loss=0.0344
Epoch=168, loss=0.0489
Epoch=169, loss=0.0386
Epoch=170, loss=0.0488
Epoch=171, loss=0.0395
Epoch=172, loss=0.0438
Epoch=173, loss=0.0417
Epoch=174, loss=0.0526
Epoch=175, loss=0.0398
Epoch=176, loss=0.0348
Epoch=177, loss=0.0433
Epoch=178, loss=0.0437
Epoch=179, loss=0.0473
Epoch=180, loss=0.0473
Epoch=181, loss=0.0319
Epoch=182, loss=0.0501
Early stopping!
Loading 162th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8038+-0.0064, F1Ma=0.7841+-0.0042, acc=0.8038+-0.0064
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7949274913335939, 0.7936294776105425, 0.7968865332752432, 0.8041397451550721, 0.8500000238418579, 0.75, 0.7282398343086243, 0.8642857074737549, 0.75, 0.7325918674468994, 0.7782355227361057, 0.017661372400592245, 0.7466764967358541, 0.025961118195880793, 0.7782355227361057, 0.017661372400592245], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7702552419444524, 0.7630099050530339, 0.7734716216167559, 0.7727307424902319, 0.8928571343421936, 0.7900000214576721, 0.7717601656913757, 0.8928571343421936, 0.7900000214576721, 0.7707930207252502, 0.8011659541391373, 0.005892139497317471, 0.780946215483067, 0.005941583424789998, 0.8011659541391373, 0.005892139497317451], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7747462981100721, 0.7652553075645037, 0.7625815093130355, 0.7637523524142221, 0.9428571462631226, 0.7960000038146973, 0.7780464291572571, 0.9428571462631226, 0.7940000295639038, 0.7765957713127136, 0.8038087835211816, 0.006421104213933446, 0.784073404707826, 0.004209800366480077, 0.8038087835211816, 0.006421104213933428]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6918
Epoch=002, loss=0.6893
Epoch=003, loss=0.6858
Epoch=004, loss=0.6810
Epoch=005, loss=0.6750
Epoch=006, loss=0.6675
Epoch=007, loss=0.6588
Epoch=008, loss=0.6464
Epoch=009, loss=0.6334
Epoch=010, loss=0.6186
Epoch=011, loss=0.5976
Epoch=012, loss=0.5798
Epoch=013, loss=0.5612
Epoch=014, loss=0.5378
Epoch=015, loss=0.5120
Epoch=016, loss=0.4852
Epoch=017, loss=0.4574
Epoch=018, loss=0.4247
Epoch=019, loss=0.4034
Epoch=020, loss=0.3715
Epoch=021, loss=0.3493
Epoch=022, loss=0.3147
Epoch=023, loss=0.2958
Epoch=024, loss=0.2810
Epoch=025, loss=0.2556
Epoch=026, loss=0.2371
Epoch=027, loss=0.2275
Epoch=028, loss=0.2139
Epoch=029, loss=0.1984
Epoch=030, loss=0.1840
Epoch=031, loss=0.1664
Epoch=032, loss=0.1635
Epoch=033, loss=0.1474
Epoch=034, loss=0.1465
Epoch=035, loss=0.1440
Epoch=036, loss=0.1322
Epoch=037, loss=0.1291
Epoch=038, loss=0.1187
Epoch=039, loss=0.1109
Epoch=040, loss=0.1110
Epoch=041, loss=0.1088
Epoch=042, loss=0.0896
Epoch=043, loss=0.1244
Epoch=044, loss=0.1014
Epoch=045, loss=0.1019
Epoch=046, loss=0.0971
Epoch=047, loss=0.1051
Epoch=048, loss=0.0966
Epoch=049, loss=0.0997
Epoch=050, loss=0.0916
Epoch=051, loss=0.0972
Epoch=052, loss=0.0861
Epoch=053, loss=0.0801
Epoch=054, loss=0.0801
Epoch=055, loss=0.0705
Epoch=056, loss=0.0850
Epoch=057, loss=0.0668
Epoch=058, loss=0.0766
Epoch=059, loss=0.0783
Epoch=060, loss=0.0798
Epoch=061, loss=0.0743
Epoch=062, loss=0.0671
Epoch=063, loss=0.0602
Epoch=064, loss=0.0663
Epoch=065, loss=0.0763
Epoch=066, loss=0.0609
Epoch=067, loss=0.0672
Epoch=068, loss=0.0791
Epoch=069, loss=0.0790
Epoch=070, loss=0.0680
Epoch=071, loss=0.0600
Epoch=072, loss=0.0724
Epoch=073, loss=0.0664
Epoch=074, loss=0.0633
Epoch=075, loss=0.0482
Epoch=076, loss=0.0591
Epoch=077, loss=0.0548
Epoch=078, loss=0.0540
Epoch=079, loss=0.0475
Epoch=080, loss=0.0491
Epoch=081, loss=0.0560
Epoch=082, loss=0.0536
Epoch=083, loss=0.0620
Epoch=084, loss=0.0654
Epoch=085, loss=0.0584
Epoch=086, loss=0.0519
Epoch=087, loss=0.0458
Epoch=088, loss=0.0422
Epoch=089, loss=0.0447
Epoch=090, loss=0.0401
Epoch=091, loss=0.0467
Epoch=092, loss=0.0478
Epoch=093, loss=0.0566
Epoch=094, loss=0.0431
Epoch=095, loss=0.0415
Epoch=096, loss=0.0426
Epoch=097, loss=0.0501
Epoch=098, loss=0.0351
Epoch=099, loss=0.0514
Epoch=100, loss=0.0367
Epoch=101, loss=0.0419
Epoch=102, loss=0.0453
Epoch=103, loss=0.0358
Epoch=104, loss=0.0374
Epoch=105, loss=0.0391
Epoch=106, loss=0.0398
Epoch=107, loss=0.0317
Epoch=108, loss=0.0298
Epoch=109, loss=0.0423
Epoch=110, loss=0.0468
Epoch=111, loss=0.0370
Epoch=112, loss=0.0499
Epoch=113, loss=0.0306
Epoch=114, loss=0.0342
Epoch=115, loss=0.0330
Epoch=116, loss=0.0436
Epoch=117, loss=0.0320
Epoch=118, loss=0.0377
Epoch=119, loss=0.0382
Epoch=120, loss=0.0370
Epoch=121, loss=0.0309
Epoch=122, loss=0.0360
Epoch=123, loss=0.0271
Epoch=124, loss=0.0296
Epoch=125, loss=0.0277
Epoch=126, loss=0.0315
Epoch=127, loss=0.0324
Epoch=128, loss=0.0301
Epoch=129, loss=0.0339
Epoch=130, loss=0.0291
Epoch=131, loss=0.0269
Epoch=132, loss=0.0339
Epoch=133, loss=0.0250
Epoch=134, loss=0.0306
Epoch=135, loss=0.0353
Epoch=136, loss=0.0347
Epoch=137, loss=0.0364
Epoch=138, loss=0.0357
Epoch=139, loss=0.0366
Epoch=140, loss=0.0362
Epoch=141, loss=0.0212
Epoch=142, loss=0.0266
Epoch=143, loss=0.0322
Epoch=144, loss=0.0353
Epoch=145, loss=0.0279
Epoch=146, loss=0.0294
Epoch=147, loss=0.0238
Epoch=148, loss=0.0224
Epoch=149, loss=0.0236
Epoch=150, loss=0.0253
Epoch=151, loss=0.0290
Epoch=152, loss=0.0268
Epoch=153, loss=0.0300
Epoch=154, loss=0.0197
Epoch=155, loss=0.0262
Epoch=156, loss=0.0206
Epoch=157, loss=0.0239
Epoch=158, loss=0.0332
Epoch=159, loss=0.0312
Epoch=160, loss=0.0359
Epoch=161, loss=0.0242
Epoch=162, loss=0.0225
Epoch=163, loss=0.0307
Epoch=164, loss=0.0162
Epoch=165, loss=0.0172
Epoch=166, loss=0.0247
Epoch=167, loss=0.0175
Epoch=168, loss=0.0234
Epoch=169, loss=0.0222
Epoch=170, loss=0.0265
Epoch=171, loss=0.0221
Epoch=172, loss=0.0319
Epoch=173, loss=0.0099
Epoch=174, loss=0.0309
Epoch=175, loss=0.0236
Epoch=176, loss=0.0196
Epoch=177, loss=0.0186
Epoch=178, loss=0.0150
Epoch=179, loss=0.0128
Epoch=180, loss=0.0235
Epoch=181, loss=0.0198
Epoch=182, loss=0.0221
Epoch=183, loss=0.0215
Epoch=184, loss=0.0219
Epoch=185, loss=0.0219
Epoch=186, loss=0.0193
Epoch=187, loss=0.0202
Epoch=188, loss=0.0278
Epoch=189, loss=0.0138
Epoch=190, loss=0.0279
Epoch=191, loss=0.0087
Epoch=192, loss=0.0224
Epoch=193, loss=0.0252
Epoch=194, loss=0.0134
Epoch=195, loss=0.0145
Epoch=196, loss=0.0183
Epoch=197, loss=0.0200
Epoch=198, loss=0.0136
Epoch=199, loss=0.0129
Epoch=200, loss=0.0177
Epoch=201, loss=0.0181
Epoch=202, loss=0.0132
Epoch=203, loss=0.0168
Epoch=204, loss=0.0196
Epoch=205, loss=0.0194
Epoch=206, loss=0.0214
Epoch=207, loss=0.0133
Epoch=208, loss=0.0190
Epoch=209, loss=0.0117
Epoch=210, loss=0.0213
Epoch=211, loss=0.0112
Early stopping!
Loading 191th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8090+-0.0081, F1Ma=0.7926+-0.0123, acc=0.8090+-0.0081
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7949274913335939, 0.7936294776105425, 0.7968865332752432, 0.8041397451550721, 0.8500000238418579, 0.75, 0.7282398343086243, 0.8642857074737549, 0.75, 0.7325918674468994, 0.7782355227361057, 0.017661372400592245, 0.7466764967358541, 0.025961118195880793, 0.7782355227361057, 0.017661372400592245], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7702552419444524, 0.7630099050530339, 0.7734716216167559, 0.7727307424902319, 0.8928571343421936, 0.7900000214576721, 0.7717601656913757, 0.8928571343421936, 0.7900000214576721, 0.7707930207252502, 0.8011659541391373, 0.005892139497317471, 0.780946215483067, 0.005941583424789998, 0.8011659541391373, 0.005892139497317451], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7747462981100721, 0.7652553075645037, 0.7625815093130355, 0.7637523524142221, 0.9428571462631226, 0.7960000038146973, 0.7780464291572571, 0.9428571462631226, 0.7940000295639038, 0.7765957713127136, 0.8038087835211816, 0.006421104213933446, 0.784073404707826, 0.004209800366480077, 0.8038087835211816, 0.006421104213933428], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.927835562093092, 0.9205007681027395, 0.9245919583478858, 0.9132348546107278, 0.9714285731315613, 0.8259999752044678, 0.7964216470718384, 0.9714285731315613, 0.8240000009536743, 0.7964216470718384, 0.8090167120093277, 0.00806149532061509, 0.7926282805954586, 0.012319274692445535, 0.8090167120093277, 0.00806149532061509]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6912
Epoch=002, loss=0.6859
Epoch=003, loss=0.6756
Epoch=004, loss=0.6707
Epoch=005, loss=0.6536
Epoch=006, loss=0.6437
Epoch=007, loss=0.6276
Epoch=008, loss=0.6032
Epoch=009, loss=0.5833
Epoch=010, loss=0.5556
Epoch=011, loss=0.5269
Epoch=012, loss=0.5051
Epoch=013, loss=0.4765
Epoch=014, loss=0.4352
Epoch=015, loss=0.4040
Epoch=016, loss=0.4053
Epoch=017, loss=0.3632
Epoch=018, loss=0.3251
Epoch=019, loss=0.3011
Epoch=020, loss=0.2789
Epoch=021, loss=0.2591
Epoch=022, loss=0.2527
Epoch=023, loss=0.2237
Epoch=024, loss=0.1916
Epoch=025, loss=0.2139
Epoch=026, loss=0.1584
Epoch=027, loss=0.1630
Epoch=028, loss=0.1600
Epoch=029, loss=0.1401
Epoch=030, loss=0.1374
Epoch=031, loss=0.1216
Epoch=032, loss=0.1158
Epoch=033, loss=0.0879
Epoch=034, loss=0.1083
Epoch=035, loss=0.0851
Epoch=036, loss=0.0810
Epoch=037, loss=0.0827
Epoch=038, loss=0.0745
Epoch=039, loss=0.0735
Epoch=040, loss=0.0605
Epoch=041, loss=0.0725
Epoch=042, loss=0.0578
Epoch=043, loss=0.0634
Epoch=044, loss=0.0658
Epoch=045, loss=0.0597
Epoch=046, loss=0.0628
Epoch=047, loss=0.0563
Epoch=048, loss=0.0483
Epoch=049, loss=0.0441
Epoch=050, loss=0.0488
Epoch=051, loss=0.0406
Epoch=052, loss=0.0406
Epoch=053, loss=0.0405
Epoch=054, loss=0.0384
Epoch=055, loss=0.0372
Epoch=056, loss=0.0407
Epoch=057, loss=0.0396
Epoch=058, loss=0.0312
Epoch=059, loss=0.0287
Epoch=060, loss=0.0267
Epoch=061, loss=0.0282
Epoch=062, loss=0.0254
Epoch=063, loss=0.0275
Epoch=064, loss=0.0263
Epoch=065, loss=0.0206
Epoch=066, loss=0.0291
Epoch=067, loss=0.0215
Epoch=068, loss=0.0228
Epoch=069, loss=0.0311
Epoch=070, loss=0.0217
Epoch=071, loss=0.0218
Epoch=072, loss=0.0186
Epoch=073, loss=0.0209
Epoch=074, loss=0.0222
Epoch=075, loss=0.0222
Epoch=076, loss=0.0203
Epoch=077, loss=0.0154
Epoch=078, loss=0.0191
Epoch=079, loss=0.0175
Epoch=080, loss=0.0129
Epoch=081, loss=0.0282
Epoch=082, loss=0.0179
Epoch=083, loss=0.0288
Epoch=084, loss=0.0195
Epoch=085, loss=0.0114
Epoch=086, loss=0.0181
Epoch=087, loss=0.0135
Epoch=088, loss=0.0165
Epoch=089, loss=0.0168
Epoch=090, loss=0.0216
Epoch=091, loss=0.0126
Epoch=092, loss=0.0134
Epoch=093, loss=0.0093
Epoch=094, loss=0.0117
Epoch=095, loss=0.0086
Epoch=096, loss=0.0111
Epoch=097, loss=0.0088
Epoch=098, loss=0.0117
Epoch=099, loss=0.0104
Epoch=100, loss=0.0067
Epoch=101, loss=0.0089
Epoch=102, loss=0.0068
Epoch=103, loss=0.0113
Epoch=104, loss=0.0144
Epoch=105, loss=0.0142
Epoch=106, loss=0.0078
Epoch=107, loss=0.0122
Epoch=108, loss=0.0136
Epoch=109, loss=0.0262
Epoch=110, loss=0.0101
Epoch=111, loss=0.0191
Epoch=112, loss=0.0158
Epoch=113, loss=0.0110
Epoch=114, loss=0.0117
Epoch=115, loss=0.0044
Epoch=116, loss=0.0114
Epoch=117, loss=0.0050
Epoch=118, loss=0.0066
Epoch=119, loss=0.0129
Epoch=120, loss=0.0071
Epoch=121, loss=0.0114
Epoch=122, loss=0.0065
Epoch=123, loss=0.0053
Epoch=124, loss=0.0101
Epoch=125, loss=0.0081
Epoch=126, loss=0.0107
Epoch=127, loss=0.0117
Epoch=128, loss=0.0070
Epoch=129, loss=0.0058
Epoch=130, loss=0.0084
Epoch=131, loss=0.0067
Epoch=132, loss=0.0090
Epoch=133, loss=0.0074
Epoch=134, loss=0.0062
Epoch=135, loss=0.0076
Early stopping!
Loading 115th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8087+-0.0125, F1Ma=0.7863+-0.0151, acc=0.8087+-0.0125
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7788285596607789, 0.780886052881948, 0.784440947830439, 0.7884356143122087, 0.7928571701049805, 0.7099999785423279, 0.707446813583374, 0.7928571701049805, 0.7059999704360962, 0.7122824192047119, 0.6751651768363779, 0.012505639497357408, 0.5862443142103897, 0.028565771298318502, 0.6751651768363779, 0.012505639497357408], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7949274913335939, 0.7936294776105425, 0.7968865332752432, 0.8041397451550721, 0.8500000238418579, 0.75, 0.7282398343086243, 0.8642857074737549, 0.75, 0.7325918674468994, 0.7782355227361057, 0.017661372400592245, 0.7466764967358541, 0.025961118195880793, 0.7782355227361057, 0.017661372400592245], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7702552419444524, 0.7630099050530339, 0.7734716216167559, 0.7727307424902319, 0.8928571343421936, 0.7900000214576721, 0.7717601656913757, 0.8928571343421936, 0.7900000214576721, 0.7707930207252502, 0.8011659541391373, 0.005892139497317471, 0.780946215483067, 0.005941583424789998, 0.8011659541391373, 0.005892139497317451], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7747462981100721, 0.7652553075645037, 0.7625815093130355, 0.7637523524142221, 0.9428571462631226, 0.7960000038146973, 0.7780464291572571, 0.9428571462631226, 0.7940000295639038, 0.7765957713127136, 0.8038087835211816, 0.006421104213933446, 0.784073404707826, 0.004209800366480077, 0.8038087835211816, 0.006421104213933428], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.927835562093092, 0.9205007681027395, 0.9245919583478858, 0.9132348546107278, 0.9714285731315613, 0.8259999752044678, 0.7964216470718384, 0.9714285731315613, 0.8240000009536743, 0.7964216470718384, 0.8090167120093277, 0.00806149532061509, 0.7926282805954586, 0.012319274692445535, 0.8090167120093277, 0.00806149532061509], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.905482132388687, 0.8946851228482389, 0.9002228791375766, 0.8911215097847323, 0.9428571462631226, 0.8080000281333923, 0.7843326926231384, 0.9428571462631226, 0.8100000023841858, 0.7862669229507446, 0.8087057909055577, 0.012537004374714764, 0.7862935961996875, 0.01508627467587277, 0.8087057909055577, 0.012537004374714781]]
