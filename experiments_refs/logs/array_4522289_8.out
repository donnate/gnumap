My SLURM_ARRAY_TASK_ID:  8
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_8
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_8.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6928
Epoch=009, loss=0.6927
Epoch=010, loss=0.6927
Epoch=011, loss=0.6926
Epoch=012, loss=0.6925
Epoch=013, loss=0.6925
Epoch=014, loss=0.6924
Epoch=015, loss=0.6923
Epoch=016, loss=0.6922
Epoch=017, loss=0.6922
Epoch=018, loss=0.6921
Epoch=019, loss=0.6920
Epoch=020, loss=0.6919
Epoch=021, loss=0.6918
Epoch=022, loss=0.6916
Epoch=023, loss=0.6915
Epoch=024, loss=0.6914
Epoch=025, loss=0.6913
Epoch=026, loss=0.6911
Epoch=027, loss=0.6909
Epoch=028, loss=0.6908
Epoch=029, loss=0.6906
Epoch=030, loss=0.6903
Epoch=031, loss=0.6901
Epoch=032, loss=0.6900
Epoch=033, loss=0.6897
Epoch=034, loss=0.6895
Epoch=035, loss=0.6893
Epoch=036, loss=0.6889
Epoch=037, loss=0.6887
Epoch=038, loss=0.6885
Epoch=039, loss=0.6881
Epoch=040, loss=0.6878
Epoch=041, loss=0.6876
Epoch=042, loss=0.6871
Epoch=043, loss=0.6868
Epoch=044, loss=0.6862
Epoch=045, loss=0.6859
Epoch=046, loss=0.6855
Epoch=047, loss=0.6852
Epoch=048, loss=0.6847
Epoch=049, loss=0.6844
Epoch=050, loss=0.6836
Epoch=051, loss=0.6832
Epoch=052, loss=0.6826
Epoch=053, loss=0.6818
Epoch=054, loss=0.6813
Epoch=055, loss=0.6809
Epoch=056, loss=0.6802
Epoch=057, loss=0.6793
Epoch=058, loss=0.6789
Epoch=059, loss=0.6779
Epoch=060, loss=0.6773
Epoch=061, loss=0.6765
Epoch=062, loss=0.6757
Epoch=063, loss=0.6749
Epoch=064, loss=0.6741
Epoch=065, loss=0.6731
Epoch=066, loss=0.6724
Epoch=067, loss=0.6715
Epoch=068, loss=0.6699
Epoch=069, loss=0.6703
Epoch=070, loss=0.6678
Epoch=071, loss=0.6672
Epoch=072, loss=0.6656
Epoch=073, loss=0.6640
Epoch=074, loss=0.6634
Epoch=075, loss=0.6619
Epoch=076, loss=0.6610
Epoch=077, loss=0.6599
Epoch=078, loss=0.6587
Epoch=079, loss=0.6574
Epoch=080, loss=0.6554
Epoch=081, loss=0.6536
Epoch=082, loss=0.6519
Epoch=083, loss=0.6513
Epoch=084, loss=0.6491
Epoch=085, loss=0.6471
Epoch=086, loss=0.6463
Epoch=087, loss=0.6446
Epoch=088, loss=0.6423
Epoch=089, loss=0.6422
Epoch=090, loss=0.6393
Epoch=091, loss=0.6373
Epoch=092, loss=0.6337
Epoch=093, loss=0.6325
Epoch=094, loss=0.6305
Epoch=095, loss=0.6274
Epoch=096, loss=0.6251
Epoch=097, loss=0.6248
Epoch=098, loss=0.6219
Epoch=099, loss=0.6208
Epoch=100, loss=0.6181
Epoch=101, loss=0.6146
Epoch=102, loss=0.6136
Epoch=103, loss=0.6112
Epoch=104, loss=0.6088
Epoch=105, loss=0.6049
Epoch=106, loss=0.6026
Epoch=107, loss=0.6008
Epoch=108, loss=0.5970
Epoch=109, loss=0.5930
Epoch=110, loss=0.5946
Epoch=111, loss=0.5899
Epoch=112, loss=0.5856
Epoch=113, loss=0.5865
Epoch=114, loss=0.5811
Epoch=115, loss=0.5773
Epoch=116, loss=0.5722
Epoch=117, loss=0.5700
Epoch=118, loss=0.5683
Epoch=119, loss=0.5648
Epoch=120, loss=0.5617
Epoch=121, loss=0.5611
Epoch=122, loss=0.5567
Epoch=123, loss=0.5596
Epoch=124, loss=0.5508
Epoch=125, loss=0.5459
Epoch=126, loss=0.5443
Epoch=127, loss=0.5432
Epoch=128, loss=0.5370
Epoch=129, loss=0.5315
Epoch=130, loss=0.5306
Epoch=131, loss=0.5296
Epoch=132, loss=0.5238
Epoch=133, loss=0.5244
Epoch=134, loss=0.5150
Epoch=135, loss=0.5141
Epoch=136, loss=0.5082
Epoch=137, loss=0.5071
Epoch=138, loss=0.5041
Epoch=139, loss=0.5022
Epoch=140, loss=0.4967
Epoch=141, loss=0.4918
Epoch=142, loss=0.4907
Epoch=143, loss=0.4859
Epoch=144, loss=0.4830
Epoch=145, loss=0.4788
Epoch=146, loss=0.4749
Epoch=147, loss=0.4700
Epoch=148, loss=0.4680
Epoch=149, loss=0.4654
Epoch=150, loss=0.4594
Epoch=151, loss=0.4564
Epoch=152, loss=0.4514
Epoch=153, loss=0.4542
Epoch=154, loss=0.4485
Epoch=155, loss=0.4437
Epoch=156, loss=0.4390
Epoch=157, loss=0.4330
Epoch=158, loss=0.4332
Epoch=159, loss=0.4287
Epoch=160, loss=0.4209
Epoch=161, loss=0.4206
Epoch=162, loss=0.4194
Epoch=163, loss=0.4120
Epoch=164, loss=0.4072
Epoch=165, loss=0.4092
Epoch=166, loss=0.4031
Epoch=167, loss=0.3940
Epoch=168, loss=0.3938
Epoch=169, loss=0.3950
Epoch=170, loss=0.3914
Epoch=171, loss=0.3882
Epoch=172, loss=0.3800
Epoch=173, loss=0.3773
Epoch=174, loss=0.3766
Epoch=175, loss=0.3738
Epoch=176, loss=0.3659
Epoch=177, loss=0.3620
Epoch=178, loss=0.3579
Epoch=179, loss=0.3545
Epoch=180, loss=0.3537
Epoch=181, loss=0.3509
Epoch=182, loss=0.3529
Epoch=183, loss=0.3540
Epoch=184, loss=0.3444
Epoch=185, loss=0.3399
Epoch=186, loss=0.3357
Epoch=187, loss=0.3340
Epoch=188, loss=0.3282
Epoch=189, loss=0.3257
Epoch=190, loss=0.3232
Epoch=191, loss=0.3256
Epoch=192, loss=0.3193
Epoch=193, loss=0.3051
Epoch=194, loss=0.3136
Epoch=195, loss=0.3095
Epoch=196, loss=0.3081
Epoch=197, loss=0.3113
Epoch=198, loss=0.2996
Epoch=199, loss=0.3039
Epoch=200, loss=0.2985
Epoch=201, loss=0.2980
Epoch=202, loss=0.2900
Epoch=203, loss=0.2884
Epoch=204, loss=0.2812
Epoch=205, loss=0.2826
Epoch=206, loss=0.2841
Epoch=207, loss=0.2865
Epoch=208, loss=0.2774
Epoch=209, loss=0.2701
Epoch=210, loss=0.2651
Epoch=211, loss=0.2698
Epoch=212, loss=0.2661
Epoch=213, loss=0.2652
Epoch=214, loss=0.2580
Epoch=215, loss=0.2507
Epoch=216, loss=0.2589
Epoch=217, loss=0.2608
Epoch=218, loss=0.2499
Epoch=219, loss=0.2529
Epoch=220, loss=0.2461
Epoch=221, loss=0.2467
Epoch=222, loss=0.2530
Epoch=223, loss=0.2352
Epoch=224, loss=0.2370
Epoch=225, loss=0.2435
Epoch=226, loss=0.2342
Epoch=227, loss=0.2310
Epoch=228, loss=0.2313
Epoch=229, loss=0.2369
Epoch=230, loss=0.2281
Epoch=231, loss=0.2218
Epoch=232, loss=0.2226
Epoch=233, loss=0.2214
Epoch=234, loss=0.2226
Epoch=235, loss=0.2241
Epoch=236, loss=0.2118
Epoch=237, loss=0.2203
Epoch=238, loss=0.2095
Epoch=239, loss=0.2115
Epoch=240, loss=0.2057
Epoch=241, loss=0.2203
Epoch=242, loss=0.2086
Epoch=243, loss=0.2034
Epoch=244, loss=0.1966
Epoch=245, loss=0.2080
Epoch=246, loss=0.2019
Epoch=247, loss=0.1988
Epoch=248, loss=0.1907
Epoch=249, loss=0.1930
Epoch=250, loss=0.1941
Epoch=251, loss=0.1915
Epoch=252, loss=0.1929
Epoch=253, loss=0.1951
Epoch=254, loss=0.1925
Epoch=255, loss=0.1902
Epoch=256, loss=0.1932
Epoch=257, loss=0.1855
Epoch=258, loss=0.1850
Epoch=259, loss=0.1818
Epoch=260, loss=0.1851
Epoch=261, loss=0.1895
Epoch=262, loss=0.1737
Epoch=263, loss=0.1720
Epoch=264, loss=0.1797
Epoch=265, loss=0.1789
Epoch=266, loss=0.1707
Epoch=267, loss=0.1762
Epoch=268, loss=0.1787
Epoch=269, loss=0.1680
Epoch=270, loss=0.1655
Epoch=271, loss=0.1706
Epoch=272, loss=0.1711
Epoch=273, loss=0.1652
Epoch=274, loss=0.1690
Epoch=275, loss=0.1691
Epoch=276, loss=0.1730
Epoch=277, loss=0.1563
Epoch=278, loss=0.1610
Epoch=279, loss=0.1644
Epoch=280, loss=0.1669
Epoch=281, loss=0.1615
Epoch=282, loss=0.1683
Epoch=283, loss=0.1615
Epoch=284, loss=0.1621
Epoch=285, loss=0.1604
Epoch=286, loss=0.1573
Epoch=287, loss=0.1585
Epoch=288, loss=0.1728
Epoch=289, loss=0.1544
Epoch=290, loss=0.1550
Epoch=291, loss=0.1436
Epoch=292, loss=0.1535
Epoch=293, loss=0.1488
Epoch=294, loss=0.1408
Epoch=295, loss=0.1551
Epoch=296, loss=0.1472
Epoch=297, loss=0.1464
Epoch=298, loss=0.1389
Epoch=299, loss=0.1446
Epoch=300, loss=0.1449
Epoch=301, loss=0.1456
Epoch=302, loss=0.1523
Epoch=303, loss=0.1404
Epoch=304, loss=0.1427
Epoch=305, loss=0.1402
Epoch=306, loss=0.1366
Epoch=307, loss=0.1357
Epoch=308, loss=0.1492
Epoch=309, loss=0.1412
Epoch=310, loss=0.1403
Epoch=311, loss=0.1306
Epoch=312, loss=0.1298
Epoch=313, loss=0.1409
Epoch=314, loss=0.1381
Epoch=315, loss=0.1356
Epoch=316, loss=0.1371
Epoch=317, loss=0.1358
Epoch=318, loss=0.1324
Epoch=319, loss=0.1302
Epoch=320, loss=0.1336
Epoch=321, loss=0.1260
Epoch=322, loss=0.1314
Epoch=323, loss=0.1235
Epoch=324, loss=0.1319
Epoch=325, loss=0.1204
Epoch=326, loss=0.1230
Epoch=327, loss=0.1411
Epoch=328, loss=0.1222
Epoch=329, loss=0.1180
Epoch=330, loss=0.1338
Epoch=331, loss=0.1290
Epoch=332, loss=0.1266
Epoch=333, loss=0.1251
Epoch=334, loss=0.1227
Epoch=335, loss=0.1205
Epoch=336, loss=0.1240
Epoch=337, loss=0.1212
Epoch=338, loss=0.1251
Epoch=339, loss=0.1265
Epoch=340, loss=0.1296
Epoch=341, loss=0.1204
Epoch=342, loss=0.1132
Epoch=343, loss=0.1127
Epoch=344, loss=0.1186
Epoch=345, loss=0.1241
Epoch=346, loss=0.1217
Epoch=347, loss=0.1241
Epoch=348, loss=0.1239
Epoch=349, loss=0.1094
Epoch=350, loss=0.1031
Epoch=351, loss=0.1204
Epoch=352, loss=0.1261
Epoch=353, loss=0.1166
Epoch=354, loss=0.1165
Epoch=355, loss=0.1109
Epoch=356, loss=0.1294
Epoch=357, loss=0.1019
Epoch=358, loss=0.1087
Epoch=359, loss=0.1075
Epoch=360, loss=0.1046
Epoch=361, loss=0.1067
Epoch=362, loss=0.1014
Epoch=363, loss=0.1058
Epoch=364, loss=0.1058
Epoch=365, loss=0.0960
Epoch=366, loss=0.1030
Epoch=367, loss=0.0994
Epoch=368, loss=0.1019
Epoch=369, loss=0.0991
Epoch=370, loss=0.1129
Epoch=371, loss=0.1229
Epoch=372, loss=0.1008
Epoch=373, loss=0.1121
Epoch=374, loss=0.1051
Epoch=375, loss=0.1050
Epoch=376, loss=0.1033
Epoch=377, loss=0.0935
Epoch=378, loss=0.1045
Epoch=379, loss=0.0995
Epoch=380, loss=0.0987
Epoch=381, loss=0.0977
Epoch=382, loss=0.0974
Epoch=383, loss=0.1063
Epoch=384, loss=0.0923
Epoch=385, loss=0.1076
Epoch=386, loss=0.0887
Epoch=387, loss=0.1017
Epoch=388, loss=0.0974
Epoch=389, loss=0.0988
Epoch=390, loss=0.0991
Epoch=391, loss=0.0957
Epoch=392, loss=0.1035
Epoch=393, loss=0.0884
Epoch=394, loss=0.0917
Epoch=395, loss=0.1104
Epoch=396, loss=0.0925
Epoch=397, loss=0.0985
Epoch=398, loss=0.1041
Epoch=399, loss=0.0962
Epoch=400, loss=0.0901
Epoch=401, loss=0.0952
Epoch=402, loss=0.0948
Epoch=403, loss=0.0869
Epoch=404, loss=0.0864
Epoch=405, loss=0.0943
Epoch=406, loss=0.0846
Epoch=407, loss=0.0854
Epoch=408, loss=0.1008
Epoch=409, loss=0.0854
Epoch=410, loss=0.0904
Epoch=411, loss=0.0867
Epoch=412, loss=0.0904
Epoch=413, loss=0.0936
Epoch=414, loss=0.0943
Epoch=415, loss=0.0928
Epoch=416, loss=0.0826
Epoch=417, loss=0.0837
Epoch=418, loss=0.0996
Epoch=419, loss=0.0878
Epoch=420, loss=0.0853
Epoch=421, loss=0.0858
Epoch=422, loss=0.0903
Epoch=423, loss=0.0774
Epoch=424, loss=0.0815
Epoch=425, loss=0.0813
Epoch=426, loss=0.0906
Epoch=427, loss=0.0830
Epoch=428, loss=0.0794
Epoch=429, loss=0.0741
Epoch=430, loss=0.0856
Epoch=431, loss=0.0772
Epoch=432, loss=0.0876
Epoch=433, loss=0.0973
Epoch=434, loss=0.0816
Epoch=435, loss=0.0869
Epoch=436, loss=0.0883
Epoch=437, loss=0.0796
Epoch=438, loss=0.0802
Epoch=439, loss=0.0800
Epoch=440, loss=0.0903
Epoch=441, loss=0.0832
Epoch=442, loss=0.0805
Epoch=443, loss=0.0785
Epoch=444, loss=0.0856
Epoch=445, loss=0.0780
Epoch=446, loss=0.0799
Epoch=447, loss=0.0756
Epoch=448, loss=0.0788
Epoch=449, loss=0.0772
Early stopping!
Loading 429th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7208+-0.0198, F1Ma=0.6499+-0.0163, acc=0.7208+-0.0198
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6924
Epoch=009, loss=0.6923
Epoch=010, loss=0.6921
Epoch=011, loss=0.6919
Epoch=012, loss=0.6918
Epoch=013, loss=0.6915
Epoch=014, loss=0.6912
Epoch=015, loss=0.6909
Epoch=016, loss=0.6906
Epoch=017, loss=0.6903
Epoch=018, loss=0.6899
Epoch=019, loss=0.6895
Epoch=020, loss=0.6889
Epoch=021, loss=0.6885
Epoch=022, loss=0.6879
Epoch=023, loss=0.6872
Epoch=024, loss=0.6867
Epoch=025, loss=0.6858
Epoch=026, loss=0.6851
Epoch=027, loss=0.6842
Epoch=028, loss=0.6833
Epoch=029, loss=0.6821
Epoch=030, loss=0.6813
Epoch=031, loss=0.6799
Epoch=032, loss=0.6789
Epoch=033, loss=0.6775
Epoch=034, loss=0.6760
Epoch=035, loss=0.6746
Epoch=036, loss=0.6728
Epoch=037, loss=0.6712
Epoch=038, loss=0.6694
Epoch=039, loss=0.6671
Epoch=040, loss=0.6650
Epoch=041, loss=0.6629
Epoch=042, loss=0.6604
Epoch=043, loss=0.6583
Epoch=044, loss=0.6551
Epoch=045, loss=0.6526
Epoch=046, loss=0.6506
Epoch=047, loss=0.6465
Epoch=048, loss=0.6438
Epoch=049, loss=0.6396
Epoch=050, loss=0.6366
Epoch=051, loss=0.6330
Epoch=052, loss=0.6298
Epoch=053, loss=0.6242
Epoch=054, loss=0.6219
Epoch=055, loss=0.6167
Epoch=056, loss=0.6119
Epoch=057, loss=0.6080
Epoch=058, loss=0.6024
Epoch=059, loss=0.5970
Epoch=060, loss=0.5923
Epoch=061, loss=0.5856
Epoch=062, loss=0.5814
Epoch=063, loss=0.5753
Epoch=064, loss=0.5679
Epoch=065, loss=0.5638
Epoch=066, loss=0.5566
Epoch=067, loss=0.5503
Epoch=068, loss=0.5445
Epoch=069, loss=0.5389
Epoch=070, loss=0.5292
Epoch=071, loss=0.5223
Epoch=072, loss=0.5167
Epoch=073, loss=0.5088
Epoch=074, loss=0.5030
Epoch=075, loss=0.4940
Epoch=076, loss=0.4885
Epoch=077, loss=0.4801
Epoch=078, loss=0.4757
Epoch=079, loss=0.4616
Epoch=080, loss=0.4563
Epoch=081, loss=0.4465
Epoch=082, loss=0.4432
Epoch=083, loss=0.4326
Epoch=084, loss=0.4234
Epoch=085, loss=0.4209
Epoch=086, loss=0.4123
Epoch=087, loss=0.4032
Epoch=088, loss=0.3939
Epoch=089, loss=0.3856
Epoch=090, loss=0.3806
Epoch=091, loss=0.3735
Epoch=092, loss=0.3643
Epoch=093, loss=0.3573
Epoch=094, loss=0.3559
Epoch=095, loss=0.3434
Epoch=096, loss=0.3335
Epoch=097, loss=0.3325
Epoch=098, loss=0.3159
Epoch=099, loss=0.3114
Epoch=100, loss=0.3126
Epoch=101, loss=0.3033
Epoch=102, loss=0.2924
Epoch=103, loss=0.2890
Epoch=104, loss=0.2785
Epoch=105, loss=0.2753
Epoch=106, loss=0.2710
Epoch=107, loss=0.2675
Epoch=108, loss=0.2577
Epoch=109, loss=0.2531
Epoch=110, loss=0.2528
Epoch=111, loss=0.2547
Epoch=112, loss=0.2419
Epoch=113, loss=0.2372
Epoch=114, loss=0.2298
Epoch=115, loss=0.2310
Epoch=116, loss=0.2255
Epoch=117, loss=0.2214
Epoch=118, loss=0.2129
Epoch=119, loss=0.2170
Epoch=120, loss=0.1984
Epoch=121, loss=0.2039
Epoch=122, loss=0.2015
Epoch=123, loss=0.1960
Epoch=124, loss=0.1938
Epoch=125, loss=0.1856
Epoch=126, loss=0.1840
Epoch=127, loss=0.1931
Epoch=128, loss=0.1879
Epoch=129, loss=0.1727
Epoch=130, loss=0.1658
Epoch=131, loss=0.1741
Epoch=132, loss=0.1701
Epoch=133, loss=0.1703
Epoch=134, loss=0.1653
Epoch=135, loss=0.1621
Epoch=136, loss=0.1549
Epoch=137, loss=0.1592
Epoch=138, loss=0.1542
Epoch=139, loss=0.1547
Epoch=140, loss=0.1559
Epoch=141, loss=0.1499
Epoch=142, loss=0.1554
Epoch=143, loss=0.1414
Epoch=144, loss=0.1503
Epoch=145, loss=0.1415
Epoch=146, loss=0.1338
Epoch=147, loss=0.1497
Epoch=148, loss=0.1384
Epoch=149, loss=0.1320
Epoch=150, loss=0.1328
Epoch=151, loss=0.1295
Epoch=152, loss=0.1302
Epoch=153, loss=0.1326
Epoch=154, loss=0.1358
Epoch=155, loss=0.1255
Epoch=156, loss=0.1206
Epoch=157, loss=0.1274
Epoch=158, loss=0.1143
Epoch=159, loss=0.1264
Epoch=160, loss=0.1171
Epoch=161, loss=0.1306
Epoch=162, loss=0.1188
Epoch=163, loss=0.1137
Epoch=164, loss=0.1183
Epoch=165, loss=0.1041
Epoch=166, loss=0.1126
Epoch=167, loss=0.1169
Epoch=168, loss=0.1041
Epoch=169, loss=0.1125
Epoch=170, loss=0.1036
Epoch=171, loss=0.1049
Epoch=172, loss=0.1058
Epoch=173, loss=0.1003
Epoch=174, loss=0.0986
Epoch=175, loss=0.0998
Epoch=176, loss=0.0995
Epoch=177, loss=0.1098
Epoch=178, loss=0.1136
Epoch=179, loss=0.1056
Epoch=180, loss=0.0917
Epoch=181, loss=0.1029
Epoch=182, loss=0.1013
Epoch=183, loss=0.0973
Epoch=184, loss=0.0969
Epoch=185, loss=0.0969
Epoch=186, loss=0.0967
Epoch=187, loss=0.0918
Epoch=188, loss=0.1005
Epoch=189, loss=0.0972
Epoch=190, loss=0.0978
Epoch=191, loss=0.0886
Epoch=192, loss=0.0942
Epoch=193, loss=0.0974
Epoch=194, loss=0.0859
Epoch=195, loss=0.0998
Epoch=196, loss=0.0842
Epoch=197, loss=0.0909
Epoch=198, loss=0.0871
Epoch=199, loss=0.0993
Epoch=200, loss=0.0871
Epoch=201, loss=0.0886
Epoch=202, loss=0.0904
Epoch=203, loss=0.0799
Epoch=204, loss=0.0845
Epoch=205, loss=0.0967
Epoch=206, loss=0.0772
Epoch=207, loss=0.0735
Epoch=208, loss=0.0799
Epoch=209, loss=0.0796
Epoch=210, loss=0.0854
Epoch=211, loss=0.0866
Epoch=212, loss=0.0754
Epoch=213, loss=0.0927
Epoch=214, loss=0.0805
Epoch=215, loss=0.0889
Epoch=216, loss=0.0844
Epoch=217, loss=0.0740
Epoch=218, loss=0.0766
Epoch=219, loss=0.0820
Epoch=220, loss=0.0875
Epoch=221, loss=0.0755
Epoch=222, loss=0.0737
Epoch=223, loss=0.0798
Epoch=224, loss=0.0749
Epoch=225, loss=0.0806
Epoch=226, loss=0.0643
Epoch=227, loss=0.0781
Epoch=228, loss=0.0794
Epoch=229, loss=0.0748
Epoch=230, loss=0.0742
Epoch=231, loss=0.0743
Epoch=232, loss=0.0788
Epoch=233, loss=0.0755
Epoch=234, loss=0.0644
Epoch=235, loss=0.0689
Epoch=236, loss=0.0799
Epoch=237, loss=0.0738
Epoch=238, loss=0.0825
Epoch=239, loss=0.0721
Epoch=240, loss=0.0704
Epoch=241, loss=0.0734
Epoch=242, loss=0.0835
Epoch=243, loss=0.0753
Epoch=244, loss=0.0665
Epoch=245, loss=0.0695
Epoch=246, loss=0.0706
Early stopping!
Loading 226th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7879+-0.0185, F1Ma=0.7486+-0.0379, acc=0.7879+-0.0185
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929531235602327, 0.7895258122502471, 0.8020120333130498, 0.7915496942654312, 0.8357142806053162, 0.7580000162124634, 0.7529013752937317, 0.8642857074737549, 0.7580000162124634, 0.7625725269317627, 0.7878740769529731, 0.018499805674310175, 0.7485698505034516, 0.03786179248380028, 0.7878740769529733, 0.01849980567431013]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6930
Epoch=002, loss=0.6929
Epoch=003, loss=0.6927
Epoch=004, loss=0.6925
Epoch=005, loss=0.6922
Epoch=006, loss=0.6919
Epoch=007, loss=0.6914
Epoch=008, loss=0.6910
Epoch=009, loss=0.6904
Epoch=010, loss=0.6898
Epoch=011, loss=0.6890
Epoch=012, loss=0.6881
Epoch=013, loss=0.6870
Epoch=014, loss=0.6859
Epoch=015, loss=0.6845
Epoch=016, loss=0.6831
Epoch=017, loss=0.6815
Epoch=018, loss=0.6793
Epoch=019, loss=0.6772
Epoch=020, loss=0.6748
Epoch=021, loss=0.6721
Epoch=022, loss=0.6697
Epoch=023, loss=0.6661
Epoch=024, loss=0.6628
Epoch=025, loss=0.6585
Epoch=026, loss=0.6543
Epoch=027, loss=0.6492
Epoch=028, loss=0.6454
Epoch=029, loss=0.6396
Epoch=030, loss=0.6331
Epoch=031, loss=0.6263
Epoch=032, loss=0.6204
Epoch=033, loss=0.6126
Epoch=034, loss=0.6048
Epoch=035, loss=0.5957
Epoch=036, loss=0.5889
Epoch=037, loss=0.5792
Epoch=038, loss=0.5688
Epoch=039, loss=0.5595
Epoch=040, loss=0.5487
Epoch=041, loss=0.5382
Epoch=042, loss=0.5274
Epoch=043, loss=0.5159
Epoch=044, loss=0.5018
Epoch=045, loss=0.4881
Epoch=046, loss=0.4767
Epoch=047, loss=0.4635
Epoch=048, loss=0.4545
Epoch=049, loss=0.4396
Epoch=050, loss=0.4271
Epoch=051, loss=0.4116
Epoch=052, loss=0.3977
Epoch=053, loss=0.3860
Epoch=054, loss=0.3802
Epoch=055, loss=0.3600
Epoch=056, loss=0.3449
Epoch=057, loss=0.3362
Epoch=058, loss=0.3196
Epoch=059, loss=0.3026
Epoch=060, loss=0.2975
Epoch=061, loss=0.2864
Epoch=062, loss=0.2824
Epoch=063, loss=0.2656
Epoch=064, loss=0.2515
Epoch=065, loss=0.2466
Epoch=066, loss=0.2348
Epoch=067, loss=0.2299
Epoch=068, loss=0.2189
Epoch=069, loss=0.2072
Epoch=070, loss=0.2081
Epoch=071, loss=0.1989
Epoch=072, loss=0.1928
Epoch=073, loss=0.1886
Epoch=074, loss=0.1770
Epoch=075, loss=0.1716
Epoch=076, loss=0.1669
Epoch=077, loss=0.1661
Epoch=078, loss=0.1538
Epoch=079, loss=0.1579
Epoch=080, loss=0.1559
Epoch=081, loss=0.1513
Epoch=082, loss=0.1290
Epoch=083, loss=0.1338
Epoch=084, loss=0.1278
Epoch=085, loss=0.1210
Epoch=086, loss=0.1255
Epoch=087, loss=0.1262
Epoch=088, loss=0.1155
Epoch=089, loss=0.1124
Epoch=090, loss=0.1014
Epoch=091, loss=0.1084
Epoch=092, loss=0.1129
Epoch=093, loss=0.1130
Epoch=094, loss=0.1044
Epoch=095, loss=0.0956
Epoch=096, loss=0.1006
Epoch=097, loss=0.1031
Epoch=098, loss=0.0948
Epoch=099, loss=0.0938
Epoch=100, loss=0.0931
Epoch=101, loss=0.0881
Epoch=102, loss=0.0927
Epoch=103, loss=0.0948
Epoch=104, loss=0.0814
Epoch=105, loss=0.0885
Epoch=106, loss=0.0840
Epoch=107, loss=0.0820
Epoch=108, loss=0.0822
Epoch=109, loss=0.0844
Epoch=110, loss=0.0882
Epoch=111, loss=0.0746
Epoch=112, loss=0.0732
Epoch=113, loss=0.0864
Epoch=114, loss=0.0757
Epoch=115, loss=0.0740
Epoch=116, loss=0.0753
Epoch=117, loss=0.0715
Epoch=118, loss=0.0734
Epoch=119, loss=0.0737
Epoch=120, loss=0.0747
Epoch=121, loss=0.0710
Epoch=122, loss=0.0651
Epoch=123, loss=0.0697
Epoch=124, loss=0.0667
Epoch=125, loss=0.0756
Epoch=126, loss=0.0761
Epoch=127, loss=0.0657
Epoch=128, loss=0.0707
Epoch=129, loss=0.0642
Epoch=130, loss=0.0819
Epoch=131, loss=0.0634
Epoch=132, loss=0.0611
Epoch=133, loss=0.0599
Epoch=134, loss=0.0633
Epoch=135, loss=0.0548
Epoch=136, loss=0.0689
Epoch=137, loss=0.0658
Epoch=138, loss=0.0554
Epoch=139, loss=0.0531
Epoch=140, loss=0.0560
Epoch=141, loss=0.0690
Epoch=142, loss=0.0569
Epoch=143, loss=0.0626
Epoch=144, loss=0.0663
Epoch=145, loss=0.0556
Epoch=146, loss=0.0568
Epoch=147, loss=0.0614
Epoch=148, loss=0.0594
Epoch=149, loss=0.0544
Epoch=150, loss=0.0559
Epoch=151, loss=0.0739
Epoch=152, loss=0.0549
Epoch=153, loss=0.0569
Epoch=154, loss=0.0584
Epoch=155, loss=0.0589
Epoch=156, loss=0.0567
Epoch=157, loss=0.0660
Epoch=158, loss=0.0509
Epoch=159, loss=0.0731
Epoch=160, loss=0.0623
Epoch=161, loss=0.0571
Epoch=162, loss=0.0555
Epoch=163, loss=0.0526
Epoch=164, loss=0.0559
Epoch=165, loss=0.0517
Epoch=166, loss=0.0624
Epoch=167, loss=0.0546
Epoch=168, loss=0.0462
Epoch=169, loss=0.0542
Epoch=170, loss=0.0575
Epoch=171, loss=0.0458
Epoch=172, loss=0.0547
Epoch=173, loss=0.0530
Epoch=174, loss=0.0545
Epoch=175, loss=0.0525
Epoch=176, loss=0.0418
Epoch=177, loss=0.0499
Epoch=178, loss=0.0484
Epoch=179, loss=0.0491
Epoch=180, loss=0.0545
Epoch=181, loss=0.0411
Epoch=182, loss=0.0485
Epoch=183, loss=0.0476
Epoch=184, loss=0.0472
Epoch=185, loss=0.0515
Epoch=186, loss=0.0444
Epoch=187, loss=0.0425
Epoch=188, loss=0.0460
Epoch=189, loss=0.0444
Epoch=190, loss=0.0424
Epoch=191, loss=0.0443
Epoch=192, loss=0.0436
Epoch=193, loss=0.0454
Epoch=194, loss=0.0436
Epoch=195, loss=0.0456
Epoch=196, loss=0.0388
Epoch=197, loss=0.0368
Epoch=198, loss=0.0483
Epoch=199, loss=0.0433
Epoch=200, loss=0.0481
Epoch=201, loss=0.0471
Epoch=202, loss=0.0518
Epoch=203, loss=0.0550
Epoch=204, loss=0.0384
Epoch=205, loss=0.0416
Epoch=206, loss=0.0380
Epoch=207, loss=0.0430
Epoch=208, loss=0.0363
Epoch=209, loss=0.0438
Epoch=210, loss=0.0463
Epoch=211, loss=0.0335
Epoch=212, loss=0.0374
Epoch=213, loss=0.0356
Epoch=214, loss=0.0418
Epoch=215, loss=0.0391
Epoch=216, loss=0.0336
Epoch=217, loss=0.0377
Epoch=218, loss=0.0398
Epoch=219, loss=0.0440
Epoch=220, loss=0.0507
Epoch=221, loss=0.0381
Epoch=222, loss=0.0304
Epoch=223, loss=0.0434
Epoch=224, loss=0.0484
Epoch=225, loss=0.0395
Epoch=226, loss=0.0422
Epoch=227, loss=0.0500
Epoch=228, loss=0.0280
Epoch=229, loss=0.0380
Epoch=230, loss=0.0506
Epoch=231, loss=0.0467
Epoch=232, loss=0.0385
Epoch=233, loss=0.0359
Epoch=234, loss=0.0419
Epoch=235, loss=0.0412
Epoch=236, loss=0.0406
Epoch=237, loss=0.0439
Epoch=238, loss=0.0426
Epoch=239, loss=0.0318
Epoch=240, loss=0.0363
Epoch=241, loss=0.0346
Epoch=242, loss=0.0432
Epoch=243, loss=0.0344
Epoch=244, loss=0.0365
Epoch=245, loss=0.0295
Epoch=246, loss=0.0271
Epoch=247, loss=0.0391
Epoch=248, loss=0.0338
Epoch=249, loss=0.0394
Epoch=250, loss=0.0323
Epoch=251, loss=0.0292
Epoch=252, loss=0.0285
Epoch=253, loss=0.0367
Epoch=254, loss=0.0304
Epoch=255, loss=0.0402
Epoch=256, loss=0.0358
Epoch=257, loss=0.0330
Epoch=258, loss=0.0300
Epoch=259, loss=0.0272
Epoch=260, loss=0.0471
Epoch=261, loss=0.0334
Epoch=262, loss=0.0330
Epoch=263, loss=0.0322
Epoch=264, loss=0.0387
Epoch=265, loss=0.0286
Epoch=266, loss=0.0356
Early stopping!
Loading 246th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7940+-0.0108, F1Ma=0.7747+-0.0134, acc=0.7940+-0.0108
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929531235602327, 0.7895258122502471, 0.8020120333130498, 0.7915496942654312, 0.8357142806053162, 0.7580000162124634, 0.7529013752937317, 0.8642857074737549, 0.7580000162124634, 0.7625725269317627, 0.7878740769529731, 0.018499805674310175, 0.7485698505034516, 0.03786179248380028, 0.7878740769529733, 0.01849980567431013], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7821459076054664, 0.7739728387099222, 0.7818484925952998, 0.7678131636609296, 0.8857142925262451, 0.777999997138977, 0.7446808218955994, 0.8785714507102966, 0.7739999890327454, 0.7412959337234497, 0.7940147687524292, 0.010765011816409875, 0.7747264799914066, 0.013397076931117777, 0.7940147687524292, 0.01076501181640984]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6925
Epoch=002, loss=0.6918
Epoch=003, loss=0.6908
Epoch=004, loss=0.6896
Epoch=005, loss=0.6880
Epoch=006, loss=0.6860
Epoch=007, loss=0.6837
Epoch=008, loss=0.6806
Epoch=009, loss=0.6774
Epoch=010, loss=0.6735
Epoch=011, loss=0.6685
Epoch=012, loss=0.6632
Epoch=013, loss=0.6568
Epoch=014, loss=0.6488
Epoch=015, loss=0.6417
Epoch=016, loss=0.6320
Epoch=017, loss=0.6234
Epoch=018, loss=0.6109
Epoch=019, loss=0.5989
Epoch=020, loss=0.5862
Epoch=021, loss=0.5717
Epoch=022, loss=0.5531
Epoch=023, loss=0.5397
Epoch=024, loss=0.5190
Epoch=025, loss=0.5013
Epoch=026, loss=0.4826
Epoch=027, loss=0.4618
Epoch=028, loss=0.4426
Epoch=029, loss=0.4222
Epoch=030, loss=0.3989
Epoch=031, loss=0.3755
Epoch=032, loss=0.3609
Epoch=033, loss=0.3395
Epoch=034, loss=0.3193
Epoch=035, loss=0.2943
Epoch=036, loss=0.2853
Epoch=037, loss=0.2629
Epoch=038, loss=0.2467
Epoch=039, loss=0.2321
Epoch=040, loss=0.2122
Epoch=041, loss=0.2037
Epoch=042, loss=0.1901
Epoch=043, loss=0.1831
Epoch=044, loss=0.1670
Epoch=045, loss=0.1629
Epoch=046, loss=0.1525
Epoch=047, loss=0.1328
Epoch=048, loss=0.1517
Epoch=049, loss=0.1418
Epoch=050, loss=0.1207
Epoch=051, loss=0.1247
Epoch=052, loss=0.1061
Epoch=053, loss=0.1134
Epoch=054, loss=0.1159
Epoch=055, loss=0.1112
Epoch=056, loss=0.0994
Epoch=057, loss=0.1089
Epoch=058, loss=0.1002
Epoch=059, loss=0.0941
Epoch=060, loss=0.0902
Epoch=061, loss=0.0914
Epoch=062, loss=0.0838
Epoch=063, loss=0.0920
Epoch=064, loss=0.0868
Epoch=065, loss=0.0942
Epoch=066, loss=0.0880
Epoch=067, loss=0.0872
Epoch=068, loss=0.0833
Epoch=069, loss=0.0973
Epoch=070, loss=0.0805
Epoch=071, loss=0.0773
Epoch=072, loss=0.0762
Epoch=073, loss=0.0781
Epoch=074, loss=0.0694
Epoch=075, loss=0.0719
Epoch=076, loss=0.0812
Epoch=077, loss=0.0762
Epoch=078, loss=0.0751
Epoch=079, loss=0.0720
Epoch=080, loss=0.0861
Epoch=081, loss=0.0701
Epoch=082, loss=0.0690
Epoch=083, loss=0.0818
Epoch=084, loss=0.0610
Epoch=085, loss=0.0664
Epoch=086, loss=0.0714
Epoch=087, loss=0.0650
Epoch=088, loss=0.0588
Epoch=089, loss=0.0589
Epoch=090, loss=0.0661
Epoch=091, loss=0.0651
Epoch=092, loss=0.0628
Epoch=093, loss=0.0672
Epoch=094, loss=0.0603
Epoch=095, loss=0.0657
Epoch=096, loss=0.0731
Epoch=097, loss=0.0662
Epoch=098, loss=0.0612
Epoch=099, loss=0.0606
Epoch=100, loss=0.0633
Epoch=101, loss=0.0635
Epoch=102, loss=0.0526
Epoch=103, loss=0.0601
Epoch=104, loss=0.0476
Epoch=105, loss=0.0626
Epoch=106, loss=0.0570
Epoch=107, loss=0.0530
Epoch=108, loss=0.0584
Epoch=109, loss=0.0608
Epoch=110, loss=0.0496
Epoch=111, loss=0.0475
Epoch=112, loss=0.0400
Epoch=113, loss=0.0526
Epoch=114, loss=0.0552
Epoch=115, loss=0.0556
Epoch=116, loss=0.0429
Epoch=117, loss=0.0563
Epoch=118, loss=0.0453
Epoch=119, loss=0.0453
Epoch=120, loss=0.0492
Epoch=121, loss=0.0415
Epoch=122, loss=0.0572
Epoch=123, loss=0.0419
Epoch=124, loss=0.0384
Epoch=125, loss=0.0495
Epoch=126, loss=0.0594
Epoch=127, loss=0.0443
Epoch=128, loss=0.0544
Epoch=129, loss=0.0504
Epoch=130, loss=0.0443
Epoch=131, loss=0.0451
Epoch=132, loss=0.0372
Epoch=133, loss=0.0396
Epoch=134, loss=0.0439
Epoch=135, loss=0.0383
Epoch=136, loss=0.0523
Epoch=137, loss=0.0399
Epoch=138, loss=0.0349
Epoch=139, loss=0.0493
Epoch=140, loss=0.0435
Epoch=141, loss=0.0426
Epoch=142, loss=0.0410
Epoch=143, loss=0.0471
Epoch=144, loss=0.0405
Epoch=145, loss=0.0436
Epoch=146, loss=0.0387
Epoch=147, loss=0.0414
Epoch=148, loss=0.0506
Epoch=149, loss=0.0436
Epoch=150, loss=0.0353
Epoch=151, loss=0.0377
Epoch=152, loss=0.0460
Epoch=153, loss=0.0444
Epoch=154, loss=0.0505
Epoch=155, loss=0.0542
Epoch=156, loss=0.0288
Epoch=157, loss=0.0402
Epoch=158, loss=0.0414
Epoch=159, loss=0.0421
Epoch=160, loss=0.0465
Epoch=161, loss=0.0412
Epoch=162, loss=0.0393
Epoch=163, loss=0.0364
Epoch=164, loss=0.0418
Epoch=165, loss=0.0333
Epoch=166, loss=0.0303
Epoch=167, loss=0.0501
Epoch=168, loss=0.0370
Epoch=169, loss=0.0390
Epoch=170, loss=0.0357
Epoch=171, loss=0.0360
Epoch=172, loss=0.0451
Epoch=173, loss=0.0441
Epoch=174, loss=0.0472
Epoch=175, loss=0.0382
Epoch=176, loss=0.0395
Early stopping!
Loading 156th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8030+-0.0057, F1Ma=0.7808+-0.0063, acc=0.8030+-0.0057
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929531235602327, 0.7895258122502471, 0.8020120333130498, 0.7915496942654312, 0.8357142806053162, 0.7580000162124634, 0.7529013752937317, 0.8642857074737549, 0.7580000162124634, 0.7625725269317627, 0.7878740769529731, 0.018499805674310175, 0.7485698505034516, 0.03786179248380028, 0.7878740769529733, 0.01849980567431013], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7821459076054664, 0.7739728387099222, 0.7818484925952998, 0.7678131636609296, 0.8857142925262451, 0.777999997138977, 0.7446808218955994, 0.8785714507102966, 0.7739999890327454, 0.7412959337234497, 0.7940147687524292, 0.010765011816409875, 0.7747264799914066, 0.013397076931117777, 0.7940147687524292, 0.01076501181640984], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7827515779849454, 0.7750215733778016, 0.7955597002833699, 0.7765945976111648, 0.9428571462631226, 0.8159999847412109, 0.8075435161590576, 0.9428571462631226, 0.8159999847412109, 0.8099613189697266, 0.8029537504858142, 0.005669516526641433, 0.780785591265281, 0.006268099161052819, 0.8029537504858142, 0.005669516526641433]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6917
Epoch=002, loss=0.6890
Epoch=003, loss=0.6858
Epoch=004, loss=0.6808
Epoch=005, loss=0.6744
Epoch=006, loss=0.6667
Epoch=007, loss=0.6564
Epoch=008, loss=0.6454
Epoch=009, loss=0.6317
Epoch=010, loss=0.6166
Epoch=011, loss=0.5989
Epoch=012, loss=0.5801
Epoch=013, loss=0.5602
Epoch=014, loss=0.5356
Epoch=015, loss=0.5090
Epoch=016, loss=0.4863
Epoch=017, loss=0.4607
Epoch=018, loss=0.4396
Epoch=019, loss=0.4093
Epoch=020, loss=0.3894
Epoch=021, loss=0.3689
Epoch=022, loss=0.3321
Epoch=023, loss=0.3045
Epoch=024, loss=0.2921
Epoch=025, loss=0.2698
Epoch=026, loss=0.2529
Epoch=027, loss=0.2439
Epoch=028, loss=0.2251
Epoch=029, loss=0.1940
Epoch=030, loss=0.1959
Epoch=031, loss=0.1774
Epoch=032, loss=0.1747
Epoch=033, loss=0.1672
Epoch=034, loss=0.1584
Epoch=035, loss=0.1640
Epoch=036, loss=0.1353
Epoch=037, loss=0.1380
Epoch=038, loss=0.1383
Epoch=039, loss=0.1298
Epoch=040, loss=0.1194
Epoch=041, loss=0.1278
Epoch=042, loss=0.1217
Epoch=043, loss=0.1191
Epoch=044, loss=0.1068
Epoch=045, loss=0.1178
Epoch=046, loss=0.1139
Epoch=047, loss=0.1158
Epoch=048, loss=0.0914
Epoch=049, loss=0.0913
Epoch=050, loss=0.0918
Epoch=051, loss=0.0911
Epoch=052, loss=0.1000
Epoch=053, loss=0.0855
Epoch=054, loss=0.0841
Epoch=055, loss=0.0841
Epoch=056, loss=0.0750
Epoch=057, loss=0.0740
Epoch=058, loss=0.0767
Epoch=059, loss=0.0870
Epoch=060, loss=0.0863
Epoch=061, loss=0.0870
Epoch=062, loss=0.0847
Epoch=063, loss=0.0655
Epoch=064, loss=0.0796
Epoch=065, loss=0.0759
Epoch=066, loss=0.0745
Epoch=067, loss=0.0653
Epoch=068, loss=0.0802
Epoch=069, loss=0.0660
Epoch=070, loss=0.0715
Epoch=071, loss=0.0617
Epoch=072, loss=0.0635
Epoch=073, loss=0.0768
Epoch=074, loss=0.0683
Epoch=075, loss=0.0459
Epoch=076, loss=0.0882
Epoch=077, loss=0.0641
Epoch=078, loss=0.0632
Epoch=079, loss=0.0727
Epoch=080, loss=0.0559
Epoch=081, loss=0.0654
Epoch=082, loss=0.0603
Epoch=083, loss=0.0615
Epoch=084, loss=0.0633
Epoch=085, loss=0.0577
Epoch=086, loss=0.0556
Epoch=087, loss=0.0671
Epoch=088, loss=0.0462
Epoch=089, loss=0.0600
Epoch=090, loss=0.0497
Epoch=091, loss=0.0744
Epoch=092, loss=0.0558
Epoch=093, loss=0.0429
Epoch=094, loss=0.0587
Epoch=095, loss=0.0444
Epoch=096, loss=0.0579
Epoch=097, loss=0.0533
Epoch=098, loss=0.0594
Epoch=099, loss=0.0481
Epoch=100, loss=0.0449
Epoch=101, loss=0.0468
Epoch=102, loss=0.0496
Epoch=103, loss=0.0406
Epoch=104, loss=0.0585
Epoch=105, loss=0.0496
Epoch=106, loss=0.0616
Epoch=107, loss=0.0379
Epoch=108, loss=0.0470
Epoch=109, loss=0.0444
Epoch=110, loss=0.0540
Epoch=111, loss=0.0542
Epoch=112, loss=0.0478
Epoch=113, loss=0.0377
Epoch=114, loss=0.0531
Epoch=115, loss=0.0477
Epoch=116, loss=0.0564
Epoch=117, loss=0.0399
Epoch=118, loss=0.0511
Epoch=119, loss=0.0348
Epoch=120, loss=0.0339
Epoch=121, loss=0.0435
Epoch=122, loss=0.0389
Epoch=123, loss=0.0403
Epoch=124, loss=0.0463
Epoch=125, loss=0.0439
Epoch=126, loss=0.0439
Epoch=127, loss=0.0328
Epoch=128, loss=0.0359
Epoch=129, loss=0.0374
Epoch=130, loss=0.0475
Epoch=131, loss=0.0357
Epoch=132, loss=0.0366
Epoch=133, loss=0.0387
Epoch=134, loss=0.0487
Epoch=135, loss=0.0513
Epoch=136, loss=0.0364
Epoch=137, loss=0.0407
Epoch=138, loss=0.0369
Epoch=139, loss=0.0354
Epoch=140, loss=0.0376
Epoch=141, loss=0.0319
Epoch=142, loss=0.0373
Epoch=143, loss=0.0370
Epoch=144, loss=0.0315
Epoch=145, loss=0.0440
Epoch=146, loss=0.0315
Epoch=147, loss=0.0252
Epoch=148, loss=0.0321
Epoch=149, loss=0.0302
Epoch=150, loss=0.0444
Epoch=151, loss=0.0376
Epoch=152, loss=0.0339
Epoch=153, loss=0.0240
Epoch=154, loss=0.0349
Epoch=155, loss=0.0303
Epoch=156, loss=0.0312
Epoch=157, loss=0.0322
Epoch=158, loss=0.0356
Epoch=159, loss=0.0313
Epoch=160, loss=0.0316
Epoch=161, loss=0.0276
Epoch=162, loss=0.0380
Epoch=163, loss=0.0365
Epoch=164, loss=0.0349
Epoch=165, loss=0.0345
Epoch=166, loss=0.0278
Epoch=167, loss=0.0281
Epoch=168, loss=0.0311
Epoch=169, loss=0.0292
Epoch=170, loss=0.0266
Epoch=171, loss=0.0287
Epoch=172, loss=0.0203
Epoch=173, loss=0.0310
Epoch=174, loss=0.0311
Epoch=175, loss=0.0188
Epoch=176, loss=0.0354
Epoch=177, loss=0.0279
Epoch=178, loss=0.0363
Epoch=179, loss=0.0335
Epoch=180, loss=0.0191
Epoch=181, loss=0.0236
Epoch=182, loss=0.0294
Epoch=183, loss=0.0205
Epoch=184, loss=0.0395
Epoch=185, loss=0.0315
Epoch=186, loss=0.0323
Epoch=187, loss=0.0269
Epoch=188, loss=0.0256
Epoch=189, loss=0.0319
Epoch=190, loss=0.0334
Epoch=191, loss=0.0257
Epoch=192, loss=0.0269
Epoch=193, loss=0.0223
Epoch=194, loss=0.0213
Epoch=195, loss=0.0235
Early stopping!
Loading 175th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8184+-0.0100, F1Ma=0.8044+-0.0132, acc=0.8184+-0.0100
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929531235602327, 0.7895258122502471, 0.8020120333130498, 0.7915496942654312, 0.8357142806053162, 0.7580000162124634, 0.7529013752937317, 0.8642857074737549, 0.7580000162124634, 0.7625725269317627, 0.7878740769529731, 0.018499805674310175, 0.7485698505034516, 0.03786179248380028, 0.7878740769529733, 0.01849980567431013], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7821459076054664, 0.7739728387099222, 0.7818484925952998, 0.7678131636609296, 0.8857142925262451, 0.777999997138977, 0.7446808218955994, 0.8785714507102966, 0.7739999890327454, 0.7412959337234497, 0.7940147687524292, 0.010765011816409875, 0.7747264799914066, 0.013397076931117777, 0.7940147687524292, 0.01076501181640984], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7827515779849454, 0.7750215733778016, 0.7955597002833699, 0.7765945976111648, 0.9428571462631226, 0.8159999847412109, 0.8075435161590576, 0.9428571462631226, 0.8159999847412109, 0.8099613189697266, 0.8029537504858142, 0.005669516526641433, 0.780785591265281, 0.006268099161052819, 0.8029537504858142, 0.005669516526641433], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7703066267424162, 0.77962294226311, 0.7748308602990686, 0.7747810445547125, 0.9428571462631226, 0.8080000281333923, 0.7877175807952881, 0.9428571462631226, 0.8080000281333923, 0.7877175807952881, 0.8184220753983678, 0.010031121473766457, 0.8044463981246306, 0.013247614806239032, 0.8184220753983678, 0.010031121473766438]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6923
Epoch=002, loss=0.6873
Epoch=003, loss=0.6794
Epoch=004, loss=0.6722
Epoch=005, loss=0.6584
Epoch=006, loss=0.6464
Epoch=007, loss=0.6242
Epoch=008, loss=0.6084
Epoch=009, loss=0.5844
Epoch=010, loss=0.5546
Epoch=011, loss=0.5250
Epoch=012, loss=0.5013
Epoch=013, loss=0.4894
Epoch=014, loss=0.4288
Epoch=015, loss=0.4084
Epoch=016, loss=0.3961
Epoch=017, loss=0.3387
Epoch=018, loss=0.3142
Epoch=019, loss=0.3118
Epoch=020, loss=0.2646
Epoch=021, loss=0.2517
Epoch=022, loss=0.2190
Epoch=023, loss=0.2045
Epoch=024, loss=0.1868
Epoch=025, loss=0.1790
Epoch=026, loss=0.1593
Epoch=027, loss=0.1631
Epoch=028, loss=0.1599
Epoch=029, loss=0.1421
Epoch=030, loss=0.1667
Epoch=031, loss=0.1356
Epoch=032, loss=0.1229
Epoch=033, loss=0.0862
Epoch=034, loss=0.1016
Epoch=035, loss=0.0991
Epoch=036, loss=0.0848
Epoch=037, loss=0.0827
Epoch=038, loss=0.0893
Epoch=039, loss=0.0732
Epoch=040, loss=0.0780
Epoch=041, loss=0.0674
Epoch=042, loss=0.0799
Epoch=043, loss=0.0663
Epoch=044, loss=0.0572
Epoch=045, loss=0.0579
Epoch=046, loss=0.0525
Epoch=047, loss=0.0644
Epoch=048, loss=0.0483
Epoch=049, loss=0.0523
Epoch=050, loss=0.0436
Epoch=051, loss=0.0543
Epoch=052, loss=0.0449
Epoch=053, loss=0.0532
Epoch=054, loss=0.0357
Epoch=055, loss=0.0283
Epoch=056, loss=0.0296
Epoch=057, loss=0.0392
Epoch=058, loss=0.0260
Epoch=059, loss=0.0321
Epoch=060, loss=0.0328
Epoch=061, loss=0.0364
Epoch=062, loss=0.0363
Epoch=063, loss=0.0242
Epoch=064, loss=0.0321
Epoch=065, loss=0.0284
Epoch=066, loss=0.0258
Epoch=067, loss=0.0241
Epoch=068, loss=0.0380
Epoch=069, loss=0.0315
Epoch=070, loss=0.0272
Epoch=071, loss=0.0307
Epoch=072, loss=0.0180
Epoch=073, loss=0.0140
Epoch=074, loss=0.0226
Epoch=075, loss=0.0193
Epoch=076, loss=0.0196
Epoch=077, loss=0.0170
Epoch=078, loss=0.0242
Epoch=079, loss=0.0188
Epoch=080, loss=0.0190
Epoch=081, loss=0.0196
Epoch=082, loss=0.0190
Epoch=083, loss=0.0164
Epoch=084, loss=0.0206
Epoch=085, loss=0.0262
Epoch=086, loss=0.0136
Epoch=087, loss=0.0226
Epoch=088, loss=0.0160
Epoch=089, loss=0.0112
Epoch=090, loss=0.0126
Epoch=091, loss=0.0120
Epoch=092, loss=0.0187
Epoch=093, loss=0.0132
Epoch=094, loss=0.0127
Epoch=095, loss=0.0120
Epoch=096, loss=0.0119
Epoch=097, loss=0.0170
Epoch=098, loss=0.0105
Epoch=099, loss=0.0143
Epoch=100, loss=0.0080
Epoch=101, loss=0.0113
Epoch=102, loss=0.0215
Epoch=103, loss=0.0118
Epoch=104, loss=0.0087
Epoch=105, loss=0.0127
Epoch=106, loss=0.0079
Epoch=107, loss=0.0099
Epoch=108, loss=0.0070
Epoch=109, loss=0.0137
Epoch=110, loss=0.0102
Epoch=111, loss=0.0103
Epoch=112, loss=0.0085
Epoch=113, loss=0.0094
Epoch=114, loss=0.0103
Epoch=115, loss=0.0065
Epoch=116, loss=0.0088
Epoch=117, loss=0.0057
Epoch=118, loss=0.0088
Epoch=119, loss=0.0061
Epoch=120, loss=0.0066
Epoch=121, loss=0.0085
Epoch=122, loss=0.0063
Epoch=123, loss=0.0058
Epoch=124, loss=0.0143
Epoch=125, loss=0.0080
Epoch=126, loss=0.0054
Epoch=127, loss=0.0074
Epoch=128, loss=0.0102
Epoch=129, loss=0.0081
Epoch=130, loss=0.0072
Epoch=131, loss=0.0054
Epoch=132, loss=0.0033
Epoch=133, loss=0.0097
Epoch=134, loss=0.0074
Epoch=135, loss=0.0059
Epoch=136, loss=0.0056
Epoch=137, loss=0.0054
Epoch=138, loss=0.0047
Epoch=139, loss=0.0055
Epoch=140, loss=0.0061
Epoch=141, loss=0.0079
Epoch=142, loss=0.0076
Epoch=143, loss=0.0048
Epoch=144, loss=0.0043
Epoch=145, loss=0.0103
Epoch=146, loss=0.0046
Epoch=147, loss=0.0081
Epoch=148, loss=0.0066
Epoch=149, loss=0.0051
Epoch=150, loss=0.0109
Epoch=151, loss=0.0033
Epoch=152, loss=0.0053
Epoch=153, loss=0.0052
Epoch=154, loss=0.0082
Epoch=155, loss=0.0032
Epoch=156, loss=0.0032
Epoch=157, loss=0.0087
Epoch=158, loss=0.0089
Epoch=159, loss=0.0037
Epoch=160, loss=0.0040
Epoch=161, loss=0.0043
Epoch=162, loss=0.0141
Epoch=163, loss=0.0052
Epoch=164, loss=0.0069
Epoch=165, loss=0.0068
Epoch=166, loss=0.0020
Epoch=167, loss=0.0051
Epoch=168, loss=0.0065
Epoch=169, loss=0.0052
Epoch=170, loss=0.0058
Epoch=171, loss=0.0087
Epoch=172, loss=0.0041
Epoch=173, loss=0.0021
Epoch=174, loss=0.0062
Epoch=175, loss=0.0090
Epoch=176, loss=0.0033
Epoch=177, loss=0.0078
Epoch=178, loss=0.0060
Epoch=179, loss=0.0049
Epoch=180, loss=0.0114
Epoch=181, loss=0.0035
Epoch=182, loss=0.0026
Epoch=183, loss=0.0042
Epoch=184, loss=0.0056
Epoch=185, loss=0.0097
Epoch=186, loss=0.0042
Early stopping!
Loading 166th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8005+-0.0089, F1Ma=0.7804+-0.0147, acc=0.8005+-0.0089
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7605796582528653, 0.7771569568863665, 0.7977452840718828, 0.8041542758690012, 0.7928571701049805, 0.7559999823570251, 0.740812361240387, 0.7785714268684387, 0.75, 0.7369439005851746, 0.7207928488146133, 0.01978476029107555, 0.6499239416080951, 0.01628553923515609, 0.7207928488146133, 0.01978476029107555], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929531235602327, 0.7895258122502471, 0.8020120333130498, 0.7915496942654312, 0.8357142806053162, 0.7580000162124634, 0.7529013752937317, 0.8642857074737549, 0.7580000162124634, 0.7625725269317627, 0.7878740769529731, 0.018499805674310175, 0.7485698505034516, 0.03786179248380028, 0.7878740769529733, 0.01849980567431013], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7821459076054664, 0.7739728387099222, 0.7818484925952998, 0.7678131636609296, 0.8857142925262451, 0.777999997138977, 0.7446808218955994, 0.8785714507102966, 0.7739999890327454, 0.7412959337234497, 0.7940147687524292, 0.010765011816409875, 0.7747264799914066, 0.013397076931117777, 0.7940147687524292, 0.01076501181640984], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7827515779849454, 0.7750215733778016, 0.7955597002833699, 0.7765945976111648, 0.9428571462631226, 0.8159999847412109, 0.8075435161590576, 0.9428571462631226, 0.8159999847412109, 0.8099613189697266, 0.8029537504858142, 0.005669516526641433, 0.780785591265281, 0.006268099161052819, 0.8029537504858142, 0.005669516526641433], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7703066267424162, 0.77962294226311, 0.7748308602990686, 0.7747810445547125, 0.9428571462631226, 0.8080000281333923, 0.7877175807952881, 0.9428571462631226, 0.8080000281333923, 0.7877175807952881, 0.8184220753983678, 0.010031121473766457, 0.8044463981246306, 0.013247614806239032, 0.8184220753983678, 0.010031121473766438], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7199178995046406, 0.7377977234036353, 0.7087394546482362, 0.7438293473282569, 0.949999988079071, 0.828000009059906, 0.7949709892272949, 0.949999988079071, 0.8299999833106995, 0.7954545617103577, 0.8005441119315974, 0.008867385934783456, 0.7803857263289722, 0.014695560906862037, 0.8005441119315974, 0.008867385934783456]]
