My SLURM_ARRAY_TASK_ID:  11
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_11
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_11.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6928
Epoch=009, loss=0.6927
Epoch=010, loss=0.6927
Epoch=011, loss=0.6927
Epoch=012, loss=0.6926
Epoch=013, loss=0.6925
Epoch=014, loss=0.6924
Epoch=015, loss=0.6923
Epoch=016, loss=0.6923
Epoch=017, loss=0.6922
Epoch=018, loss=0.6921
Epoch=019, loss=0.6919
Epoch=020, loss=0.6918
Epoch=021, loss=0.6917
Epoch=022, loss=0.6916
Epoch=023, loss=0.6915
Epoch=024, loss=0.6913
Epoch=025, loss=0.6912
Epoch=026, loss=0.6910
Epoch=027, loss=0.6908
Epoch=028, loss=0.6907
Epoch=029, loss=0.6905
Epoch=030, loss=0.6903
Epoch=031, loss=0.6901
Epoch=032, loss=0.6899
Epoch=033, loss=0.6896
Epoch=034, loss=0.6893
Epoch=035, loss=0.6890
Epoch=036, loss=0.6887
Epoch=037, loss=0.6886
Epoch=038, loss=0.6881
Epoch=039, loss=0.6879
Epoch=040, loss=0.6874
Epoch=041, loss=0.6871
Epoch=042, loss=0.6868
Epoch=043, loss=0.6863
Epoch=044, loss=0.6858
Epoch=045, loss=0.6852
Epoch=046, loss=0.6848
Epoch=047, loss=0.6843
Epoch=048, loss=0.6840
Epoch=049, loss=0.6835
Epoch=050, loss=0.6828
Epoch=051, loss=0.6822
Epoch=052, loss=0.6817
Epoch=053, loss=0.6810
Epoch=054, loss=0.6801
Epoch=055, loss=0.6794
Epoch=056, loss=0.6785
Epoch=057, loss=0.6780
Epoch=058, loss=0.6770
Epoch=059, loss=0.6763
Epoch=060, loss=0.6759
Epoch=061, loss=0.6746
Epoch=062, loss=0.6735
Epoch=063, loss=0.6724
Epoch=064, loss=0.6713
Epoch=065, loss=0.6704
Epoch=066, loss=0.6694
Epoch=067, loss=0.6682
Epoch=068, loss=0.6667
Epoch=069, loss=0.6662
Epoch=070, loss=0.6641
Epoch=071, loss=0.6638
Epoch=072, loss=0.6617
Epoch=073, loss=0.6605
Epoch=074, loss=0.6589
Epoch=075, loss=0.6576
Epoch=076, loss=0.6556
Epoch=077, loss=0.6540
Epoch=078, loss=0.6529
Epoch=079, loss=0.6507
Epoch=080, loss=0.6492
Epoch=081, loss=0.6473
Epoch=082, loss=0.6451
Epoch=083, loss=0.6430
Epoch=084, loss=0.6423
Epoch=085, loss=0.6391
Epoch=086, loss=0.6386
Epoch=087, loss=0.6357
Epoch=088, loss=0.6330
Epoch=089, loss=0.6317
Epoch=090, loss=0.6282
Epoch=091, loss=0.6274
Epoch=092, loss=0.6242
Epoch=093, loss=0.6226
Epoch=094, loss=0.6200
Epoch=095, loss=0.6152
Epoch=096, loss=0.6136
Epoch=097, loss=0.6128
Epoch=098, loss=0.6082
Epoch=099, loss=0.6063
Epoch=100, loss=0.6035
Epoch=101, loss=0.5990
Epoch=102, loss=0.5982
Epoch=103, loss=0.5959
Epoch=104, loss=0.5925
Epoch=105, loss=0.5906
Epoch=106, loss=0.5871
Epoch=107, loss=0.5820
Epoch=108, loss=0.5792
Epoch=109, loss=0.5738
Epoch=110, loss=0.5747
Epoch=111, loss=0.5694
Epoch=112, loss=0.5669
Epoch=113, loss=0.5636
Epoch=114, loss=0.5598
Epoch=115, loss=0.5593
Epoch=116, loss=0.5559
Epoch=117, loss=0.5481
Epoch=118, loss=0.5468
Epoch=119, loss=0.5438
Epoch=120, loss=0.5361
Epoch=121, loss=0.5365
Epoch=122, loss=0.5323
Epoch=123, loss=0.5270
Epoch=124, loss=0.5240
Epoch=125, loss=0.5223
Epoch=126, loss=0.5156
Epoch=127, loss=0.5124
Epoch=128, loss=0.5092
Epoch=129, loss=0.5062
Epoch=130, loss=0.5020
Epoch=131, loss=0.5004
Epoch=132, loss=0.4922
Epoch=133, loss=0.4889
Epoch=134, loss=0.4855
Epoch=135, loss=0.4774
Epoch=136, loss=0.4773
Epoch=137, loss=0.4749
Epoch=138, loss=0.4702
Epoch=139, loss=0.4687
Epoch=140, loss=0.4661
Epoch=141, loss=0.4574
Epoch=142, loss=0.4568
Epoch=143, loss=0.4494
Epoch=144, loss=0.4468
Epoch=145, loss=0.4455
Epoch=146, loss=0.4358
Epoch=147, loss=0.4364
Epoch=148, loss=0.4316
Epoch=149, loss=0.4230
Epoch=150, loss=0.4276
Epoch=151, loss=0.4198
Epoch=152, loss=0.4170
Epoch=153, loss=0.4111
Epoch=154, loss=0.4057
Epoch=155, loss=0.4018
Epoch=156, loss=0.4007
Epoch=157, loss=0.3935
Epoch=158, loss=0.3897
Epoch=159, loss=0.3894
Epoch=160, loss=0.3818
Epoch=161, loss=0.3845
Epoch=162, loss=0.3712
Epoch=163, loss=0.3696
Epoch=164, loss=0.3608
Epoch=165, loss=0.3639
Epoch=166, loss=0.3620
Epoch=167, loss=0.3582
Epoch=168, loss=0.3492
Epoch=169, loss=0.3486
Epoch=170, loss=0.3436
Epoch=171, loss=0.3458
Epoch=172, loss=0.3375
Epoch=173, loss=0.3317
Epoch=174, loss=0.3312
Epoch=175, loss=0.3241
Epoch=176, loss=0.3328
Epoch=177, loss=0.3136
Epoch=178, loss=0.3188
Epoch=179, loss=0.3270
Epoch=180, loss=0.3182
Epoch=181, loss=0.3105
Epoch=182, loss=0.3088
Epoch=183, loss=0.3061
Epoch=184, loss=0.3028
Epoch=185, loss=0.2948
Epoch=186, loss=0.2883
Epoch=187, loss=0.2911
Epoch=188, loss=0.2962
Epoch=189, loss=0.2811
Epoch=190, loss=0.2880
Epoch=191, loss=0.2749
Epoch=192, loss=0.2732
Epoch=193, loss=0.2741
Epoch=194, loss=0.2693
Epoch=195, loss=0.2669
Epoch=196, loss=0.2660
Epoch=197, loss=0.2635
Epoch=198, loss=0.2592
Epoch=199, loss=0.2674
Epoch=200, loss=0.2640
Epoch=201, loss=0.2561
Epoch=202, loss=0.2474
Epoch=203, loss=0.2501
Epoch=204, loss=0.2536
Epoch=205, loss=0.2444
Epoch=206, loss=0.2503
Epoch=207, loss=0.2497
Epoch=208, loss=0.2350
Epoch=209, loss=0.2363
Epoch=210, loss=0.2317
Epoch=211, loss=0.2382
Epoch=212, loss=0.2295
Epoch=213, loss=0.2351
Epoch=214, loss=0.2231
Epoch=215, loss=0.2226
Epoch=216, loss=0.2260
Epoch=217, loss=0.2239
Epoch=218, loss=0.2202
Epoch=219, loss=0.2232
Epoch=220, loss=0.2154
Epoch=221, loss=0.2119
Epoch=222, loss=0.2172
Epoch=223, loss=0.2096
Epoch=224, loss=0.2117
Epoch=225, loss=0.2018
Epoch=226, loss=0.2133
Epoch=227, loss=0.2046
Epoch=228, loss=0.2003
Epoch=229, loss=0.2010
Epoch=230, loss=0.2031
Epoch=231, loss=0.2010
Epoch=232, loss=0.1891
Epoch=233, loss=0.1961
Epoch=234, loss=0.1929
Epoch=235, loss=0.1853
Epoch=236, loss=0.1897
Epoch=237, loss=0.1940
Epoch=238, loss=0.1860
Epoch=239, loss=0.1904
Epoch=240, loss=0.1826
Epoch=241, loss=0.1855
Epoch=242, loss=0.1814
Epoch=243, loss=0.1786
Epoch=244, loss=0.1802
Epoch=245, loss=0.1854
Epoch=246, loss=0.1789
Epoch=247, loss=0.1779
Epoch=248, loss=0.1745
Epoch=249, loss=0.1735
Epoch=250, loss=0.1700
Epoch=251, loss=0.1760
Epoch=252, loss=0.1662
Epoch=253, loss=0.1724
Epoch=254, loss=0.1616
Epoch=255, loss=0.1688
Epoch=256, loss=0.1565
Epoch=257, loss=0.1590
Epoch=258, loss=0.1678
Epoch=259, loss=0.1636
Epoch=260, loss=0.1588
Epoch=261, loss=0.1773
Epoch=262, loss=0.1612
Epoch=263, loss=0.1547
Epoch=264, loss=0.1632
Epoch=265, loss=0.1538
Epoch=266, loss=0.1524
Epoch=267, loss=0.1566
Epoch=268, loss=0.1509
Epoch=269, loss=0.1562
Epoch=270, loss=0.1443
Epoch=271, loss=0.1501
Epoch=272, loss=0.1549
Epoch=273, loss=0.1428
Epoch=274, loss=0.1574
Epoch=275, loss=0.1464
Epoch=276, loss=0.1390
Epoch=277, loss=0.1619
Epoch=278, loss=0.1467
Epoch=279, loss=0.1533
Epoch=280, loss=0.1412
Epoch=281, loss=0.1400
Epoch=282, loss=0.1455
Epoch=283, loss=0.1386
Epoch=284, loss=0.1379
Epoch=285, loss=0.1354
Epoch=286, loss=0.1301
Epoch=287, loss=0.1429
Epoch=288, loss=0.1369
Epoch=289, loss=0.1347
Epoch=290, loss=0.1239
Epoch=291, loss=0.1373
Epoch=292, loss=0.1271
Epoch=293, loss=0.1352
Epoch=294, loss=0.1308
Epoch=295, loss=0.1274
Epoch=296, loss=0.1310
Epoch=297, loss=0.1304
Epoch=298, loss=0.1254
Epoch=299, loss=0.1211
Epoch=300, loss=0.1263
Epoch=301, loss=0.1240
Epoch=302, loss=0.1286
Epoch=303, loss=0.1260
Epoch=304, loss=0.1358
Epoch=305, loss=0.1286
Epoch=306, loss=0.1219
Epoch=307, loss=0.1258
Epoch=308, loss=0.1237
Epoch=309, loss=0.1233
Epoch=310, loss=0.1272
Epoch=311, loss=0.1125
Epoch=312, loss=0.1161
Epoch=313, loss=0.1148
Epoch=314, loss=0.1188
Epoch=315, loss=0.1187
Epoch=316, loss=0.1148
Epoch=317, loss=0.1139
Epoch=318, loss=0.1205
Epoch=319, loss=0.1036
Epoch=320, loss=0.1115
Epoch=321, loss=0.1108
Epoch=322, loss=0.1089
Epoch=323, loss=0.1093
Epoch=324, loss=0.1234
Epoch=325, loss=0.1162
Epoch=326, loss=0.1074
Epoch=327, loss=0.1219
Epoch=328, loss=0.1244
Epoch=329, loss=0.1002
Epoch=330, loss=0.1036
Epoch=331, loss=0.1120
Epoch=332, loss=0.1107
Epoch=333, loss=0.1154
Epoch=334, loss=0.1228
Epoch=335, loss=0.1101
Epoch=336, loss=0.0981
Epoch=337, loss=0.1075
Epoch=338, loss=0.1174
Epoch=339, loss=0.1075
Epoch=340, loss=0.1004
Epoch=341, loss=0.0998
Epoch=342, loss=0.1017
Epoch=343, loss=0.0974
Epoch=344, loss=0.0927
Epoch=345, loss=0.0991
Epoch=346, loss=0.1031
Epoch=347, loss=0.1014
Epoch=348, loss=0.1126
Epoch=349, loss=0.1068
Epoch=350, loss=0.1022
Epoch=351, loss=0.0985
Epoch=352, loss=0.0997
Epoch=353, loss=0.0960
Epoch=354, loss=0.1047
Epoch=355, loss=0.0979
Epoch=356, loss=0.0942
Epoch=357, loss=0.0958
Epoch=358, loss=0.0978
Epoch=359, loss=0.0916
Epoch=360, loss=0.1015
Epoch=361, loss=0.1078
Epoch=362, loss=0.0894
Epoch=363, loss=0.1030
Epoch=364, loss=0.0864
Epoch=365, loss=0.0905
Epoch=366, loss=0.0998
Epoch=367, loss=0.0963
Epoch=368, loss=0.0978
Epoch=369, loss=0.0919
Epoch=370, loss=0.0864
Epoch=371, loss=0.0879
Epoch=372, loss=0.0925
Epoch=373, loss=0.0892
Epoch=374, loss=0.1004
Epoch=375, loss=0.1033
Epoch=376, loss=0.0944
Epoch=377, loss=0.0902
Epoch=378, loss=0.0868
Epoch=379, loss=0.1002
Epoch=380, loss=0.0936
Epoch=381, loss=0.0966
Epoch=382, loss=0.0973
Epoch=383, loss=0.0893
Epoch=384, loss=0.0932
Early stopping!
Loading 364th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7195+-0.0203, F1Ma=0.6582+-0.0340, acc=0.7195+-0.0203
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6929
Epoch=003, loss=0.6929
Epoch=004, loss=0.6928
Epoch=005, loss=0.6927
Epoch=006, loss=0.6925
Epoch=007, loss=0.6925
Epoch=008, loss=0.6923
Epoch=009, loss=0.6921
Epoch=010, loss=0.6920
Epoch=011, loss=0.6918
Epoch=012, loss=0.6916
Epoch=013, loss=0.6914
Epoch=014, loss=0.6911
Epoch=015, loss=0.6908
Epoch=016, loss=0.6905
Epoch=017, loss=0.6902
Epoch=018, loss=0.6898
Epoch=019, loss=0.6894
Epoch=020, loss=0.6890
Epoch=021, loss=0.6885
Epoch=022, loss=0.6880
Epoch=023, loss=0.6874
Epoch=024, loss=0.6867
Epoch=025, loss=0.6861
Epoch=026, loss=0.6855
Epoch=027, loss=0.6845
Epoch=028, loss=0.6836
Epoch=029, loss=0.6829
Epoch=030, loss=0.6819
Epoch=031, loss=0.6811
Epoch=032, loss=0.6797
Epoch=033, loss=0.6787
Epoch=034, loss=0.6772
Epoch=035, loss=0.6760
Epoch=036, loss=0.6739
Epoch=037, loss=0.6729
Epoch=038, loss=0.6713
Epoch=039, loss=0.6693
Epoch=040, loss=0.6677
Epoch=041, loss=0.6658
Epoch=042, loss=0.6637
Epoch=043, loss=0.6615
Epoch=044, loss=0.6589
Epoch=045, loss=0.6563
Epoch=046, loss=0.6543
Epoch=047, loss=0.6504
Epoch=048, loss=0.6475
Epoch=049, loss=0.6450
Epoch=050, loss=0.6417
Epoch=051, loss=0.6386
Epoch=052, loss=0.6360
Epoch=053, loss=0.6325
Epoch=054, loss=0.6277
Epoch=055, loss=0.6231
Epoch=056, loss=0.6198
Epoch=057, loss=0.6158
Epoch=058, loss=0.6120
Epoch=059, loss=0.6071
Epoch=060, loss=0.6022
Epoch=061, loss=0.5974
Epoch=062, loss=0.5944
Epoch=063, loss=0.5874
Epoch=064, loss=0.5830
Epoch=065, loss=0.5771
Epoch=066, loss=0.5718
Epoch=067, loss=0.5681
Epoch=068, loss=0.5603
Epoch=069, loss=0.5540
Epoch=070, loss=0.5501
Epoch=071, loss=0.5420
Epoch=072, loss=0.5367
Epoch=073, loss=0.5307
Epoch=074, loss=0.5246
Epoch=075, loss=0.5164
Epoch=076, loss=0.5116
Epoch=077, loss=0.5025
Epoch=078, loss=0.4978
Epoch=079, loss=0.4905
Epoch=080, loss=0.4851
Epoch=081, loss=0.4750
Epoch=082, loss=0.4741
Epoch=083, loss=0.4655
Epoch=084, loss=0.4559
Epoch=085, loss=0.4514
Epoch=086, loss=0.4445
Epoch=087, loss=0.4349
Epoch=088, loss=0.4268
Epoch=089, loss=0.4168
Epoch=090, loss=0.4152
Epoch=091, loss=0.4035
Epoch=092, loss=0.3986
Epoch=093, loss=0.3934
Epoch=094, loss=0.3873
Epoch=095, loss=0.3839
Epoch=096, loss=0.3747
Epoch=097, loss=0.3610
Epoch=098, loss=0.3563
Epoch=099, loss=0.3556
Epoch=100, loss=0.3474
Epoch=101, loss=0.3309
Epoch=102, loss=0.3386
Epoch=103, loss=0.3262
Epoch=104, loss=0.3271
Epoch=105, loss=0.3146
Epoch=106, loss=0.3056
Epoch=107, loss=0.3084
Epoch=108, loss=0.2915
Epoch=109, loss=0.2911
Epoch=110, loss=0.2937
Epoch=111, loss=0.2808
Epoch=112, loss=0.2741
Epoch=113, loss=0.2726
Epoch=114, loss=0.2624
Epoch=115, loss=0.2603
Epoch=116, loss=0.2545
Epoch=117, loss=0.2532
Epoch=118, loss=0.2434
Epoch=119, loss=0.2383
Epoch=120, loss=0.2336
Epoch=121, loss=0.2303
Epoch=122, loss=0.2272
Epoch=123, loss=0.2166
Epoch=124, loss=0.2212
Epoch=125, loss=0.2040
Epoch=126, loss=0.2156
Epoch=127, loss=0.2100
Epoch=128, loss=0.2060
Epoch=129, loss=0.2064
Epoch=130, loss=0.2015
Epoch=131, loss=0.1900
Epoch=132, loss=0.1989
Epoch=133, loss=0.1849
Epoch=134, loss=0.1843
Epoch=135, loss=0.1863
Epoch=136, loss=0.1795
Epoch=137, loss=0.1706
Epoch=138, loss=0.1700
Epoch=139, loss=0.1710
Epoch=140, loss=0.1689
Epoch=141, loss=0.1618
Epoch=142, loss=0.1742
Epoch=143, loss=0.1606
Epoch=144, loss=0.1591
Epoch=145, loss=0.1554
Epoch=146, loss=0.1508
Epoch=147, loss=0.1531
Epoch=148, loss=0.1510
Epoch=149, loss=0.1545
Epoch=150, loss=0.1488
Epoch=151, loss=0.1447
Epoch=152, loss=0.1464
Epoch=153, loss=0.1461
Epoch=154, loss=0.1466
Epoch=155, loss=0.1356
Epoch=156, loss=0.1352
Epoch=157, loss=0.1423
Epoch=158, loss=0.1295
Epoch=159, loss=0.1222
Epoch=160, loss=0.1285
Epoch=161, loss=0.1352
Epoch=162, loss=0.1306
Epoch=163, loss=0.1354
Epoch=164, loss=0.1282
Epoch=165, loss=0.1227
Epoch=166, loss=0.1244
Epoch=167, loss=0.1191
Epoch=168, loss=0.1188
Epoch=169, loss=0.1137
Epoch=170, loss=0.1232
Epoch=171, loss=0.1193
Epoch=172, loss=0.1077
Epoch=173, loss=0.1117
Epoch=174, loss=0.1186
Epoch=175, loss=0.1113
Epoch=176, loss=0.1059
Epoch=177, loss=0.1134
Epoch=178, loss=0.1101
Epoch=179, loss=0.1089
Epoch=180, loss=0.1010
Epoch=181, loss=0.1035
Epoch=182, loss=0.1049
Epoch=183, loss=0.1142
Epoch=184, loss=0.1010
Epoch=185, loss=0.0910
Epoch=186, loss=0.1036
Epoch=187, loss=0.1039
Epoch=188, loss=0.0971
Epoch=189, loss=0.0985
Epoch=190, loss=0.0968
Epoch=191, loss=0.1043
Epoch=192, loss=0.1006
Epoch=193, loss=0.0915
Epoch=194, loss=0.0927
Epoch=195, loss=0.0833
Epoch=196, loss=0.0867
Epoch=197, loss=0.0869
Epoch=198, loss=0.0941
Epoch=199, loss=0.0917
Epoch=200, loss=0.0979
Epoch=201, loss=0.0923
Epoch=202, loss=0.0871
Epoch=203, loss=0.0923
Epoch=204, loss=0.0924
Epoch=205, loss=0.0962
Epoch=206, loss=0.0911
Epoch=207, loss=0.0861
Epoch=208, loss=0.0889
Epoch=209, loss=0.0854
Epoch=210, loss=0.0911
Epoch=211, loss=0.0858
Epoch=212, loss=0.0839
Epoch=213, loss=0.0824
Epoch=214, loss=0.0843
Epoch=215, loss=0.0776
Epoch=216, loss=0.0910
Epoch=217, loss=0.0774
Epoch=218, loss=0.0879
Epoch=219, loss=0.0769
Epoch=220, loss=0.0828
Epoch=221, loss=0.0855
Epoch=222, loss=0.0757
Epoch=223, loss=0.0703
Epoch=224, loss=0.0881
Epoch=225, loss=0.0774
Epoch=226, loss=0.0671
Epoch=227, loss=0.0733
Epoch=228, loss=0.0667
Epoch=229, loss=0.0889
Epoch=230, loss=0.0762
Epoch=231, loss=0.0733
Epoch=232, loss=0.0700
Epoch=233, loss=0.0658
Epoch=234, loss=0.0686
Epoch=235, loss=0.0609
Epoch=236, loss=0.0679
Epoch=237, loss=0.0677
Epoch=238, loss=0.0760
Epoch=239, loss=0.0683
Epoch=240, loss=0.0845
Epoch=241, loss=0.0707
Epoch=242, loss=0.0635
Epoch=243, loss=0.0644
Epoch=244, loss=0.0672
Epoch=245, loss=0.0614
Epoch=246, loss=0.0698
Epoch=247, loss=0.0631
Epoch=248, loss=0.0742
Epoch=249, loss=0.0672
Epoch=250, loss=0.0597
Epoch=251, loss=0.0599
Epoch=252, loss=0.0731
Epoch=253, loss=0.0743
Epoch=254, loss=0.0693
Epoch=255, loss=0.0603
Epoch=256, loss=0.0622
Epoch=257, loss=0.0595
Epoch=258, loss=0.0640
Epoch=259, loss=0.0615
Epoch=260, loss=0.0672
Epoch=261, loss=0.0599
Epoch=262, loss=0.0677
Epoch=263, loss=0.0621
Epoch=264, loss=0.0604
Epoch=265, loss=0.0562
Epoch=266, loss=0.0631
Epoch=267, loss=0.0602
Epoch=268, loss=0.0728
Epoch=269, loss=0.0554
Epoch=270, loss=0.0583
Epoch=271, loss=0.0508
Epoch=272, loss=0.0597
Epoch=273, loss=0.0528
Epoch=274, loss=0.0613
Epoch=275, loss=0.0589
Epoch=276, loss=0.0577
Epoch=277, loss=0.0594
Epoch=278, loss=0.0556
Epoch=279, loss=0.0575
Epoch=280, loss=0.0646
Epoch=281, loss=0.0610
Epoch=282, loss=0.0507
Epoch=283, loss=0.0543
Epoch=284, loss=0.0606
Epoch=285, loss=0.0493
Epoch=286, loss=0.0571
Epoch=287, loss=0.0680
Epoch=288, loss=0.0553
Epoch=289, loss=0.0560
Epoch=290, loss=0.0491
Epoch=291, loss=0.0541
Epoch=292, loss=0.0480
Epoch=293, loss=0.0498
Epoch=294, loss=0.0544
Epoch=295, loss=0.0609
Epoch=296, loss=0.0492
Epoch=297, loss=0.0551
Epoch=298, loss=0.0500
Epoch=299, loss=0.0553
Epoch=300, loss=0.0433
Epoch=301, loss=0.0496
Epoch=302, loss=0.0551
Epoch=303, loss=0.0423
Epoch=304, loss=0.0569
Epoch=305, loss=0.0484
Epoch=306, loss=0.0480
Epoch=307, loss=0.0498
Epoch=308, loss=0.0478
Epoch=309, loss=0.0538
Epoch=310, loss=0.0452
Epoch=311, loss=0.0480
Epoch=312, loss=0.0565
Epoch=313, loss=0.0433
Epoch=314, loss=0.0524
Epoch=315, loss=0.0399
Epoch=316, loss=0.0568
Epoch=317, loss=0.0412
Epoch=318, loss=0.0462
Epoch=319, loss=0.0404
Epoch=320, loss=0.0547
Epoch=321, loss=0.0465
Epoch=322, loss=0.0570
Epoch=323, loss=0.0532
Epoch=324, loss=0.0521
Epoch=325, loss=0.0484
Epoch=326, loss=0.0442
Epoch=327, loss=0.0397
Epoch=328, loss=0.0494
Epoch=329, loss=0.0515
Epoch=330, loss=0.0464
Epoch=331, loss=0.0498
Epoch=332, loss=0.0493
Epoch=333, loss=0.0457
Epoch=334, loss=0.0477
Epoch=335, loss=0.0498
Epoch=336, loss=0.0421
Epoch=337, loss=0.0411
Epoch=338, loss=0.0426
Epoch=339, loss=0.0455
Epoch=340, loss=0.0456
Epoch=341, loss=0.0409
Epoch=342, loss=0.0410
Epoch=343, loss=0.0396
Epoch=344, loss=0.0408
Epoch=345, loss=0.0477
Epoch=346, loss=0.0459
Epoch=347, loss=0.0422
Epoch=348, loss=0.0422
Epoch=349, loss=0.0468
Epoch=350, loss=0.0537
Epoch=351, loss=0.0396
Epoch=352, loss=0.0425
Epoch=353, loss=0.0444
Epoch=354, loss=0.0464
Epoch=355, loss=0.0386
Epoch=356, loss=0.0463
Epoch=357, loss=0.0363
Epoch=358, loss=0.0490
Epoch=359, loss=0.0405
Epoch=360, loss=0.0398
Epoch=361, loss=0.0391
Epoch=362, loss=0.0377
Epoch=363, loss=0.0388
Epoch=364, loss=0.0448
Epoch=365, loss=0.0422
Epoch=366, loss=0.0427
Epoch=367, loss=0.0425
Epoch=368, loss=0.0330
Epoch=369, loss=0.0422
Epoch=370, loss=0.0343
Epoch=371, loss=0.0495
Epoch=372, loss=0.0450
Epoch=373, loss=0.0445
Epoch=374, loss=0.0414
Epoch=375, loss=0.0373
Epoch=376, loss=0.0357
Epoch=377, loss=0.0381
Epoch=378, loss=0.0326
Epoch=379, loss=0.0397
Epoch=380, loss=0.0435
Epoch=381, loss=0.0384
Epoch=382, loss=0.0399
Epoch=383, loss=0.0435
Epoch=384, loss=0.0413
Epoch=385, loss=0.0348
Epoch=386, loss=0.0417
Epoch=387, loss=0.0431
Epoch=388, loss=0.0373
Epoch=389, loss=0.0410
Epoch=390, loss=0.0419
Epoch=391, loss=0.0320
Epoch=392, loss=0.0429
Epoch=393, loss=0.0332
Epoch=394, loss=0.0288
Epoch=395, loss=0.0343
Epoch=396, loss=0.0328
Epoch=397, loss=0.0345
Epoch=398, loss=0.0308
Epoch=399, loss=0.0392
Epoch=400, loss=0.0341
Epoch=401, loss=0.0392
Epoch=402, loss=0.0307
Epoch=403, loss=0.0330
Epoch=404, loss=0.0395
Epoch=405, loss=0.0393
Epoch=406, loss=0.0289
Epoch=407, loss=0.0318
Epoch=408, loss=0.0389
Epoch=409, loss=0.0362
Epoch=410, loss=0.0264
Epoch=411, loss=0.0487
Epoch=412, loss=0.0301
Epoch=413, loss=0.0331
Epoch=414, loss=0.0380
Epoch=415, loss=0.0310
Epoch=416, loss=0.0405
Epoch=417, loss=0.0295
Epoch=418, loss=0.0319
Epoch=419, loss=0.0425
Epoch=420, loss=0.0285
Epoch=421, loss=0.0346
Epoch=422, loss=0.0331
Epoch=423, loss=0.0328
Epoch=424, loss=0.0363
Epoch=425, loss=0.0325
Epoch=426, loss=0.0417
Epoch=427, loss=0.0289
Epoch=428, loss=0.0333
Epoch=429, loss=0.0410
Epoch=430, loss=0.0250
Epoch=431, loss=0.0409
Epoch=432, loss=0.0305
Epoch=433, loss=0.0345
Epoch=434, loss=0.0336
Epoch=435, loss=0.0290
Epoch=436, loss=0.0306
Epoch=437, loss=0.0273
Epoch=438, loss=0.0314
Epoch=439, loss=0.0266
Epoch=440, loss=0.0254
Epoch=441, loss=0.0315
Epoch=442, loss=0.0434
Epoch=443, loss=0.0286
Epoch=444, loss=0.0292
Epoch=445, loss=0.0301
Epoch=446, loss=0.0349
Epoch=447, loss=0.0262
Epoch=448, loss=0.0337
Epoch=449, loss=0.0405
Epoch=450, loss=0.0332
Early stopping!
Loading 430th epoch
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7752+-0.0104, F1Ma=0.7457+-0.0213, acc=0.7752+-0.0104
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.946919007231802, 0.9389081297835806, 0.9418389869261041, 0.9325551320203622, 0.8357142806053162, 0.7519999742507935, 0.7635396718978882, 0.8285714387893677, 0.7519999742507935, 0.7611218690872192, 0.775204041974349, 0.010401344949604903, 0.7457029572432045, 0.02128690215355303, 0.775204041974349, 0.010401344949604903]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6924
Epoch=005, loss=0.6921
Epoch=006, loss=0.6918
Epoch=007, loss=0.6913
Epoch=008, loss=0.6908
Epoch=009, loss=0.6903
Epoch=010, loss=0.6896
Epoch=011, loss=0.6888
Epoch=012, loss=0.6879
Epoch=013, loss=0.6869
Epoch=014, loss=0.6856
Epoch=015, loss=0.6844
Epoch=016, loss=0.6828
Epoch=017, loss=0.6810
Epoch=018, loss=0.6789
Epoch=019, loss=0.6769
Epoch=020, loss=0.6741
Epoch=021, loss=0.6719
Epoch=022, loss=0.6690
Epoch=023, loss=0.6653
Epoch=024, loss=0.6620
Epoch=025, loss=0.6586
Epoch=026, loss=0.6541
Epoch=027, loss=0.6494
Epoch=028, loss=0.6451
Epoch=029, loss=0.6398
Epoch=030, loss=0.6335
Epoch=031, loss=0.6282
Epoch=032, loss=0.6207
Epoch=033, loss=0.6117
Epoch=034, loss=0.6052
Epoch=035, loss=0.5980
Epoch=036, loss=0.5888
Epoch=037, loss=0.5804
Epoch=038, loss=0.5694
Epoch=039, loss=0.5601
Epoch=040, loss=0.5483
Epoch=041, loss=0.5413
Epoch=042, loss=0.5252
Epoch=043, loss=0.5158
Epoch=044, loss=0.5041
Epoch=045, loss=0.4918
Epoch=046, loss=0.4817
Epoch=047, loss=0.4704
Epoch=048, loss=0.4555
Epoch=049, loss=0.4443
Epoch=050, loss=0.4269
Epoch=051, loss=0.4137
Epoch=052, loss=0.3998
Epoch=053, loss=0.3941
Epoch=054, loss=0.3740
Epoch=055, loss=0.3636
Epoch=056, loss=0.3521
Epoch=057, loss=0.3340
Epoch=058, loss=0.3234
Epoch=059, loss=0.3133
Epoch=060, loss=0.3016
Epoch=061, loss=0.2906
Epoch=062, loss=0.2733
Epoch=063, loss=0.2720
Epoch=064, loss=0.2569
Epoch=065, loss=0.2447
Epoch=066, loss=0.2366
Epoch=067, loss=0.2266
Epoch=068, loss=0.2133
Epoch=069, loss=0.2091
Epoch=070, loss=0.2017
Epoch=071, loss=0.1917
Epoch=072, loss=0.1886
Epoch=073, loss=0.1793
Epoch=074, loss=0.1829
Epoch=075, loss=0.1743
Epoch=076, loss=0.1711
Epoch=077, loss=0.1542
Epoch=078, loss=0.1539
Epoch=079, loss=0.1552
Epoch=080, loss=0.1571
Epoch=081, loss=0.1386
Epoch=082, loss=0.1313
Epoch=083, loss=0.1424
Epoch=084, loss=0.1256
Epoch=085, loss=0.1285
Epoch=086, loss=0.1258
Epoch=087, loss=0.1221
Epoch=088, loss=0.1129
Epoch=089, loss=0.1176
Epoch=090, loss=0.1200
Epoch=091, loss=0.1111
Epoch=092, loss=0.1024
Epoch=093, loss=0.1113
Epoch=094, loss=0.0972
Epoch=095, loss=0.1030
Epoch=096, loss=0.0927
Epoch=097, loss=0.0976
Epoch=098, loss=0.1012
Epoch=099, loss=0.1069
Epoch=100, loss=0.1082
Epoch=101, loss=0.0877
Epoch=102, loss=0.1057
Epoch=103, loss=0.0883
Epoch=104, loss=0.0875
Epoch=105, loss=0.0966
Epoch=106, loss=0.0930
Epoch=107, loss=0.0844
Epoch=108, loss=0.0972
Epoch=109, loss=0.0907
Epoch=110, loss=0.0951
Epoch=111, loss=0.0860
Epoch=112, loss=0.0884
Epoch=113, loss=0.0818
Epoch=114, loss=0.0923
Epoch=115, loss=0.0822
Epoch=116, loss=0.0809
Epoch=117, loss=0.0850
Epoch=118, loss=0.0726
Epoch=119, loss=0.0735
Epoch=120, loss=0.0781
Epoch=121, loss=0.0878
Epoch=122, loss=0.0684
Epoch=123, loss=0.0698
Epoch=124, loss=0.0832
Epoch=125, loss=0.0708
Epoch=126, loss=0.0756
Epoch=127, loss=0.0666
Epoch=128, loss=0.0701
Epoch=129, loss=0.0817
Epoch=130, loss=0.0606
Epoch=131, loss=0.0760
Epoch=132, loss=0.0625
Epoch=133, loss=0.0833
Epoch=134, loss=0.0624
Epoch=135, loss=0.0780
Epoch=136, loss=0.0596
Epoch=137, loss=0.0649
Epoch=138, loss=0.0700
Epoch=139, loss=0.0573
Epoch=140, loss=0.0679
Epoch=141, loss=0.0711
Epoch=142, loss=0.0693
Epoch=143, loss=0.0602
Epoch=144, loss=0.0585
Epoch=145, loss=0.0576
Epoch=146, loss=0.0635
Epoch=147, loss=0.0551
Epoch=148, loss=0.0601
Epoch=149, loss=0.0598
Epoch=150, loss=0.0522
Epoch=151, loss=0.0664
Epoch=152, loss=0.0553
Epoch=153, loss=0.0639
Epoch=154, loss=0.0576
Epoch=155, loss=0.0514
Epoch=156, loss=0.0509
Epoch=157, loss=0.0646
Epoch=158, loss=0.0523
Epoch=159, loss=0.0619
Epoch=160, loss=0.0647
Epoch=161, loss=0.0579
Epoch=162, loss=0.0640
Epoch=163, loss=0.0515
Epoch=164, loss=0.0517
Epoch=165, loss=0.0525
Epoch=166, loss=0.0477
Epoch=167, loss=0.0606
Epoch=168, loss=0.0457
Epoch=169, loss=0.0492
Epoch=170, loss=0.0559
Epoch=171, loss=0.0465
Epoch=172, loss=0.0545
Epoch=173, loss=0.0468
Epoch=174, loss=0.0472
Epoch=175, loss=0.0556
Epoch=176, loss=0.0430
Epoch=177, loss=0.0500
Epoch=178, loss=0.0553
Epoch=179, loss=0.0442
Epoch=180, loss=0.0451
Epoch=181, loss=0.0558
Epoch=182, loss=0.0460
Epoch=183, loss=0.0494
Epoch=184, loss=0.0487
Epoch=185, loss=0.0585
Epoch=186, loss=0.0502
Epoch=187, loss=0.0553
Epoch=188, loss=0.0464
Epoch=189, loss=0.0598
Epoch=190, loss=0.0465
Epoch=191, loss=0.0450
Epoch=192, loss=0.0428
Epoch=193, loss=0.0453
Epoch=194, loss=0.0487
Epoch=195, loss=0.0494
Epoch=196, loss=0.0395
Epoch=197, loss=0.0405
Epoch=198, loss=0.0469
Epoch=199, loss=0.0442
Epoch=200, loss=0.0390
Epoch=201, loss=0.0436
Epoch=202, loss=0.0450
Epoch=203, loss=0.0662
Epoch=204, loss=0.0429
Epoch=205, loss=0.0393
Epoch=206, loss=0.0406
Epoch=207, loss=0.0437
Epoch=208, loss=0.0412
Epoch=209, loss=0.0545
Epoch=210, loss=0.0434
Epoch=211, loss=0.0381
Epoch=212, loss=0.0422
Epoch=213, loss=0.0537
Epoch=214, loss=0.0380
Epoch=215, loss=0.0401
Epoch=216, loss=0.0390
Epoch=217, loss=0.0499
Epoch=218, loss=0.0406
Epoch=219, loss=0.0402
Epoch=220, loss=0.0310
Epoch=221, loss=0.0381
Epoch=222, loss=0.0434
Epoch=223, loss=0.0470
Epoch=224, loss=0.0467
Epoch=225, loss=0.0530
Epoch=226, loss=0.0513
Epoch=227, loss=0.0351
Epoch=228, loss=0.0350
Epoch=229, loss=0.0449
Epoch=230, loss=0.0424
Epoch=231, loss=0.0413
Epoch=232, loss=0.0405
Epoch=233, loss=0.0392
Epoch=234, loss=0.0459
Epoch=235, loss=0.0387
Epoch=236, loss=0.0421
Epoch=237, loss=0.0476
Epoch=238, loss=0.0353
Epoch=239, loss=0.0408
Epoch=240, loss=0.0406
Early stopping!
Loading 220th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7841+-0.0108, F1Ma=0.7566+-0.0228, acc=0.7841+-0.0108
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.946919007231802, 0.9389081297835806, 0.9418389869261041, 0.9325551320203622, 0.8357142806053162, 0.7519999742507935, 0.7635396718978882, 0.8285714387893677, 0.7519999742507935, 0.7611218690872192, 0.775204041974349, 0.010401344949604903, 0.7457029572432045, 0.02128690215355303, 0.775204041974349, 0.010401344949604903], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7886319599343545, 0.7913794990957401, 0.7568745071634579, 0.7566294810245396, 0.8714285492897034, 0.7620000243186951, 0.7674081325531006, 0.8785714507102966, 0.765999972820282, 0.7678917050361633, 0.7841430237077341, 0.010783517567571206, 0.7566121735665832, 0.022768161727637543, 0.7841430237077341, 0.010783517567571232]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6920
Epoch=003, loss=0.6911
Epoch=004, loss=0.6900
Epoch=005, loss=0.6885
Epoch=006, loss=0.6869
Epoch=007, loss=0.6847
Epoch=008, loss=0.6822
Epoch=009, loss=0.6788
Epoch=010, loss=0.6752
Epoch=011, loss=0.6704
Epoch=012, loss=0.6662
Epoch=013, loss=0.6596
Epoch=014, loss=0.6530
Epoch=015, loss=0.6458
Epoch=016, loss=0.6373
Epoch=017, loss=0.6271
Epoch=018, loss=0.6167
Epoch=019, loss=0.6053
Epoch=020, loss=0.5938
Epoch=021, loss=0.5768
Epoch=022, loss=0.5601
Epoch=023, loss=0.5483
Epoch=024, loss=0.5300
Epoch=025, loss=0.5100
Epoch=026, loss=0.4987
Epoch=027, loss=0.4732
Epoch=028, loss=0.4562
Epoch=029, loss=0.4374
Epoch=030, loss=0.4168
Epoch=031, loss=0.3958
Epoch=032, loss=0.3770
Epoch=033, loss=0.3591
Epoch=034, loss=0.3430
Epoch=035, loss=0.3287
Epoch=036, loss=0.3006
Epoch=037, loss=0.2856
Epoch=038, loss=0.2735
Epoch=039, loss=0.2434
Epoch=040, loss=0.2382
Epoch=041, loss=0.2234
Epoch=042, loss=0.2057
Epoch=043, loss=0.2033
Epoch=044, loss=0.1910
Epoch=045, loss=0.1653
Epoch=046, loss=0.1696
Epoch=047, loss=0.1665
Epoch=048, loss=0.1538
Epoch=049, loss=0.1513
Epoch=050, loss=0.1397
Epoch=051, loss=0.1227
Epoch=052, loss=0.1198
Epoch=053, loss=0.1459
Epoch=054, loss=0.1331
Epoch=055, loss=0.1205
Epoch=056, loss=0.1110
Epoch=057, loss=0.1202
Epoch=058, loss=0.1171
Epoch=059, loss=0.1134
Epoch=060, loss=0.1071
Epoch=061, loss=0.0983
Epoch=062, loss=0.1025
Epoch=063, loss=0.1024
Epoch=064, loss=0.1038
Epoch=065, loss=0.0884
Epoch=066, loss=0.0981
Epoch=067, loss=0.0877
Epoch=068, loss=0.0934
Epoch=069, loss=0.0855
Epoch=070, loss=0.0844
Epoch=071, loss=0.0741
Epoch=072, loss=0.0770
Epoch=073, loss=0.0701
Epoch=074, loss=0.0850
Epoch=075, loss=0.0810
Epoch=076, loss=0.0712
Epoch=077, loss=0.0767
Epoch=078, loss=0.0676
Epoch=079, loss=0.0730
Epoch=080, loss=0.0585
Epoch=081, loss=0.0735
Epoch=082, loss=0.0700
Epoch=083, loss=0.0800
Epoch=084, loss=0.0695
Epoch=085, loss=0.0651
Epoch=086, loss=0.0588
Epoch=087, loss=0.0614
Epoch=088, loss=0.0706
Epoch=089, loss=0.0785
Epoch=090, loss=0.0722
Epoch=091, loss=0.0514
Epoch=092, loss=0.0644
Epoch=093, loss=0.0653
Epoch=094, loss=0.0688
Epoch=095, loss=0.0627
Epoch=096, loss=0.0689
Epoch=097, loss=0.0602
Epoch=098, loss=0.0658
Epoch=099, loss=0.0669
Epoch=100, loss=0.0591
Epoch=101, loss=0.0587
Epoch=102, loss=0.0699
Epoch=103, loss=0.0583
Epoch=104, loss=0.0577
Epoch=105, loss=0.0580
Epoch=106, loss=0.0549
Epoch=107, loss=0.0515
Epoch=108, loss=0.0630
Epoch=109, loss=0.0578
Epoch=110, loss=0.0530
Epoch=111, loss=0.0404
Epoch=112, loss=0.0513
Epoch=113, loss=0.0592
Epoch=114, loss=0.0572
Epoch=115, loss=0.0603
Epoch=116, loss=0.0661
Epoch=117, loss=0.0558
Epoch=118, loss=0.0529
Epoch=119, loss=0.0511
Epoch=120, loss=0.0457
Epoch=121, loss=0.0511
Epoch=122, loss=0.0555
Epoch=123, loss=0.0560
Epoch=124, loss=0.0430
Epoch=125, loss=0.0530
Epoch=126, loss=0.0455
Epoch=127, loss=0.0470
Epoch=128, loss=0.0467
Epoch=129, loss=0.0501
Epoch=130, loss=0.0417
Epoch=131, loss=0.0493
Early stopping!
Loading 111th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7956+-0.0059, F1Ma=0.7766+-0.0104, acc=0.7956+-0.0059
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.946919007231802, 0.9389081297835806, 0.9418389869261041, 0.9325551320203622, 0.8357142806053162, 0.7519999742507935, 0.7635396718978882, 0.8285714387893677, 0.7519999742507935, 0.7611218690872192, 0.775204041974349, 0.010401344949604903, 0.7457029572432045, 0.02128690215355303, 0.775204041974349, 0.010401344949604903], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7886319599343545, 0.7913794990957401, 0.7568745071634579, 0.7566294810245396, 0.8714285492897034, 0.7620000243186951, 0.7674081325531006, 0.8785714507102966, 0.765999972820282, 0.7678917050361633, 0.7841430237077341, 0.010783517567571206, 0.7566121735665832, 0.022768161727637543, 0.7841430237077341, 0.010783517567571232], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7791174564137759, 0.7897175944102405, 0.7343651545211339, 0.746416857696295, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.7955693742712786, 0.0058530433259282744, 0.7765824154763509, 0.010410670649334602, 0.7955693742712787, 0.005853043325928239]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6920
Epoch=002, loss=0.6895
Epoch=003, loss=0.6865
Epoch=004, loss=0.6817
Epoch=005, loss=0.6756
Epoch=006, loss=0.6681
Epoch=007, loss=0.6588
Epoch=008, loss=0.6473
Epoch=009, loss=0.6317
Epoch=010, loss=0.6215
Epoch=011, loss=0.5998
Epoch=012, loss=0.5819
Epoch=013, loss=0.5598
Epoch=014, loss=0.5345
Epoch=015, loss=0.5166
Epoch=016, loss=0.4885
Epoch=017, loss=0.4567
Epoch=018, loss=0.4317
Epoch=019, loss=0.4064
Epoch=020, loss=0.3773
Epoch=021, loss=0.3516
Epoch=022, loss=0.3222
Epoch=023, loss=0.3025
Epoch=024, loss=0.2755
Epoch=025, loss=0.2636
Epoch=026, loss=0.2437
Epoch=027, loss=0.2248
Epoch=028, loss=0.2154
Epoch=029, loss=0.1976
Epoch=030, loss=0.1925
Epoch=031, loss=0.1795
Epoch=032, loss=0.1585
Epoch=033, loss=0.1528
Epoch=034, loss=0.1443
Epoch=035, loss=0.1283
Epoch=036, loss=0.1340
Epoch=037, loss=0.1211
Epoch=038, loss=0.1293
Epoch=039, loss=0.1345
Epoch=040, loss=0.1214
Epoch=041, loss=0.1118
Epoch=042, loss=0.1088
Epoch=043, loss=0.0998
Epoch=044, loss=0.1058
Epoch=045, loss=0.1012
Epoch=046, loss=0.0960
Epoch=047, loss=0.1057
Epoch=048, loss=0.0965
Epoch=049, loss=0.1060
Epoch=050, loss=0.0942
Epoch=051, loss=0.1025
Epoch=052, loss=0.0902
Epoch=053, loss=0.0826
Epoch=054, loss=0.0871
Epoch=055, loss=0.0742
Epoch=056, loss=0.0893
Epoch=057, loss=0.0693
Epoch=058, loss=0.0665
Epoch=059, loss=0.0818
Epoch=060, loss=0.0627
Epoch=061, loss=0.0841
Epoch=062, loss=0.0755
Epoch=063, loss=0.0641
Epoch=064, loss=0.0574
Epoch=065, loss=0.0685
Epoch=066, loss=0.0712
Epoch=067, loss=0.0767
Epoch=068, loss=0.0691
Epoch=069, loss=0.0624
Epoch=070, loss=0.0637
Epoch=071, loss=0.0656
Epoch=072, loss=0.0740
Epoch=073, loss=0.0868
Epoch=074, loss=0.0677
Epoch=075, loss=0.0662
Epoch=076, loss=0.0668
Epoch=077, loss=0.0661
Epoch=078, loss=0.0623
Epoch=079, loss=0.0571
Epoch=080, loss=0.0604
Epoch=081, loss=0.0739
Epoch=082, loss=0.0620
Epoch=083, loss=0.0544
Epoch=084, loss=0.0497
Epoch=085, loss=0.0531
Epoch=086, loss=0.0626
Epoch=087, loss=0.0375
Epoch=088, loss=0.0506
Epoch=089, loss=0.0607
Epoch=090, loss=0.0479
Epoch=091, loss=0.0482
Epoch=092, loss=0.0409
Epoch=093, loss=0.0543
Epoch=094, loss=0.0583
Epoch=095, loss=0.0435
Epoch=096, loss=0.0396
Epoch=097, loss=0.0408
Epoch=098, loss=0.0530
Epoch=099, loss=0.0367
Epoch=100, loss=0.0382
Epoch=101, loss=0.0456
Epoch=102, loss=0.0486
Epoch=103, loss=0.0332
Epoch=104, loss=0.0350
Epoch=105, loss=0.0300
Epoch=106, loss=0.0533
Epoch=107, loss=0.0478
Epoch=108, loss=0.0367
Epoch=109, loss=0.0465
Epoch=110, loss=0.0330
Epoch=111, loss=0.0319
Epoch=112, loss=0.0503
Epoch=113, loss=0.0326
Epoch=114, loss=0.0384
Epoch=115, loss=0.0367
Epoch=116, loss=0.0338
Epoch=117, loss=0.0318
Epoch=118, loss=0.0308
Epoch=119, loss=0.0515
Epoch=120, loss=0.0347
Epoch=121, loss=0.0409
Epoch=122, loss=0.0327
Epoch=123, loss=0.0360
Epoch=124, loss=0.0350
Epoch=125, loss=0.0415
Early stopping!
Loading 105th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8004+-0.0065, F1Ma=0.7876+-0.0089, acc=0.8004+-0.0065
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.946919007231802, 0.9389081297835806, 0.9418389869261041, 0.9325551320203622, 0.8357142806053162, 0.7519999742507935, 0.7635396718978882, 0.8285714387893677, 0.7519999742507935, 0.7611218690872192, 0.775204041974349, 0.010401344949604903, 0.7457029572432045, 0.02128690215355303, 0.775204041974349, 0.010401344949604903], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7886319599343545, 0.7913794990957401, 0.7568745071634579, 0.7566294810245396, 0.8714285492897034, 0.7620000243186951, 0.7674081325531006, 0.8785714507102966, 0.765999972820282, 0.7678917050361633, 0.7841430237077341, 0.010783517567571206, 0.7566121735665832, 0.022768161727637543, 0.7841430237077341, 0.010783517567571232], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7791174564137759, 0.7897175944102405, 0.7343651545211339, 0.746416857696295, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.7955693742712786, 0.0058530433259282744, 0.7765824154763509, 0.010410670649334602, 0.7955693742712787, 0.005853043325928239], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9198434138888094, 0.9141457665727967, 0.9169406147719539, 0.9085340686127451, 0.8857142925262451, 0.8299999833106995, 0.8133462071418762, 0.8857142925262451, 0.828000009059906, 0.8128626942634583, 0.8003886513797124, 0.006450207986233886, 0.7876491674527882, 0.008879314623422377, 0.8003886513797124, 0.006450207986233886]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6910
Epoch=002, loss=0.6860
Epoch=003, loss=0.6761
Epoch=004, loss=0.6701
Epoch=005, loss=0.6529
Epoch=006, loss=0.6400
Epoch=007, loss=0.6235
Epoch=008, loss=0.5979
Epoch=009, loss=0.5812
Epoch=010, loss=0.5650
Epoch=011, loss=0.5208
Epoch=012, loss=0.5017
Epoch=013, loss=0.4755
Epoch=014, loss=0.4441
Epoch=015, loss=0.4076
Epoch=016, loss=0.3880
Epoch=017, loss=0.3725
Epoch=018, loss=0.3143
Epoch=019, loss=0.3074
Epoch=020, loss=0.2901
Epoch=021, loss=0.2513
Epoch=022, loss=0.2136
Epoch=023, loss=0.2187
Epoch=024, loss=0.1984
Epoch=025, loss=0.1757
Epoch=026, loss=0.1761
Epoch=027, loss=0.1727
Epoch=028, loss=0.1474
Epoch=029, loss=0.1449
Epoch=030, loss=0.1364
Epoch=031, loss=0.1189
Epoch=032, loss=0.1024
Epoch=033, loss=0.1333
Epoch=034, loss=0.1056
Epoch=035, loss=0.1240
Epoch=036, loss=0.1136
Epoch=037, loss=0.1122
Epoch=038, loss=0.0949
Epoch=039, loss=0.0956
Epoch=040, loss=0.0882
Epoch=041, loss=0.0892
Epoch=042, loss=0.0803
Epoch=043, loss=0.0803
Epoch=044, loss=0.0799
Epoch=045, loss=0.0819
Epoch=046, loss=0.0588
Epoch=047, loss=0.0788
Epoch=048, loss=0.0551
Epoch=049, loss=0.0751
Epoch=050, loss=0.0522
Epoch=051, loss=0.0649
Epoch=052, loss=0.0469
Epoch=053, loss=0.0584
Epoch=054, loss=0.0688
Epoch=055, loss=0.0419
Epoch=056, loss=0.0496
Epoch=057, loss=0.0448
Epoch=058, loss=0.0485
Epoch=059, loss=0.0491
Epoch=060, loss=0.0451
Epoch=061, loss=0.0463
Epoch=062, loss=0.0361
Epoch=063, loss=0.0485
Epoch=064, loss=0.0263
Epoch=065, loss=0.0294
Epoch=066, loss=0.0321
Epoch=067, loss=0.0267
Epoch=068, loss=0.0331
Epoch=069, loss=0.0305
Epoch=070, loss=0.0308
Epoch=071, loss=0.0308
Epoch=072, loss=0.0334
Epoch=073, loss=0.0269
Epoch=074, loss=0.0230
Epoch=075, loss=0.0255
Epoch=076, loss=0.0233
Epoch=077, loss=0.0286
Epoch=078, loss=0.0196
Epoch=079, loss=0.0289
Epoch=080, loss=0.0311
Epoch=081, loss=0.0238
Epoch=082, loss=0.0182
Epoch=083, loss=0.0213
Epoch=084, loss=0.0252
Epoch=085, loss=0.0197
Epoch=086, loss=0.0249
Epoch=087, loss=0.0287
Epoch=088, loss=0.0204
Epoch=089, loss=0.0235
Epoch=090, loss=0.0199
Epoch=091, loss=0.0189
Epoch=092, loss=0.0199
Epoch=093, loss=0.0253
Epoch=094, loss=0.0128
Epoch=095, loss=0.0128
Epoch=096, loss=0.0296
Epoch=097, loss=0.0117
Epoch=098, loss=0.0143
Epoch=099, loss=0.0223
Epoch=100, loss=0.0150
Epoch=101, loss=0.0171
Epoch=102, loss=0.0132
Epoch=103, loss=0.0126
Epoch=104, loss=0.0096
Epoch=105, loss=0.0192
Epoch=106, loss=0.0127
Epoch=107, loss=0.0165
Epoch=108, loss=0.0177
Epoch=109, loss=0.0109
Epoch=110, loss=0.0120
Epoch=111, loss=0.0092
Epoch=112, loss=0.0147
Epoch=113, loss=0.0139
Epoch=114, loss=0.0130
Epoch=115, loss=0.0097
Epoch=116, loss=0.0082
Epoch=117, loss=0.0100
Epoch=118, loss=0.0203
Epoch=119, loss=0.0124
Epoch=120, loss=0.0110
Epoch=121, loss=0.0162
Epoch=122, loss=0.0076
Epoch=123, loss=0.0201
Epoch=124, loss=0.0147
Epoch=125, loss=0.0092
Epoch=126, loss=0.0093
Epoch=127, loss=0.0179
Epoch=128, loss=0.0107
Epoch=129, loss=0.0113
Epoch=130, loss=0.0093
Epoch=131, loss=0.0049
Epoch=132, loss=0.0147
Epoch=133, loss=0.0079
Epoch=134, loss=0.0090
Epoch=135, loss=0.0086
Epoch=136, loss=0.0080
Epoch=137, loss=0.0114
Epoch=138, loss=0.0097
Epoch=139, loss=0.0066
Epoch=140, loss=0.0054
Epoch=141, loss=0.0096
Epoch=142, loss=0.0142
Epoch=143, loss=0.0102
Epoch=144, loss=0.0109
Epoch=145, loss=0.0129
Epoch=146, loss=0.0073
Epoch=147, loss=0.0084
Epoch=148, loss=0.0081
Epoch=149, loss=0.0051
Epoch=150, loss=0.0061
Epoch=151, loss=0.0061
Early stopping!
Loading 131th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7999+-0.0105, F1Ma=0.7854+-0.0110, acc=0.7999+-0.0105
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8089900459454564, 0.8078644635231768, 0.7796359040647538, 0.7695312601263447, 0.7357142567634583, 0.7200000286102295, 0.6992263197898865, 0.7285714149475098, 0.722000002861023, 0.6987427473068237, 0.7195491643995338, 0.02032405187782438, 0.6582118157394837, 0.0339756088076691, 0.7195491643995338, 0.02032405187782436], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.946919007231802, 0.9389081297835806, 0.9418389869261041, 0.9325551320203622, 0.8357142806053162, 0.7519999742507935, 0.7635396718978882, 0.8285714387893677, 0.7519999742507935, 0.7611218690872192, 0.775204041974349, 0.010401344949604903, 0.7457029572432045, 0.02128690215355303, 0.775204041974349, 0.010401344949604903], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7886319599343545, 0.7913794990957401, 0.7568745071634579, 0.7566294810245396, 0.8714285492897034, 0.7620000243186951, 0.7674081325531006, 0.8785714507102966, 0.765999972820282, 0.7678917050361633, 0.7841430237077341, 0.010783517567571206, 0.7566121735665832, 0.022768161727637543, 0.7841430237077341, 0.010783517567571232], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7791174564137759, 0.7897175944102405, 0.7343651545211339, 0.746416857696295, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.9428571462631226, 0.8080000281333923, 0.801740825176239, 0.7955693742712786, 0.0058530433259282744, 0.7765824154763509, 0.010410670649334602, 0.7955693742712787, 0.005853043325928239], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9198434138888094, 0.9141457665727967, 0.9169406147719539, 0.9085340686127451, 0.8857142925262451, 0.8299999833106995, 0.8133462071418762, 0.8857142925262451, 0.828000009059906, 0.8128626942634583, 0.8003886513797124, 0.006450207986233886, 0.7876491674527882, 0.008879314623422377, 0.8003886513797124, 0.006450207986233886], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9063202010669767, 0.8977518608861007, 0.8998376114845766, 0.8882536082144339, 0.9714285731315613, 0.8259999752044678, 0.8109284043312073, 0.9714285731315613, 0.8240000009536743, 0.8118955492973328, 0.7999222697240574, 0.01046735648588677, 0.7853621218872947, 0.010956858438314414, 0.7999222697240576, 0.010467356485886805]]
