{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661cb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7151ed3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4067f7b5db242938b7dbbae37a9fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c09bcc84e248d99cd409e395f5b6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9c07821dd48f8b10f92d225a1fd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51414fdda9e74c1db9f62b3ecbdff5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea565ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a472d9c",
   "metadata": {},
   "source": [
    "## Part 1: Building the Graph\n",
    "The first part of Parametric UMAP is shared with non-parametric UMAP, so we can use the same code. First we build a nearest-neighbors graph, using pynndescent, then we build a fuzzy simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51e747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynndescent import NNDescent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4732e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 25 16:19:19 2022 Building RP forest with 17 trees\n",
      "Fri Nov 25 16:19:25 2022 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\t 5  /  16\n",
      "\tStopping threshold met -- exiting after 5 iterations\n"
     ]
    }
   ],
   "source": [
    "# number of trees in random projection forest\n",
    "n_trees = 5 + int(round((X.shape[0]) ** 0.5 / 20.0))\n",
    "# max number of nearest neighbor iters to perform\n",
    "n_iters = max(5, int(round(np.log2(X.shape[0]))))\n",
    "# distance metric\n",
    "metric=\"euclidean\"\n",
    "# number of neighbors for computing k-neighbor graph\n",
    "n_neighbors = 10\n",
    "\n",
    "# get nearest neighbors\n",
    "nnd = NNDescent(\n",
    "    X.reshape((len(X), np.product(np.shape(X)[1:]))),\n",
    "    n_neighbors=n_neighbors,\n",
    "    metric=metric,\n",
    "    n_trees=n_trees,\n",
    "    n_iters=n_iters,\n",
    "    max_candidates=60,\n",
    "    verbose=True\n",
    ")\n",
    "# get indices and distances\n",
    "knn_indices, knn_dists = nnd.neighbor_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972cdd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (60000, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nearest neighbors and distances for each point in the dataset\n",
    "np.shape(knn_indices), np.shape(knn_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5c87e",
   "metadata": {},
   "source": [
    "### Build fuzzy simplicial  complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66e6e1",
   "metadata": {},
   "source": [
    "The `fuzzy_simplicial_set` function takes the nearest neighbor graph and computes a graph of the probabilities of an edge exists between points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76819c6a",
   "metadata": {},
   "source": [
    "Local, one-directional, probabilities ($P^{\\textrm{UMAP}}_{i|j}$) are computed between a point and its neighbors to determine the probability with which an edge (or simplex exists), based upon an assumption that data is uniformly distributed across a manifold in a warped dataspace. Under this assumption, a local notion of distance is set by the distance to the $k$\\textsuperscript{th} nearest neighbor and the local probability is scaled by that local notion of distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a7af33",
   "metadata": {},
   "source": [
    "$$\n",
    "p_{j \\mid i}^{\\textrm{UMAP}} = \\exp( -(\\textrm{d}( \\mathbf{x}_{i},\\mathbf{x}_{j}) - \\rho_{i}) / \\sigma_{i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35a0d0",
   "metadata": {},
   "source": [
    "Where $\\rho_{i}$ is a local connectivity parameter set to the distance from $x_i$ to its nearest neighbor, and $\\sigma_{i}$ is a local connectivity parameter set to match the local distance around $x_i$ upon its $k$ nearest neighbors (where $k$ is a hyperparameter). In the UMAP package, these are calculated using `smooth_knn_dist`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8aa9a",
   "metadata": {},
   "source": [
    "After computing the one-directional edge probabilities for each datapoint,Â we then compute a global probability as the probability of either of the two local, one-directional, probabilities occurring:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976ce94",
   "metadata": {},
   "source": [
    "$$\n",
    "p_{i j}=\\left(p_{j \\mid i}+p_{i \\mid j}\\right)-p_{j \\mid i} p_{i \\mid j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef69a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "from umap.umap_ import fuzzy_simplicial_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71873fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices and distances\n",
    "knn_indices, knn_dists = nnd.neighbor_graph\n",
    "random_state = check_random_state(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aca63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build fuzzy_simplicial_set\n",
    "umap_graph, sigmas, rhos = fuzzy_simplicial_set(\n",
    "    X = X,\n",
    "    n_neighbors = n_neighbors,\n",
    "    metric = metric,\n",
    "    random_state = random_state,\n",
    "    knn_indices= knn_indices,\n",
    "    knn_dists = knn_dists,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "763b505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_scipy_sparse_matrix, to_networkx, from_scipy_sparse_matrix\n",
    "G = from_scipy_sparse_matrix(umap_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04b0a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 803462])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6897f9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 59999, 59999, 59999],\n",
       "        [ 8728, 18932, 24149,  ..., 52171, 57087, 58186]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e323805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41200., 165022., 203256.,  99584.,  68654.,  46784.,  31314.,\n",
       "         22062.,  15892., 109694.]),\n",
       " array([3.73e-43, 1.00e-01, 2.00e-01, 3.00e-01, 4.00e-01, 5.00e-01,\n",
       "        6.00e-01, 7.00e-01, 8.00e-01, 9.00e-01, 1.00e+00], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(G[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ecd96",
   "metadata": {},
   "source": [
    "## Part 2: Embedding the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77d9ce",
   "metadata": {},
   "source": [
    "Now we learn an embedding for the graph, using a neural network. This is where Parametric UMAP differs from non-parametric UMAP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b064cf",
   "metadata": {},
   "source": [
    "### Create neural network model\n",
    "We first create a neural network to perform the parametric embedding. Here, we'll use a simple convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5bb2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2 # number of latent dimensions\n",
    "dims = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22edf8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    tf.keras.layers.InputLayer(input_shape=dims),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=3, strides=(2, 2), activation=\"relu\", padding=\"same\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=n_components),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a120647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b709300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "n_components = 2 # number of latent dimensions\n",
    "dims = X.shape[1:]\n",
    "class encoder(torch.nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride = 2),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride = 2),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Flatten(),\n",
    "                torch.nn.Linear(128, 512),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(512,512),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(512, n_components)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.main(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057430b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c205153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = encoder(n_components)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c34fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "083ef02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (1): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=  torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride = 2),\n",
    "    torch.nn.ReLU(),\n",
    ")\n",
    "layer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e8fb8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
