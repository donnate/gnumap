My SLURM_ARRAY_TASK_ID:  4
My SLURM_ARRAY_JOB_ID:  4522273
DGI
Cora
result file is 4522273_4
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522273_4.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6929
Epoch=006, loss=0.6929
Epoch=007, loss=0.6928
Epoch=008, loss=0.6927
Epoch=009, loss=0.6927
Epoch=010, loss=0.6926
Epoch=011, loss=0.6925
Epoch=012, loss=0.6925
Epoch=013, loss=0.6924
Epoch=014, loss=0.6923
Epoch=015, loss=0.6923
Epoch=016, loss=0.6921
Epoch=017, loss=0.6920
Epoch=018, loss=0.6919
Epoch=019, loss=0.6918
Epoch=020, loss=0.6916
Epoch=021, loss=0.6915
Epoch=022, loss=0.6913
Epoch=023, loss=0.6912
Epoch=024, loss=0.6910
Epoch=025, loss=0.6908
Epoch=026, loss=0.6906
Epoch=027, loss=0.6904
Epoch=028, loss=0.6902
Epoch=029, loss=0.6899
Epoch=030, loss=0.6897
Epoch=031, loss=0.6894
Epoch=032, loss=0.6891
Epoch=033, loss=0.6888
Epoch=034, loss=0.6885
Epoch=035, loss=0.6881
Epoch=036, loss=0.6879
Epoch=037, loss=0.6874
Epoch=038, loss=0.6871
Epoch=039, loss=0.6867
Epoch=040, loss=0.6863
Epoch=041, loss=0.6859
Epoch=042, loss=0.6855
Epoch=043, loss=0.6848
Epoch=044, loss=0.6844
Epoch=045, loss=0.6839
Epoch=046, loss=0.6833
Epoch=047, loss=0.6826
Epoch=048, loss=0.6820
Epoch=049, loss=0.6813
Epoch=050, loss=0.6807
Epoch=051, loss=0.6800
Epoch=052, loss=0.6795
Epoch=053, loss=0.6787
Epoch=054, loss=0.6777
Epoch=055, loss=0.6773
Epoch=056, loss=0.6763
Epoch=057, loss=0.6752
Epoch=058, loss=0.6744
Epoch=059, loss=0.6733
Epoch=060, loss=0.6724
Epoch=061, loss=0.6715
Epoch=062, loss=0.6703
Epoch=063, loss=0.6693
Epoch=064, loss=0.6681
Epoch=065, loss=0.6668
Epoch=066, loss=0.6661
Epoch=067, loss=0.6648
Epoch=068, loss=0.6632
Epoch=069, loss=0.6617
Epoch=070, loss=0.6606
Epoch=071, loss=0.6589
Epoch=072, loss=0.6578
Epoch=073, loss=0.6560
Epoch=074, loss=0.6547
Epoch=075, loss=0.6535
Epoch=076, loss=0.6507
Epoch=077, loss=0.6506
Epoch=078, loss=0.6477
Epoch=079, loss=0.6458
Epoch=080, loss=0.6449
Epoch=081, loss=0.6426
Epoch=082, loss=0.6398
Epoch=083, loss=0.6387
Epoch=084, loss=0.6375
Epoch=085, loss=0.6351
Epoch=086, loss=0.6335
Epoch=087, loss=0.6305
Epoch=088, loss=0.6277
Epoch=089, loss=0.6251
Epoch=090, loss=0.6240
Epoch=091, loss=0.6223
Epoch=092, loss=0.6208
Epoch=093, loss=0.6171
Epoch=094, loss=0.6146
Epoch=095, loss=0.6125
Epoch=096, loss=0.6086
Epoch=097, loss=0.6065
Epoch=098, loss=0.6055
Epoch=099, loss=0.6015
Epoch=100, loss=0.5995
Epoch=101, loss=0.5976
Epoch=102, loss=0.5943
Epoch=103, loss=0.5899
Epoch=104, loss=0.5868
Epoch=105, loss=0.5836
Epoch=106, loss=0.5816
Epoch=107, loss=0.5819
Epoch=108, loss=0.5781
Epoch=109, loss=0.5723
Epoch=110, loss=0.5702
Epoch=111, loss=0.5677
Epoch=112, loss=0.5628
Epoch=113, loss=0.5619
Epoch=114, loss=0.5559
Epoch=115, loss=0.5558
Epoch=116, loss=0.5526
Epoch=117, loss=0.5489
Epoch=118, loss=0.5430
Epoch=119, loss=0.5408
Epoch=120, loss=0.5369
Epoch=121, loss=0.5373
Epoch=122, loss=0.5304
Epoch=123, loss=0.5291
Epoch=124, loss=0.5218
Epoch=125, loss=0.5199
Epoch=126, loss=0.5155
Epoch=127, loss=0.5156
Epoch=128, loss=0.5105
Epoch=129, loss=0.5059
Epoch=130, loss=0.5046
Epoch=131, loss=0.4976
Epoch=132, loss=0.4959
Epoch=133, loss=0.4902
Epoch=134, loss=0.4871
Epoch=135, loss=0.4830
Epoch=136, loss=0.4797
Epoch=137, loss=0.4785
Epoch=138, loss=0.4676
Epoch=139, loss=0.4689
Epoch=140, loss=0.4665
Epoch=141, loss=0.4626
Epoch=142, loss=0.4554
Epoch=143, loss=0.4528
Epoch=144, loss=0.4512
Epoch=145, loss=0.4496
Epoch=146, loss=0.4421
Epoch=147, loss=0.4423
Epoch=148, loss=0.4414
Epoch=149, loss=0.4369
Epoch=150, loss=0.4253
Epoch=151, loss=0.4238
Epoch=152, loss=0.4235
Epoch=153, loss=0.4169
Epoch=154, loss=0.4173
Epoch=155, loss=0.4167
Epoch=156, loss=0.4080
Epoch=157, loss=0.4061
Epoch=158, loss=0.4008
Epoch=159, loss=0.3970
Epoch=160, loss=0.3907
Epoch=161, loss=0.3920
Epoch=162, loss=0.3882
Epoch=163, loss=0.3775
Epoch=164, loss=0.3833
Epoch=165, loss=0.3772
Epoch=166, loss=0.3819
Epoch=167, loss=0.3710
Epoch=168, loss=0.3714
Epoch=169, loss=0.3690
Epoch=170, loss=0.3586
Epoch=171, loss=0.3566
Epoch=172, loss=0.3547
Epoch=173, loss=0.3545
Epoch=174, loss=0.3514
Epoch=175, loss=0.3440
Epoch=176, loss=0.3518
Epoch=177, loss=0.3494
Epoch=178, loss=0.3367
Epoch=179, loss=0.3360
Epoch=180, loss=0.3345
Epoch=181, loss=0.3182
Epoch=182, loss=0.3217
Epoch=183, loss=0.3226
Epoch=184, loss=0.3183
Epoch=185, loss=0.3205
Epoch=186, loss=0.3128
Epoch=187, loss=0.3090
Epoch=188, loss=0.3095
Epoch=189, loss=0.3036
Epoch=190, loss=0.3039
Epoch=191, loss=0.2991
Epoch=192, loss=0.2934
Epoch=193, loss=0.2922
Epoch=194, loss=0.2920
Epoch=195, loss=0.2924
Epoch=196, loss=0.2856
Epoch=197, loss=0.2797
Epoch=198, loss=0.2765
Epoch=199, loss=0.2823
Epoch=200, loss=0.2786
Epoch=201, loss=0.2805
Epoch=202, loss=0.2738
Epoch=203, loss=0.2742
Epoch=204, loss=0.2749
Epoch=205, loss=0.2652
Epoch=206, loss=0.2594
Epoch=207, loss=0.2700
Epoch=208, loss=0.2612
Epoch=209, loss=0.2593
Epoch=210, loss=0.2537
Epoch=211, loss=0.2548
Epoch=212, loss=0.2583
Epoch=213, loss=0.2511
Epoch=214, loss=0.2511
Epoch=215, loss=0.2502
Epoch=216, loss=0.2454
Epoch=217, loss=0.2427
Epoch=218, loss=0.2452
Epoch=219, loss=0.2307
Epoch=220, loss=0.2400
Epoch=221, loss=0.2425
Epoch=222, loss=0.2350
Epoch=223, loss=0.2347
Epoch=224, loss=0.2330
Epoch=225, loss=0.2363
Epoch=226, loss=0.2217
Epoch=227, loss=0.2183
Epoch=228, loss=0.2205
Epoch=229, loss=0.2181
Epoch=230, loss=0.2204
Epoch=231, loss=0.2200
Epoch=232, loss=0.2152
Epoch=233, loss=0.2143
Epoch=234, loss=0.2130
Epoch=235, loss=0.2159
Epoch=236, loss=0.2062
Epoch=237, loss=0.1950
Epoch=238, loss=0.2017
Epoch=239, loss=0.2012
Epoch=240, loss=0.2072
Epoch=241, loss=0.1999
Epoch=242, loss=0.2013
Epoch=243, loss=0.2009
Epoch=244, loss=0.1935
Epoch=245, loss=0.1983
Epoch=246, loss=0.1974
Epoch=247, loss=0.1946
Epoch=248, loss=0.1903
Epoch=249, loss=0.1993
Epoch=250, loss=0.1880
Epoch=251, loss=0.1944
Epoch=252, loss=0.1880
Epoch=253, loss=0.1841
Epoch=254, loss=0.1927
Epoch=255, loss=0.1988
Epoch=256, loss=0.1877
Epoch=257, loss=0.1936
Epoch=258, loss=0.1841
Epoch=259, loss=0.1888
Epoch=260, loss=0.1776
Epoch=261, loss=0.1710
Epoch=262, loss=0.1755
Epoch=263, loss=0.1841
Epoch=264, loss=0.1828
Epoch=265, loss=0.1772
Epoch=266, loss=0.1725
Epoch=267, loss=0.1729
Epoch=268, loss=0.1731
Epoch=269, loss=0.1744
Epoch=270, loss=0.1757
Epoch=271, loss=0.1708
Epoch=272, loss=0.1644
Epoch=273, loss=0.1694
Epoch=274, loss=0.1681
Epoch=275, loss=0.1648
Epoch=276, loss=0.1635
Epoch=277, loss=0.1795
Epoch=278, loss=0.1592
Epoch=279, loss=0.1577
Epoch=280, loss=0.1602
Epoch=281, loss=0.1542
Epoch=282, loss=0.1643
Epoch=283, loss=0.1585
Epoch=284, loss=0.1642
Epoch=285, loss=0.1642
Epoch=286, loss=0.1607
Epoch=287, loss=0.1599
Epoch=288, loss=0.1653
Epoch=289, loss=0.1524
Epoch=290, loss=0.1550
Epoch=291, loss=0.1551
Epoch=292, loss=0.1622
Epoch=293, loss=0.1441
Epoch=294, loss=0.1545
Epoch=295, loss=0.1503
Epoch=296, loss=0.1467
Epoch=297, loss=0.1502
Epoch=298, loss=0.1432
Epoch=299, loss=0.1455
Epoch=300, loss=0.1454
Epoch=301, loss=0.1541
Epoch=302, loss=0.1421
Epoch=303, loss=0.1436
Epoch=304, loss=0.1459
Epoch=305, loss=0.1448
Epoch=306, loss=0.1439
Epoch=307, loss=0.1429
Epoch=308, loss=0.1450
Epoch=309, loss=0.1532
Epoch=310, loss=0.1339
Epoch=311, loss=0.1416
Epoch=312, loss=0.1331
Epoch=313, loss=0.1381
Epoch=314, loss=0.1281
Epoch=315, loss=0.1411
Epoch=316, loss=0.1359
Epoch=317, loss=0.1465
Epoch=318, loss=0.1371
Epoch=319, loss=0.1400
Epoch=320, loss=0.1455
Epoch=321, loss=0.1316
Epoch=322, loss=0.1322
Epoch=323, loss=0.1381
Epoch=324, loss=0.1316
Epoch=325, loss=0.1286
Epoch=326, loss=0.1328
Epoch=327, loss=0.1238
Epoch=328, loss=0.1249
Epoch=329, loss=0.1318
Epoch=330, loss=0.1321
Epoch=331, loss=0.1288
Epoch=332, loss=0.1299
Epoch=333, loss=0.1333
Epoch=334, loss=0.1182
Epoch=335, loss=0.1261
Epoch=336, loss=0.1262
Epoch=337, loss=0.1392
Epoch=338, loss=0.1166
Epoch=339, loss=0.1344
Epoch=340, loss=0.1256
Epoch=341, loss=0.1235
Epoch=342, loss=0.1179
Epoch=343, loss=0.1345
Epoch=344, loss=0.1230
Epoch=345, loss=0.1206
Epoch=346, loss=0.1084
Epoch=347, loss=0.1052
Epoch=348, loss=0.1284
Epoch=349, loss=0.1293
Epoch=350, loss=0.1263
Epoch=351, loss=0.1244
Epoch=352, loss=0.1155
Epoch=353, loss=0.1224
Epoch=354, loss=0.1224
Epoch=355, loss=0.1205
Epoch=356, loss=0.1145
Epoch=357, loss=0.1310
Epoch=358, loss=0.1108
Epoch=359, loss=0.1244
Epoch=360, loss=0.1137
Epoch=361, loss=0.1090
Epoch=362, loss=0.1152
Epoch=363, loss=0.1124
Epoch=364, loss=0.1252
Epoch=365, loss=0.1211
Epoch=366, loss=0.1150
Epoch=367, loss=0.1121
Early stopping!
Loading 347th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
