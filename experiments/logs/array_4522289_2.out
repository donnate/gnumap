My SLURM_ARRAY_TASK_ID:  2
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_2
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_2.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6931
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6929
Epoch=010, loss=0.6928
Epoch=011, loss=0.6928
Epoch=012, loss=0.6928
Epoch=013, loss=0.6927
Epoch=014, loss=0.6926
Epoch=015, loss=0.6926
Epoch=016, loss=0.6925
Epoch=017, loss=0.6925
Epoch=018, loss=0.6924
Epoch=019, loss=0.6923
Epoch=020, loss=0.6923
Epoch=021, loss=0.6922
Epoch=022, loss=0.6920
Epoch=023, loss=0.6920
Epoch=024, loss=0.6919
Epoch=025, loss=0.6917
Epoch=026, loss=0.6916
Epoch=027, loss=0.6915
Epoch=028, loss=0.6914
Epoch=029, loss=0.6912
Epoch=030, loss=0.6910
Epoch=031, loss=0.6909
Epoch=032, loss=0.6907
Epoch=033, loss=0.6905
Epoch=034, loss=0.6903
Epoch=035, loss=0.6900
Epoch=036, loss=0.6898
Epoch=037, loss=0.6896
Epoch=038, loss=0.6893
Epoch=039, loss=0.6891
Epoch=040, loss=0.6888
Epoch=041, loss=0.6884
Epoch=042, loss=0.6881
Epoch=043, loss=0.6878
Epoch=044, loss=0.6876
Epoch=045, loss=0.6871
Epoch=046, loss=0.6867
Epoch=047, loss=0.6863
Epoch=048, loss=0.6858
Epoch=049, loss=0.6852
Epoch=050, loss=0.6848
Epoch=051, loss=0.6844
Epoch=052, loss=0.6838
Epoch=053, loss=0.6834
Epoch=054, loss=0.6829
Epoch=055, loss=0.6819
Epoch=056, loss=0.6814
Epoch=057, loss=0.6809
Epoch=058, loss=0.6802
Epoch=059, loss=0.6792
Epoch=060, loss=0.6783
Epoch=061, loss=0.6776
Epoch=062, loss=0.6770
Epoch=063, loss=0.6762
Epoch=064, loss=0.6755
Epoch=065, loss=0.6745
Epoch=066, loss=0.6735
Epoch=067, loss=0.6725
Epoch=068, loss=0.6715
Epoch=069, loss=0.6703
Epoch=070, loss=0.6695
Epoch=071, loss=0.6682
Epoch=072, loss=0.6667
Epoch=073, loss=0.6653
Epoch=074, loss=0.6641
Epoch=075, loss=0.6631
Epoch=076, loss=0.6614
Epoch=077, loss=0.6604
Epoch=078, loss=0.6587
Epoch=079, loss=0.6579
Epoch=080, loss=0.6559
Epoch=081, loss=0.6546
Epoch=082, loss=0.6524
Epoch=083, loss=0.6510
Epoch=084, loss=0.6499
Epoch=085, loss=0.6464
Epoch=086, loss=0.6452
Epoch=087, loss=0.6444
Epoch=088, loss=0.6426
Epoch=089, loss=0.6396
Epoch=090, loss=0.6377
Epoch=091, loss=0.6362
Epoch=092, loss=0.6345
Epoch=093, loss=0.6307
Epoch=094, loss=0.6298
Epoch=095, loss=0.6277
Epoch=096, loss=0.6255
Epoch=097, loss=0.6230
Epoch=098, loss=0.6204
Epoch=099, loss=0.6188
Epoch=100, loss=0.6145
Epoch=101, loss=0.6131
Epoch=102, loss=0.6091
Epoch=103, loss=0.6089
Epoch=104, loss=0.6045
Epoch=105, loss=0.6016
Epoch=106, loss=0.5986
Epoch=107, loss=0.5973
Epoch=108, loss=0.5913
Epoch=109, loss=0.5909
Epoch=110, loss=0.5875
Epoch=111, loss=0.5831
Epoch=112, loss=0.5833
Epoch=113, loss=0.5773
Epoch=114, loss=0.5766
Epoch=115, loss=0.5723
Epoch=116, loss=0.5689
Epoch=117, loss=0.5658
Epoch=118, loss=0.5628
Epoch=119, loss=0.5566
Epoch=120, loss=0.5510
Epoch=121, loss=0.5522
Epoch=122, loss=0.5499
Epoch=123, loss=0.5444
Epoch=124, loss=0.5399
Epoch=125, loss=0.5382
Epoch=126, loss=0.5337
Epoch=127, loss=0.5300
Epoch=128, loss=0.5231
Epoch=129, loss=0.5205
Epoch=130, loss=0.5204
Epoch=131, loss=0.5124
Epoch=132, loss=0.5092
Epoch=133, loss=0.5062
Epoch=134, loss=0.4999
Epoch=135, loss=0.4954
Epoch=136, loss=0.4921
Epoch=137, loss=0.4870
Epoch=138, loss=0.4870
Epoch=139, loss=0.4823
Epoch=140, loss=0.4795
Epoch=141, loss=0.4743
Epoch=142, loss=0.4606
Epoch=143, loss=0.4639
Epoch=144, loss=0.4628
Epoch=145, loss=0.4586
Epoch=146, loss=0.4536
Epoch=147, loss=0.4512
Epoch=148, loss=0.4447
Epoch=149, loss=0.4428
Epoch=150, loss=0.4362
Epoch=151, loss=0.4300
Epoch=152, loss=0.4290
Epoch=153, loss=0.4285
Epoch=154, loss=0.4202
Epoch=155, loss=0.4204
Epoch=156, loss=0.4171
Epoch=157, loss=0.4093
Epoch=158, loss=0.4069
Epoch=159, loss=0.3970
Epoch=160, loss=0.4016
Epoch=161, loss=0.3931
Epoch=162, loss=0.3894
Epoch=163, loss=0.3848
Epoch=164, loss=0.3846
Epoch=165, loss=0.3775
Epoch=166, loss=0.3699
Epoch=167, loss=0.3680
Epoch=168, loss=0.3646
Epoch=169, loss=0.3652
Epoch=170, loss=0.3603
Epoch=171, loss=0.3558
Epoch=172, loss=0.3532
Epoch=173, loss=0.3417
Epoch=174, loss=0.3450
Epoch=175, loss=0.3353
Epoch=176, loss=0.3354
Epoch=177, loss=0.3309
Epoch=178, loss=0.3310
Epoch=179, loss=0.3224
Epoch=180, loss=0.3217
Epoch=181, loss=0.3195
Epoch=182, loss=0.3104
Epoch=183, loss=0.3143
Epoch=184, loss=0.3106
Epoch=185, loss=0.3049
Epoch=186, loss=0.3007
Epoch=187, loss=0.3037
Epoch=188, loss=0.2930
Epoch=189, loss=0.2918
Epoch=190, loss=0.2834
Epoch=191, loss=0.2812
Epoch=192, loss=0.2858
Epoch=193, loss=0.2806
Epoch=194, loss=0.2728
Epoch=195, loss=0.2776
Epoch=196, loss=0.2720
Epoch=197, loss=0.2697
Epoch=198, loss=0.2664
Epoch=199, loss=0.2707
Epoch=200, loss=0.2579
Epoch=201, loss=0.2646
Epoch=202, loss=0.2505
Epoch=203, loss=0.2540
Epoch=204, loss=0.2538
Epoch=205, loss=0.2486
Epoch=206, loss=0.2433
Epoch=207, loss=0.2386
Epoch=208, loss=0.2477
Epoch=209, loss=0.2355
Epoch=210, loss=0.2307
Epoch=211, loss=0.2385
Epoch=212, loss=0.2274
Epoch=213, loss=0.2294
Epoch=214, loss=0.2228
Epoch=215, loss=0.2247
Epoch=216, loss=0.2233
Epoch=217, loss=0.2210
Epoch=218, loss=0.2249
Epoch=219, loss=0.2104
Epoch=220, loss=0.2092
Epoch=221, loss=0.2181
Epoch=222, loss=0.2164
Epoch=223, loss=0.2058
Epoch=224, loss=0.2108
Epoch=225, loss=0.2068
Epoch=226, loss=0.2000
Epoch=227, loss=0.2007
Epoch=228, loss=0.2021
Epoch=229, loss=0.1981
Epoch=230, loss=0.1953
Epoch=231, loss=0.1988
Epoch=232, loss=0.1995
Epoch=233, loss=0.1941
Epoch=234, loss=0.1959
Epoch=235, loss=0.1874
Epoch=236, loss=0.1847
Epoch=237, loss=0.1874
Epoch=238, loss=0.1811
Epoch=239, loss=0.1840
Epoch=240, loss=0.1828
Epoch=241, loss=0.1753
Epoch=242, loss=0.1785
Epoch=243, loss=0.1690
Epoch=244, loss=0.1712
Epoch=245, loss=0.1787
Epoch=246, loss=0.1836
Epoch=247, loss=0.1821
Epoch=248, loss=0.1725
Epoch=249, loss=0.1602
Epoch=250, loss=0.1689
Epoch=251, loss=0.1607
Epoch=252, loss=0.1586
Epoch=253, loss=0.1653
Epoch=254, loss=0.1592
Epoch=255, loss=0.1624
Epoch=256, loss=0.1684
Epoch=257, loss=0.1554
Epoch=258, loss=0.1607
Epoch=259, loss=0.1554
Epoch=260, loss=0.1493
Epoch=261, loss=0.1530
Epoch=262, loss=0.1571
Epoch=263, loss=0.1597
Epoch=264, loss=0.1460
Epoch=265, loss=0.1470
Epoch=266, loss=0.1501
Epoch=267, loss=0.1559
Epoch=268, loss=0.1476
Epoch=269, loss=0.1497
Epoch=270, loss=0.1541
Epoch=271, loss=0.1408
Epoch=272, loss=0.1515
Epoch=273, loss=0.1351
Epoch=274, loss=0.1400
Epoch=275, loss=0.1421
Epoch=276, loss=0.1389
Epoch=277, loss=0.1419
Epoch=278, loss=0.1401
Epoch=279, loss=0.1451
Epoch=280, loss=0.1331
Epoch=281, loss=0.1439
Epoch=282, loss=0.1344
Epoch=283, loss=0.1209
Epoch=284, loss=0.1306
Epoch=285, loss=0.1240
Epoch=286, loss=0.1386
Epoch=287, loss=0.1315
Epoch=288, loss=0.1274
Epoch=289, loss=0.1351
Epoch=290, loss=0.1234
Epoch=291, loss=0.1265
Epoch=292, loss=0.1184
Epoch=293, loss=0.1279
Epoch=294, loss=0.1290
Epoch=295, loss=0.1314
Epoch=296, loss=0.1253
Epoch=297, loss=0.1251
Epoch=298, loss=0.1321
Epoch=299, loss=0.1274
Epoch=300, loss=0.1253
Epoch=301, loss=0.1101
Epoch=302, loss=0.1196
Epoch=303, loss=0.1210
Epoch=304, loss=0.1151
Epoch=305, loss=0.1271
Epoch=306, loss=0.1252
Epoch=307, loss=0.1146
Epoch=308, loss=0.1197
Epoch=309, loss=0.1180
Epoch=310, loss=0.1133
Epoch=311, loss=0.1190
Epoch=312, loss=0.1188
Epoch=313, loss=0.1135
Epoch=314, loss=0.1112
Epoch=315, loss=0.1179
Epoch=316, loss=0.1146
Epoch=317, loss=0.1149
Epoch=318, loss=0.1135
Epoch=319, loss=0.1098
Epoch=320, loss=0.1149
Epoch=321, loss=0.1093
Epoch=322, loss=0.1074
Epoch=323, loss=0.1060
Epoch=324, loss=0.1036
Epoch=325, loss=0.1201
Epoch=326, loss=0.1159
Epoch=327, loss=0.1166
Epoch=328, loss=0.1043
Epoch=329, loss=0.1045
Epoch=330, loss=0.1212
Epoch=331, loss=0.1141
Epoch=332, loss=0.1053
Epoch=333, loss=0.1081
Epoch=334, loss=0.1091
Epoch=335, loss=0.1029
Epoch=336, loss=0.0895
Epoch=337, loss=0.1069
Epoch=338, loss=0.1049
Epoch=339, loss=0.1120
Epoch=340, loss=0.1012
Epoch=341, loss=0.1066
Epoch=342, loss=0.0978
Epoch=343, loss=0.0968
Epoch=344, loss=0.1037
Epoch=345, loss=0.1095
Epoch=346, loss=0.1020
Epoch=347, loss=0.0984
Epoch=348, loss=0.0995
Epoch=349, loss=0.0876
Epoch=350, loss=0.0966
Epoch=351, loss=0.1051
Epoch=352, loss=0.1010
Epoch=353, loss=0.0993
Epoch=354, loss=0.0954
Epoch=355, loss=0.0992
Epoch=356, loss=0.0953
Epoch=357, loss=0.0962
Epoch=358, loss=0.0886
Epoch=359, loss=0.1025
Epoch=360, loss=0.0977
Epoch=361, loss=0.0941
Epoch=362, loss=0.0891
Epoch=363, loss=0.1003
Epoch=364, loss=0.0853
Epoch=365, loss=0.0890
Epoch=366, loss=0.1055
Epoch=367, loss=0.0907
Epoch=368, loss=0.0901
Epoch=369, loss=0.1057
Epoch=370, loss=0.0893
Epoch=371, loss=0.0903
Epoch=372, loss=0.0826
Epoch=373, loss=0.0883
Epoch=374, loss=0.0909
Epoch=375, loss=0.0903
Epoch=376, loss=0.0931
Epoch=377, loss=0.0962
Epoch=378, loss=0.0886
Epoch=379, loss=0.0886
Epoch=380, loss=0.0863
Epoch=381, loss=0.0921
Epoch=382, loss=0.0846
Epoch=383, loss=0.0867
Epoch=384, loss=0.0885
Epoch=385, loss=0.0784
Epoch=386, loss=0.0886
Epoch=387, loss=0.0956
Epoch=388, loss=0.0953
Epoch=389, loss=0.0889
Epoch=390, loss=0.0850
Epoch=391, loss=0.0869
Epoch=392, loss=0.0884
Epoch=393, loss=0.0893
Epoch=394, loss=0.0819
Epoch=395, loss=0.0854
Epoch=396, loss=0.0860
Epoch=397, loss=0.0843
Epoch=398, loss=0.0811
Epoch=399, loss=0.0859
Epoch=400, loss=0.0785
Epoch=401, loss=0.0888
Epoch=402, loss=0.0728
Epoch=403, loss=0.0825
Epoch=404, loss=0.0783
Epoch=405, loss=0.0876
Epoch=406, loss=0.0878
Epoch=407, loss=0.0832
Epoch=408, loss=0.0819
Epoch=409, loss=0.0809
Epoch=410, loss=0.0813
Epoch=411, loss=0.0860
Epoch=412, loss=0.0831
Epoch=413, loss=0.0794
Epoch=414, loss=0.0810
Epoch=415, loss=0.0788
Epoch=416, loss=0.0781
Epoch=417, loss=0.0762
Epoch=418, loss=0.0795
Epoch=419, loss=0.0856
Epoch=420, loss=0.0838
Epoch=421, loss=0.0800
Epoch=422, loss=0.0774
Early stopping!
Loading 402th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7271+-0.0147, F1Ma=0.6451+-0.0223, acc=0.7271+-0.0147
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6927
Epoch=008, loss=0.6926
Epoch=009, loss=0.6924
Epoch=010, loss=0.6923
Epoch=011, loss=0.6922
Epoch=012, loss=0.6920
Epoch=013, loss=0.6918
Epoch=014, loss=0.6916
Epoch=015, loss=0.6913
Epoch=016, loss=0.6910
Epoch=017, loss=0.6908
Epoch=018, loss=0.6905
Epoch=019, loss=0.6901
Epoch=020, loss=0.6898
Epoch=021, loss=0.6894
Epoch=022, loss=0.6889
Epoch=023, loss=0.6883
Epoch=024, loss=0.6878
Epoch=025, loss=0.6873
Epoch=026, loss=0.6866
Epoch=027, loss=0.6859
Epoch=028, loss=0.6852
Epoch=029, loss=0.6842
Epoch=030, loss=0.6833
Epoch=031, loss=0.6825
Epoch=032, loss=0.6815
Epoch=033, loss=0.6805
Epoch=034, loss=0.6791
Epoch=035, loss=0.6776
Epoch=036, loss=0.6765
Epoch=037, loss=0.6750
Epoch=038, loss=0.6732
Epoch=039, loss=0.6714
Epoch=040, loss=0.6700
Epoch=041, loss=0.6684
Epoch=042, loss=0.6671
Epoch=043, loss=0.6646
Epoch=044, loss=0.6623
Epoch=045, loss=0.6595
Epoch=046, loss=0.6567
Epoch=047, loss=0.6550
Epoch=048, loss=0.6519
Epoch=049, loss=0.6492
Epoch=050, loss=0.6457
Epoch=051, loss=0.6432
Epoch=052, loss=0.6395
Epoch=053, loss=0.6363
Epoch=054, loss=0.6323
Epoch=055, loss=0.6306
Epoch=056, loss=0.6261
Epoch=057, loss=0.6221
Epoch=058, loss=0.6175
Epoch=059, loss=0.6112
Epoch=060, loss=0.6073
Epoch=061, loss=0.6030
Epoch=062, loss=0.6013
Epoch=063, loss=0.5944
Epoch=064, loss=0.5890
Epoch=065, loss=0.5833
Epoch=066, loss=0.5767
Epoch=067, loss=0.5721
Epoch=068, loss=0.5680
Epoch=069, loss=0.5621
Epoch=070, loss=0.5551
Epoch=071, loss=0.5484
Epoch=072, loss=0.5428
Epoch=073, loss=0.5388
Epoch=074, loss=0.5293
Epoch=075, loss=0.5241
Epoch=076, loss=0.5164
Epoch=077, loss=0.5072
Epoch=078, loss=0.5033
Epoch=079, loss=0.4965
Epoch=080, loss=0.4904
Epoch=081, loss=0.4799
Epoch=082, loss=0.4761
Epoch=083, loss=0.4677
Epoch=084, loss=0.4601
Epoch=085, loss=0.4543
Epoch=086, loss=0.4447
Epoch=087, loss=0.4424
Epoch=088, loss=0.4314
Epoch=089, loss=0.4187
Epoch=090, loss=0.4223
Epoch=091, loss=0.4101
Epoch=092, loss=0.3989
Epoch=093, loss=0.4031
Epoch=094, loss=0.3872
Epoch=095, loss=0.3775
Epoch=096, loss=0.3754
Epoch=097, loss=0.3659
Epoch=098, loss=0.3614
Epoch=099, loss=0.3554
Epoch=100, loss=0.3492
Epoch=101, loss=0.3401
Epoch=102, loss=0.3296
Epoch=103, loss=0.3290
Epoch=104, loss=0.3165
Epoch=105, loss=0.3159
Epoch=106, loss=0.3062
Epoch=107, loss=0.3071
Epoch=108, loss=0.2930
Epoch=109, loss=0.2897
Epoch=110, loss=0.2808
Epoch=111, loss=0.2730
Epoch=112, loss=0.2767
Epoch=113, loss=0.2689
Epoch=114, loss=0.2680
Epoch=115, loss=0.2548
Epoch=116, loss=0.2528
Epoch=117, loss=0.2477
Epoch=118, loss=0.2414
Epoch=119, loss=0.2405
Epoch=120, loss=0.2452
Epoch=121, loss=0.2318
Epoch=122, loss=0.2276
Epoch=123, loss=0.2176
Epoch=124, loss=0.2071
Epoch=125, loss=0.2178
Epoch=126, loss=0.2107
Epoch=127, loss=0.2081
Epoch=128, loss=0.1994
Epoch=129, loss=0.1972
Epoch=130, loss=0.1925
Epoch=131, loss=0.1937
Epoch=132, loss=0.1922
Epoch=133, loss=0.1854
Epoch=134, loss=0.1863
Epoch=135, loss=0.1847
Epoch=136, loss=0.1745
Epoch=137, loss=0.1724
Epoch=138, loss=0.1698
Epoch=139, loss=0.1686
Epoch=140, loss=0.1600
Epoch=141, loss=0.1676
Epoch=142, loss=0.1595
Epoch=143, loss=0.1604
Epoch=144, loss=0.1609
Epoch=145, loss=0.1495
Epoch=146, loss=0.1485
Epoch=147, loss=0.1485
Epoch=148, loss=0.1489
Epoch=149, loss=0.1485
Epoch=150, loss=0.1367
Epoch=151, loss=0.1447
Epoch=152, loss=0.1335
Epoch=153, loss=0.1288
Epoch=154, loss=0.1369
Epoch=155, loss=0.1372
Epoch=156, loss=0.1361
Epoch=157, loss=0.1293
Epoch=158, loss=0.1307
Epoch=159, loss=0.1328
Epoch=160, loss=0.1292
Epoch=161, loss=0.1197
Epoch=162, loss=0.1305
Epoch=163, loss=0.1298
Epoch=164, loss=0.1210
Epoch=165, loss=0.1217
Epoch=166, loss=0.1224
Epoch=167, loss=0.1143
Epoch=168, loss=0.1158
Epoch=169, loss=0.1139
Epoch=170, loss=0.1135
Epoch=171, loss=0.1067
Epoch=172, loss=0.1043
Epoch=173, loss=0.1078
Epoch=174, loss=0.1136
Epoch=175, loss=0.1103
Epoch=176, loss=0.0974
Epoch=177, loss=0.1092
Epoch=178, loss=0.1085
Epoch=179, loss=0.1043
Epoch=180, loss=0.1042
Epoch=181, loss=0.1088
Epoch=182, loss=0.1111
Epoch=183, loss=0.1003
Epoch=184, loss=0.0995
Epoch=185, loss=0.0993
Epoch=186, loss=0.0902
Epoch=187, loss=0.0986
Epoch=188, loss=0.1023
Epoch=189, loss=0.0959
Epoch=190, loss=0.0926
Epoch=191, loss=0.0925
Epoch=192, loss=0.0969
Epoch=193, loss=0.0858
Epoch=194, loss=0.0936
Epoch=195, loss=0.0865
Epoch=196, loss=0.0973
Epoch=197, loss=0.0971
Epoch=198, loss=0.0948
Epoch=199, loss=0.0960
Epoch=200, loss=0.0889
Epoch=201, loss=0.0982
Epoch=202, loss=0.0926
Epoch=203, loss=0.0830
Epoch=204, loss=0.0911
Epoch=205, loss=0.0853
Epoch=206, loss=0.0812
Epoch=207, loss=0.0842
Epoch=208, loss=0.0892
Epoch=209, loss=0.0767
Epoch=210, loss=0.0802
Epoch=211, loss=0.0778
Epoch=212, loss=0.0789
Epoch=213, loss=0.0740
Epoch=214, loss=0.0706
Epoch=215, loss=0.0819
Epoch=216, loss=0.0756
Epoch=217, loss=0.0814
Epoch=218, loss=0.0816
Epoch=219, loss=0.0735
Epoch=220, loss=0.0676
Epoch=221, loss=0.0700
Epoch=222, loss=0.0810
Epoch=223, loss=0.0814
Epoch=224, loss=0.0861
Epoch=225, loss=0.0816
Epoch=226, loss=0.0703
Epoch=227, loss=0.0741
Epoch=228, loss=0.0891
Epoch=229, loss=0.0722
Epoch=230, loss=0.0649
Epoch=231, loss=0.0740
Epoch=232, loss=0.0758
Epoch=233, loss=0.0697
Epoch=234, loss=0.0698
Epoch=235, loss=0.0708
Epoch=236, loss=0.0662
Epoch=237, loss=0.0712
Epoch=238, loss=0.0691
Epoch=239, loss=0.0761
Epoch=240, loss=0.0741
Epoch=241, loss=0.0606
Epoch=242, loss=0.0748
Epoch=243, loss=0.0729
Epoch=244, loss=0.0796
Epoch=245, loss=0.0773
Epoch=246, loss=0.0738
Epoch=247, loss=0.0617
Epoch=248, loss=0.0725
Epoch=249, loss=0.0634
Epoch=250, loss=0.0644
Epoch=251, loss=0.0589
Epoch=252, loss=0.0666
Epoch=253, loss=0.0711
Epoch=254, loss=0.0602
Epoch=255, loss=0.0670
Epoch=256, loss=0.0612
Epoch=257, loss=0.0641
Epoch=258, loss=0.0545
Epoch=259, loss=0.0568
Epoch=260, loss=0.0637
Epoch=261, loss=0.0608
Epoch=262, loss=0.0626
Epoch=263, loss=0.0636
Epoch=264, loss=0.0594
Epoch=265, loss=0.0694
Epoch=266, loss=0.0584
Epoch=267, loss=0.0492
Epoch=268, loss=0.0605
Epoch=269, loss=0.0625
Epoch=270, loss=0.0627
Epoch=271, loss=0.0638
Epoch=272, loss=0.0773
Epoch=273, loss=0.0548
Epoch=274, loss=0.0638
Epoch=275, loss=0.0555
Epoch=276, loss=0.0539
Epoch=277, loss=0.0619
Epoch=278, loss=0.0683
Epoch=279, loss=0.0614
Epoch=280, loss=0.0543
Epoch=281, loss=0.0568
Epoch=282, loss=0.0546
Epoch=283, loss=0.0593
Epoch=284, loss=0.0597
Epoch=285, loss=0.0663
Epoch=286, loss=0.0639
Epoch=287, loss=0.0495
Early stopping!
Loading 267th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7390+-0.0184, F1Ma=0.6883+-0.0414, acc=0.7390+-0.0184
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7884130656597431, 0.7823462790408146, 0.8040859975011612, 0.7946910950163584, 0.8785714507102966, 0.722000002861023, 0.7263056039810181, 0.8714285492897034, 0.7200000286102295, 0.7282398343086243, 0.7389817333851536, 0.018408459368776674, 0.6882823691724065, 0.04136776013377592, 0.7389817333851536, 0.01840845936877666]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6923
Epoch=005, loss=0.6920
Epoch=006, loss=0.6916
Epoch=007, loss=0.6911
Epoch=008, loss=0.6907
Epoch=009, loss=0.6901
Epoch=010, loss=0.6893
Epoch=011, loss=0.6886
Epoch=012, loss=0.6876
Epoch=013, loss=0.6865
Epoch=014, loss=0.6854
Epoch=015, loss=0.6840
Epoch=016, loss=0.6828
Epoch=017, loss=0.6808
Epoch=018, loss=0.6787
Epoch=019, loss=0.6766
Epoch=020, loss=0.6746
Epoch=021, loss=0.6717
Epoch=022, loss=0.6691
Epoch=023, loss=0.6654
Epoch=024, loss=0.6617
Epoch=025, loss=0.6582
Epoch=026, loss=0.6545
Epoch=027, loss=0.6504
Epoch=028, loss=0.6449
Epoch=029, loss=0.6402
Epoch=030, loss=0.6344
Epoch=031, loss=0.6281
Epoch=032, loss=0.6224
Epoch=033, loss=0.6141
Epoch=034, loss=0.6081
Epoch=035, loss=0.6004
Epoch=036, loss=0.5937
Epoch=037, loss=0.5841
Epoch=038, loss=0.5764
Epoch=039, loss=0.5658
Epoch=040, loss=0.5570
Epoch=041, loss=0.5437
Epoch=042, loss=0.5333
Epoch=043, loss=0.5231
Epoch=044, loss=0.5141
Epoch=045, loss=0.5033
Epoch=046, loss=0.4900
Epoch=047, loss=0.4793
Epoch=048, loss=0.4610
Epoch=049, loss=0.4495
Epoch=050, loss=0.4393
Epoch=051, loss=0.4304
Epoch=052, loss=0.4133
Epoch=053, loss=0.4006
Epoch=054, loss=0.3849
Epoch=055, loss=0.3763
Epoch=056, loss=0.3560
Epoch=057, loss=0.3487
Epoch=058, loss=0.3443
Epoch=059, loss=0.3251
Epoch=060, loss=0.3082
Epoch=061, loss=0.3087
Epoch=062, loss=0.2929
Epoch=063, loss=0.2809
Epoch=064, loss=0.2675
Epoch=065, loss=0.2567
Epoch=066, loss=0.2538
Epoch=067, loss=0.2474
Epoch=068, loss=0.2413
Epoch=069, loss=0.2218
Epoch=070, loss=0.2273
Epoch=071, loss=0.2044
Epoch=072, loss=0.2023
Epoch=073, loss=0.1954
Epoch=074, loss=0.1890
Epoch=075, loss=0.1840
Epoch=076, loss=0.1718
Epoch=077, loss=0.1748
Epoch=078, loss=0.1622
Epoch=079, loss=0.1632
Epoch=080, loss=0.1533
Epoch=081, loss=0.1453
Epoch=082, loss=0.1478
Epoch=083, loss=0.1493
Epoch=084, loss=0.1429
Epoch=085, loss=0.1418
Epoch=086, loss=0.1437
Epoch=087, loss=0.1251
Epoch=088, loss=0.1279
Epoch=089, loss=0.1359
Epoch=090, loss=0.1146
Epoch=091, loss=0.1211
Epoch=092, loss=0.1149
Epoch=093, loss=0.1115
Epoch=094, loss=0.1230
Epoch=095, loss=0.1051
Epoch=096, loss=0.1138
Epoch=097, loss=0.1049
Epoch=098, loss=0.1097
Epoch=099, loss=0.1001
Epoch=100, loss=0.1064
Epoch=101, loss=0.1050
Epoch=102, loss=0.1110
Epoch=103, loss=0.1018
Epoch=104, loss=0.1022
Epoch=105, loss=0.0916
Epoch=106, loss=0.1034
Epoch=107, loss=0.0926
Epoch=108, loss=0.0913
Epoch=109, loss=0.0998
Epoch=110, loss=0.0950
Epoch=111, loss=0.0896
Epoch=112, loss=0.0855
Epoch=113, loss=0.0858
Epoch=114, loss=0.0940
Epoch=115, loss=0.0835
Epoch=116, loss=0.0856
Epoch=117, loss=0.0871
Epoch=118, loss=0.0785
Epoch=119, loss=0.0748
Epoch=120, loss=0.0856
Epoch=121, loss=0.0892
Epoch=122, loss=0.0807
Epoch=123, loss=0.0882
Epoch=124, loss=0.0759
Epoch=125, loss=0.0724
Epoch=126, loss=0.0728
Epoch=127, loss=0.0702
Epoch=128, loss=0.0651
Epoch=129, loss=0.0739
Epoch=130, loss=0.0638
Epoch=131, loss=0.0611
Epoch=132, loss=0.0731
Epoch=133, loss=0.0813
Epoch=134, loss=0.0728
Epoch=135, loss=0.0774
Epoch=136, loss=0.0758
Epoch=137, loss=0.0625
Epoch=138, loss=0.0623
Epoch=139, loss=0.0632
Epoch=140, loss=0.0680
Epoch=141, loss=0.0672
Epoch=142, loss=0.0637
Epoch=143, loss=0.0658
Epoch=144, loss=0.0628
Epoch=145, loss=0.0719
Epoch=146, loss=0.0551
Epoch=147, loss=0.0655
Epoch=148, loss=0.0690
Epoch=149, loss=0.0864
Epoch=150, loss=0.0641
Epoch=151, loss=0.0658
Epoch=152, loss=0.0574
Epoch=153, loss=0.0565
Epoch=154, loss=0.0610
Epoch=155, loss=0.0554
Epoch=156, loss=0.0655
Epoch=157, loss=0.0612
Epoch=158, loss=0.0546
Epoch=159, loss=0.0546
Epoch=160, loss=0.0665
Epoch=161, loss=0.0514
Epoch=162, loss=0.0534
Epoch=163, loss=0.0657
Epoch=164, loss=0.0562
Epoch=165, loss=0.0601
Epoch=166, loss=0.0541
Epoch=167, loss=0.0679
Epoch=168, loss=0.0685
Epoch=169, loss=0.0492
Epoch=170, loss=0.0640
Epoch=171, loss=0.0461
Epoch=172, loss=0.0454
Epoch=173, loss=0.0548
Epoch=174, loss=0.0561
Epoch=175, loss=0.0511
Epoch=176, loss=0.0434
Epoch=177, loss=0.0529
Epoch=178, loss=0.0556
Epoch=179, loss=0.0693
Epoch=180, loss=0.0474
Epoch=181, loss=0.0558
Epoch=182, loss=0.0565
Epoch=183, loss=0.0476
Epoch=184, loss=0.0470
Epoch=185, loss=0.0577
Epoch=186, loss=0.0580
Epoch=187, loss=0.0523
Epoch=188, loss=0.0585
Epoch=189, loss=0.0570
Epoch=190, loss=0.0456
Epoch=191, loss=0.0456
Epoch=192, loss=0.0550
Epoch=193, loss=0.0462
Epoch=194, loss=0.0524
Epoch=195, loss=0.0518
Epoch=196, loss=0.0469
Early stopping!
Loading 176th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7949+-0.0099, F1Ma=0.7775+-0.0225, acc=0.7949+-0.0099
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7884130656597431, 0.7823462790408146, 0.8040859975011612, 0.7946910950163584, 0.8785714507102966, 0.722000002861023, 0.7263056039810181, 0.8714285492897034, 0.7200000286102295, 0.7282398343086243, 0.7389817333851536, 0.018408459368776674, 0.6882823691724065, 0.04136776013377592, 0.7389817333851536, 0.01840845936877666], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753610042704491, 0.7771043642690278, 0.8040589927591285, 0.7997604845520727, 0.9214285612106323, 0.7699999809265137, 0.7857833504676819, 0.9142857193946838, 0.765999972820282, 0.7843326926231384, 0.7949475320637387, 0.009873886985278149, 0.7774964836974675, 0.022492824322406058, 0.7949475320637387, 0.009873886985278128]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6919
Epoch=003, loss=0.6910
Epoch=004, loss=0.6899
Epoch=005, loss=0.6884
Epoch=006, loss=0.6866
Epoch=007, loss=0.6846
Epoch=008, loss=0.6816
Epoch=009, loss=0.6784
Epoch=010, loss=0.6745
Epoch=011, loss=0.6699
Epoch=012, loss=0.6647
Epoch=013, loss=0.6590
Epoch=014, loss=0.6518
Epoch=015, loss=0.6442
Epoch=016, loss=0.6354
Epoch=017, loss=0.6256
Epoch=018, loss=0.6149
Epoch=019, loss=0.6029
Epoch=020, loss=0.5905
Epoch=021, loss=0.5756
Epoch=022, loss=0.5625
Epoch=023, loss=0.5453
Epoch=024, loss=0.5277
Epoch=025, loss=0.5113
Epoch=026, loss=0.4889
Epoch=027, loss=0.4731
Epoch=028, loss=0.4527
Epoch=029, loss=0.4325
Epoch=030, loss=0.4111
Epoch=031, loss=0.3932
Epoch=032, loss=0.3748
Epoch=033, loss=0.3538
Epoch=034, loss=0.3285
Epoch=035, loss=0.3153
Epoch=036, loss=0.3002
Epoch=037, loss=0.2787
Epoch=038, loss=0.2605
Epoch=039, loss=0.2525
Epoch=040, loss=0.2299
Epoch=041, loss=0.2191
Epoch=042, loss=0.2090
Epoch=043, loss=0.2005
Epoch=044, loss=0.1847
Epoch=045, loss=0.1766
Epoch=046, loss=0.1651
Epoch=047, loss=0.1606
Epoch=048, loss=0.1513
Epoch=049, loss=0.1379
Epoch=050, loss=0.1358
Epoch=051, loss=0.1222
Epoch=052, loss=0.1369
Epoch=053, loss=0.1273
Epoch=054, loss=0.1290
Epoch=055, loss=0.1082
Epoch=056, loss=0.1083
Epoch=057, loss=0.1207
Epoch=058, loss=0.1087
Epoch=059, loss=0.1019
Epoch=060, loss=0.1055
Epoch=061, loss=0.1051
Epoch=062, loss=0.0955
Epoch=063, loss=0.0968
Epoch=064, loss=0.0822
Epoch=065, loss=0.0899
Epoch=066, loss=0.0923
Epoch=067, loss=0.0864
Epoch=068, loss=0.0746
Epoch=069, loss=0.0753
Epoch=070, loss=0.0679
Epoch=071, loss=0.0733
Epoch=072, loss=0.0922
Epoch=073, loss=0.0827
Epoch=074, loss=0.0874
Epoch=075, loss=0.0832
Epoch=076, loss=0.0889
Epoch=077, loss=0.0818
Epoch=078, loss=0.0722
Epoch=079, loss=0.0805
Epoch=080, loss=0.0785
Epoch=081, loss=0.0701
Epoch=082, loss=0.0693
Epoch=083, loss=0.0665
Epoch=084, loss=0.0614
Epoch=085, loss=0.0637
Epoch=086, loss=0.0611
Epoch=087, loss=0.0643
Epoch=088, loss=0.0759
Epoch=089, loss=0.0563
Epoch=090, loss=0.0652
Epoch=091, loss=0.0667
Epoch=092, loss=0.0649
Epoch=093, loss=0.0726
Epoch=094, loss=0.0628
Epoch=095, loss=0.0701
Epoch=096, loss=0.0733
Epoch=097, loss=0.0576
Epoch=098, loss=0.0732
Epoch=099, loss=0.0537
Epoch=100, loss=0.0672
Epoch=101, loss=0.0664
Epoch=102, loss=0.0471
Epoch=103, loss=0.0593
Epoch=104, loss=0.0555
Epoch=105, loss=0.0671
Epoch=106, loss=0.0607
Epoch=107, loss=0.0565
Epoch=108, loss=0.0579
Epoch=109, loss=0.0533
Epoch=110, loss=0.0607
Epoch=111, loss=0.0471
Epoch=112, loss=0.0519
Epoch=113, loss=0.0536
Epoch=114, loss=0.0621
Epoch=115, loss=0.0512
Epoch=116, loss=0.0438
Epoch=117, loss=0.0593
Epoch=118, loss=0.0537
Epoch=119, loss=0.0500
Epoch=120, loss=0.0560
Epoch=121, loss=0.0545
Epoch=122, loss=0.0528
Epoch=123, loss=0.0509
Epoch=124, loss=0.0561
Epoch=125, loss=0.0535
Epoch=126, loss=0.0471
Epoch=127, loss=0.0498
Epoch=128, loss=0.0512
Epoch=129, loss=0.0443
Epoch=130, loss=0.0440
Epoch=131, loss=0.0499
Epoch=132, loss=0.0455
Epoch=133, loss=0.0464
Epoch=134, loss=0.0418
Epoch=135, loss=0.0483
Epoch=136, loss=0.0443
Epoch=137, loss=0.0534
Epoch=138, loss=0.0452
Epoch=139, loss=0.0539
Epoch=140, loss=0.0570
Epoch=141, loss=0.0380
Epoch=142, loss=0.0381
Epoch=143, loss=0.0467
Epoch=144, loss=0.0442
Epoch=145, loss=0.0435
Epoch=146, loss=0.0374
Epoch=147, loss=0.0331
Epoch=148, loss=0.0393
Epoch=149, loss=0.0465
Epoch=150, loss=0.0512
Epoch=151, loss=0.0382
Epoch=152, loss=0.0396
Epoch=153, loss=0.0276
Epoch=154, loss=0.0345
Epoch=155, loss=0.0402
Epoch=156, loss=0.0444
Epoch=157, loss=0.0398
Epoch=158, loss=0.0395
Epoch=159, loss=0.0400
Epoch=160, loss=0.0519
Epoch=161, loss=0.0324
Epoch=162, loss=0.0366
Epoch=163, loss=0.0542
Epoch=164, loss=0.0302
Epoch=165, loss=0.0454
Epoch=166, loss=0.0421
Epoch=167, loss=0.0338
Epoch=168, loss=0.0415
Epoch=169, loss=0.0371
Epoch=170, loss=0.0409
Epoch=171, loss=0.0379
Epoch=172, loss=0.0287
Epoch=173, loss=0.0488
Early stopping!
Loading 153th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8082+-0.0198, F1Ma=0.7833+-0.0409, acc=0.8082+-0.0198
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7884130656597431, 0.7823462790408146, 0.8040859975011612, 0.7946910950163584, 0.8785714507102966, 0.722000002861023, 0.7263056039810181, 0.8714285492897034, 0.7200000286102295, 0.7282398343086243, 0.7389817333851536, 0.018408459368776674, 0.6882823691724065, 0.04136776013377592, 0.7389817333851536, 0.01840845936877666], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753610042704491, 0.7771043642690278, 0.8040589927591285, 0.7997604845520727, 0.9214285612106323, 0.7699999809265137, 0.7857833504676819, 0.9142857193946838, 0.765999972820282, 0.7843326926231384, 0.7949475320637387, 0.009873886985278149, 0.7774964836974675, 0.022492824322406058, 0.7949475320637387, 0.009873886985278128], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7863530317328681, 0.7775986975762487, 0.7938566012191741, 0.787595303150568, 0.9357143044471741, 0.8059999942779541, 0.7973887920379639, 0.9357143044471741, 0.8059999942779541, 0.7964216470718384, 0.8082394092499028, 0.019793919761462237, 0.7832866992649055, 0.040887736916491196, 0.8082394092499028, 0.019793919761462237]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6917
Epoch=002, loss=0.6893
Epoch=003, loss=0.6861
Epoch=004, loss=0.6815
Epoch=005, loss=0.6747
Epoch=006, loss=0.6682
Epoch=007, loss=0.6591
Epoch=008, loss=0.6464
Epoch=009, loss=0.6333
Epoch=010, loss=0.6171
Epoch=011, loss=0.6000
Epoch=012, loss=0.5795
Epoch=013, loss=0.5571
Epoch=014, loss=0.5311
Epoch=015, loss=0.5068
Epoch=016, loss=0.4805
Epoch=017, loss=0.4502
Epoch=018, loss=0.4304
Epoch=019, loss=0.4076
Epoch=020, loss=0.3620
Epoch=021, loss=0.3454
Epoch=022, loss=0.3201
Epoch=023, loss=0.3082
Epoch=024, loss=0.2650
Epoch=025, loss=0.2718
Epoch=026, loss=0.2411
Epoch=027, loss=0.2282
Epoch=028, loss=0.2024
Epoch=029, loss=0.2014
Epoch=030, loss=0.1972
Epoch=031, loss=0.1722
Epoch=032, loss=0.1584
Epoch=033, loss=0.1516
Epoch=034, loss=0.1578
Epoch=035, loss=0.1593
Epoch=036, loss=0.1270
Epoch=037, loss=0.1244
Epoch=038, loss=0.1107
Epoch=039, loss=0.1312
Epoch=040, loss=0.1173
Epoch=041, loss=0.1154
Epoch=042, loss=0.0981
Epoch=043, loss=0.1066
Epoch=044, loss=0.0992
Epoch=045, loss=0.1116
Epoch=046, loss=0.0945
Epoch=047, loss=0.0859
Epoch=048, loss=0.1068
Epoch=049, loss=0.1023
Epoch=050, loss=0.0939
Epoch=051, loss=0.0954
Epoch=052, loss=0.0906
Epoch=053, loss=0.1060
Epoch=054, loss=0.0801
Epoch=055, loss=0.0838
Epoch=056, loss=0.0944
Epoch=057, loss=0.1006
Epoch=058, loss=0.0741
Epoch=059, loss=0.0650
Epoch=060, loss=0.0927
Epoch=061, loss=0.0797
Epoch=062, loss=0.0742
Epoch=063, loss=0.0905
Epoch=064, loss=0.0591
Epoch=065, loss=0.0712
Epoch=066, loss=0.0745
Epoch=067, loss=0.0604
Epoch=068, loss=0.0660
Epoch=069, loss=0.0725
Epoch=070, loss=0.0837
Epoch=071, loss=0.0635
Epoch=072, loss=0.0677
Epoch=073, loss=0.0520
Epoch=074, loss=0.0665
Epoch=075, loss=0.0782
Epoch=076, loss=0.0650
Epoch=077, loss=0.0594
Epoch=078, loss=0.0681
Epoch=079, loss=0.0579
Epoch=080, loss=0.0506
Epoch=081, loss=0.0525
Epoch=082, loss=0.0477
Epoch=083, loss=0.0578
Epoch=084, loss=0.0642
Epoch=085, loss=0.0600
Epoch=086, loss=0.0582
Epoch=087, loss=0.0610
Epoch=088, loss=0.0630
Epoch=089, loss=0.0665
Epoch=090, loss=0.0489
Epoch=091, loss=0.0422
Epoch=092, loss=0.0539
Epoch=093, loss=0.0530
Epoch=094, loss=0.0457
Epoch=095, loss=0.0370
Epoch=096, loss=0.0466
Epoch=097, loss=0.0427
Epoch=098, loss=0.0364
Epoch=099, loss=0.0539
Epoch=100, loss=0.0350
Epoch=101, loss=0.0467
Epoch=102, loss=0.0453
Epoch=103, loss=0.0498
Epoch=104, loss=0.0574
Epoch=105, loss=0.0485
Epoch=106, loss=0.0598
Epoch=107, loss=0.0420
Epoch=108, loss=0.0459
Epoch=109, loss=0.0414
Epoch=110, loss=0.0367
Epoch=111, loss=0.0390
Epoch=112, loss=0.0456
Epoch=113, loss=0.0510
Epoch=114, loss=0.0398
Epoch=115, loss=0.0367
Epoch=116, loss=0.0403
Epoch=117, loss=0.0456
Epoch=118, loss=0.0400
Epoch=119, loss=0.0499
Epoch=120, loss=0.0336
Epoch=121, loss=0.0388
Epoch=122, loss=0.0396
Epoch=123, loss=0.0325
Epoch=124, loss=0.0434
Epoch=125, loss=0.0311
Epoch=126, loss=0.0281
Epoch=127, loss=0.0322
Epoch=128, loss=0.0418
Epoch=129, loss=0.0456
Epoch=130, loss=0.0319
Epoch=131, loss=0.0374
Epoch=132, loss=0.0499
Epoch=133, loss=0.0387
Epoch=134, loss=0.0537
Epoch=135, loss=0.0497
Epoch=136, loss=0.0328
Epoch=137, loss=0.0498
Epoch=138, loss=0.0594
Epoch=139, loss=0.0327
Epoch=140, loss=0.0448
Epoch=141, loss=0.0558
Epoch=142, loss=0.0331
Epoch=143, loss=0.0447
Epoch=144, loss=0.0351
Epoch=145, loss=0.0453
Epoch=146, loss=0.0450
Early stopping!
Loading 126th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7890+-0.0141, F1Ma=0.7573+-0.0239, acc=0.7890+-0.0141
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7884130656597431, 0.7823462790408146, 0.8040859975011612, 0.7946910950163584, 0.8785714507102966, 0.722000002861023, 0.7263056039810181, 0.8714285492897034, 0.7200000286102295, 0.7282398343086243, 0.7389817333851536, 0.018408459368776674, 0.6882823691724065, 0.04136776013377592, 0.7389817333851536, 0.01840845936877666], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753610042704491, 0.7771043642690278, 0.8040589927591285, 0.7997604845520727, 0.9214285612106323, 0.7699999809265137, 0.7857833504676819, 0.9142857193946838, 0.765999972820282, 0.7843326926231384, 0.7949475320637387, 0.009873886985278149, 0.7774964836974675, 0.022492824322406058, 0.7949475320637387, 0.009873886985278128], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7863530317328681, 0.7775986975762487, 0.7938566012191741, 0.787595303150568, 0.9357143044471741, 0.8059999942779541, 0.7973887920379639, 0.9357143044471741, 0.8059999942779541, 0.7964216470718384, 0.8082394092499028, 0.019793919761462237, 0.7832866992649055, 0.040887736916491196, 0.8082394092499028, 0.019793919761462237], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592503806943292, 0.7522511529785001, 0.7700924282303974, 0.7602141596211042, 0.9642857313156128, 0.7879999876022339, 0.7819148898124695, 0.9642857313156128, 0.7879999876022339, 0.7833655476570129, 0.7889623008161678, 0.014103279819717639, 0.7572947433924954, 0.023934795252537947, 0.7889623008161679, 0.014103279819717644]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6917
Epoch=002, loss=0.6874
Epoch=003, loss=0.6776
Epoch=004, loss=0.6731
Epoch=005, loss=0.6567
Epoch=006, loss=0.6486
Epoch=007, loss=0.6293
Epoch=008, loss=0.6077
Epoch=009, loss=0.5922
Epoch=010, loss=0.5578
Epoch=011, loss=0.5289
Epoch=012, loss=0.5105
Epoch=013, loss=0.4816
Epoch=014, loss=0.4318
Epoch=015, loss=0.4123
Epoch=016, loss=0.3892
Epoch=017, loss=0.3484
Epoch=018, loss=0.3167
Epoch=019, loss=0.2982
Epoch=020, loss=0.2796
Epoch=021, loss=0.2363
Epoch=022, loss=0.2306
Epoch=023, loss=0.2199
Epoch=024, loss=0.1986
Epoch=025, loss=0.1800
Epoch=026, loss=0.1737
Epoch=027, loss=0.1675
Epoch=028, loss=0.1491
Epoch=029, loss=0.1396
Epoch=030, loss=0.1272
Epoch=031, loss=0.1165
Epoch=032, loss=0.1089
Epoch=033, loss=0.1042
Epoch=034, loss=0.1118
Epoch=035, loss=0.0868
Epoch=036, loss=0.0838
Epoch=037, loss=0.0744
Epoch=038, loss=0.0742
Epoch=039, loss=0.0724
Epoch=040, loss=0.0850
Epoch=041, loss=0.0666
Epoch=042, loss=0.0665
Epoch=043, loss=0.0595
Epoch=044, loss=0.0488
Epoch=045, loss=0.0569
Epoch=046, loss=0.0600
Epoch=047, loss=0.0698
Epoch=048, loss=0.0544
Epoch=049, loss=0.0477
Epoch=050, loss=0.0527
Epoch=051, loss=0.0442
Epoch=052, loss=0.0498
Epoch=053, loss=0.0453
Epoch=054, loss=0.0417
Epoch=055, loss=0.0337
Epoch=056, loss=0.0340
Epoch=057, loss=0.0359
Epoch=058, loss=0.0324
Epoch=059, loss=0.0326
Epoch=060, loss=0.0313
Epoch=061, loss=0.0316
Epoch=062, loss=0.0286
Epoch=063, loss=0.0322
Epoch=064, loss=0.0200
Epoch=065, loss=0.0328
Epoch=066, loss=0.0225
Epoch=067, loss=0.0260
Epoch=068, loss=0.0253
Epoch=069, loss=0.0169
Epoch=070, loss=0.0247
Epoch=071, loss=0.0210
Epoch=072, loss=0.0218
Epoch=073, loss=0.0282
Epoch=074, loss=0.0264
Epoch=075, loss=0.0344
Epoch=076, loss=0.0118
Epoch=077, loss=0.0135
Epoch=078, loss=0.0161
Epoch=079, loss=0.0182
Epoch=080, loss=0.0201
Epoch=081, loss=0.0179
Epoch=082, loss=0.0179
Epoch=083, loss=0.0131
Epoch=084, loss=0.0164
Epoch=085, loss=0.0120
Epoch=086, loss=0.0146
Epoch=087, loss=0.0103
Epoch=088, loss=0.0140
Epoch=089, loss=0.0181
Epoch=090, loss=0.0153
Epoch=091, loss=0.0102
Epoch=092, loss=0.0161
Epoch=093, loss=0.0110
Epoch=094, loss=0.0112
Epoch=095, loss=0.0084
Epoch=096, loss=0.0237
Epoch=097, loss=0.0092
Epoch=098, loss=0.0168
Epoch=099, loss=0.0107
Epoch=100, loss=0.0133
Epoch=101, loss=0.0094
Epoch=102, loss=0.0105
Epoch=103, loss=0.0098
Epoch=104, loss=0.0089
Epoch=105, loss=0.0156
Epoch=106, loss=0.0090
Epoch=107, loss=0.0101
Epoch=108, loss=0.0116
Epoch=109, loss=0.0098
Epoch=110, loss=0.0074
Epoch=111, loss=0.0099
Epoch=112, loss=0.0071
Epoch=113, loss=0.0131
Epoch=114, loss=0.0100
Epoch=115, loss=0.0083
Epoch=116, loss=0.0113
Epoch=117, loss=0.0076
Epoch=118, loss=0.0172
Epoch=119, loss=0.0097
Epoch=120, loss=0.0093
Epoch=121, loss=0.0080
Epoch=122, loss=0.0083
Epoch=123, loss=0.0072
Epoch=124, loss=0.0126
Epoch=125, loss=0.0084
Epoch=126, loss=0.0081
Epoch=127, loss=0.0126
Epoch=128, loss=0.0057
Epoch=129, loss=0.0071
Epoch=130, loss=0.0071
Epoch=131, loss=0.0044
Epoch=132, loss=0.0063
Epoch=133, loss=0.0054
Epoch=134, loss=0.0069
Epoch=135, loss=0.0087
Epoch=136, loss=0.0074
Epoch=137, loss=0.0107
Epoch=138, loss=0.0068
Epoch=139, loss=0.0061
Epoch=140, loss=0.0033
Epoch=141, loss=0.0058
Epoch=142, loss=0.0042
Epoch=143, loss=0.0045
Epoch=144, loss=0.0040
Epoch=145, loss=0.0080
Epoch=146, loss=0.0065
Epoch=147, loss=0.0042
Epoch=148, loss=0.0076
Epoch=149, loss=0.0045
Epoch=150, loss=0.0062
Epoch=151, loss=0.0024
Epoch=152, loss=0.0110
Epoch=153, loss=0.0051
Epoch=154, loss=0.0052
Epoch=155, loss=0.0055
Epoch=156, loss=0.0072
Epoch=157, loss=0.0071
Epoch=158, loss=0.0050
Epoch=159, loss=0.0033
Epoch=160, loss=0.0040
Epoch=161, loss=0.0088
Epoch=162, loss=0.0044
Epoch=163, loss=0.0067
Epoch=164, loss=0.0033
Epoch=165, loss=0.0115
Epoch=166, loss=0.0071
Epoch=167, loss=0.0053
Epoch=168, loss=0.0042
Epoch=169, loss=0.0042
Epoch=170, loss=0.0057
Epoch=171, loss=0.0042
Early stopping!
Loading 151th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8047+-0.0175, F1Ma=0.7848+-0.0199, acc=0.8047+-0.0175
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753275420928378, 0.7752342760324589, 0.7892909994995121, 0.7860557203583749, 0.7785714268684387, 0.6940000057220459, 0.7151837348937988, 0.7857142686843872, 0.6980000138282776, 0.7127659320831299, 0.7270890011659542, 0.014664883171623256, 0.6451213801111263, 0.022259000335184628, 0.7270890011659542, 0.014664883171623252], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7884130656597431, 0.7823462790408146, 0.8040859975011612, 0.7946910950163584, 0.8785714507102966, 0.722000002861023, 0.7263056039810181, 0.8714285492897034, 0.7200000286102295, 0.7282398343086243, 0.7389817333851536, 0.018408459368776674, 0.6882823691724065, 0.04136776013377592, 0.7389817333851536, 0.01840845936877666], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7753610042704491, 0.7771043642690278, 0.8040589927591285, 0.7997604845520727, 0.9214285612106323, 0.7699999809265137, 0.7857833504676819, 0.9142857193946838, 0.765999972820282, 0.7843326926231384, 0.7949475320637387, 0.009873886985278149, 0.7774964836974675, 0.022492824322406058, 0.7949475320637387, 0.009873886985278128], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7863530317328681, 0.7775986975762487, 0.7938566012191741, 0.787595303150568, 0.9357143044471741, 0.8059999942779541, 0.7973887920379639, 0.9357143044471741, 0.8059999942779541, 0.7964216470718384, 0.8082394092499028, 0.019793919761462237, 0.7832866992649055, 0.040887736916491196, 0.8082394092499028, 0.019793919761462237], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592503806943292, 0.7522511529785001, 0.7700924282303974, 0.7602141596211042, 0.9642857313156128, 0.7879999876022339, 0.7819148898124695, 0.9642857313156128, 0.7879999876022339, 0.7833655476570129, 0.7889623008161678, 0.014103279819717639, 0.7572947433924954, 0.023934795252537947, 0.7889623008161679, 0.014103279819717644], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9066306695056892, 0.8968110286488412, 0.9000320456272122, 0.8889428852971933, 0.9642857313156128, 0.8059999942779541, 0.7896518111228943, 0.9642857313156128, 0.8059999942779541, 0.7891682982444763, 0.8047415468324912, 0.017472203057843035, 0.7847638354059469, 0.019923281197215897, 0.8047415468324912, 0.017472203057843014]]
