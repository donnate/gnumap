My SLURM_ARRAY_TASK_ID:  5
My SLURM_ARRAY_JOB_ID:  4522273
DGI
Cora
result file is 4522273_5
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522273_5.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6929
Epoch=010, loss=0.6928
Epoch=011, loss=0.6928
Epoch=012, loss=0.6927
Epoch=013, loss=0.6927
Epoch=014, loss=0.6926
Epoch=015, loss=0.6926
Epoch=016, loss=0.6925
Epoch=017, loss=0.6924
Epoch=018, loss=0.6924
Epoch=019, loss=0.6923
Epoch=020, loss=0.6922
Epoch=021, loss=0.6921
Epoch=022, loss=0.6920
Epoch=023, loss=0.6919
Epoch=024, loss=0.6918
Epoch=025, loss=0.6916
Epoch=026, loss=0.6915
Epoch=027, loss=0.6914
Epoch=028, loss=0.6912
Epoch=029, loss=0.6911
Epoch=030, loss=0.6909
Epoch=031, loss=0.6908
Epoch=032, loss=0.6905
Epoch=033, loss=0.6904
Epoch=034, loss=0.6901
Epoch=035, loss=0.6900
Epoch=036, loss=0.6897
Epoch=037, loss=0.6895
Epoch=038, loss=0.6892
Epoch=039, loss=0.6890
Epoch=040, loss=0.6887
Epoch=041, loss=0.6884
Epoch=042, loss=0.6879
Epoch=043, loss=0.6877
Epoch=044, loss=0.6873
Epoch=045, loss=0.6869
Epoch=046, loss=0.6865
Epoch=047, loss=0.6861
Epoch=048, loss=0.6856
Epoch=049, loss=0.6851
Epoch=050, loss=0.6845
Epoch=051, loss=0.6843
Epoch=052, loss=0.6836
Epoch=053, loss=0.6832
Epoch=054, loss=0.6823
Epoch=055, loss=0.6819
Epoch=056, loss=0.6809
Epoch=057, loss=0.6804
Epoch=058, loss=0.6798
Epoch=059, loss=0.6790
Epoch=060, loss=0.6785
Epoch=061, loss=0.6776
Epoch=062, loss=0.6765
Epoch=063, loss=0.6755
Epoch=064, loss=0.6746
Epoch=065, loss=0.6737
Epoch=066, loss=0.6730
Epoch=067, loss=0.6722
Epoch=068, loss=0.6703
Epoch=069, loss=0.6693
Epoch=070, loss=0.6688
Epoch=071, loss=0.6673
Epoch=072, loss=0.6662
Epoch=073, loss=0.6644
Epoch=074, loss=0.6633
Epoch=075, loss=0.6615
Epoch=076, loss=0.6612
Epoch=077, loss=0.6593
Epoch=078, loss=0.6572
Epoch=079, loss=0.6557
Epoch=080, loss=0.6538
Epoch=081, loss=0.6526
Epoch=082, loss=0.6512
Epoch=083, loss=0.6497
Epoch=084, loss=0.6469
Epoch=085, loss=0.6455
Epoch=086, loss=0.6438
Epoch=087, loss=0.6423
Epoch=088, loss=0.6402
Epoch=089, loss=0.6379
Epoch=090, loss=0.6359
Epoch=091, loss=0.6343
Epoch=092, loss=0.6318
Epoch=093, loss=0.6291
Epoch=094, loss=0.6246
Epoch=095, loss=0.6244
Epoch=096, loss=0.6207
Epoch=097, loss=0.6201
Epoch=098, loss=0.6164
Epoch=099, loss=0.6138
Epoch=100, loss=0.6121
Epoch=101, loss=0.6077
Epoch=102, loss=0.6051
Epoch=103, loss=0.6051
Epoch=104, loss=0.6001
Epoch=105, loss=0.5970
Epoch=106, loss=0.5947
Epoch=107, loss=0.5914
Epoch=108, loss=0.5891
Epoch=109, loss=0.5862
Epoch=110, loss=0.5828
Epoch=111, loss=0.5812
Epoch=112, loss=0.5771
Epoch=113, loss=0.5711
Epoch=114, loss=0.5728
Epoch=115, loss=0.5680
Epoch=116, loss=0.5636
Epoch=117, loss=0.5579
Epoch=118, loss=0.5554
Epoch=119, loss=0.5530
Epoch=120, loss=0.5477
Epoch=121, loss=0.5458
Epoch=122, loss=0.5393
Epoch=123, loss=0.5371
Epoch=124, loss=0.5325
Epoch=125, loss=0.5281
Epoch=126, loss=0.5272
Epoch=127, loss=0.5224
Epoch=128, loss=0.5182
Epoch=129, loss=0.5163
Epoch=130, loss=0.5125
Epoch=131, loss=0.5066
Epoch=132, loss=0.5018
Epoch=133, loss=0.4953
Epoch=134, loss=0.4923
Epoch=135, loss=0.4876
Epoch=136, loss=0.4899
Epoch=137, loss=0.4849
Epoch=138, loss=0.4802
Epoch=139, loss=0.4721
Epoch=140, loss=0.4721
Epoch=141, loss=0.4690
Epoch=142, loss=0.4616
Epoch=143, loss=0.4579
Epoch=144, loss=0.4576
Epoch=145, loss=0.4515
Epoch=146, loss=0.4484
Epoch=147, loss=0.4413
Epoch=148, loss=0.4392
Epoch=149, loss=0.4357
Epoch=150, loss=0.4330
Epoch=151, loss=0.4292
Epoch=152, loss=0.4253
Epoch=153, loss=0.4187
Epoch=154, loss=0.4198
Epoch=155, loss=0.4103
Epoch=156, loss=0.4099
Epoch=157, loss=0.4031
Epoch=158, loss=0.4016
Epoch=159, loss=0.3926
Epoch=160, loss=0.3944
Epoch=161, loss=0.3820
Epoch=162, loss=0.3801
Epoch=163, loss=0.3825
Epoch=164, loss=0.3680
Epoch=165, loss=0.3727
Epoch=166, loss=0.3715
Epoch=167, loss=0.3636
Epoch=168, loss=0.3604
Epoch=169, loss=0.3561
Epoch=170, loss=0.3497
Epoch=171, loss=0.3519
Epoch=172, loss=0.3456
Epoch=173, loss=0.3435
Epoch=174, loss=0.3418
Epoch=175, loss=0.3430
Epoch=176, loss=0.3396
Epoch=177, loss=0.3367
Epoch=178, loss=0.3290
Epoch=179, loss=0.3232
Epoch=180, loss=0.3151
Epoch=181, loss=0.3216
Epoch=182, loss=0.3121
Epoch=183, loss=0.3050
Epoch=184, loss=0.3175
Epoch=185, loss=0.3058
Epoch=186, loss=0.3055
Epoch=187, loss=0.2993
Epoch=188, loss=0.3001
Epoch=189, loss=0.3005
Epoch=190, loss=0.2866
Epoch=191, loss=0.2865
Epoch=192, loss=0.2808
Epoch=193, loss=0.2921
Epoch=194, loss=0.2788
Epoch=195, loss=0.2796
Epoch=196, loss=0.2768
Epoch=197, loss=0.2732
Epoch=198, loss=0.2591
Epoch=199, loss=0.2744
Epoch=200, loss=0.2620
Epoch=201, loss=0.2567
Epoch=202, loss=0.2557
Epoch=203, loss=0.2575
Epoch=204, loss=0.2595
Epoch=205, loss=0.2497
Epoch=206, loss=0.2461
Epoch=207, loss=0.2495
Epoch=208, loss=0.2429
Epoch=209, loss=0.2384
Epoch=210, loss=0.2382
Epoch=211, loss=0.2327
Epoch=212, loss=0.2492
Epoch=213, loss=0.2360
Epoch=214, loss=0.2316
Epoch=215, loss=0.2232
Epoch=216, loss=0.2304
Epoch=217, loss=0.2277
Epoch=218, loss=0.2247
Epoch=219, loss=0.2175
Epoch=220, loss=0.2158
Epoch=221, loss=0.2150
Epoch=222, loss=0.2170
Epoch=223, loss=0.2133
Epoch=224, loss=0.2068
Epoch=225, loss=0.2095
Epoch=226, loss=0.2042
Epoch=227, loss=0.2108
Epoch=228, loss=0.2082
Epoch=229, loss=0.2006
Epoch=230, loss=0.2058
Epoch=231, loss=0.1994
Epoch=232, loss=0.2005
Epoch=233, loss=0.2066
Epoch=234, loss=0.1957
Epoch=235, loss=0.1903
Epoch=236, loss=0.1926
Epoch=237, loss=0.2016
Epoch=238, loss=0.1865
Epoch=239, loss=0.1822
Epoch=240, loss=0.1866
Epoch=241, loss=0.1839
Epoch=242, loss=0.1725
Epoch=243, loss=0.1787
Epoch=244, loss=0.1791
Epoch=245, loss=0.1765
Epoch=246, loss=0.1739
Epoch=247, loss=0.1771
Epoch=248, loss=0.1760
Epoch=249, loss=0.1714
Epoch=250, loss=0.1723
Epoch=251, loss=0.1724
Epoch=252, loss=0.1620
Epoch=253, loss=0.1626
Epoch=254, loss=0.1663
Epoch=255, loss=0.1677
Epoch=256, loss=0.1693
Epoch=257, loss=0.1666
Epoch=258, loss=0.1614
Epoch=259, loss=0.1598
Epoch=260, loss=0.1669
Epoch=261, loss=0.1590
Epoch=262, loss=0.1527
Epoch=263, loss=0.1616
Epoch=264, loss=0.1526
Epoch=265, loss=0.1553
Epoch=266, loss=0.1522
Epoch=267, loss=0.1554
Epoch=268, loss=0.1585
Epoch=269, loss=0.1514
Epoch=270, loss=0.1527
Epoch=271, loss=0.1460
Epoch=272, loss=0.1453
Epoch=273, loss=0.1444
Epoch=274, loss=0.1499
Epoch=275, loss=0.1319
Epoch=276, loss=0.1404
Epoch=277, loss=0.1418
Epoch=278, loss=0.1384
Epoch=279, loss=0.1403
Epoch=280, loss=0.1379
Epoch=281, loss=0.1337
Epoch=282, loss=0.1477
Epoch=283, loss=0.1408
Epoch=284, loss=0.1467
Epoch=285, loss=0.1394
Epoch=286, loss=0.1357
Epoch=287, loss=0.1360
Epoch=288, loss=0.1379
Epoch=289, loss=0.1328
Epoch=290, loss=0.1318
Epoch=291, loss=0.1287
Epoch=292, loss=0.1339
Epoch=293, loss=0.1288
Epoch=294, loss=0.1236
Epoch=295, loss=0.1317
Epoch=296, loss=0.1317
Epoch=297, loss=0.1324
Epoch=298, loss=0.1203
Epoch=299, loss=0.1298
Epoch=300, loss=0.1322
Epoch=301, loss=0.1238
Epoch=302, loss=0.1292
Epoch=303, loss=0.1348
Epoch=304, loss=0.1185
Epoch=305, loss=0.1217
Epoch=306, loss=0.1243
Epoch=307, loss=0.1147
Epoch=308, loss=0.1126
Epoch=309, loss=0.1230
Epoch=310, loss=0.1307
Epoch=311, loss=0.1177
Epoch=312, loss=0.1232
Epoch=313, loss=0.1108
Epoch=314, loss=0.1173
Epoch=315, loss=0.1090
Epoch=316, loss=0.1118
Epoch=317, loss=0.1031
Epoch=318, loss=0.1167
Epoch=319, loss=0.1143
Epoch=320, loss=0.1315
Epoch=321, loss=0.1158
Epoch=322, loss=0.1125
Epoch=323, loss=0.1108
Epoch=324, loss=0.1070
Epoch=325, loss=0.1056
Epoch=326, loss=0.1059
Epoch=327, loss=0.1128
Epoch=328, loss=0.1114
Epoch=329, loss=0.1071
Epoch=330, loss=0.1167
Epoch=331, loss=0.1138
Epoch=332, loss=0.1018
Epoch=333, loss=0.0984
Epoch=334, loss=0.1040
Epoch=335, loss=0.1116
Epoch=336, loss=0.1099
Epoch=337, loss=0.0997
Epoch=338, loss=0.0988
Epoch=339, loss=0.1036
Epoch=340, loss=0.1071
Epoch=341, loss=0.0997
Epoch=342, loss=0.0992
Epoch=343, loss=0.1010
Epoch=344, loss=0.1103
Epoch=345, loss=0.0928
Epoch=346, loss=0.1019
Epoch=347, loss=0.1092
Epoch=348, loss=0.0926
Epoch=349, loss=0.1019
Epoch=350, loss=0.0926
Epoch=351, loss=0.0867
Epoch=352, loss=0.0926
Epoch=353, loss=0.0936
Epoch=354, loss=0.0939
Epoch=355, loss=0.1114
Epoch=356, loss=0.0942
Epoch=357, loss=0.0931
Epoch=358, loss=0.0908
Epoch=359, loss=0.0983
Epoch=360, loss=0.0962
Epoch=361, loss=0.0947
Epoch=362, loss=0.0956
Epoch=363, loss=0.0960
Epoch=364, loss=0.0980
Epoch=365, loss=0.0869
Epoch=366, loss=0.0984
Epoch=367, loss=0.0939
Epoch=368, loss=0.0979
Epoch=369, loss=0.0827
Epoch=370, loss=0.1004
Epoch=371, loss=0.0889
Epoch=372, loss=0.0885
Epoch=373, loss=0.0888
Epoch=374, loss=0.0990
Epoch=375, loss=0.0910
Epoch=376, loss=0.0908
Epoch=377, loss=0.0846
Epoch=378, loss=0.0915
Epoch=379, loss=0.0962
Epoch=380, loss=0.0895
Epoch=381, loss=0.0871
Epoch=382, loss=0.0837
Epoch=383, loss=0.0808
Epoch=384, loss=0.0870
Epoch=385, loss=0.0814
Epoch=386, loss=0.0936
Epoch=387, loss=0.0830
Epoch=388, loss=0.0918
Epoch=389, loss=0.0918
Epoch=390, loss=0.0852
Epoch=391, loss=0.0874
Epoch=392, loss=0.0843
Epoch=393, loss=0.0875
Epoch=394, loss=0.0940
Epoch=395, loss=0.0831
Epoch=396, loss=0.0798
Epoch=397, loss=0.0842
Epoch=398, loss=0.0777
Epoch=399, loss=0.0735
Epoch=400, loss=0.0885
Epoch=401, loss=0.0819
Epoch=402, loss=0.0809
Epoch=403, loss=0.0788
Epoch=404, loss=0.0873
Epoch=405, loss=0.0823
Epoch=406, loss=0.0731
Epoch=407, loss=0.0742
Epoch=408, loss=0.0804
Epoch=409, loss=0.0771
Epoch=410, loss=0.0819
Epoch=411, loss=0.0830
Epoch=412, loss=0.0858
Epoch=413, loss=0.0849
Epoch=414, loss=0.0795
Epoch=415, loss=0.0764
Epoch=416, loss=0.0722
Epoch=417, loss=0.0782
Epoch=418, loss=0.0758
Epoch=419, loss=0.0760
Epoch=420, loss=0.0819
Epoch=421, loss=0.0754
Epoch=422, loss=0.0824
Epoch=423, loss=0.0935
Epoch=424, loss=0.0895
Epoch=425, loss=0.0805
Epoch=426, loss=0.0733
Epoch=427, loss=0.0807
Epoch=428, loss=0.0808
Epoch=429, loss=0.0681
Epoch=430, loss=0.0718
Epoch=431, loss=0.0709
Epoch=432, loss=0.0708
Epoch=433, loss=0.0720
Epoch=434, loss=0.0784
Epoch=435, loss=0.0675
Epoch=436, loss=0.0771
Epoch=437, loss=0.0698
Epoch=438, loss=0.0738
Epoch=439, loss=0.0660
Epoch=440, loss=0.0794
Epoch=441, loss=0.0740
Epoch=442, loss=0.0730
Epoch=443, loss=0.0825
Epoch=444, loss=0.0727
Epoch=445, loss=0.0655
Epoch=446, loss=0.0735
Epoch=447, loss=0.0678
Epoch=448, loss=0.0658
Epoch=449, loss=0.0755
Epoch=450, loss=0.0718
Epoch=451, loss=0.0647
Epoch=452, loss=0.0772
Epoch=453, loss=0.0672
Epoch=454, loss=0.0742
Epoch=455, loss=0.0717
Epoch=456, loss=0.0656
Epoch=457, loss=0.0639
Epoch=458, loss=0.0738
Epoch=459, loss=0.0758
Epoch=460, loss=0.0680
Epoch=461, loss=0.0662
Epoch=462, loss=0.0662
Epoch=463, loss=0.0721
Epoch=464, loss=0.0752
Epoch=465, loss=0.0639
Epoch=466, loss=0.0627
Epoch=467, loss=0.0651
Epoch=468, loss=0.0770
Epoch=469, loss=0.0646
Epoch=470, loss=0.0668
Epoch=471, loss=0.0794
Epoch=472, loss=0.0704
Epoch=473, loss=0.0645
Epoch=474, loss=0.0734
Epoch=475, loss=0.0602
Epoch=476, loss=0.0620
Epoch=477, loss=0.0653
Epoch=478, loss=0.0729
Epoch=479, loss=0.0641
Epoch=480, loss=0.0781
Epoch=481, loss=0.0753
Epoch=482, loss=0.0684
Epoch=483, loss=0.0770
Epoch=484, loss=0.0620
Epoch=485, loss=0.0651
Epoch=486, loss=0.0621
Epoch=487, loss=0.0673
Epoch=488, loss=0.0659
Epoch=489, loss=0.0585
Epoch=490, loss=0.0664
Epoch=491, loss=0.0675
Epoch=492, loss=0.0581
Epoch=493, loss=0.0652
Epoch=494, loss=0.0656
Epoch=495, loss=0.0625
Epoch=496, loss=0.0674
Epoch=497, loss=0.0707
Epoch=498, loss=0.0644
Epoch=499, loss=0.0655
Loading 492th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
