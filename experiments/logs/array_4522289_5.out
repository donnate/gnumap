My SLURM_ARRAY_TASK_ID:  5
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_5
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_5.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6929
Epoch=010, loss=0.6928
Epoch=011, loss=0.6928
Epoch=012, loss=0.6927
Epoch=013, loss=0.6927
Epoch=014, loss=0.6926
Epoch=015, loss=0.6926
Epoch=016, loss=0.6925
Epoch=017, loss=0.6924
Epoch=018, loss=0.6924
Epoch=019, loss=0.6923
Epoch=020, loss=0.6922
Epoch=021, loss=0.6921
Epoch=022, loss=0.6920
Epoch=023, loss=0.6919
Epoch=024, loss=0.6918
Epoch=025, loss=0.6916
Epoch=026, loss=0.6915
Epoch=027, loss=0.6914
Epoch=028, loss=0.6912
Epoch=029, loss=0.6911
Epoch=030, loss=0.6909
Epoch=031, loss=0.6908
Epoch=032, loss=0.6905
Epoch=033, loss=0.6904
Epoch=034, loss=0.6901
Epoch=035, loss=0.6900
Epoch=036, loss=0.6897
Epoch=037, loss=0.6895
Epoch=038, loss=0.6892
Epoch=039, loss=0.6890
Epoch=040, loss=0.6887
Epoch=041, loss=0.6884
Epoch=042, loss=0.6879
Epoch=043, loss=0.6877
Epoch=044, loss=0.6873
Epoch=045, loss=0.6869
Epoch=046, loss=0.6865
Epoch=047, loss=0.6861
Epoch=048, loss=0.6856
Epoch=049, loss=0.6851
Epoch=050, loss=0.6845
Epoch=051, loss=0.6843
Epoch=052, loss=0.6836
Epoch=053, loss=0.6832
Epoch=054, loss=0.6823
Epoch=055, loss=0.6819
Epoch=056, loss=0.6809
Epoch=057, loss=0.6804
Epoch=058, loss=0.6798
Epoch=059, loss=0.6790
Epoch=060, loss=0.6785
Epoch=061, loss=0.6776
Epoch=062, loss=0.6765
Epoch=063, loss=0.6755
Epoch=064, loss=0.6746
Epoch=065, loss=0.6737
Epoch=066, loss=0.6730
Epoch=067, loss=0.6722
Epoch=068, loss=0.6703
Epoch=069, loss=0.6693
Epoch=070, loss=0.6688
Epoch=071, loss=0.6673
Epoch=072, loss=0.6662
Epoch=073, loss=0.6644
Epoch=074, loss=0.6633
Epoch=075, loss=0.6615
Epoch=076, loss=0.6612
Epoch=077, loss=0.6593
Epoch=078, loss=0.6572
Epoch=079, loss=0.6557
Epoch=080, loss=0.6538
Epoch=081, loss=0.6526
Epoch=082, loss=0.6512
Epoch=083, loss=0.6497
Epoch=084, loss=0.6469
Epoch=085, loss=0.6455
Epoch=086, loss=0.6438
Epoch=087, loss=0.6423
Epoch=088, loss=0.6402
Epoch=089, loss=0.6379
Epoch=090, loss=0.6359
Epoch=091, loss=0.6343
Epoch=092, loss=0.6318
Epoch=093, loss=0.6291
Epoch=094, loss=0.6246
Epoch=095, loss=0.6244
Epoch=096, loss=0.6207
Epoch=097, loss=0.6201
Epoch=098, loss=0.6164
Epoch=099, loss=0.6138
Epoch=100, loss=0.6121
Epoch=101, loss=0.6077
Epoch=102, loss=0.6051
Epoch=103, loss=0.6051
Epoch=104, loss=0.6001
Epoch=105, loss=0.5970
Epoch=106, loss=0.5947
Epoch=107, loss=0.5914
Epoch=108, loss=0.5891
Epoch=109, loss=0.5862
Epoch=110, loss=0.5828
Epoch=111, loss=0.5812
Epoch=112, loss=0.5771
Epoch=113, loss=0.5711
Epoch=114, loss=0.5728
Epoch=115, loss=0.5680
Epoch=116, loss=0.5636
Epoch=117, loss=0.5579
Epoch=118, loss=0.5554
Epoch=119, loss=0.5530
Epoch=120, loss=0.5477
Epoch=121, loss=0.5458
Epoch=122, loss=0.5393
Epoch=123, loss=0.5371
Epoch=124, loss=0.5325
Epoch=125, loss=0.5281
Epoch=126, loss=0.5272
Epoch=127, loss=0.5224
Epoch=128, loss=0.5182
Epoch=129, loss=0.5163
Epoch=130, loss=0.5125
Epoch=131, loss=0.5066
Epoch=132, loss=0.5018
Epoch=133, loss=0.4953
Epoch=134, loss=0.4923
Epoch=135, loss=0.4876
Epoch=136, loss=0.4899
Epoch=137, loss=0.4849
Epoch=138, loss=0.4802
Epoch=139, loss=0.4721
Epoch=140, loss=0.4721
Epoch=141, loss=0.4690
Epoch=142, loss=0.4616
Epoch=143, loss=0.4579
Epoch=144, loss=0.4576
Epoch=145, loss=0.4515
Epoch=146, loss=0.4484
Epoch=147, loss=0.4413
Epoch=148, loss=0.4392
Epoch=149, loss=0.4357
Epoch=150, loss=0.4330
Epoch=151, loss=0.4292
Epoch=152, loss=0.4253
Epoch=153, loss=0.4187
Epoch=154, loss=0.4198
Epoch=155, loss=0.4103
Epoch=156, loss=0.4099
Epoch=157, loss=0.4031
Epoch=158, loss=0.4016
Epoch=159, loss=0.3926
Epoch=160, loss=0.3944
Epoch=161, loss=0.3820
Epoch=162, loss=0.3801
Epoch=163, loss=0.3825
Epoch=164, loss=0.3680
Epoch=165, loss=0.3727
Epoch=166, loss=0.3715
Epoch=167, loss=0.3636
Epoch=168, loss=0.3604
Epoch=169, loss=0.3561
Epoch=170, loss=0.3497
Epoch=171, loss=0.3519
Epoch=172, loss=0.3456
Epoch=173, loss=0.3435
Epoch=174, loss=0.3418
Epoch=175, loss=0.3430
Epoch=176, loss=0.3396
Epoch=177, loss=0.3367
Epoch=178, loss=0.3290
Epoch=179, loss=0.3232
Epoch=180, loss=0.3151
Epoch=181, loss=0.3216
Epoch=182, loss=0.3121
Epoch=183, loss=0.3050
Epoch=184, loss=0.3175
Epoch=185, loss=0.3058
Epoch=186, loss=0.3055
Epoch=187, loss=0.2993
Epoch=188, loss=0.3001
Epoch=189, loss=0.3005
Epoch=190, loss=0.2866
Epoch=191, loss=0.2865
Epoch=192, loss=0.2808
Epoch=193, loss=0.2921
Epoch=194, loss=0.2788
Epoch=195, loss=0.2796
Epoch=196, loss=0.2768
Epoch=197, loss=0.2732
Epoch=198, loss=0.2591
Epoch=199, loss=0.2744
Epoch=200, loss=0.2620
Epoch=201, loss=0.2567
Epoch=202, loss=0.2557
Epoch=203, loss=0.2575
Epoch=204, loss=0.2595
Epoch=205, loss=0.2497
Epoch=206, loss=0.2461
Epoch=207, loss=0.2495
Epoch=208, loss=0.2429
Epoch=209, loss=0.2384
Epoch=210, loss=0.2382
Epoch=211, loss=0.2327
Epoch=212, loss=0.2492
Epoch=213, loss=0.2360
Epoch=214, loss=0.2316
Epoch=215, loss=0.2232
Epoch=216, loss=0.2304
Epoch=217, loss=0.2277
Epoch=218, loss=0.2247
Epoch=219, loss=0.2175
Epoch=220, loss=0.2158
Epoch=221, loss=0.2150
Epoch=222, loss=0.2170
Epoch=223, loss=0.2133
Epoch=224, loss=0.2068
Epoch=225, loss=0.2095
Epoch=226, loss=0.2042
Epoch=227, loss=0.2108
Epoch=228, loss=0.2082
Epoch=229, loss=0.2006
Epoch=230, loss=0.2058
Epoch=231, loss=0.1994
Epoch=232, loss=0.2005
Epoch=233, loss=0.2066
Epoch=234, loss=0.1957
Epoch=235, loss=0.1903
Epoch=236, loss=0.1926
Epoch=237, loss=0.2016
Epoch=238, loss=0.1865
Epoch=239, loss=0.1822
Epoch=240, loss=0.1866
Epoch=241, loss=0.1839
Epoch=242, loss=0.1725
Epoch=243, loss=0.1787
Epoch=244, loss=0.1791
Epoch=245, loss=0.1765
Epoch=246, loss=0.1739
Epoch=247, loss=0.1771
Epoch=248, loss=0.1760
Epoch=249, loss=0.1714
Epoch=250, loss=0.1723
Epoch=251, loss=0.1724
Epoch=252, loss=0.1620
Epoch=253, loss=0.1626
Epoch=254, loss=0.1663
Epoch=255, loss=0.1677
Epoch=256, loss=0.1693
Epoch=257, loss=0.1666
Epoch=258, loss=0.1614
Epoch=259, loss=0.1598
Epoch=260, loss=0.1669
Epoch=261, loss=0.1590
Epoch=262, loss=0.1527
Epoch=263, loss=0.1616
Epoch=264, loss=0.1526
Epoch=265, loss=0.1553
Epoch=266, loss=0.1522
Epoch=267, loss=0.1554
Epoch=268, loss=0.1585
Epoch=269, loss=0.1514
Epoch=270, loss=0.1527
Epoch=271, loss=0.1460
Epoch=272, loss=0.1453
Epoch=273, loss=0.1444
Epoch=274, loss=0.1499
Epoch=275, loss=0.1319
Epoch=276, loss=0.1404
Epoch=277, loss=0.1418
Epoch=278, loss=0.1384
Epoch=279, loss=0.1403
Epoch=280, loss=0.1379
Epoch=281, loss=0.1337
Epoch=282, loss=0.1477
Epoch=283, loss=0.1408
Epoch=284, loss=0.1467
Epoch=285, loss=0.1394
Epoch=286, loss=0.1357
Epoch=287, loss=0.1360
Epoch=288, loss=0.1379
Epoch=289, loss=0.1328
Epoch=290, loss=0.1318
Epoch=291, loss=0.1287
Epoch=292, loss=0.1339
Epoch=293, loss=0.1288
Epoch=294, loss=0.1236
Epoch=295, loss=0.1317
Epoch=296, loss=0.1317
Epoch=297, loss=0.1324
Epoch=298, loss=0.1203
Epoch=299, loss=0.1298
Epoch=300, loss=0.1322
Epoch=301, loss=0.1238
Epoch=302, loss=0.1292
Epoch=303, loss=0.1348
Epoch=304, loss=0.1185
Epoch=305, loss=0.1217
Epoch=306, loss=0.1243
Epoch=307, loss=0.1147
Epoch=308, loss=0.1126
Epoch=309, loss=0.1230
Epoch=310, loss=0.1307
Epoch=311, loss=0.1177
Epoch=312, loss=0.1232
Epoch=313, loss=0.1108
Epoch=314, loss=0.1173
Epoch=315, loss=0.1090
Epoch=316, loss=0.1118
Epoch=317, loss=0.1031
Epoch=318, loss=0.1167
Epoch=319, loss=0.1143
Epoch=320, loss=0.1315
Epoch=321, loss=0.1158
Epoch=322, loss=0.1125
Epoch=323, loss=0.1108
Epoch=324, loss=0.1070
Epoch=325, loss=0.1056
Epoch=326, loss=0.1059
Epoch=327, loss=0.1128
Epoch=328, loss=0.1114
Epoch=329, loss=0.1071
Epoch=330, loss=0.1167
Epoch=331, loss=0.1138
Epoch=332, loss=0.1018
Epoch=333, loss=0.0984
Epoch=334, loss=0.1040
Epoch=335, loss=0.1116
Epoch=336, loss=0.1099
Epoch=337, loss=0.0997
Epoch=338, loss=0.0988
Epoch=339, loss=0.1036
Epoch=340, loss=0.1071
Epoch=341, loss=0.0997
Epoch=342, loss=0.0992
Epoch=343, loss=0.1010
Epoch=344, loss=0.1103
Epoch=345, loss=0.0928
Epoch=346, loss=0.1019
Epoch=347, loss=0.1092
Epoch=348, loss=0.0926
Epoch=349, loss=0.1019
Epoch=350, loss=0.0926
Epoch=351, loss=0.0867
Epoch=352, loss=0.0926
Epoch=353, loss=0.0936
Epoch=354, loss=0.0939
Epoch=355, loss=0.1114
Epoch=356, loss=0.0942
Epoch=357, loss=0.0931
Epoch=358, loss=0.0908
Epoch=359, loss=0.0983
Epoch=360, loss=0.0962
Epoch=361, loss=0.0947
Epoch=362, loss=0.0956
Epoch=363, loss=0.0960
Epoch=364, loss=0.0980
Epoch=365, loss=0.0869
Epoch=366, loss=0.0984
Epoch=367, loss=0.0939
Epoch=368, loss=0.0979
Epoch=369, loss=0.0827
Epoch=370, loss=0.1004
Epoch=371, loss=0.0889
Epoch=372, loss=0.0885
Epoch=373, loss=0.0888
Epoch=374, loss=0.0990
Epoch=375, loss=0.0910
Epoch=376, loss=0.0908
Epoch=377, loss=0.0846
Epoch=378, loss=0.0915
Epoch=379, loss=0.0962
Epoch=380, loss=0.0895
Epoch=381, loss=0.0871
Epoch=382, loss=0.0837
Epoch=383, loss=0.0808
Epoch=384, loss=0.0870
Epoch=385, loss=0.0814
Epoch=386, loss=0.0936
Epoch=387, loss=0.0830
Epoch=388, loss=0.0918
Epoch=389, loss=0.0918
Epoch=390, loss=0.0852
Epoch=391, loss=0.0874
Epoch=392, loss=0.0843
Epoch=393, loss=0.0875
Epoch=394, loss=0.0940
Epoch=395, loss=0.0831
Epoch=396, loss=0.0798
Epoch=397, loss=0.0842
Epoch=398, loss=0.0777
Epoch=399, loss=0.0735
Epoch=400, loss=0.0885
Epoch=401, loss=0.0819
Epoch=402, loss=0.0809
Epoch=403, loss=0.0788
Epoch=404, loss=0.0873
Epoch=405, loss=0.0823
Epoch=406, loss=0.0731
Epoch=407, loss=0.0742
Epoch=408, loss=0.0804
Epoch=409, loss=0.0771
Epoch=410, loss=0.0819
Epoch=411, loss=0.0830
Epoch=412, loss=0.0858
Epoch=413, loss=0.0849
Epoch=414, loss=0.0795
Epoch=415, loss=0.0764
Epoch=416, loss=0.0722
Epoch=417, loss=0.0782
Epoch=418, loss=0.0758
Epoch=419, loss=0.0760
Epoch=420, loss=0.0819
Epoch=421, loss=0.0754
Epoch=422, loss=0.0824
Epoch=423, loss=0.0935
Epoch=424, loss=0.0895
Epoch=425, loss=0.0805
Epoch=426, loss=0.0733
Epoch=427, loss=0.0807
Epoch=428, loss=0.0808
Epoch=429, loss=0.0681
Epoch=430, loss=0.0718
Epoch=431, loss=0.0709
Epoch=432, loss=0.0708
Epoch=433, loss=0.0720
Epoch=434, loss=0.0784
Epoch=435, loss=0.0675
Epoch=436, loss=0.0771
Epoch=437, loss=0.0698
Epoch=438, loss=0.0738
Epoch=439, loss=0.0660
Epoch=440, loss=0.0794
Epoch=441, loss=0.0740
Epoch=442, loss=0.0730
Epoch=443, loss=0.0825
Epoch=444, loss=0.0727
Epoch=445, loss=0.0655
Epoch=446, loss=0.0735
Epoch=447, loss=0.0678
Epoch=448, loss=0.0658
Epoch=449, loss=0.0755
Epoch=450, loss=0.0718
Epoch=451, loss=0.0647
Epoch=452, loss=0.0772
Epoch=453, loss=0.0672
Epoch=454, loss=0.0742
Epoch=455, loss=0.0717
Epoch=456, loss=0.0656
Epoch=457, loss=0.0639
Epoch=458, loss=0.0738
Epoch=459, loss=0.0758
Epoch=460, loss=0.0680
Epoch=461, loss=0.0662
Epoch=462, loss=0.0662
Epoch=463, loss=0.0721
Epoch=464, loss=0.0752
Epoch=465, loss=0.0639
Epoch=466, loss=0.0627
Epoch=467, loss=0.0651
Epoch=468, loss=0.0770
Epoch=469, loss=0.0646
Epoch=470, loss=0.0668
Epoch=471, loss=0.0794
Epoch=472, loss=0.0704
Epoch=473, loss=0.0645
Epoch=474, loss=0.0734
Epoch=475, loss=0.0602
Epoch=476, loss=0.0620
Epoch=477, loss=0.0653
Epoch=478, loss=0.0729
Epoch=479, loss=0.0641
Epoch=480, loss=0.0781
Epoch=481, loss=0.0753
Epoch=482, loss=0.0684
Epoch=483, loss=0.0770
Epoch=484, loss=0.0620
Epoch=485, loss=0.0651
Epoch=486, loss=0.0621
Epoch=487, loss=0.0673
Epoch=488, loss=0.0659
Epoch=489, loss=0.0585
Epoch=490, loss=0.0664
Epoch=491, loss=0.0675
Epoch=492, loss=0.0581
Epoch=493, loss=0.0652
Epoch=494, loss=0.0656
Epoch=495, loss=0.0625
Epoch=496, loss=0.0674
Epoch=497, loss=0.0707
Epoch=498, loss=0.0644
Epoch=499, loss=0.0655
Loading 492th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7161+-0.0080, F1Ma=0.6696+-0.0304, acc=0.7161+-0.0080
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6925
Epoch=009, loss=0.6924
Epoch=010, loss=0.6923
Epoch=011, loss=0.6921
Epoch=012, loss=0.6919
Epoch=013, loss=0.6917
Epoch=014, loss=0.6915
Epoch=015, loss=0.6913
Epoch=016, loss=0.6910
Epoch=017, loss=0.6907
Epoch=018, loss=0.6904
Epoch=019, loss=0.6901
Epoch=020, loss=0.6898
Epoch=021, loss=0.6893
Epoch=022, loss=0.6888
Epoch=023, loss=0.6883
Epoch=024, loss=0.6878
Epoch=025, loss=0.6872
Epoch=026, loss=0.6866
Epoch=027, loss=0.6860
Epoch=028, loss=0.6853
Epoch=029, loss=0.6842
Epoch=030, loss=0.6835
Epoch=031, loss=0.6824
Epoch=032, loss=0.6814
Epoch=033, loss=0.6804
Epoch=034, loss=0.6790
Epoch=035, loss=0.6779
Epoch=036, loss=0.6765
Epoch=037, loss=0.6753
Epoch=038, loss=0.6737
Epoch=039, loss=0.6718
Epoch=040, loss=0.6704
Epoch=041, loss=0.6687
Epoch=042, loss=0.6666
Epoch=043, loss=0.6646
Epoch=044, loss=0.6626
Epoch=045, loss=0.6611
Epoch=046, loss=0.6586
Epoch=047, loss=0.6562
Epoch=048, loss=0.6529
Epoch=049, loss=0.6503
Epoch=050, loss=0.6473
Epoch=051, loss=0.6446
Epoch=052, loss=0.6422
Epoch=053, loss=0.6388
Epoch=054, loss=0.6346
Epoch=055, loss=0.6319
Epoch=056, loss=0.6283
Epoch=057, loss=0.6242
Epoch=058, loss=0.6202
Epoch=059, loss=0.6158
Epoch=060, loss=0.6121
Epoch=061, loss=0.6072
Epoch=062, loss=0.6014
Epoch=063, loss=0.5980
Epoch=064, loss=0.5947
Epoch=065, loss=0.5889
Epoch=066, loss=0.5831
Epoch=067, loss=0.5794
Epoch=068, loss=0.5711
Epoch=069, loss=0.5697
Epoch=070, loss=0.5635
Epoch=071, loss=0.5529
Epoch=072, loss=0.5485
Epoch=073, loss=0.5434
Epoch=074, loss=0.5365
Epoch=075, loss=0.5325
Epoch=076, loss=0.5270
Epoch=077, loss=0.5196
Epoch=078, loss=0.5132
Epoch=079, loss=0.5065
Epoch=080, loss=0.5016
Epoch=081, loss=0.4930
Epoch=082, loss=0.4895
Epoch=083, loss=0.4769
Epoch=084, loss=0.4710
Epoch=085, loss=0.4650
Epoch=086, loss=0.4565
Epoch=087, loss=0.4496
Epoch=088, loss=0.4472
Epoch=089, loss=0.4376
Epoch=090, loss=0.4287
Epoch=091, loss=0.4191
Epoch=092, loss=0.4134
Epoch=093, loss=0.4065
Epoch=094, loss=0.4045
Epoch=095, loss=0.3961
Epoch=096, loss=0.3885
Epoch=097, loss=0.3850
Epoch=098, loss=0.3729
Epoch=099, loss=0.3628
Epoch=100, loss=0.3562
Epoch=101, loss=0.3546
Epoch=102, loss=0.3431
Epoch=103, loss=0.3376
Epoch=104, loss=0.3310
Epoch=105, loss=0.3291
Epoch=106, loss=0.3154
Epoch=107, loss=0.3092
Epoch=108, loss=0.3051
Epoch=109, loss=0.3019
Epoch=110, loss=0.2890
Epoch=111, loss=0.2865
Epoch=112, loss=0.2810
Epoch=113, loss=0.2720
Epoch=114, loss=0.2666
Epoch=115, loss=0.2680
Epoch=116, loss=0.2680
Epoch=117, loss=0.2540
Epoch=118, loss=0.2465
Epoch=119, loss=0.2428
Epoch=120, loss=0.2447
Epoch=121, loss=0.2310
Epoch=122, loss=0.2280
Epoch=123, loss=0.2290
Epoch=124, loss=0.2278
Epoch=125, loss=0.2214
Epoch=126, loss=0.2065
Epoch=127, loss=0.2098
Epoch=128, loss=0.2080
Epoch=129, loss=0.1953
Epoch=130, loss=0.1971
Epoch=131, loss=0.1936
Epoch=132, loss=0.1981
Epoch=133, loss=0.1817
Epoch=134, loss=0.1783
Epoch=135, loss=0.1777
Epoch=136, loss=0.1818
Epoch=137, loss=0.1759
Epoch=138, loss=0.1723
Epoch=139, loss=0.1679
Epoch=140, loss=0.1632
Epoch=141, loss=0.1580
Epoch=142, loss=0.1625
Epoch=143, loss=0.1672
Epoch=144, loss=0.1514
Epoch=145, loss=0.1561
Epoch=146, loss=0.1480
Epoch=147, loss=0.1414
Epoch=148, loss=0.1426
Epoch=149, loss=0.1433
Epoch=150, loss=0.1346
Epoch=151, loss=0.1486
Epoch=152, loss=0.1380
Epoch=153, loss=0.1386
Epoch=154, loss=0.1372
Epoch=155, loss=0.1295
Epoch=156, loss=0.1296
Epoch=157, loss=0.1277
Epoch=158, loss=0.1304
Epoch=159, loss=0.1252
Epoch=160, loss=0.1239
Epoch=161, loss=0.1103
Epoch=162, loss=0.1238
Epoch=163, loss=0.1209
Epoch=164, loss=0.1200
Epoch=165, loss=0.1168
Epoch=166, loss=0.1199
Epoch=167, loss=0.1142
Epoch=168, loss=0.1153
Epoch=169, loss=0.1009
Epoch=170, loss=0.1038
Epoch=171, loss=0.1059
Epoch=172, loss=0.1034
Epoch=173, loss=0.1093
Epoch=174, loss=0.1004
Epoch=175, loss=0.1117
Epoch=176, loss=0.0958
Epoch=177, loss=0.1017
Epoch=178, loss=0.1072
Epoch=179, loss=0.1010
Epoch=180, loss=0.0987
Epoch=181, loss=0.0944
Epoch=182, loss=0.0968
Epoch=183, loss=0.0926
Epoch=184, loss=0.0976
Epoch=185, loss=0.0907
Epoch=186, loss=0.0803
Epoch=187, loss=0.0933
Epoch=188, loss=0.0935
Epoch=189, loss=0.0894
Epoch=190, loss=0.0840
Epoch=191, loss=0.0878
Epoch=192, loss=0.0938
Epoch=193, loss=0.0882
Epoch=194, loss=0.0844
Epoch=195, loss=0.0851
Epoch=196, loss=0.0891
Epoch=197, loss=0.0828
Epoch=198, loss=0.0844
Epoch=199, loss=0.0850
Epoch=200, loss=0.0781
Epoch=201, loss=0.0883
Epoch=202, loss=0.0834
Epoch=203, loss=0.0793
Epoch=204, loss=0.0751
Epoch=205, loss=0.0811
Epoch=206, loss=0.0689
Epoch=207, loss=0.0708
Epoch=208, loss=0.0773
Epoch=209, loss=0.0733
Epoch=210, loss=0.0765
Epoch=211, loss=0.0755
Epoch=212, loss=0.0743
Epoch=213, loss=0.0747
Epoch=214, loss=0.0731
Epoch=215, loss=0.0685
Epoch=216, loss=0.0672
Epoch=217, loss=0.0724
Epoch=218, loss=0.0708
Epoch=219, loss=0.0705
Epoch=220, loss=0.0675
Epoch=221, loss=0.0739
Epoch=222, loss=0.0626
Epoch=223, loss=0.0640
Epoch=224, loss=0.0679
Epoch=225, loss=0.0703
Epoch=226, loss=0.0649
Epoch=227, loss=0.0700
Epoch=228, loss=0.0758
Epoch=229, loss=0.0663
Epoch=230, loss=0.0660
Epoch=231, loss=0.0631
Epoch=232, loss=0.0704
Epoch=233, loss=0.0648
Epoch=234, loss=0.0677
Epoch=235, loss=0.0614
Epoch=236, loss=0.0686
Epoch=237, loss=0.0586
Epoch=238, loss=0.0607
Epoch=239, loss=0.0520
Epoch=240, loss=0.0665
Epoch=241, loss=0.0562
Epoch=242, loss=0.0630
Epoch=243, loss=0.0617
Epoch=244, loss=0.0577
Epoch=245, loss=0.0548
Epoch=246, loss=0.0566
Epoch=247, loss=0.0644
Epoch=248, loss=0.0688
Epoch=249, loss=0.0592
Epoch=250, loss=0.0565
Epoch=251, loss=0.0615
Epoch=252, loss=0.0538
Epoch=253, loss=0.0565
Epoch=254, loss=0.0530
Epoch=255, loss=0.0488
Epoch=256, loss=0.0482
Epoch=257, loss=0.0538
Epoch=258, loss=0.0566
Epoch=259, loss=0.0558
Epoch=260, loss=0.0513
Epoch=261, loss=0.0530
Epoch=262, loss=0.0571
Epoch=263, loss=0.0508
Epoch=264, loss=0.0669
Epoch=265, loss=0.0562
Epoch=266, loss=0.0511
Epoch=267, loss=0.0505
Epoch=268, loss=0.0432
Epoch=269, loss=0.0535
Epoch=270, loss=0.0500
Epoch=271, loss=0.0537
Epoch=272, loss=0.0526
Epoch=273, loss=0.0567
Epoch=274, loss=0.0518
Epoch=275, loss=0.0554
Epoch=276, loss=0.0507
Epoch=277, loss=0.0489
Epoch=278, loss=0.0508
Epoch=279, loss=0.0532
Epoch=280, loss=0.0493
Epoch=281, loss=0.0467
Epoch=282, loss=0.0539
Epoch=283, loss=0.0560
Epoch=284, loss=0.0602
Epoch=285, loss=0.0438
Epoch=286, loss=0.0448
Epoch=287, loss=0.0514
Epoch=288, loss=0.0453
Early stopping!
Loading 268th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7681+-0.0135, F1Ma=0.7204+-0.0228, acc=0.7681+-0.0135
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847899409318095, 0.7839247137392812, 0.8074849943650105, 0.8090985553127226, 0.8999999761581421, 0.7459999918937683, 0.7543520331382751, 0.8928571343421936, 0.7459999918937683, 0.7538684606552124, 0.7681305868635835, 0.013473596615215013, 0.7204154241375547, 0.02281253766382178, 0.7681305868635835, 0.013473596615215]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6927
Epoch=003, loss=0.6925
Epoch=004, loss=0.6922
Epoch=005, loss=0.6919
Epoch=006, loss=0.6915
Epoch=007, loss=0.6910
Epoch=008, loss=0.6904
Epoch=009, loss=0.6898
Epoch=010, loss=0.6890
Epoch=011, loss=0.6882
Epoch=012, loss=0.6871
Epoch=013, loss=0.6859
Epoch=014, loss=0.6846
Epoch=015, loss=0.6831
Epoch=016, loss=0.6814
Epoch=017, loss=0.6793
Epoch=018, loss=0.6773
Epoch=019, loss=0.6746
Epoch=020, loss=0.6721
Epoch=021, loss=0.6691
Epoch=022, loss=0.6658
Epoch=023, loss=0.6622
Epoch=024, loss=0.6589
Epoch=025, loss=0.6546
Epoch=026, loss=0.6497
Epoch=027, loss=0.6449
Epoch=028, loss=0.6395
Epoch=029, loss=0.6336
Epoch=030, loss=0.6279
Epoch=031, loss=0.6205
Epoch=032, loss=0.6140
Epoch=033, loss=0.6069
Epoch=034, loss=0.5982
Epoch=035, loss=0.5897
Epoch=036, loss=0.5813
Epoch=037, loss=0.5701
Epoch=038, loss=0.5623
Epoch=039, loss=0.5517
Epoch=040, loss=0.5404
Epoch=041, loss=0.5271
Epoch=042, loss=0.5180
Epoch=043, loss=0.5070
Epoch=044, loss=0.4923
Epoch=045, loss=0.4818
Epoch=046, loss=0.4675
Epoch=047, loss=0.4527
Epoch=048, loss=0.4434
Epoch=049, loss=0.4271
Epoch=050, loss=0.4130
Epoch=051, loss=0.3976
Epoch=052, loss=0.3839
Epoch=053, loss=0.3749
Epoch=054, loss=0.3675
Epoch=055, loss=0.3505
Epoch=056, loss=0.3334
Epoch=057, loss=0.3238
Epoch=058, loss=0.3107
Epoch=059, loss=0.2984
Epoch=060, loss=0.2844
Epoch=061, loss=0.2746
Epoch=062, loss=0.2608
Epoch=063, loss=0.2542
Epoch=064, loss=0.2401
Epoch=065, loss=0.2317
Epoch=066, loss=0.2248
Epoch=067, loss=0.2132
Epoch=068, loss=0.2128
Epoch=069, loss=0.1964
Epoch=070, loss=0.1925
Epoch=071, loss=0.1881
Epoch=072, loss=0.1845
Epoch=073, loss=0.1804
Epoch=074, loss=0.1763
Epoch=075, loss=0.1729
Epoch=076, loss=0.1705
Epoch=077, loss=0.1572
Epoch=078, loss=0.1562
Epoch=079, loss=0.1541
Epoch=080, loss=0.1362
Epoch=081, loss=0.1446
Epoch=082, loss=0.1330
Epoch=083, loss=0.1312
Epoch=084, loss=0.1269
Epoch=085, loss=0.1243
Epoch=086, loss=0.1205
Epoch=087, loss=0.1178
Epoch=088, loss=0.1136
Epoch=089, loss=0.1116
Epoch=090, loss=0.1113
Epoch=091, loss=0.1106
Epoch=092, loss=0.1159
Epoch=093, loss=0.1005
Epoch=094, loss=0.1043
Epoch=095, loss=0.1125
Epoch=096, loss=0.1091
Epoch=097, loss=0.0960
Epoch=098, loss=0.0908
Epoch=099, loss=0.1026
Epoch=100, loss=0.0978
Epoch=101, loss=0.0949
Epoch=102, loss=0.0907
Epoch=103, loss=0.0951
Epoch=104, loss=0.0865
Epoch=105, loss=0.0904
Epoch=106, loss=0.0831
Epoch=107, loss=0.0858
Epoch=108, loss=0.0830
Epoch=109, loss=0.0807
Epoch=110, loss=0.0883
Epoch=111, loss=0.0812
Epoch=112, loss=0.0758
Epoch=113, loss=0.0858
Epoch=114, loss=0.0807
Epoch=115, loss=0.0745
Epoch=116, loss=0.0757
Epoch=117, loss=0.0726
Epoch=118, loss=0.0736
Epoch=119, loss=0.0760
Epoch=120, loss=0.0793
Epoch=121, loss=0.0772
Epoch=122, loss=0.0776
Epoch=123, loss=0.0826
Epoch=124, loss=0.0783
Epoch=125, loss=0.0853
Epoch=126, loss=0.0727
Epoch=127, loss=0.0661
Epoch=128, loss=0.0795
Epoch=129, loss=0.0679
Epoch=130, loss=0.0681
Epoch=131, loss=0.0716
Epoch=132, loss=0.0668
Epoch=133, loss=0.0626
Epoch=134, loss=0.0581
Epoch=135, loss=0.0661
Epoch=136, loss=0.0598
Epoch=137, loss=0.0597
Epoch=138, loss=0.0636
Epoch=139, loss=0.0635
Epoch=140, loss=0.0752
Epoch=141, loss=0.0756
Epoch=142, loss=0.0581
Epoch=143, loss=0.0557
Epoch=144, loss=0.0576
Epoch=145, loss=0.0769
Epoch=146, loss=0.0632
Epoch=147, loss=0.0626
Epoch=148, loss=0.0604
Epoch=149, loss=0.0604
Epoch=150, loss=0.0629
Epoch=151, loss=0.0574
Epoch=152, loss=0.0557
Epoch=153, loss=0.0560
Epoch=154, loss=0.0613
Epoch=155, loss=0.0559
Epoch=156, loss=0.0501
Epoch=157, loss=0.0516
Epoch=158, loss=0.0519
Epoch=159, loss=0.0524
Epoch=160, loss=0.0682
Epoch=161, loss=0.0560
Epoch=162, loss=0.0508
Epoch=163, loss=0.0535
Epoch=164, loss=0.0497
Epoch=165, loss=0.0541
Epoch=166, loss=0.0564
Epoch=167, loss=0.0536
Epoch=168, loss=0.0506
Epoch=169, loss=0.0492
Epoch=170, loss=0.0506
Epoch=171, loss=0.0523
Epoch=172, loss=0.0495
Epoch=173, loss=0.0636
Epoch=174, loss=0.0461
Epoch=175, loss=0.0478
Epoch=176, loss=0.0499
Epoch=177, loss=0.0475
Epoch=178, loss=0.0492
Epoch=179, loss=0.0395
Epoch=180, loss=0.0402
Epoch=181, loss=0.0516
Epoch=182, loss=0.0605
Epoch=183, loss=0.0620
Epoch=184, loss=0.0538
Epoch=185, loss=0.0531
Epoch=186, loss=0.0460
Epoch=187, loss=0.0518
Epoch=188, loss=0.0569
Epoch=189, loss=0.0494
Epoch=190, loss=0.0542
Epoch=191, loss=0.0448
Epoch=192, loss=0.0476
Epoch=193, loss=0.0591
Epoch=194, loss=0.0483
Epoch=195, loss=0.0418
Epoch=196, loss=0.0415
Epoch=197, loss=0.0374
Epoch=198, loss=0.0522
Epoch=199, loss=0.0570
Epoch=200, loss=0.0411
Epoch=201, loss=0.0466
Epoch=202, loss=0.0492
Epoch=203, loss=0.0439
Epoch=204, loss=0.0422
Epoch=205, loss=0.0410
Epoch=206, loss=0.0438
Epoch=207, loss=0.0433
Epoch=208, loss=0.0506
Epoch=209, loss=0.0454
Epoch=210, loss=0.0392
Epoch=211, loss=0.0478
Epoch=212, loss=0.0452
Epoch=213, loss=0.0450
Epoch=214, loss=0.0347
Epoch=215, loss=0.0359
Epoch=216, loss=0.0455
Epoch=217, loss=0.0417
Epoch=218, loss=0.0414
Epoch=219, loss=0.0408
Epoch=220, loss=0.0371
Epoch=221, loss=0.0431
Epoch=222, loss=0.0418
Epoch=223, loss=0.0465
Epoch=224, loss=0.0432
Epoch=225, loss=0.0384
Epoch=226, loss=0.0380
Epoch=227, loss=0.0401
Epoch=228, loss=0.0392
Epoch=229, loss=0.0359
Epoch=230, loss=0.0382
Epoch=231, loss=0.0438
Epoch=232, loss=0.0402
Epoch=233, loss=0.0432
Epoch=234, loss=0.0391
Early stopping!
Loading 214th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7890+-0.0126, F1Ma=0.7691+-0.0136, acc=0.7890+-0.0126
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847899409318095, 0.7839247137392812, 0.8074849943650105, 0.8090985553127226, 0.8999999761581421, 0.7459999918937683, 0.7543520331382751, 0.8928571343421936, 0.7459999918937683, 0.7538684606552124, 0.7681305868635835, 0.013473596615215013, 0.7204154241375547, 0.02281253766382178, 0.7681305868635835, 0.013473596615215], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7818412727066195, 0.7774986197836451, 0.7955578999672341, 0.7951870410428645, 0.9142857193946838, 0.7620000243186951, 0.768858790397644, 0.9071428775787354, 0.7639999985694885, 0.7664409875869751, 0.7890400310921104, 0.012587505623006404, 0.7691291118625301, 0.013553408667331398, 0.7890400310921104, 0.012587505623006404]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6920
Epoch=003, loss=0.6912
Epoch=004, loss=0.6900
Epoch=005, loss=0.6884
Epoch=006, loss=0.6866
Epoch=007, loss=0.6843
Epoch=008, loss=0.6817
Epoch=009, loss=0.6784
Epoch=010, loss=0.6739
Epoch=011, loss=0.6700
Epoch=012, loss=0.6643
Epoch=013, loss=0.6581
Epoch=014, loss=0.6516
Epoch=015, loss=0.6440
Epoch=016, loss=0.6348
Epoch=017, loss=0.6242
Epoch=018, loss=0.6136
Epoch=019, loss=0.6006
Epoch=020, loss=0.5880
Epoch=021, loss=0.5748
Epoch=022, loss=0.5576
Epoch=023, loss=0.5421
Epoch=024, loss=0.5226
Epoch=025, loss=0.5078
Epoch=026, loss=0.4855
Epoch=027, loss=0.4625
Epoch=028, loss=0.4457
Epoch=029, loss=0.4297
Epoch=030, loss=0.4070
Epoch=031, loss=0.3815
Epoch=032, loss=0.3600
Epoch=033, loss=0.3397
Epoch=034, loss=0.3167
Epoch=035, loss=0.2994
Epoch=036, loss=0.2898
Epoch=037, loss=0.2730
Epoch=038, loss=0.2568
Epoch=039, loss=0.2273
Epoch=040, loss=0.2314
Epoch=041, loss=0.2192
Epoch=042, loss=0.2055
Epoch=043, loss=0.2024
Epoch=044, loss=0.1916
Epoch=045, loss=0.1753
Epoch=046, loss=0.1549
Epoch=047, loss=0.1500
Epoch=048, loss=0.1395
Epoch=049, loss=0.1340
Epoch=050, loss=0.1461
Epoch=051, loss=0.1275
Epoch=052, loss=0.1317
Epoch=053, loss=0.1232
Epoch=054, loss=0.1085
Epoch=055, loss=0.1049
Epoch=056, loss=0.1018
Epoch=057, loss=0.1204
Epoch=058, loss=0.1016
Epoch=059, loss=0.1036
Epoch=060, loss=0.1046
Epoch=061, loss=0.0837
Epoch=062, loss=0.0838
Epoch=063, loss=0.0889
Epoch=064, loss=0.0980
Epoch=065, loss=0.0952
Epoch=066, loss=0.0856
Epoch=067, loss=0.0758
Epoch=068, loss=0.0862
Epoch=069, loss=0.0892
Epoch=070, loss=0.0843
Epoch=071, loss=0.0818
Epoch=072, loss=0.0784
Epoch=073, loss=0.0768
Epoch=074, loss=0.0840
Epoch=075, loss=0.0699
Epoch=076, loss=0.0758
Epoch=077, loss=0.0690
Epoch=078, loss=0.0718
Epoch=079, loss=0.0683
Epoch=080, loss=0.0919
Epoch=081, loss=0.0608
Epoch=082, loss=0.0636
Epoch=083, loss=0.0798
Epoch=084, loss=0.0683
Epoch=085, loss=0.0618
Epoch=086, loss=0.0781
Epoch=087, loss=0.0784
Epoch=088, loss=0.0728
Epoch=089, loss=0.0650
Epoch=090, loss=0.0673
Epoch=091, loss=0.0622
Epoch=092, loss=0.0602
Epoch=093, loss=0.0637
Epoch=094, loss=0.0629
Epoch=095, loss=0.0554
Epoch=096, loss=0.0570
Epoch=097, loss=0.0622
Epoch=098, loss=0.0646
Epoch=099, loss=0.0587
Epoch=100, loss=0.0573
Epoch=101, loss=0.0631
Epoch=102, loss=0.0427
Epoch=103, loss=0.0488
Epoch=104, loss=0.0552
Epoch=105, loss=0.0707
Epoch=106, loss=0.0521
Epoch=107, loss=0.0533
Epoch=108, loss=0.0680
Epoch=109, loss=0.0559
Epoch=110, loss=0.0503
Epoch=111, loss=0.0492
Epoch=112, loss=0.0575
Epoch=113, loss=0.0671
Epoch=114, loss=0.0594
Epoch=115, loss=0.0540
Epoch=116, loss=0.0477
Epoch=117, loss=0.0566
Epoch=118, loss=0.0550
Epoch=119, loss=0.0568
Epoch=120, loss=0.0512
Epoch=121, loss=0.0465
Epoch=122, loss=0.0608
Early stopping!
Loading 102th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8082+-0.0222, F1Ma=0.7840+-0.0260, acc=0.8082+-0.0222
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847899409318095, 0.7839247137392812, 0.8074849943650105, 0.8090985553127226, 0.8999999761581421, 0.7459999918937683, 0.7543520331382751, 0.8928571343421936, 0.7459999918937683, 0.7538684606552124, 0.7681305868635835, 0.013473596615215013, 0.7204154241375547, 0.02281253766382178, 0.7681305868635835, 0.013473596615215], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7818412727066195, 0.7774986197836451, 0.7955578999672341, 0.7951870410428645, 0.9142857193946838, 0.7620000243186951, 0.768858790397644, 0.9071428775787354, 0.7639999985694885, 0.7664409875869751, 0.7890400310921104, 0.012587505623006404, 0.7691291118625301, 0.013553408667331398, 0.7890400310921104, 0.012587505623006404], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7824376094223138, 0.7771752541241178, 0.7911075184802451, 0.7923284234952901, 0.9071428775787354, 0.765999972820282, 0.7736943960189819, 0.8928571343421936, 0.7680000066757202, 0.7678917050361633, 0.8081616789739602, 0.02220094253011159, 0.7839682568291017, 0.02602894301217142, 0.8081616789739602, 0.02220094253011159]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6919
Epoch=002, loss=0.6896
Epoch=003, loss=0.6863
Epoch=004, loss=0.6814
Epoch=005, loss=0.6762
Epoch=006, loss=0.6684
Epoch=007, loss=0.6590
Epoch=008, loss=0.6475
Epoch=009, loss=0.6333
Epoch=010, loss=0.6201
Epoch=011, loss=0.6017
Epoch=012, loss=0.5805
Epoch=013, loss=0.5605
Epoch=014, loss=0.5347
Epoch=015, loss=0.5083
Epoch=016, loss=0.4801
Epoch=017, loss=0.4628
Epoch=018, loss=0.4272
Epoch=019, loss=0.3993
Epoch=020, loss=0.3699
Epoch=021, loss=0.3416
Epoch=022, loss=0.3178
Epoch=023, loss=0.3085
Epoch=024, loss=0.2709
Epoch=025, loss=0.2532
Epoch=026, loss=0.2443
Epoch=027, loss=0.2385
Epoch=028, loss=0.2032
Epoch=029, loss=0.2005
Epoch=030, loss=0.2028
Epoch=031, loss=0.1876
Epoch=032, loss=0.1719
Epoch=033, loss=0.1680
Epoch=034, loss=0.1573
Epoch=035, loss=0.1461
Epoch=036, loss=0.1453
Epoch=037, loss=0.1506
Epoch=038, loss=0.1330
Epoch=039, loss=0.1318
Epoch=040, loss=0.1283
Epoch=041, loss=0.1366
Epoch=042, loss=0.1218
Epoch=043, loss=0.1236
Epoch=044, loss=0.1116
Epoch=045, loss=0.1236
Epoch=046, loss=0.0968
Epoch=047, loss=0.1229
Epoch=048, loss=0.0879
Epoch=049, loss=0.0986
Epoch=050, loss=0.0900
Epoch=051, loss=0.1065
Epoch=052, loss=0.1015
Epoch=053, loss=0.0886
Epoch=054, loss=0.0989
Epoch=055, loss=0.1003
Epoch=056, loss=0.0933
Epoch=057, loss=0.0852
Epoch=058, loss=0.1035
Epoch=059, loss=0.0678
Epoch=060, loss=0.1041
Epoch=061, loss=0.0687
Epoch=062, loss=0.0806
Epoch=063, loss=0.0817
Epoch=064, loss=0.0794
Epoch=065, loss=0.0860
Epoch=066, loss=0.0688
Epoch=067, loss=0.0786
Epoch=068, loss=0.0731
Epoch=069, loss=0.0634
Epoch=070, loss=0.0638
Epoch=071, loss=0.0642
Epoch=072, loss=0.0834
Epoch=073, loss=0.0629
Epoch=074, loss=0.0481
Epoch=075, loss=0.0713
Epoch=076, loss=0.0569
Epoch=077, loss=0.0644
Epoch=078, loss=0.0684
Epoch=079, loss=0.0670
Epoch=080, loss=0.0600
Epoch=081, loss=0.0765
Epoch=082, loss=0.0620
Epoch=083, loss=0.0589
Epoch=084, loss=0.0707
Epoch=085, loss=0.0529
Epoch=086, loss=0.0550
Epoch=087, loss=0.0666
Epoch=088, loss=0.0673
Epoch=089, loss=0.0489
Epoch=090, loss=0.0472
Epoch=091, loss=0.0504
Epoch=092, loss=0.0594
Epoch=093, loss=0.0412
Epoch=094, loss=0.0496
Epoch=095, loss=0.0440
Epoch=096, loss=0.0543
Epoch=097, loss=0.0548
Epoch=098, loss=0.0539
Epoch=099, loss=0.0507
Epoch=100, loss=0.0541
Epoch=101, loss=0.0567
Epoch=102, loss=0.0414
Epoch=103, loss=0.0473
Epoch=104, loss=0.0428
Epoch=105, loss=0.0513
Epoch=106, loss=0.0524
Epoch=107, loss=0.0487
Epoch=108, loss=0.0452
Epoch=109, loss=0.0532
Epoch=110, loss=0.0371
Epoch=111, loss=0.0501
Epoch=112, loss=0.0461
Epoch=113, loss=0.0589
Epoch=114, loss=0.0453
Epoch=115, loss=0.0439
Epoch=116, loss=0.0475
Epoch=117, loss=0.0458
Epoch=118, loss=0.0418
Epoch=119, loss=0.0406
Epoch=120, loss=0.0432
Epoch=121, loss=0.0484
Epoch=122, loss=0.0437
Epoch=123, loss=0.0472
Epoch=124, loss=0.0314
Epoch=125, loss=0.0360
Epoch=126, loss=0.0403
Epoch=127, loss=0.0403
Epoch=128, loss=0.0395
Epoch=129, loss=0.0411
Epoch=130, loss=0.0452
Epoch=131, loss=0.0337
Epoch=132, loss=0.0438
Epoch=133, loss=0.0344
Epoch=134, loss=0.0413
Epoch=135, loss=0.0461
Epoch=136, loss=0.0413
Epoch=137, loss=0.0343
Epoch=138, loss=0.0417
Epoch=139, loss=0.0451
Epoch=140, loss=0.0380
Epoch=141, loss=0.0336
Epoch=142, loss=0.0469
Epoch=143, loss=0.0482
Epoch=144, loss=0.0345
Early stopping!
Loading 124th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8066+-0.0149, F1Ma=0.7839+-0.0155, acc=0.8066+-0.0149
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847899409318095, 0.7839247137392812, 0.8074849943650105, 0.8090985553127226, 0.8999999761581421, 0.7459999918937683, 0.7543520331382751, 0.8928571343421936, 0.7459999918937683, 0.7538684606552124, 0.7681305868635835, 0.013473596615215013, 0.7204154241375547, 0.02281253766382178, 0.7681305868635835, 0.013473596615215], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7818412727066195, 0.7774986197836451, 0.7955578999672341, 0.7951870410428645, 0.9142857193946838, 0.7620000243186951, 0.768858790397644, 0.9071428775787354, 0.7639999985694885, 0.7664409875869751, 0.7890400310921104, 0.012587505623006404, 0.7691291118625301, 0.013553408667331398, 0.7890400310921104, 0.012587505623006404], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7824376094223138, 0.7771752541241178, 0.7911075184802451, 0.7923284234952901, 0.9071428775787354, 0.765999972820282, 0.7736943960189819, 0.8928571343421936, 0.7680000066757202, 0.7678917050361633, 0.8081616789739602, 0.02220094253011159, 0.7839682568291017, 0.02602894301217142, 0.8081616789739602, 0.02220094253011159], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7806419962045749, 0.786516024024012, 0.8014593362594472, 0.8042711889628992, 0.9785714149475098, 0.7820000052452087, 0.7896518111228943, 0.9857142567634583, 0.7820000052452087, 0.7872340679168701, 0.8066070734551107, 0.014894224307523385, 0.7839193230605404, 0.01552785472781814, 0.8066070734551107, 0.014894224307523385]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6910
Epoch=002, loss=0.6870
Epoch=003, loss=0.6761
Epoch=004, loss=0.6699
Epoch=005, loss=0.6541
Epoch=006, loss=0.6398
Epoch=007, loss=0.6320
Epoch=008, loss=0.5992
Epoch=009, loss=0.5823
Epoch=010, loss=0.5648
Epoch=011, loss=0.5275
Epoch=012, loss=0.5040
Epoch=013, loss=0.5064
Epoch=014, loss=0.4553
Epoch=015, loss=0.4243
Epoch=016, loss=0.4083
Epoch=017, loss=0.3621
Epoch=018, loss=0.3309
Epoch=019, loss=0.3495
Epoch=020, loss=0.2619
Epoch=021, loss=0.2454
Epoch=022, loss=0.2563
Epoch=023, loss=0.2177
Epoch=024, loss=0.2234
Epoch=025, loss=0.1945
Epoch=026, loss=0.1790
Epoch=027, loss=0.1886
Epoch=028, loss=0.1568
Epoch=029, loss=0.1455
Epoch=030, loss=0.1300
Epoch=031, loss=0.1471
Epoch=032, loss=0.1230
Epoch=033, loss=0.1116
Epoch=034, loss=0.1090
Epoch=035, loss=0.1114
Epoch=036, loss=0.1012
Epoch=037, loss=0.1182
Epoch=038, loss=0.0953
Epoch=039, loss=0.1296
Epoch=040, loss=0.0781
Epoch=041, loss=0.1282
Epoch=042, loss=0.0896
Epoch=043, loss=0.1112
Epoch=044, loss=0.0612
Epoch=045, loss=0.0696
Epoch=046, loss=0.0974
Epoch=047, loss=0.0606
Epoch=048, loss=0.0865
Epoch=049, loss=0.0528
Epoch=050, loss=0.0666
Epoch=051, loss=0.0567
Epoch=052, loss=0.0568
Epoch=053, loss=0.0462
Epoch=054, loss=0.0443
Epoch=055, loss=0.0446
Epoch=056, loss=0.0421
Epoch=057, loss=0.0370
Epoch=058, loss=0.0442
Epoch=059, loss=0.0420
Epoch=060, loss=0.0463
Epoch=061, loss=0.0394
Epoch=062, loss=0.0421
Epoch=063, loss=0.0368
Epoch=064, loss=0.0380
Epoch=065, loss=0.0390
Epoch=066, loss=0.0265
Epoch=067, loss=0.0314
Epoch=068, loss=0.0299
Epoch=069, loss=0.0319
Epoch=070, loss=0.0209
Epoch=071, loss=0.0283
Epoch=072, loss=0.0330
Epoch=073, loss=0.0306
Epoch=074, loss=0.0310
Epoch=075, loss=0.0253
Epoch=076, loss=0.0198
Epoch=077, loss=0.0231
Epoch=078, loss=0.0208
Epoch=079, loss=0.0203
Epoch=080, loss=0.0257
Epoch=081, loss=0.0173
Epoch=082, loss=0.0253
Epoch=083, loss=0.0185
Epoch=084, loss=0.0160
Epoch=085, loss=0.0249
Epoch=086, loss=0.0222
Epoch=087, loss=0.0152
Epoch=088, loss=0.0145
Epoch=089, loss=0.0155
Epoch=090, loss=0.0200
Epoch=091, loss=0.0144
Epoch=092, loss=0.0189
Epoch=093, loss=0.0145
Epoch=094, loss=0.0117
Epoch=095, loss=0.0104
Epoch=096, loss=0.0120
Epoch=097, loss=0.0137
Epoch=098, loss=0.0139
Epoch=099, loss=0.0157
Epoch=100, loss=0.0118
Epoch=101, loss=0.0174
Epoch=102, loss=0.0192
Epoch=103, loss=0.0102
Epoch=104, loss=0.0186
Epoch=105, loss=0.0110
Epoch=106, loss=0.0100
Epoch=107, loss=0.0145
Epoch=108, loss=0.0169
Epoch=109, loss=0.0103
Epoch=110, loss=0.0154
Epoch=111, loss=0.0116
Epoch=112, loss=0.0171
Epoch=113, loss=0.0130
Epoch=114, loss=0.0100
Epoch=115, loss=0.0188
Epoch=116, loss=0.0167
Epoch=117, loss=0.0171
Epoch=118, loss=0.0110
Epoch=119, loss=0.0086
Epoch=120, loss=0.0144
Epoch=121, loss=0.0112
Epoch=122, loss=0.0148
Epoch=123, loss=0.0060
Epoch=124, loss=0.0078
Epoch=125, loss=0.0154
Epoch=126, loss=0.0121
Epoch=127, loss=0.0122
Epoch=128, loss=0.0090
Epoch=129, loss=0.0103
Epoch=130, loss=0.0097
Epoch=131, loss=0.0047
Epoch=132, loss=0.0101
Epoch=133, loss=0.0109
Epoch=134, loss=0.0085
Epoch=135, loss=0.0104
Epoch=136, loss=0.0072
Epoch=137, loss=0.0062
Epoch=138, loss=0.0074
Epoch=139, loss=0.0080
Epoch=140, loss=0.0067
Epoch=141, loss=0.0088
Epoch=142, loss=0.0050
Epoch=143, loss=0.0054
Epoch=144, loss=0.0097
Epoch=145, loss=0.0051
Epoch=146, loss=0.0070
Epoch=147, loss=0.0090
Epoch=148, loss=0.0084
Epoch=149, loss=0.0049
Epoch=150, loss=0.0063
Epoch=151, loss=0.0060
Early stopping!
Loading 131th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8036+-0.0107, F1Ma=0.7896+-0.0125, acc=0.8036+-0.0107
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7672246807489808, 0.770797994593995, 0.7794900784577772, 0.7875628735653015, 0.8642857074737549, 0.7099999785423279, 0.7224371433258057, 0.8785714507102966, 0.699999988079071, 0.7137330770492554, 0.7161290322580647, 0.008023933401050275, 0.6696385035036221, 0.030441921422346634, 0.7161290322580646, 0.008023933401050244], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847899409318095, 0.7839247137392812, 0.8074849943650105, 0.8090985553127226, 0.8999999761581421, 0.7459999918937683, 0.7543520331382751, 0.8928571343421936, 0.7459999918937683, 0.7538684606552124, 0.7681305868635835, 0.013473596615215013, 0.7204154241375547, 0.02281253766382178, 0.7681305868635835, 0.013473596615215], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7818412727066195, 0.7774986197836451, 0.7955578999672341, 0.7951870410428645, 0.9142857193946838, 0.7620000243186951, 0.768858790397644, 0.9071428775787354, 0.7639999985694885, 0.7664409875869751, 0.7890400310921104, 0.012587505623006404, 0.7691291118625301, 0.013553408667331398, 0.7890400310921104, 0.012587505623006404], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7824376094223138, 0.7771752541241178, 0.7911075184802451, 0.7923284234952901, 0.9071428775787354, 0.765999972820282, 0.7736943960189819, 0.8928571343421936, 0.7680000066757202, 0.7678917050361633, 0.8081616789739602, 0.02220094253011159, 0.7839682568291017, 0.02602894301217142, 0.8081616789739602, 0.02220094253011159], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7806419962045749, 0.786516024024012, 0.8014593362594472, 0.8042711889628992, 0.9785714149475098, 0.7820000052452087, 0.7896518111228943, 0.9857142567634583, 0.7820000052452087, 0.7872340679168701, 0.8066070734551107, 0.014894224307523385, 0.7839193230605404, 0.01552785472781814, 0.8066070734551107, 0.014894224307523385], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9115831710864545, 0.9009557330122447, 0.9131995578423571, 0.9069531553821033, 0.9285714030265808, 0.7979999780654907, 0.7969052195549011, 0.9285714030265808, 0.7979999780654907, 0.7964216470718384, 0.803575592693354, 0.010701965817020244, 0.7895794053220802, 0.012472944564426545, 0.803575592693354, 0.010701965817020277]]
