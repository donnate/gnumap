My SLURM_ARRAY_TASK_ID:  7
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_7
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_7.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6929
Epoch=007, loss=0.6929
Epoch=008, loss=0.6928
Epoch=009, loss=0.6928
Epoch=010, loss=0.6927
Epoch=011, loss=0.6927
Epoch=012, loss=0.6926
Epoch=013, loss=0.6925
Epoch=014, loss=0.6925
Epoch=015, loss=0.6924
Epoch=016, loss=0.6924
Epoch=017, loss=0.6922
Epoch=018, loss=0.6922
Epoch=019, loss=0.6921
Epoch=020, loss=0.6920
Epoch=021, loss=0.6919
Epoch=022, loss=0.6917
Epoch=023, loss=0.6916
Epoch=024, loss=0.6915
Epoch=025, loss=0.6914
Epoch=026, loss=0.6912
Epoch=027, loss=0.6911
Epoch=028, loss=0.6909
Epoch=029, loss=0.6908
Epoch=030, loss=0.6906
Epoch=031, loss=0.6904
Epoch=032, loss=0.6902
Epoch=033, loss=0.6900
Epoch=034, loss=0.6898
Epoch=035, loss=0.6895
Epoch=036, loss=0.6893
Epoch=037, loss=0.6891
Epoch=038, loss=0.6887
Epoch=039, loss=0.6884
Epoch=040, loss=0.6881
Epoch=041, loss=0.6878
Epoch=042, loss=0.6875
Epoch=043, loss=0.6872
Epoch=044, loss=0.6867
Epoch=045, loss=0.6863
Epoch=046, loss=0.6858
Epoch=047, loss=0.6854
Epoch=048, loss=0.6852
Epoch=049, loss=0.6845
Epoch=050, loss=0.6840
Epoch=051, loss=0.6836
Epoch=052, loss=0.6828
Epoch=053, loss=0.6827
Epoch=054, loss=0.6817
Epoch=055, loss=0.6811
Epoch=056, loss=0.6807
Epoch=057, loss=0.6798
Epoch=058, loss=0.6791
Epoch=059, loss=0.6782
Epoch=060, loss=0.6774
Epoch=061, loss=0.6768
Epoch=062, loss=0.6763
Epoch=063, loss=0.6753
Epoch=064, loss=0.6746
Epoch=065, loss=0.6733
Epoch=066, loss=0.6727
Epoch=067, loss=0.6717
Epoch=068, loss=0.6707
Epoch=069, loss=0.6693
Epoch=070, loss=0.6685
Epoch=071, loss=0.6669
Epoch=072, loss=0.6664
Epoch=073, loss=0.6650
Epoch=074, loss=0.6639
Epoch=075, loss=0.6622
Epoch=076, loss=0.6612
Epoch=077, loss=0.6598
Epoch=078, loss=0.6586
Epoch=079, loss=0.6568
Epoch=080, loss=0.6554
Epoch=081, loss=0.6535
Epoch=082, loss=0.6529
Epoch=083, loss=0.6507
Epoch=084, loss=0.6496
Epoch=085, loss=0.6469
Epoch=086, loss=0.6455
Epoch=087, loss=0.6431
Epoch=088, loss=0.6422
Epoch=089, loss=0.6405
Epoch=090, loss=0.6381
Epoch=091, loss=0.6360
Epoch=092, loss=0.6359
Epoch=093, loss=0.6324
Epoch=094, loss=0.6296
Epoch=095, loss=0.6284
Epoch=096, loss=0.6261
Epoch=097, loss=0.6243
Epoch=098, loss=0.6220
Epoch=099, loss=0.6181
Epoch=100, loss=0.6167
Epoch=101, loss=0.6129
Epoch=102, loss=0.6112
Epoch=103, loss=0.6101
Epoch=104, loss=0.6075
Epoch=105, loss=0.6048
Epoch=106, loss=0.6006
Epoch=107, loss=0.5979
Epoch=108, loss=0.5958
Epoch=109, loss=0.5929
Epoch=110, loss=0.5909
Epoch=111, loss=0.5877
Epoch=112, loss=0.5831
Epoch=113, loss=0.5816
Epoch=114, loss=0.5784
Epoch=115, loss=0.5772
Epoch=116, loss=0.5717
Epoch=117, loss=0.5689
Epoch=118, loss=0.5656
Epoch=119, loss=0.5618
Epoch=120, loss=0.5613
Epoch=121, loss=0.5549
Epoch=122, loss=0.5538
Epoch=123, loss=0.5487
Epoch=124, loss=0.5469
Epoch=125, loss=0.5429
Epoch=126, loss=0.5409
Epoch=127, loss=0.5378
Epoch=128, loss=0.5286
Epoch=129, loss=0.5291
Epoch=130, loss=0.5272
Epoch=131, loss=0.5240
Epoch=132, loss=0.5179
Epoch=133, loss=0.5162
Epoch=134, loss=0.5139
Epoch=135, loss=0.5064
Epoch=136, loss=0.5043
Epoch=137, loss=0.4998
Epoch=138, loss=0.4952
Epoch=139, loss=0.4936
Epoch=140, loss=0.4894
Epoch=141, loss=0.4857
Epoch=142, loss=0.4860
Epoch=143, loss=0.4803
Epoch=144, loss=0.4733
Epoch=145, loss=0.4691
Epoch=146, loss=0.4681
Epoch=147, loss=0.4602
Epoch=148, loss=0.4595
Epoch=149, loss=0.4548
Epoch=150, loss=0.4498
Epoch=151, loss=0.4421
Epoch=152, loss=0.4428
Epoch=153, loss=0.4404
Epoch=154, loss=0.4322
Epoch=155, loss=0.4314
Epoch=156, loss=0.4276
Epoch=157, loss=0.4287
Epoch=158, loss=0.4255
Epoch=159, loss=0.4186
Epoch=160, loss=0.4143
Epoch=161, loss=0.4081
Epoch=162, loss=0.4069
Epoch=163, loss=0.4004
Epoch=164, loss=0.3997
Epoch=165, loss=0.3955
Epoch=166, loss=0.3891
Epoch=167, loss=0.3868
Epoch=168, loss=0.3822
Epoch=169, loss=0.3777
Epoch=170, loss=0.3827
Epoch=171, loss=0.3707
Epoch=172, loss=0.3742
Epoch=173, loss=0.3617
Epoch=174, loss=0.3646
Epoch=175, loss=0.3555
Epoch=176, loss=0.3541
Epoch=177, loss=0.3543
Epoch=178, loss=0.3469
Epoch=179, loss=0.3469
Epoch=180, loss=0.3459
Epoch=181, loss=0.3364
Epoch=182, loss=0.3334
Epoch=183, loss=0.3333
Epoch=184, loss=0.3301
Epoch=185, loss=0.3256
Epoch=186, loss=0.3253
Epoch=187, loss=0.3208
Epoch=188, loss=0.3155
Epoch=189, loss=0.3165
Epoch=190, loss=0.3162
Epoch=191, loss=0.3105
Epoch=192, loss=0.3038
Epoch=193, loss=0.2939
Epoch=194, loss=0.2995
Epoch=195, loss=0.2965
Epoch=196, loss=0.2945
Epoch=197, loss=0.2916
Epoch=198, loss=0.2863
Epoch=199, loss=0.2825
Epoch=200, loss=0.2826
Epoch=201, loss=0.2757
Epoch=202, loss=0.2861
Epoch=203, loss=0.2721
Epoch=204, loss=0.2756
Epoch=205, loss=0.2671
Epoch=206, loss=0.2685
Epoch=207, loss=0.2756
Epoch=208, loss=0.2641
Epoch=209, loss=0.2585
Epoch=210, loss=0.2566
Epoch=211, loss=0.2583
Epoch=212, loss=0.2598
Epoch=213, loss=0.2485
Epoch=214, loss=0.2497
Epoch=215, loss=0.2477
Epoch=216, loss=0.2406
Epoch=217, loss=0.2374
Epoch=218, loss=0.2450
Epoch=219, loss=0.2421
Epoch=220, loss=0.2369
Epoch=221, loss=0.2348
Epoch=222, loss=0.2376
Epoch=223, loss=0.2364
Epoch=224, loss=0.2281
Epoch=225, loss=0.2350
Epoch=226, loss=0.2179
Epoch=227, loss=0.2285
Epoch=228, loss=0.2234
Epoch=229, loss=0.2200
Epoch=230, loss=0.2148
Epoch=231, loss=0.2165
Epoch=232, loss=0.2195
Epoch=233, loss=0.2151
Epoch=234, loss=0.2095
Epoch=235, loss=0.2135
Epoch=236, loss=0.2089
Epoch=237, loss=0.2106
Epoch=238, loss=0.2066
Epoch=239, loss=0.1968
Epoch=240, loss=0.1984
Epoch=241, loss=0.2140
Epoch=242, loss=0.1953
Epoch=243, loss=0.1920
Epoch=244, loss=0.1998
Epoch=245, loss=0.1839
Epoch=246, loss=0.1905
Epoch=247, loss=0.1914
Epoch=248, loss=0.1882
Epoch=249, loss=0.1942
Epoch=250, loss=0.1893
Epoch=251, loss=0.1792
Epoch=252, loss=0.1824
Epoch=253, loss=0.1811
Epoch=254, loss=0.1742
Epoch=255, loss=0.1822
Epoch=256, loss=0.1743
Epoch=257, loss=0.1771
Epoch=258, loss=0.1817
Epoch=259, loss=0.1693
Epoch=260, loss=0.1768
Epoch=261, loss=0.1759
Epoch=262, loss=0.1735
Epoch=263, loss=0.1662
Epoch=264, loss=0.1675
Epoch=265, loss=0.1666
Epoch=266, loss=0.1681
Epoch=267, loss=0.1646
Epoch=268, loss=0.1571
Epoch=269, loss=0.1592
Epoch=270, loss=0.1557
Epoch=271, loss=0.1625
Epoch=272, loss=0.1638
Epoch=273, loss=0.1540
Epoch=274, loss=0.1646
Epoch=275, loss=0.1573
Epoch=276, loss=0.1583
Epoch=277, loss=0.1576
Epoch=278, loss=0.1576
Epoch=279, loss=0.1416
Epoch=280, loss=0.1527
Epoch=281, loss=0.1526
Epoch=282, loss=0.1460
Epoch=283, loss=0.1442
Epoch=284, loss=0.1460
Epoch=285, loss=0.1519
Epoch=286, loss=0.1532
Epoch=287, loss=0.1443
Epoch=288, loss=0.1509
Epoch=289, loss=0.1420
Epoch=290, loss=0.1386
Epoch=291, loss=0.1448
Epoch=292, loss=0.1377
Epoch=293, loss=0.1484
Epoch=294, loss=0.1373
Epoch=295, loss=0.1294
Epoch=296, loss=0.1340
Epoch=297, loss=0.1409
Epoch=298, loss=0.1425
Epoch=299, loss=0.1414
Epoch=300, loss=0.1235
Epoch=301, loss=0.1310
Epoch=302, loss=0.1291
Epoch=303, loss=0.1373
Epoch=304, loss=0.1316
Epoch=305, loss=0.1242
Epoch=306, loss=0.1273
Epoch=307, loss=0.1250
Epoch=308, loss=0.1241
Epoch=309, loss=0.1399
Epoch=310, loss=0.1260
Epoch=311, loss=0.1290
Epoch=312, loss=0.1298
Epoch=313, loss=0.1195
Epoch=314, loss=0.1243
Epoch=315, loss=0.1295
Epoch=316, loss=0.1175
Epoch=317, loss=0.1197
Epoch=318, loss=0.1231
Epoch=319, loss=0.1195
Epoch=320, loss=0.1341
Epoch=321, loss=0.1216
Epoch=322, loss=0.1194
Epoch=323, loss=0.1155
Epoch=324, loss=0.1121
Epoch=325, loss=0.1203
Epoch=326, loss=0.1153
Epoch=327, loss=0.1226
Epoch=328, loss=0.1171
Epoch=329, loss=0.1089
Epoch=330, loss=0.1100
Epoch=331, loss=0.1187
Epoch=332, loss=0.1158
Epoch=333, loss=0.1168
Epoch=334, loss=0.1029
Epoch=335, loss=0.1072
Epoch=336, loss=0.1145
Epoch=337, loss=0.1159
Epoch=338, loss=0.1019
Epoch=339, loss=0.1078
Epoch=340, loss=0.1098
Epoch=341, loss=0.1163
Epoch=342, loss=0.1133
Epoch=343, loss=0.1090
Epoch=344, loss=0.1106
Epoch=345, loss=0.1028
Epoch=346, loss=0.0994
Epoch=347, loss=0.0983
Epoch=348, loss=0.1118
Epoch=349, loss=0.1079
Epoch=350, loss=0.1041
Epoch=351, loss=0.1106
Epoch=352, loss=0.0968
Epoch=353, loss=0.1038
Epoch=354, loss=0.0976
Epoch=355, loss=0.1131
Epoch=356, loss=0.0966
Epoch=357, loss=0.1033
Epoch=358, loss=0.1053
Epoch=359, loss=0.0973
Epoch=360, loss=0.1011
Epoch=361, loss=0.1058
Epoch=362, loss=0.0989
Epoch=363, loss=0.0891
Epoch=364, loss=0.1075
Epoch=365, loss=0.0965
Epoch=366, loss=0.0950
Epoch=367, loss=0.0898
Epoch=368, loss=0.0961
Epoch=369, loss=0.0881
Epoch=370, loss=0.0963
Epoch=371, loss=0.0971
Epoch=372, loss=0.0912
Epoch=373, loss=0.0883
Epoch=374, loss=0.1034
Epoch=375, loss=0.0861
Epoch=376, loss=0.0989
Epoch=377, loss=0.0862
Epoch=378, loss=0.0941
Epoch=379, loss=0.0901
Epoch=380, loss=0.0973
Epoch=381, loss=0.0957
Epoch=382, loss=0.0969
Epoch=383, loss=0.0922
Epoch=384, loss=0.0912
Epoch=385, loss=0.0855
Epoch=386, loss=0.0958
Epoch=387, loss=0.0900
Epoch=388, loss=0.0906
Epoch=389, loss=0.0849
Epoch=390, loss=0.0887
Epoch=391, loss=0.0834
Epoch=392, loss=0.0887
Epoch=393, loss=0.0824
Epoch=394, loss=0.0857
Epoch=395, loss=0.0916
Epoch=396, loss=0.0957
Epoch=397, loss=0.0820
Epoch=398, loss=0.0841
Epoch=399, loss=0.0896
Epoch=400, loss=0.0943
Epoch=401, loss=0.0851
Epoch=402, loss=0.0911
Epoch=403, loss=0.0779
Epoch=404, loss=0.0874
Epoch=405, loss=0.0804
Epoch=406, loss=0.0911
Epoch=407, loss=0.0822
Epoch=408, loss=0.0798
Epoch=409, loss=0.0824
Epoch=410, loss=0.0777
Epoch=411, loss=0.0733
Epoch=412, loss=0.0905
Epoch=413, loss=0.0867
Epoch=414, loss=0.0771
Epoch=415, loss=0.0803
Epoch=416, loss=0.0806
Epoch=417, loss=0.0848
Epoch=418, loss=0.0855
Epoch=419, loss=0.0828
Epoch=420, loss=0.0681
Epoch=421, loss=0.0840
Epoch=422, loss=0.0752
Epoch=423, loss=0.0865
Epoch=424, loss=0.0702
Epoch=425, loss=0.0773
Epoch=426, loss=0.0818
Epoch=427, loss=0.0718
Epoch=428, loss=0.0845
Epoch=429, loss=0.0715
Epoch=430, loss=0.0694
Epoch=431, loss=0.0865
Epoch=432, loss=0.0744
Epoch=433, loss=0.0769
Epoch=434, loss=0.0632
Epoch=435, loss=0.0779
Epoch=436, loss=0.0817
Epoch=437, loss=0.0684
Epoch=438, loss=0.0761
Epoch=439, loss=0.0782
Epoch=440, loss=0.0693
Epoch=441, loss=0.0748
Epoch=442, loss=0.0785
Epoch=443, loss=0.0754
Epoch=444, loss=0.0694
Epoch=445, loss=0.0715
Epoch=446, loss=0.0773
Epoch=447, loss=0.0843
Epoch=448, loss=0.0826
Epoch=449, loss=0.0853
Epoch=450, loss=0.0747
Epoch=451, loss=0.0756
Epoch=452, loss=0.0796
Epoch=453, loss=0.0732
Epoch=454, loss=0.0791
Early stopping!
Loading 434th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7203+-0.0197, F1Ma=0.6472+-0.0557, acc=0.7203+-0.0197
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6928
Epoch=005, loss=0.6927
Epoch=006, loss=0.6926
Epoch=007, loss=0.6925
Epoch=008, loss=0.6924
Epoch=009, loss=0.6922
Epoch=010, loss=0.6921
Epoch=011, loss=0.6919
Epoch=012, loss=0.6917
Epoch=013, loss=0.6915
Epoch=014, loss=0.6912
Epoch=015, loss=0.6908
Epoch=016, loss=0.6905
Epoch=017, loss=0.6901
Epoch=018, loss=0.6898
Epoch=019, loss=0.6893
Epoch=020, loss=0.6888
Epoch=021, loss=0.6883
Epoch=022, loss=0.6878
Epoch=023, loss=0.6871
Epoch=024, loss=0.6865
Epoch=025, loss=0.6858
Epoch=026, loss=0.6850
Epoch=027, loss=0.6842
Epoch=028, loss=0.6832
Epoch=029, loss=0.6822
Epoch=030, loss=0.6811
Epoch=031, loss=0.6800
Epoch=032, loss=0.6790
Epoch=033, loss=0.6774
Epoch=034, loss=0.6762
Epoch=035, loss=0.6747
Epoch=036, loss=0.6729
Epoch=037, loss=0.6710
Epoch=038, loss=0.6696
Epoch=039, loss=0.6681
Epoch=040, loss=0.6661
Epoch=041, loss=0.6641
Epoch=042, loss=0.6618
Epoch=043, loss=0.6593
Epoch=044, loss=0.6562
Epoch=045, loss=0.6538
Epoch=046, loss=0.6510
Epoch=047, loss=0.6479
Epoch=048, loss=0.6446
Epoch=049, loss=0.6408
Epoch=050, loss=0.6383
Epoch=051, loss=0.6360
Epoch=052, loss=0.6315
Epoch=053, loss=0.6285
Epoch=054, loss=0.6238
Epoch=055, loss=0.6207
Epoch=056, loss=0.6150
Epoch=057, loss=0.6112
Epoch=058, loss=0.6063
Epoch=059, loss=0.6021
Epoch=060, loss=0.5953
Epoch=061, loss=0.5922
Epoch=062, loss=0.5852
Epoch=063, loss=0.5800
Epoch=064, loss=0.5756
Epoch=065, loss=0.5684
Epoch=066, loss=0.5648
Epoch=067, loss=0.5581
Epoch=068, loss=0.5507
Epoch=069, loss=0.5467
Epoch=070, loss=0.5396
Epoch=071, loss=0.5328
Epoch=072, loss=0.5267
Epoch=073, loss=0.5199
Epoch=074, loss=0.5127
Epoch=075, loss=0.5055
Epoch=076, loss=0.5006
Epoch=077, loss=0.4926
Epoch=078, loss=0.4830
Epoch=079, loss=0.4750
Epoch=080, loss=0.4739
Epoch=081, loss=0.4626
Epoch=082, loss=0.4560
Epoch=083, loss=0.4485
Epoch=084, loss=0.4456
Epoch=085, loss=0.4320
Epoch=086, loss=0.4226
Epoch=087, loss=0.4175
Epoch=088, loss=0.4117
Epoch=089, loss=0.4052
Epoch=090, loss=0.3927
Epoch=091, loss=0.3858
Epoch=092, loss=0.3799
Epoch=093, loss=0.3728
Epoch=094, loss=0.3652
Epoch=095, loss=0.3587
Epoch=096, loss=0.3515
Epoch=097, loss=0.3517
Epoch=098, loss=0.3405
Epoch=099, loss=0.3393
Epoch=100, loss=0.3278
Epoch=101, loss=0.3257
Epoch=102, loss=0.3168
Epoch=103, loss=0.3126
Epoch=104, loss=0.3039
Epoch=105, loss=0.3005
Epoch=106, loss=0.2870
Epoch=107, loss=0.2820
Epoch=108, loss=0.2853
Epoch=109, loss=0.2736
Epoch=110, loss=0.2705
Epoch=111, loss=0.2624
Epoch=112, loss=0.2534
Epoch=113, loss=0.2437
Epoch=114, loss=0.2486
Epoch=115, loss=0.2420
Epoch=116, loss=0.2393
Epoch=117, loss=0.2359
Epoch=118, loss=0.2276
Epoch=119, loss=0.2231
Epoch=120, loss=0.2263
Epoch=121, loss=0.2164
Epoch=122, loss=0.2146
Epoch=123, loss=0.2164
Epoch=124, loss=0.1992
Epoch=125, loss=0.2027
Epoch=126, loss=0.2007
Epoch=127, loss=0.1997
Epoch=128, loss=0.1893
Epoch=129, loss=0.1813
Epoch=130, loss=0.1876
Epoch=131, loss=0.1783
Epoch=132, loss=0.1773
Epoch=133, loss=0.1741
Epoch=134, loss=0.1702
Epoch=135, loss=0.1681
Epoch=136, loss=0.1636
Epoch=137, loss=0.1583
Epoch=138, loss=0.1641
Epoch=139, loss=0.1641
Epoch=140, loss=0.1679
Epoch=141, loss=0.1613
Epoch=142, loss=0.1516
Epoch=143, loss=0.1525
Epoch=144, loss=0.1549
Epoch=145, loss=0.1496
Epoch=146, loss=0.1471
Epoch=147, loss=0.1433
Epoch=148, loss=0.1384
Epoch=149, loss=0.1446
Epoch=150, loss=0.1418
Epoch=151, loss=0.1428
Epoch=152, loss=0.1395
Epoch=153, loss=0.1260
Epoch=154, loss=0.1380
Epoch=155, loss=0.1318
Epoch=156, loss=0.1379
Epoch=157, loss=0.1265
Epoch=158, loss=0.1191
Epoch=159, loss=0.1135
Epoch=160, loss=0.1186
Epoch=161, loss=0.1331
Epoch=162, loss=0.1269
Epoch=163, loss=0.1256
Epoch=164, loss=0.1121
Epoch=165, loss=0.1235
Epoch=166, loss=0.1158
Epoch=167, loss=0.1177
Epoch=168, loss=0.1140
Epoch=169, loss=0.1085
Epoch=170, loss=0.1108
Epoch=171, loss=0.1228
Epoch=172, loss=0.1058
Epoch=173, loss=0.1141
Epoch=174, loss=0.1112
Epoch=175, loss=0.1071
Epoch=176, loss=0.1167
Epoch=177, loss=0.0961
Epoch=178, loss=0.1102
Epoch=179, loss=0.0984
Epoch=180, loss=0.1099
Epoch=181, loss=0.0991
Epoch=182, loss=0.1049
Epoch=183, loss=0.0974
Epoch=184, loss=0.0987
Epoch=185, loss=0.1042
Epoch=186, loss=0.0903
Epoch=187, loss=0.0944
Epoch=188, loss=0.0977
Epoch=189, loss=0.0937
Epoch=190, loss=0.0975
Epoch=191, loss=0.0955
Epoch=192, loss=0.0863
Epoch=193, loss=0.0944
Epoch=194, loss=0.0933
Epoch=195, loss=0.0838
Epoch=196, loss=0.0956
Epoch=197, loss=0.0861
Epoch=198, loss=0.0888
Epoch=199, loss=0.0939
Epoch=200, loss=0.1024
Epoch=201, loss=0.0844
Epoch=202, loss=0.0881
Epoch=203, loss=0.0868
Epoch=204, loss=0.0888
Epoch=205, loss=0.0882
Epoch=206, loss=0.0783
Epoch=207, loss=0.0793
Epoch=208, loss=0.0812
Epoch=209, loss=0.0725
Epoch=210, loss=0.0837
Epoch=211, loss=0.0830
Epoch=212, loss=0.0809
Epoch=213, loss=0.0860
Epoch=214, loss=0.0884
Epoch=215, loss=0.0753
Epoch=216, loss=0.0734
Epoch=217, loss=0.0811
Epoch=218, loss=0.0741
Epoch=219, loss=0.0774
Epoch=220, loss=0.0808
Epoch=221, loss=0.0748
Epoch=222, loss=0.0764
Epoch=223, loss=0.0821
Epoch=224, loss=0.0790
Epoch=225, loss=0.0716
Epoch=226, loss=0.0739
Epoch=227, loss=0.0691
Epoch=228, loss=0.0802
Epoch=229, loss=0.0789
Epoch=230, loss=0.0718
Epoch=231, loss=0.0810
Epoch=232, loss=0.0731
Epoch=233, loss=0.0730
Epoch=234, loss=0.0742
Epoch=235, loss=0.0661
Epoch=236, loss=0.0706
Epoch=237, loss=0.0738
Epoch=238, loss=0.0644
Epoch=239, loss=0.0674
Epoch=240, loss=0.0668
Epoch=241, loss=0.0699
Epoch=242, loss=0.0751
Epoch=243, loss=0.0757
Epoch=244, loss=0.0622
Epoch=245, loss=0.0726
Epoch=246, loss=0.0566
Epoch=247, loss=0.0740
Epoch=248, loss=0.0629
Epoch=249, loss=0.0678
Epoch=250, loss=0.0691
Epoch=251, loss=0.0665
Epoch=252, loss=0.0623
Epoch=253, loss=0.0704
Epoch=254, loss=0.0667
Epoch=255, loss=0.0762
Epoch=256, loss=0.0573
Epoch=257, loss=0.0572
Epoch=258, loss=0.0702
Epoch=259, loss=0.0651
Epoch=260, loss=0.0735
Epoch=261, loss=0.0587
Epoch=262, loss=0.0708
Epoch=263, loss=0.0682
Epoch=264, loss=0.0700
Epoch=265, loss=0.0580
Epoch=266, loss=0.0603
Early stopping!
Loading 246th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7666+-0.0113, F1Ma=0.7241+-0.0271, acc=0.7666+-0.0113
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592583987086976, 0.7666777703571261, 0.7599170414324756, 0.7751730979142201, 0.8928571343421936, 0.7459999918937683, 0.7446808218955994, 0.8857142925262451, 0.75, 0.747582197189331, 0.7665759813447337, 0.011295254900733926, 0.7240791768770017, 0.02710549603314485, 0.7665759813447337, 0.011295254900733905]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6927
Epoch=003, loss=0.6925
Epoch=004, loss=0.6922
Epoch=005, loss=0.6919
Epoch=006, loss=0.6914
Epoch=007, loss=0.6909
Epoch=008, loss=0.6903
Epoch=009, loss=0.6896
Epoch=010, loss=0.6889
Epoch=011, loss=0.6880
Epoch=012, loss=0.6868
Epoch=013, loss=0.6857
Epoch=014, loss=0.6842
Epoch=015, loss=0.6827
Epoch=016, loss=0.6809
Epoch=017, loss=0.6791
Epoch=018, loss=0.6768
Epoch=019, loss=0.6744
Epoch=020, loss=0.6719
Epoch=021, loss=0.6692
Epoch=022, loss=0.6656
Epoch=023, loss=0.6622
Epoch=024, loss=0.6584
Epoch=025, loss=0.6544
Epoch=026, loss=0.6498
Epoch=027, loss=0.6453
Epoch=028, loss=0.6383
Epoch=029, loss=0.6343
Epoch=030, loss=0.6275
Epoch=031, loss=0.6221
Epoch=032, loss=0.6139
Epoch=033, loss=0.6067
Epoch=034, loss=0.5999
Epoch=035, loss=0.5905
Epoch=036, loss=0.5838
Epoch=037, loss=0.5739
Epoch=038, loss=0.5627
Epoch=039, loss=0.5531
Epoch=040, loss=0.5430
Epoch=041, loss=0.5321
Epoch=042, loss=0.5190
Epoch=043, loss=0.5118
Epoch=044, loss=0.4966
Epoch=045, loss=0.4849
Epoch=046, loss=0.4734
Epoch=047, loss=0.4599
Epoch=048, loss=0.4505
Epoch=049, loss=0.4342
Epoch=050, loss=0.4250
Epoch=051, loss=0.4123
Epoch=052, loss=0.3967
Epoch=053, loss=0.3826
Epoch=054, loss=0.3713
Epoch=055, loss=0.3591
Epoch=056, loss=0.3466
Epoch=057, loss=0.3339
Epoch=058, loss=0.3200
Epoch=059, loss=0.3125
Epoch=060, loss=0.2933
Epoch=061, loss=0.2918
Epoch=062, loss=0.2741
Epoch=063, loss=0.2646
Epoch=064, loss=0.2532
Epoch=065, loss=0.2528
Epoch=066, loss=0.2276
Epoch=067, loss=0.2184
Epoch=068, loss=0.2216
Epoch=069, loss=0.2137
Epoch=070, loss=0.1985
Epoch=071, loss=0.2032
Epoch=072, loss=0.1872
Epoch=073, loss=0.1803
Epoch=074, loss=0.1845
Epoch=075, loss=0.1813
Epoch=076, loss=0.1733
Epoch=077, loss=0.1673
Epoch=078, loss=0.1629
Epoch=079, loss=0.1542
Epoch=080, loss=0.1485
Epoch=081, loss=0.1464
Epoch=082, loss=0.1389
Epoch=083, loss=0.1381
Epoch=084, loss=0.1386
Epoch=085, loss=0.1298
Epoch=086, loss=0.1334
Epoch=087, loss=0.1242
Epoch=088, loss=0.1183
Epoch=089, loss=0.1148
Epoch=090, loss=0.1103
Epoch=091, loss=0.1056
Epoch=092, loss=0.1092
Epoch=093, loss=0.1107
Epoch=094, loss=0.1055
Epoch=095, loss=0.0958
Epoch=096, loss=0.0997
Epoch=097, loss=0.1009
Epoch=098, loss=0.0944
Epoch=099, loss=0.0910
Epoch=100, loss=0.0949
Epoch=101, loss=0.0917
Epoch=102, loss=0.1059
Epoch=103, loss=0.0861
Epoch=104, loss=0.0905
Epoch=105, loss=0.0985
Epoch=106, loss=0.0863
Epoch=107, loss=0.0894
Epoch=108, loss=0.0803
Epoch=109, loss=0.0773
Epoch=110, loss=0.0803
Epoch=111, loss=0.0856
Epoch=112, loss=0.0807
Epoch=113, loss=0.0786
Epoch=114, loss=0.0741
Epoch=115, loss=0.0834
Epoch=116, loss=0.0771
Epoch=117, loss=0.0806
Epoch=118, loss=0.0733
Epoch=119, loss=0.0764
Epoch=120, loss=0.0751
Epoch=121, loss=0.0831
Epoch=122, loss=0.0805
Epoch=123, loss=0.0705
Epoch=124, loss=0.0681
Epoch=125, loss=0.0675
Epoch=126, loss=0.0712
Epoch=127, loss=0.0696
Epoch=128, loss=0.0737
Epoch=129, loss=0.0733
Epoch=130, loss=0.0623
Epoch=131, loss=0.0667
Epoch=132, loss=0.0620
Epoch=133, loss=0.0695
Epoch=134, loss=0.0670
Epoch=135, loss=0.0813
Epoch=136, loss=0.0582
Epoch=137, loss=0.0684
Epoch=138, loss=0.0618
Epoch=139, loss=0.0568
Epoch=140, loss=0.0606
Epoch=141, loss=0.0617
Epoch=142, loss=0.0624
Epoch=143, loss=0.0568
Epoch=144, loss=0.0613
Epoch=145, loss=0.0568
Epoch=146, loss=0.0629
Epoch=147, loss=0.0694
Epoch=148, loss=0.0670
Epoch=149, loss=0.0541
Epoch=150, loss=0.0605
Epoch=151, loss=0.0660
Epoch=152, loss=0.0525
Epoch=153, loss=0.0605
Epoch=154, loss=0.0680
Epoch=155, loss=0.0516
Epoch=156, loss=0.0599
Epoch=157, loss=0.0675
Epoch=158, loss=0.0515
Epoch=159, loss=0.0728
Epoch=160, loss=0.0554
Epoch=161, loss=0.0557
Epoch=162, loss=0.0578
Epoch=163, loss=0.0460
Epoch=164, loss=0.0538
Epoch=165, loss=0.0522
Epoch=166, loss=0.0505
Epoch=167, loss=0.0526
Epoch=168, loss=0.0502
Epoch=169, loss=0.0514
Epoch=170, loss=0.0540
Epoch=171, loss=0.0466
Epoch=172, loss=0.0436
Epoch=173, loss=0.0419
Epoch=174, loss=0.0523
Epoch=175, loss=0.0480
Epoch=176, loss=0.0478
Epoch=177, loss=0.0490
Epoch=178, loss=0.0357
Epoch=179, loss=0.0598
Epoch=180, loss=0.0462
Epoch=181, loss=0.0502
Epoch=182, loss=0.0478
Epoch=183, loss=0.0471
Epoch=184, loss=0.0379
Epoch=185, loss=0.0459
Epoch=186, loss=0.0407
Epoch=187, loss=0.0479
Epoch=188, loss=0.0447
Epoch=189, loss=0.0469
Epoch=190, loss=0.0405
Epoch=191, loss=0.0532
Epoch=192, loss=0.0564
Epoch=193, loss=0.0496
Epoch=194, loss=0.0364
Epoch=195, loss=0.0408
Epoch=196, loss=0.0545
Epoch=197, loss=0.0404
Epoch=198, loss=0.0508
Early stopping!
Loading 178th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7717+-0.0148, F1Ma=0.7310+-0.0195, acc=0.7717+-0.0148
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592583987086976, 0.7666777703571261, 0.7599170414324756, 0.7751730979142201, 0.8928571343421936, 0.7459999918937683, 0.7446808218955994, 0.8857142925262451, 0.75, 0.747582197189331, 0.7665759813447337, 0.011295254900733926, 0.7240791768770017, 0.02710549603314485, 0.7665759813447337, 0.011295254900733905], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7521721371865875, 0.753421331971914, 0.7603347147759146, 0.7608528554964966, 0.9142857193946838, 0.7480000257492065, 0.7669245600700378, 0.8999999761581421, 0.7459999918937683, 0.7601547241210938, 0.7717061795569373, 0.01481490936055849, 0.7310160391744613, 0.01947751075247325, 0.7717061795569373, 0.0148149093605585]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6918
Epoch=003, loss=0.6907
Epoch=004, loss=0.6896
Epoch=005, loss=0.6879
Epoch=006, loss=0.6861
Epoch=007, loss=0.6835
Epoch=008, loss=0.6806
Epoch=009, loss=0.6772
Epoch=010, loss=0.6731
Epoch=011, loss=0.6682
Epoch=012, loss=0.6629
Epoch=013, loss=0.6566
Epoch=014, loss=0.6487
Epoch=015, loss=0.6409
Epoch=016, loss=0.6332
Epoch=017, loss=0.6227
Epoch=018, loss=0.6106
Epoch=019, loss=0.5994
Epoch=020, loss=0.5852
Epoch=021, loss=0.5705
Epoch=022, loss=0.5537
Epoch=023, loss=0.5375
Epoch=024, loss=0.5226
Epoch=025, loss=0.5022
Epoch=026, loss=0.4817
Epoch=027, loss=0.4613
Epoch=028, loss=0.4395
Epoch=029, loss=0.4241
Epoch=030, loss=0.3989
Epoch=031, loss=0.3796
Epoch=032, loss=0.3634
Epoch=033, loss=0.3398
Epoch=034, loss=0.3268
Epoch=035, loss=0.3114
Epoch=036, loss=0.2837
Epoch=037, loss=0.2742
Epoch=038, loss=0.2595
Epoch=039, loss=0.2484
Epoch=040, loss=0.2240
Epoch=041, loss=0.2143
Epoch=042, loss=0.2155
Epoch=043, loss=0.1848
Epoch=044, loss=0.1909
Epoch=045, loss=0.1845
Epoch=046, loss=0.1751
Epoch=047, loss=0.1583
Epoch=048, loss=0.1523
Epoch=049, loss=0.1407
Epoch=050, loss=0.1386
Epoch=051, loss=0.1431
Epoch=052, loss=0.1351
Epoch=053, loss=0.1280
Epoch=054, loss=0.1228
Epoch=055, loss=0.1163
Epoch=056, loss=0.1069
Epoch=057, loss=0.1072
Epoch=058, loss=0.1129
Epoch=059, loss=0.1031
Epoch=060, loss=0.1097
Epoch=061, loss=0.1093
Epoch=062, loss=0.0896
Epoch=063, loss=0.1054
Epoch=064, loss=0.1075
Epoch=065, loss=0.0882
Epoch=066, loss=0.0763
Epoch=067, loss=0.0864
Epoch=068, loss=0.0816
Epoch=069, loss=0.0892
Epoch=070, loss=0.0912
Epoch=071, loss=0.0909
Epoch=072, loss=0.0853
Epoch=073, loss=0.0934
Epoch=074, loss=0.0860
Epoch=075, loss=0.0907
Epoch=076, loss=0.0718
Epoch=077, loss=0.0714
Epoch=078, loss=0.0815
Epoch=079, loss=0.0744
Epoch=080, loss=0.0719
Epoch=081, loss=0.0783
Epoch=082, loss=0.0609
Epoch=083, loss=0.0640
Epoch=084, loss=0.0751
Epoch=085, loss=0.0781
Epoch=086, loss=0.0773
Epoch=087, loss=0.0604
Epoch=088, loss=0.0555
Epoch=089, loss=0.0686
Epoch=090, loss=0.0580
Epoch=091, loss=0.0744
Epoch=092, loss=0.0528
Epoch=093, loss=0.0625
Epoch=094, loss=0.0583
Epoch=095, loss=0.0615
Epoch=096, loss=0.0604
Epoch=097, loss=0.0702
Epoch=098, loss=0.0594
Epoch=099, loss=0.0498
Epoch=100, loss=0.0649
Epoch=101, loss=0.0567
Epoch=102, loss=0.0567
Epoch=103, loss=0.0539
Epoch=104, loss=0.0556
Epoch=105, loss=0.0467
Epoch=106, loss=0.0585
Epoch=107, loss=0.0512
Epoch=108, loss=0.0645
Epoch=109, loss=0.0619
Epoch=110, loss=0.0577
Epoch=111, loss=0.0582
Epoch=112, loss=0.0535
Epoch=113, loss=0.0601
Epoch=114, loss=0.0416
Epoch=115, loss=0.0548
Epoch=116, loss=0.0497
Epoch=117, loss=0.0587
Epoch=118, loss=0.0579
Epoch=119, loss=0.0473
Epoch=120, loss=0.0605
Epoch=121, loss=0.0604
Epoch=122, loss=0.0588
Epoch=123, loss=0.0407
Epoch=124, loss=0.0506
Epoch=125, loss=0.0479
Epoch=126, loss=0.0566
Epoch=127, loss=0.0514
Epoch=128, loss=0.0531
Epoch=129, loss=0.0463
Epoch=130, loss=0.0413
Epoch=131, loss=0.0444
Epoch=132, loss=0.0336
Epoch=133, loss=0.0465
Epoch=134, loss=0.0492
Epoch=135, loss=0.0534
Epoch=136, loss=0.0527
Epoch=137, loss=0.0385
Epoch=138, loss=0.0508
Epoch=139, loss=0.0333
Epoch=140, loss=0.0427
Epoch=141, loss=0.0562
Epoch=142, loss=0.0558
Epoch=143, loss=0.0533
Epoch=144, loss=0.0478
Epoch=145, loss=0.0490
Epoch=146, loss=0.0542
Epoch=147, loss=0.0401
Epoch=148, loss=0.0403
Epoch=149, loss=0.0363
Epoch=150, loss=0.0319
Epoch=151, loss=0.0364
Epoch=152, loss=0.0328
Epoch=153, loss=0.0448
Epoch=154, loss=0.0357
Epoch=155, loss=0.0392
Epoch=156, loss=0.0398
Epoch=157, loss=0.0364
Epoch=158, loss=0.0368
Epoch=159, loss=0.0437
Epoch=160, loss=0.0275
Epoch=161, loss=0.0317
Epoch=162, loss=0.0407
Epoch=163, loss=0.0401
Epoch=164, loss=0.0380
Epoch=165, loss=0.0363
Epoch=166, loss=0.0431
Epoch=167, loss=0.0445
Epoch=168, loss=0.0444
Epoch=169, loss=0.0408
Epoch=170, loss=0.0363
Epoch=171, loss=0.0499
Epoch=172, loss=0.0425
Epoch=173, loss=0.0382
Epoch=174, loss=0.0448
Epoch=175, loss=0.0374
Epoch=176, loss=0.0418
Epoch=177, loss=0.0277
Epoch=178, loss=0.0283
Epoch=179, loss=0.0373
Epoch=180, loss=0.0401
Early stopping!
Loading 160th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7968+-0.0082, F1Ma=0.7774+-0.0132, acc=0.7968+-0.0082
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592583987086976, 0.7666777703571261, 0.7599170414324756, 0.7751730979142201, 0.8928571343421936, 0.7459999918937683, 0.7446808218955994, 0.8857142925262451, 0.75, 0.747582197189331, 0.7665759813447337, 0.011295254900733926, 0.7240791768770017, 0.02710549603314485, 0.7665759813447337, 0.011295254900733905], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7521721371865875, 0.753421331971914, 0.7603347147759146, 0.7608528554964966, 0.9142857193946838, 0.7480000257492065, 0.7669245600700378, 0.8999999761581421, 0.7459999918937683, 0.7601547241210938, 0.7717061795569373, 0.01481490936055849, 0.7310160391744613, 0.01947751075247325, 0.7717061795569373, 0.0148149093605585], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7699114602695721, 0.7649008356143472, 0.7864645031667561, 0.7771126295341129, 0.9357143044471741, 0.7879999876022339, 0.7886847257614136, 0.9357143044471741, 0.7879999876022339, 0.7891682982444763, 0.7968130586863583, 0.008179795930712039, 0.7773749677059738, 0.013224770017935965, 0.7968130586863584, 0.008179795930712025]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6916
Epoch=002, loss=0.6890
Epoch=003, loss=0.6856
Epoch=004, loss=0.6806
Epoch=005, loss=0.6746
Epoch=006, loss=0.6661
Epoch=007, loss=0.6560
Epoch=008, loss=0.6439
Epoch=009, loss=0.6297
Epoch=010, loss=0.6133
Epoch=011, loss=0.5960
Epoch=012, loss=0.5733
Epoch=013, loss=0.5488
Epoch=014, loss=0.5269
Epoch=015, loss=0.4981
Epoch=016, loss=0.4757
Epoch=017, loss=0.4493
Epoch=018, loss=0.4286
Epoch=019, loss=0.3932
Epoch=020, loss=0.3606
Epoch=021, loss=0.3470
Epoch=022, loss=0.3143
Epoch=023, loss=0.2868
Epoch=024, loss=0.2706
Epoch=025, loss=0.2603
Epoch=026, loss=0.2279
Epoch=027, loss=0.2222
Epoch=028, loss=0.2061
Epoch=029, loss=0.1809
Epoch=030, loss=0.2020
Epoch=031, loss=0.1749
Epoch=032, loss=0.1587
Epoch=033, loss=0.1676
Epoch=034, loss=0.1592
Epoch=035, loss=0.1512
Epoch=036, loss=0.1562
Epoch=037, loss=0.1379
Epoch=038, loss=0.1367
Epoch=039, loss=0.1284
Epoch=040, loss=0.1199
Epoch=041, loss=0.1219
Epoch=042, loss=0.1166
Epoch=043, loss=0.1157
Epoch=044, loss=0.1135
Epoch=045, loss=0.1098
Epoch=046, loss=0.0985
Epoch=047, loss=0.1017
Epoch=048, loss=0.1019
Epoch=049, loss=0.0875
Epoch=050, loss=0.0976
Epoch=051, loss=0.0990
Epoch=052, loss=0.0845
Epoch=053, loss=0.0940
Epoch=054, loss=0.0799
Epoch=055, loss=0.0843
Epoch=056, loss=0.0716
Epoch=057, loss=0.0783
Epoch=058, loss=0.0708
Epoch=059, loss=0.0701
Epoch=060, loss=0.0707
Epoch=061, loss=0.0823
Epoch=062, loss=0.0633
Epoch=063, loss=0.0687
Epoch=064, loss=0.0626
Epoch=065, loss=0.0747
Epoch=066, loss=0.0796
Epoch=067, loss=0.0658
Epoch=068, loss=0.0590
Epoch=069, loss=0.0659
Epoch=070, loss=0.0664
Epoch=071, loss=0.0588
Epoch=072, loss=0.0675
Epoch=073, loss=0.0643
Epoch=074, loss=0.0638
Epoch=075, loss=0.0744
Epoch=076, loss=0.0626
Epoch=077, loss=0.0666
Epoch=078, loss=0.0711
Epoch=079, loss=0.0725
Epoch=080, loss=0.0627
Epoch=081, loss=0.0513
Epoch=082, loss=0.0525
Epoch=083, loss=0.0629
Epoch=084, loss=0.0638
Epoch=085, loss=0.0531
Epoch=086, loss=0.0603
Epoch=087, loss=0.0393
Epoch=088, loss=0.0439
Epoch=089, loss=0.0538
Epoch=090, loss=0.0560
Epoch=091, loss=0.0579
Epoch=092, loss=0.0479
Epoch=093, loss=0.0499
Epoch=094, loss=0.0548
Epoch=095, loss=0.0550
Epoch=096, loss=0.0485
Epoch=097, loss=0.0541
Epoch=098, loss=0.0456
Epoch=099, loss=0.0413
Epoch=100, loss=0.0503
Epoch=101, loss=0.0505
Epoch=102, loss=0.0388
Epoch=103, loss=0.0326
Epoch=104, loss=0.0390
Epoch=105, loss=0.0441
Epoch=106, loss=0.0411
Epoch=107, loss=0.0492
Epoch=108, loss=0.0454
Epoch=109, loss=0.0440
Epoch=110, loss=0.0473
Epoch=111, loss=0.0478
Epoch=112, loss=0.0443
Epoch=113, loss=0.0429
Epoch=114, loss=0.0407
Epoch=115, loss=0.0398
Epoch=116, loss=0.0303
Epoch=117, loss=0.0422
Epoch=118, loss=0.0494
Epoch=119, loss=0.0323
Epoch=120, loss=0.0342
Epoch=121, loss=0.0475
Epoch=122, loss=0.0397
Epoch=123, loss=0.0439
Epoch=124, loss=0.0578
Epoch=125, loss=0.0415
Epoch=126, loss=0.0408
Epoch=127, loss=0.0451
Epoch=128, loss=0.0549
Epoch=129, loss=0.0295
Epoch=130, loss=0.0548
Epoch=131, loss=0.0305
Epoch=132, loss=0.0560
Epoch=133, loss=0.0403
Epoch=134, loss=0.0342
Epoch=135, loss=0.0415
Epoch=136, loss=0.0337
Epoch=137, loss=0.0246
Epoch=138, loss=0.0398
Epoch=139, loss=0.0427
Epoch=140, loss=0.0456
Epoch=141, loss=0.0360
Epoch=142, loss=0.0456
Epoch=143, loss=0.0232
Epoch=144, loss=0.0294
Epoch=145, loss=0.0284
Epoch=146, loss=0.0250
Epoch=147, loss=0.0294
Epoch=148, loss=0.0260
Epoch=149, loss=0.0357
Epoch=150, loss=0.0340
Epoch=151, loss=0.0311
Epoch=152, loss=0.0373
Epoch=153, loss=0.0291
Epoch=154, loss=0.0402
Epoch=155, loss=0.0213
Epoch=156, loss=0.0292
Epoch=157, loss=0.0371
Epoch=158, loss=0.0297
Epoch=159, loss=0.0326
Epoch=160, loss=0.0402
Epoch=161, loss=0.0322
Epoch=162, loss=0.0261
Epoch=163, loss=0.0223
Epoch=164, loss=0.0197
Epoch=165, loss=0.0214
Epoch=166, loss=0.0280
Epoch=167, loss=0.0212
Epoch=168, loss=0.0243
Epoch=169, loss=0.0242
Epoch=170, loss=0.0147
Epoch=171, loss=0.0226
Epoch=172, loss=0.0271
Epoch=173, loss=0.0264
Epoch=174, loss=0.0207
Epoch=175, loss=0.0293
Epoch=176, loss=0.0256
Epoch=177, loss=0.0288
Epoch=178, loss=0.0237
Epoch=179, loss=0.0267
Epoch=180, loss=0.0268
Epoch=181, loss=0.0201
Epoch=182, loss=0.0171
Epoch=183, loss=0.0269
Epoch=184, loss=0.0134
Epoch=185, loss=0.0254
Epoch=186, loss=0.0197
Epoch=187, loss=0.0265
Epoch=188, loss=0.0203
Epoch=189, loss=0.0237
Epoch=190, loss=0.0230
Epoch=191, loss=0.0204
Epoch=192, loss=0.0335
Epoch=193, loss=0.0181
Epoch=194, loss=0.0191
Epoch=195, loss=0.0219
Epoch=196, loss=0.0213
Epoch=197, loss=0.0267
Epoch=198, loss=0.0177
Epoch=199, loss=0.0156
Epoch=200, loss=0.0214
Epoch=201, loss=0.0126
Epoch=202, loss=0.0140
Epoch=203, loss=0.0241
Epoch=204, loss=0.0150
Epoch=205, loss=0.0113
Epoch=206, loss=0.0180
Epoch=207, loss=0.0285
Epoch=208, loss=0.0171
Epoch=209, loss=0.0149
Epoch=210, loss=0.0244
Epoch=211, loss=0.0244
Epoch=212, loss=0.0253
Epoch=213, loss=0.0181
Epoch=214, loss=0.0178
Epoch=215, loss=0.0188
Epoch=216, loss=0.0169
Epoch=217, loss=0.0172
Epoch=218, loss=0.0180
Epoch=219, loss=0.0197
Epoch=220, loss=0.0183
Epoch=221, loss=0.0138
Epoch=222, loss=0.0200
Epoch=223, loss=0.0172
Epoch=224, loss=0.0154
Epoch=225, loss=0.0257
Early stopping!
Loading 205th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8091+-0.0082, F1Ma=0.7940+-0.0071, acc=0.8091+-0.0082
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592583987086976, 0.7666777703571261, 0.7599170414324756, 0.7751730979142201, 0.8928571343421936, 0.7459999918937683, 0.7446808218955994, 0.8857142925262451, 0.75, 0.747582197189331, 0.7665759813447337, 0.011295254900733926, 0.7240791768770017, 0.02710549603314485, 0.7665759813447337, 0.011295254900733905], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7521721371865875, 0.753421331971914, 0.7603347147759146, 0.7608528554964966, 0.9142857193946838, 0.7480000257492065, 0.7669245600700378, 0.8999999761581421, 0.7459999918937683, 0.7601547241210938, 0.7717061795569373, 0.01481490936055849, 0.7310160391744613, 0.01947751075247325, 0.7717061795569373, 0.0148149093605585], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7699114602695721, 0.7649008356143472, 0.7864645031667561, 0.7771126295341129, 0.9357143044471741, 0.7879999876022339, 0.7886847257614136, 0.9357143044471741, 0.7879999876022339, 0.7891682982444763, 0.7968130586863583, 0.008179795930712039, 0.7773749677059738, 0.013224770017935965, 0.7968130586863584, 0.008179795930712025], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9311386116592156, 0.9222425587977163, 0.9405283567794503, 0.9309784328664088, 0.9642857313156128, 0.7839999794960022, 0.8031914830207825, 0.9642857313156128, 0.7839999794960022, 0.8027079105377197, 0.80909444228527, 0.008201925457840941, 0.7939557777838913, 0.007131987014629789, 0.80909444228527, 0.008201925457840913]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6923
Epoch=002, loss=0.6931
Epoch=003, loss=0.6828
Epoch=004, loss=0.6789
Epoch=005, loss=0.6687
Epoch=006, loss=0.6570
Epoch=007, loss=0.6415
Epoch=008, loss=0.6243
Epoch=009, loss=0.5999
Epoch=010, loss=0.5793
Epoch=011, loss=0.5593
Epoch=012, loss=0.5203
Epoch=013, loss=0.4981
Epoch=014, loss=0.4625
Epoch=015, loss=0.4258
Epoch=016, loss=0.3919
Epoch=017, loss=0.3829
Epoch=018, loss=0.3410
Epoch=019, loss=0.2984
Epoch=020, loss=0.3050
Epoch=021, loss=0.2731
Epoch=022, loss=0.2278
Epoch=023, loss=0.2304
Epoch=024, loss=0.2141
Epoch=025, loss=0.2064
Epoch=026, loss=0.1677
Epoch=027, loss=0.1388
Epoch=028, loss=0.1360
Epoch=029, loss=0.1395
Epoch=030, loss=0.1367
Epoch=031, loss=0.1127
Epoch=032, loss=0.1154
Epoch=033, loss=0.1044
Epoch=034, loss=0.0750
Epoch=035, loss=0.0819
Epoch=036, loss=0.0829
Epoch=037, loss=0.0783
Epoch=038, loss=0.0802
Epoch=039, loss=0.0677
Epoch=040, loss=0.0859
Epoch=041, loss=0.0696
Epoch=042, loss=0.0633
Epoch=043, loss=0.0634
Epoch=044, loss=0.0473
Epoch=045, loss=0.0540
Epoch=046, loss=0.0411
Epoch=047, loss=0.0523
Epoch=048, loss=0.0513
Epoch=049, loss=0.0556
Epoch=050, loss=0.0428
Epoch=051, loss=0.0421
Epoch=052, loss=0.0444
Epoch=053, loss=0.0457
Epoch=054, loss=0.0406
Epoch=055, loss=0.0374
Epoch=056, loss=0.0370
Epoch=057, loss=0.0319
Epoch=058, loss=0.0278
Epoch=059, loss=0.0287
Epoch=060, loss=0.0372
Epoch=061, loss=0.0295
Epoch=062, loss=0.0346
Epoch=063, loss=0.0301
Epoch=064, loss=0.0218
Epoch=065, loss=0.0336
Epoch=066, loss=0.0167
Epoch=067, loss=0.0295
Epoch=068, loss=0.0288
Epoch=069, loss=0.0239
Epoch=070, loss=0.0189
Epoch=071, loss=0.0190
Epoch=072, loss=0.0140
Epoch=073, loss=0.0209
Epoch=074, loss=0.0098
Epoch=075, loss=0.0169
Epoch=076, loss=0.0126
Epoch=077, loss=0.0169
Epoch=078, loss=0.0203
Epoch=079, loss=0.0185
Epoch=080, loss=0.0164
Epoch=081, loss=0.0157
Epoch=082, loss=0.0113
Epoch=083, loss=0.0124
Epoch=084, loss=0.0089
Epoch=085, loss=0.0127
Epoch=086, loss=0.0134
Epoch=087, loss=0.0160
Epoch=088, loss=0.0091
Epoch=089, loss=0.0161
Epoch=090, loss=0.0232
Epoch=091, loss=0.0159
Epoch=092, loss=0.0150
Epoch=093, loss=0.0199
Epoch=094, loss=0.0137
Epoch=095, loss=0.0082
Epoch=096, loss=0.0102
Epoch=097, loss=0.0060
Epoch=098, loss=0.0170
Epoch=099, loss=0.0139
Epoch=100, loss=0.0089
Epoch=101, loss=0.0060
Epoch=102, loss=0.0157
Epoch=103, loss=0.0068
Epoch=104, loss=0.0076
Epoch=105, loss=0.0118
Epoch=106, loss=0.0085
Epoch=107, loss=0.0087
Epoch=108, loss=0.0088
Epoch=109, loss=0.0075
Epoch=110, loss=0.0122
Epoch=111, loss=0.0068
Epoch=112, loss=0.0147
Epoch=113, loss=0.0188
Epoch=114, loss=0.0091
Epoch=115, loss=0.0115
Epoch=116, loss=0.0091
Epoch=117, loss=0.0089
Early stopping!
Loading 97th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8122+-0.0142, F1Ma=0.7936+-0.0171, acc=0.8122+-0.0142
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7141475604583107, 0.7390291360431792, 0.745320078205733, 0.7587268284543225, 0.8428571224212646, 0.7440000176429749, 0.7292069792747498, 0.8428571224212646, 0.7440000176429749, 0.7325918674468994, 0.7203264671589584, 0.019717460831054235, 0.6471580962589557, 0.05569848766651648, 0.7203264671589584, 0.019717460831054218], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7592583987086976, 0.7666777703571261, 0.7599170414324756, 0.7751730979142201, 0.8928571343421936, 0.7459999918937683, 0.7446808218955994, 0.8857142925262451, 0.75, 0.747582197189331, 0.7665759813447337, 0.011295254900733926, 0.7240791768770017, 0.02710549603314485, 0.7665759813447337, 0.011295254900733905], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7521721371865875, 0.753421331971914, 0.7603347147759146, 0.7608528554964966, 0.9142857193946838, 0.7480000257492065, 0.7669245600700378, 0.8999999761581421, 0.7459999918937683, 0.7601547241210938, 0.7717061795569373, 0.01481490936055849, 0.7310160391744613, 0.01947751075247325, 0.7717061795569373, 0.0148149093605585], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7699114602695721, 0.7649008356143472, 0.7864645031667561, 0.7771126295341129, 0.9357143044471741, 0.7879999876022339, 0.7886847257614136, 0.9357143044471741, 0.7879999876022339, 0.7891682982444763, 0.7968130586863583, 0.008179795930712039, 0.7773749677059738, 0.013224770017935965, 0.7968130586863584, 0.008179795930712025], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9311386116592156, 0.9222425587977163, 0.9405283567794503, 0.9309784328664088, 0.9642857313156128, 0.7839999794960022, 0.8031914830207825, 0.9642857313156128, 0.7839999794960022, 0.8027079105377197, 0.80909444228527, 0.008201925457840941, 0.7939557777838913, 0.007131987014629789, 0.80909444228527, 0.008201925457840913], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7437784924981174, 0.7634607694806582, 0.743932034465252, 0.7645317981256603, 0.9214285612106323, 0.800000011920929, 0.801740825176239, 0.9142857193946838, 0.800000011920929, 0.801740825176239, 0.8122036533229693, 0.014238438362729523, 0.7935844914351773, 0.017096182767558504, 0.8122036533229693, 0.014238438362729491]]
