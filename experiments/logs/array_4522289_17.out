My SLURM_ARRAY_TASK_ID:  17
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_17
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_17.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6929
Epoch=007, loss=0.6929
Epoch=008, loss=0.6928
Epoch=009, loss=0.6928
Epoch=010, loss=0.6927
Epoch=011, loss=0.6927
Epoch=012, loss=0.6926
Epoch=013, loss=0.6926
Epoch=014, loss=0.6925
Epoch=015, loss=0.6924
Epoch=016, loss=0.6923
Epoch=017, loss=0.6923
Epoch=018, loss=0.6921
Epoch=019, loss=0.6920
Epoch=020, loss=0.6919
Epoch=021, loss=0.6918
Epoch=022, loss=0.6917
Epoch=023, loss=0.6916
Epoch=024, loss=0.6914
Epoch=025, loss=0.6912
Epoch=026, loss=0.6911
Epoch=027, loss=0.6909
Epoch=028, loss=0.6908
Epoch=029, loss=0.6905
Epoch=030, loss=0.6903
Epoch=031, loss=0.6901
Epoch=032, loss=0.6898
Epoch=033, loss=0.6896
Epoch=034, loss=0.6893
Epoch=035, loss=0.6891
Epoch=036, loss=0.6888
Epoch=037, loss=0.6884
Epoch=038, loss=0.6882
Epoch=039, loss=0.6878
Epoch=040, loss=0.6873
Epoch=041, loss=0.6871
Epoch=042, loss=0.6865
Epoch=043, loss=0.6861
Epoch=044, loss=0.6857
Epoch=045, loss=0.6853
Epoch=046, loss=0.6849
Epoch=047, loss=0.6844
Epoch=048, loss=0.6838
Epoch=049, loss=0.6832
Epoch=050, loss=0.6827
Epoch=051, loss=0.6819
Epoch=052, loss=0.6814
Epoch=053, loss=0.6807
Epoch=054, loss=0.6799
Epoch=055, loss=0.6795
Epoch=056, loss=0.6786
Epoch=057, loss=0.6774
Epoch=058, loss=0.6769
Epoch=059, loss=0.6763
Epoch=060, loss=0.6751
Epoch=061, loss=0.6739
Epoch=062, loss=0.6736
Epoch=063, loss=0.6724
Epoch=064, loss=0.6714
Epoch=065, loss=0.6699
Epoch=066, loss=0.6688
Epoch=067, loss=0.6680
Epoch=068, loss=0.6668
Epoch=069, loss=0.6657
Epoch=070, loss=0.6640
Epoch=071, loss=0.6626
Epoch=072, loss=0.6614
Epoch=073, loss=0.6602
Epoch=074, loss=0.6590
Epoch=075, loss=0.6573
Epoch=076, loss=0.6556
Epoch=077, loss=0.6542
Epoch=078, loss=0.6528
Epoch=079, loss=0.6505
Epoch=080, loss=0.6494
Epoch=081, loss=0.6474
Epoch=082, loss=0.6459
Epoch=083, loss=0.6441
Epoch=084, loss=0.6415
Epoch=085, loss=0.6405
Epoch=086, loss=0.6379
Epoch=087, loss=0.6364
Epoch=088, loss=0.6342
Epoch=089, loss=0.6305
Epoch=090, loss=0.6299
Epoch=091, loss=0.6277
Epoch=092, loss=0.6253
Epoch=093, loss=0.6230
Epoch=094, loss=0.6201
Epoch=095, loss=0.6185
Epoch=096, loss=0.6156
Epoch=097, loss=0.6139
Epoch=098, loss=0.6101
Epoch=099, loss=0.6080
Epoch=100, loss=0.6059
Epoch=101, loss=0.6031
Epoch=102, loss=0.5993
Epoch=103, loss=0.5975
Epoch=104, loss=0.5937
Epoch=105, loss=0.5892
Epoch=106, loss=0.5896
Epoch=107, loss=0.5869
Epoch=108, loss=0.5836
Epoch=109, loss=0.5784
Epoch=110, loss=0.5776
Epoch=111, loss=0.5725
Epoch=112, loss=0.5693
Epoch=113, loss=0.5654
Epoch=114, loss=0.5633
Epoch=115, loss=0.5599
Epoch=116, loss=0.5558
Epoch=117, loss=0.5565
Epoch=118, loss=0.5498
Epoch=119, loss=0.5476
Epoch=120, loss=0.5449
Epoch=121, loss=0.5401
Epoch=122, loss=0.5363
Epoch=123, loss=0.5317
Epoch=124, loss=0.5287
Epoch=125, loss=0.5262
Epoch=126, loss=0.5220
Epoch=127, loss=0.5170
Epoch=128, loss=0.5137
Epoch=129, loss=0.5108
Epoch=130, loss=0.5071
Epoch=131, loss=0.5024
Epoch=132, loss=0.5008
Epoch=133, loss=0.4954
Epoch=134, loss=0.4908
Epoch=135, loss=0.4881
Epoch=136, loss=0.4846
Epoch=137, loss=0.4782
Epoch=138, loss=0.4799
Epoch=139, loss=0.4754
Epoch=140, loss=0.4687
Epoch=141, loss=0.4644
Epoch=142, loss=0.4591
Epoch=143, loss=0.4570
Epoch=144, loss=0.4484
Epoch=145, loss=0.4497
Epoch=146, loss=0.4431
Epoch=147, loss=0.4402
Epoch=148, loss=0.4372
Epoch=149, loss=0.4354
Epoch=150, loss=0.4274
Epoch=151, loss=0.4249
Epoch=152, loss=0.4237
Epoch=153, loss=0.4219
Epoch=154, loss=0.4119
Epoch=155, loss=0.4117
Epoch=156, loss=0.4097
Epoch=157, loss=0.4047
Epoch=158, loss=0.3977
Epoch=159, loss=0.3974
Epoch=160, loss=0.3861
Epoch=161, loss=0.3877
Epoch=162, loss=0.3808
Epoch=163, loss=0.3749
Epoch=164, loss=0.3785
Epoch=165, loss=0.3773
Epoch=166, loss=0.3674
Epoch=167, loss=0.3668
Epoch=168, loss=0.3585
Epoch=169, loss=0.3550
Epoch=170, loss=0.3530
Epoch=171, loss=0.3471
Epoch=172, loss=0.3466
Epoch=173, loss=0.3435
Epoch=174, loss=0.3345
Epoch=175, loss=0.3356
Epoch=176, loss=0.3384
Epoch=177, loss=0.3284
Epoch=178, loss=0.3234
Epoch=179, loss=0.3251
Epoch=180, loss=0.3216
Epoch=181, loss=0.3162
Epoch=182, loss=0.3178
Epoch=183, loss=0.3109
Epoch=184, loss=0.3090
Epoch=185, loss=0.3035
Epoch=186, loss=0.3062
Epoch=187, loss=0.2968
Epoch=188, loss=0.2994
Epoch=189, loss=0.2964
Epoch=190, loss=0.2904
Epoch=191, loss=0.2870
Epoch=192, loss=0.2815
Epoch=193, loss=0.2828
Epoch=194, loss=0.2750
Epoch=195, loss=0.2759
Epoch=196, loss=0.2716
Epoch=197, loss=0.2696
Epoch=198, loss=0.2616
Epoch=199, loss=0.2584
Epoch=200, loss=0.2655
Epoch=201, loss=0.2586
Epoch=202, loss=0.2510
Epoch=203, loss=0.2567
Epoch=204, loss=0.2517
Epoch=205, loss=0.2494
Epoch=206, loss=0.2504
Epoch=207, loss=0.2499
Epoch=208, loss=0.2416
Epoch=209, loss=0.2388
Epoch=210, loss=0.2354
Epoch=211, loss=0.2335
Epoch=212, loss=0.2357
Epoch=213, loss=0.2287
Epoch=214, loss=0.2279
Epoch=215, loss=0.2197
Epoch=216, loss=0.2161
Epoch=217, loss=0.2137
Epoch=218, loss=0.2207
Epoch=219, loss=0.2183
Epoch=220, loss=0.2127
Epoch=221, loss=0.2160
Epoch=222, loss=0.2130
Epoch=223, loss=0.2180
Epoch=224, loss=0.2116
Epoch=225, loss=0.2075
Epoch=226, loss=0.2053
Epoch=227, loss=0.2051
Epoch=228, loss=0.1977
Epoch=229, loss=0.1972
Epoch=230, loss=0.1988
Epoch=231, loss=0.1911
Epoch=232, loss=0.1927
Epoch=233, loss=0.1970
Epoch=234, loss=0.1891
Epoch=235, loss=0.1882
Epoch=236, loss=0.1817
Epoch=237, loss=0.1868
Epoch=238, loss=0.1858
Epoch=239, loss=0.1849
Epoch=240, loss=0.1793
Epoch=241, loss=0.1886
Epoch=242, loss=0.1784
Epoch=243, loss=0.1764
Epoch=244, loss=0.1818
Epoch=245, loss=0.1787
Epoch=246, loss=0.1743
Epoch=247, loss=0.1759
Epoch=248, loss=0.1688
Epoch=249, loss=0.1706
Epoch=250, loss=0.1760
Epoch=251, loss=0.1667
Epoch=252, loss=0.1621
Epoch=253, loss=0.1686
Epoch=254, loss=0.1613
Epoch=255, loss=0.1679
Epoch=256, loss=0.1583
Epoch=257, loss=0.1594
Epoch=258, loss=0.1589
Epoch=259, loss=0.1563
Epoch=260, loss=0.1467
Epoch=261, loss=0.1508
Epoch=262, loss=0.1584
Epoch=263, loss=0.1435
Epoch=264, loss=0.1563
Epoch=265, loss=0.1505
Epoch=266, loss=0.1565
Epoch=267, loss=0.1471
Epoch=268, loss=0.1499
Epoch=269, loss=0.1456
Epoch=270, loss=0.1395
Epoch=271, loss=0.1451
Epoch=272, loss=0.1395
Epoch=273, loss=0.1416
Epoch=274, loss=0.1490
Epoch=275, loss=0.1389
Epoch=276, loss=0.1392
Epoch=277, loss=0.1335
Epoch=278, loss=0.1444
Epoch=279, loss=0.1325
Epoch=280, loss=0.1423
Epoch=281, loss=0.1378
Epoch=282, loss=0.1429
Epoch=283, loss=0.1346
Epoch=284, loss=0.1354
Epoch=285, loss=0.1335
Epoch=286, loss=0.1324
Epoch=287, loss=0.1282
Epoch=288, loss=0.1304
Epoch=289, loss=0.1281
Epoch=290, loss=0.1253
Epoch=291, loss=0.1265
Epoch=292, loss=0.1320
Epoch=293, loss=0.1303
Epoch=294, loss=0.1239
Epoch=295, loss=0.1277
Epoch=296, loss=0.1256
Epoch=297, loss=0.1202
Epoch=298, loss=0.1242
Epoch=299, loss=0.1211
Epoch=300, loss=0.1336
Epoch=301, loss=0.1163
Epoch=302, loss=0.1184
Epoch=303, loss=0.1213
Epoch=304, loss=0.1119
Epoch=305, loss=0.1127
Epoch=306, loss=0.1163
Epoch=307, loss=0.1166
Epoch=308, loss=0.1161
Epoch=309, loss=0.1134
Epoch=310, loss=0.1160
Epoch=311, loss=0.1069
Epoch=312, loss=0.1175
Epoch=313, loss=0.1202
Epoch=314, loss=0.1072
Epoch=315, loss=0.1168
Epoch=316, loss=0.1056
Epoch=317, loss=0.1154
Epoch=318, loss=0.1137
Epoch=319, loss=0.1139
Epoch=320, loss=0.1141
Epoch=321, loss=0.1185
Epoch=322, loss=0.1099
Epoch=323, loss=0.1032
Epoch=324, loss=0.1109
Epoch=325, loss=0.1029
Epoch=326, loss=0.1096
Epoch=327, loss=0.1112
Epoch=328, loss=0.0924
Epoch=329, loss=0.1098
Epoch=330, loss=0.0986
Epoch=331, loss=0.1018
Epoch=332, loss=0.1180
Epoch=333, loss=0.1003
Epoch=334, loss=0.1025
Epoch=335, loss=0.1082
Epoch=336, loss=0.1012
Epoch=337, loss=0.0968
Epoch=338, loss=0.0926
Epoch=339, loss=0.1019
Epoch=340, loss=0.1063
Epoch=341, loss=0.0916
Epoch=342, loss=0.0941
Epoch=343, loss=0.1039
Epoch=344, loss=0.1061
Epoch=345, loss=0.0978
Epoch=346, loss=0.0973
Epoch=347, loss=0.1000
Epoch=348, loss=0.0906
Epoch=349, loss=0.0969
Epoch=350, loss=0.0885
Epoch=351, loss=0.0997
Epoch=352, loss=0.0899
Epoch=353, loss=0.1022
Epoch=354, loss=0.1009
Epoch=355, loss=0.0951
Epoch=356, loss=0.0971
Epoch=357, loss=0.0982
Epoch=358, loss=0.0845
Epoch=359, loss=0.0955
Epoch=360, loss=0.0905
Epoch=361, loss=0.0879
Epoch=362, loss=0.0917
Epoch=363, loss=0.0915
Epoch=364, loss=0.0855
Epoch=365, loss=0.0961
Epoch=366, loss=0.0998
Epoch=367, loss=0.0832
Epoch=368, loss=0.0850
Epoch=369, loss=0.0876
Epoch=370, loss=0.0910
Epoch=371, loss=0.0820
Epoch=372, loss=0.0834
Epoch=373, loss=0.0926
Epoch=374, loss=0.0865
Epoch=375, loss=0.0924
Epoch=376, loss=0.0860
Epoch=377, loss=0.0814
Epoch=378, loss=0.0800
Epoch=379, loss=0.0878
Epoch=380, loss=0.0779
Epoch=381, loss=0.0903
Epoch=382, loss=0.0829
Epoch=383, loss=0.0873
Epoch=384, loss=0.0875
Epoch=385, loss=0.0791
Epoch=386, loss=0.0836
Epoch=387, loss=0.0790
Epoch=388, loss=0.0805
Epoch=389, loss=0.0836
Epoch=390, loss=0.0822
Epoch=391, loss=0.0770
Epoch=392, loss=0.0835
Epoch=393, loss=0.0787
Epoch=394, loss=0.0773
Epoch=395, loss=0.0809
Epoch=396, loss=0.0735
Epoch=397, loss=0.0866
Epoch=398, loss=0.0839
Epoch=399, loss=0.0740
Epoch=400, loss=0.0789
Epoch=401, loss=0.0822
Epoch=402, loss=0.0772
Epoch=403, loss=0.0798
Epoch=404, loss=0.0743
Epoch=405, loss=0.0749
Epoch=406, loss=0.0864
Epoch=407, loss=0.0708
Epoch=408, loss=0.0767
Epoch=409, loss=0.0762
Epoch=410, loss=0.0767
Epoch=411, loss=0.0802
Epoch=412, loss=0.0783
Epoch=413, loss=0.0732
Epoch=414, loss=0.0798
Epoch=415, loss=0.0898
Epoch=416, loss=0.0705
Epoch=417, loss=0.0765
Epoch=418, loss=0.0706
Epoch=419, loss=0.0693
Epoch=420, loss=0.0770
Epoch=421, loss=0.0675
Epoch=422, loss=0.0692
Epoch=423, loss=0.0853
Epoch=424, loss=0.0774
Epoch=425, loss=0.0743
Epoch=426, loss=0.0703
Epoch=427, loss=0.0752
Epoch=428, loss=0.0665
Epoch=429, loss=0.0731
Epoch=430, loss=0.0717
Epoch=431, loss=0.0730
Epoch=432, loss=0.0744
Epoch=433, loss=0.0740
Epoch=434, loss=0.0741
Epoch=435, loss=0.0682
Epoch=436, loss=0.0634
Epoch=437, loss=0.0717
Epoch=438, loss=0.0669
Epoch=439, loss=0.0712
Epoch=440, loss=0.0680
Epoch=441, loss=0.0765
Epoch=442, loss=0.0671
Epoch=443, loss=0.0801
Epoch=444, loss=0.0677
Epoch=445, loss=0.0683
Epoch=446, loss=0.0721
Epoch=447, loss=0.0735
Epoch=448, loss=0.0600
Epoch=449, loss=0.0746
Epoch=450, loss=0.0657
Epoch=451, loss=0.0586
Epoch=452, loss=0.0663
Epoch=453, loss=0.0639
Epoch=454, loss=0.0676
Epoch=455, loss=0.0642
Epoch=456, loss=0.0651
Epoch=457, loss=0.0666
Epoch=458, loss=0.0659
Epoch=459, loss=0.0681
Epoch=460, loss=0.0588
Epoch=461, loss=0.0587
Epoch=462, loss=0.0649
Epoch=463, loss=0.0580
Epoch=464, loss=0.0655
Epoch=465, loss=0.0628
Epoch=466, loss=0.0661
Epoch=467, loss=0.0663
Epoch=468, loss=0.0621
Epoch=469, loss=0.0731
Epoch=470, loss=0.0626
Epoch=471, loss=0.0593
Epoch=472, loss=0.0582
Epoch=473, loss=0.0723
Epoch=474, loss=0.0647
Epoch=475, loss=0.0719
Epoch=476, loss=0.0688
Epoch=477, loss=0.0550
Epoch=478, loss=0.0588
Epoch=479, loss=0.0732
Epoch=480, loss=0.0575
Epoch=481, loss=0.0671
Epoch=482, loss=0.0654
Epoch=483, loss=0.0715
Epoch=484, loss=0.0632
Epoch=485, loss=0.0641
Epoch=486, loss=0.0585
Epoch=487, loss=0.0640
Epoch=488, loss=0.0570
Epoch=489, loss=0.0699
Epoch=490, loss=0.0556
Epoch=491, loss=0.0550
Epoch=492, loss=0.0621
Epoch=493, loss=0.0516
Epoch=494, loss=0.0649
Epoch=495, loss=0.0569
Epoch=496, loss=0.0536
Epoch=497, loss=0.0513
Epoch=498, loss=0.0590
Epoch=499, loss=0.0495
Loading 499th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.6928+-0.0218, F1Ma=0.6298+-0.0466, acc=0.6928+-0.0218
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6924
Epoch=009, loss=0.6923
Epoch=010, loss=0.6922
Epoch=011, loss=0.6920
Epoch=012, loss=0.6918
Epoch=013, loss=0.6915
Epoch=014, loss=0.6912
Epoch=015, loss=0.6910
Epoch=016, loss=0.6906
Epoch=017, loss=0.6903
Epoch=018, loss=0.6899
Epoch=019, loss=0.6894
Epoch=020, loss=0.6890
Epoch=021, loss=0.6886
Epoch=022, loss=0.6880
Epoch=023, loss=0.6874
Epoch=024, loss=0.6867
Epoch=025, loss=0.6861
Epoch=026, loss=0.6855
Epoch=027, loss=0.6846
Epoch=028, loss=0.6836
Epoch=029, loss=0.6827
Epoch=030, loss=0.6818
Epoch=031, loss=0.6807
Epoch=032, loss=0.6795
Epoch=033, loss=0.6783
Epoch=034, loss=0.6768
Epoch=035, loss=0.6754
Epoch=036, loss=0.6738
Epoch=037, loss=0.6722
Epoch=038, loss=0.6707
Epoch=039, loss=0.6688
Epoch=040, loss=0.6672
Epoch=041, loss=0.6645
Epoch=042, loss=0.6626
Epoch=043, loss=0.6599
Epoch=044, loss=0.6582
Epoch=045, loss=0.6555
Epoch=046, loss=0.6529
Epoch=047, loss=0.6498
Epoch=048, loss=0.6475
Epoch=049, loss=0.6438
Epoch=050, loss=0.6410
Epoch=051, loss=0.6378
Epoch=052, loss=0.6346
Epoch=053, loss=0.6305
Epoch=054, loss=0.6260
Epoch=055, loss=0.6233
Epoch=056, loss=0.6188
Epoch=057, loss=0.6145
Epoch=058, loss=0.6099
Epoch=059, loss=0.6042
Epoch=060, loss=0.6017
Epoch=061, loss=0.5941
Epoch=062, loss=0.5905
Epoch=063, loss=0.5846
Epoch=064, loss=0.5792
Epoch=065, loss=0.5738
Epoch=066, loss=0.5693
Epoch=067, loss=0.5612
Epoch=068, loss=0.5554
Epoch=069, loss=0.5494
Epoch=070, loss=0.5439
Epoch=071, loss=0.5390
Epoch=072, loss=0.5301
Epoch=073, loss=0.5252
Epoch=074, loss=0.5188
Epoch=075, loss=0.5097
Epoch=076, loss=0.5043
Epoch=077, loss=0.4965
Epoch=078, loss=0.4886
Epoch=079, loss=0.4804
Epoch=080, loss=0.4753
Epoch=081, loss=0.4684
Epoch=082, loss=0.4600
Epoch=083, loss=0.4515
Epoch=084, loss=0.4472
Epoch=085, loss=0.4358
Epoch=086, loss=0.4280
Epoch=087, loss=0.4225
Epoch=088, loss=0.4187
Epoch=089, loss=0.4058
Epoch=090, loss=0.3949
Epoch=091, loss=0.3904
Epoch=092, loss=0.3833
Epoch=093, loss=0.3819
Epoch=094, loss=0.3719
Epoch=095, loss=0.3591
Epoch=096, loss=0.3572
Epoch=097, loss=0.3483
Epoch=098, loss=0.3455
Epoch=099, loss=0.3310
Epoch=100, loss=0.3338
Epoch=101, loss=0.3209
Epoch=102, loss=0.3159
Epoch=103, loss=0.3072
Epoch=104, loss=0.3016
Epoch=105, loss=0.2886
Epoch=106, loss=0.2918
Epoch=107, loss=0.2828
Epoch=108, loss=0.2789
Epoch=109, loss=0.2664
Epoch=110, loss=0.2640
Epoch=111, loss=0.2622
Epoch=112, loss=0.2577
Epoch=113, loss=0.2479
Epoch=114, loss=0.2469
Epoch=115, loss=0.2370
Epoch=116, loss=0.2328
Epoch=117, loss=0.2296
Epoch=118, loss=0.2170
Epoch=119, loss=0.2181
Epoch=120, loss=0.2150
Epoch=121, loss=0.2109
Epoch=122, loss=0.2089
Epoch=123, loss=0.2004
Epoch=124, loss=0.2054
Epoch=125, loss=0.2011
Epoch=126, loss=0.1973
Epoch=127, loss=0.1928
Epoch=128, loss=0.1841
Epoch=129, loss=0.1858
Epoch=130, loss=0.1831
Epoch=131, loss=0.1797
Epoch=132, loss=0.1747
Epoch=133, loss=0.1732
Epoch=134, loss=0.1716
Epoch=135, loss=0.1647
Epoch=136, loss=0.1596
Epoch=137, loss=0.1598
Epoch=138, loss=0.1678
Epoch=139, loss=0.1551
Epoch=140, loss=0.1512
Epoch=141, loss=0.1581
Epoch=142, loss=0.1496
Epoch=143, loss=0.1530
Epoch=144, loss=0.1443
Epoch=145, loss=0.1397
Epoch=146, loss=0.1393
Epoch=147, loss=0.1371
Epoch=148, loss=0.1357
Epoch=149, loss=0.1344
Epoch=150, loss=0.1334
Epoch=151, loss=0.1402
Epoch=152, loss=0.1269
Epoch=153, loss=0.1260
Epoch=154, loss=0.1222
Epoch=155, loss=0.1189
Epoch=156, loss=0.1300
Epoch=157, loss=0.1305
Epoch=158, loss=0.1117
Epoch=159, loss=0.1156
Epoch=160, loss=0.1224
Epoch=161, loss=0.1223
Epoch=162, loss=0.1121
Epoch=163, loss=0.1140
Epoch=164, loss=0.1164
Epoch=165, loss=0.1150
Epoch=166, loss=0.1133
Epoch=167, loss=0.1093
Epoch=168, loss=0.1161
Epoch=169, loss=0.0994
Epoch=170, loss=0.1010
Epoch=171, loss=0.0996
Epoch=172, loss=0.1034
Epoch=173, loss=0.0979
Epoch=174, loss=0.1049
Epoch=175, loss=0.1078
Epoch=176, loss=0.0984
Epoch=177, loss=0.0970
Epoch=178, loss=0.0984
Epoch=179, loss=0.1043
Epoch=180, loss=0.0911
Epoch=181, loss=0.0951
Epoch=182, loss=0.0996
Epoch=183, loss=0.0903
Epoch=184, loss=0.0907
Epoch=185, loss=0.0820
Epoch=186, loss=0.0906
Epoch=187, loss=0.0900
Epoch=188, loss=0.0937
Epoch=189, loss=0.0910
Epoch=190, loss=0.0839
Epoch=191, loss=0.0897
Epoch=192, loss=0.0935
Epoch=193, loss=0.0872
Epoch=194, loss=0.0878
Epoch=195, loss=0.0808
Epoch=196, loss=0.0798
Epoch=197, loss=0.0851
Epoch=198, loss=0.0914
Epoch=199, loss=0.0804
Epoch=200, loss=0.0818
Epoch=201, loss=0.0844
Epoch=202, loss=0.0770
Epoch=203, loss=0.0788
Epoch=204, loss=0.0714
Epoch=205, loss=0.0726
Epoch=206, loss=0.0770
Epoch=207, loss=0.0727
Epoch=208, loss=0.0836
Epoch=209, loss=0.0686
Epoch=210, loss=0.0817
Epoch=211, loss=0.0742
Epoch=212, loss=0.0651
Epoch=213, loss=0.0695
Epoch=214, loss=0.0723
Epoch=215, loss=0.0726
Epoch=216, loss=0.0753
Epoch=217, loss=0.0688
Epoch=218, loss=0.0788
Epoch=219, loss=0.0682
Epoch=220, loss=0.0709
Epoch=221, loss=0.0655
Epoch=222, loss=0.0739
Epoch=223, loss=0.0692
Epoch=224, loss=0.0785
Epoch=225, loss=0.0653
Epoch=226, loss=0.0740
Epoch=227, loss=0.0626
Epoch=228, loss=0.0675
Epoch=229, loss=0.0598
Epoch=230, loss=0.0606
Epoch=231, loss=0.0624
Epoch=232, loss=0.0654
Epoch=233, loss=0.0592
Epoch=234, loss=0.0564
Epoch=235, loss=0.0568
Epoch=236, loss=0.0676
Epoch=237, loss=0.0719
Epoch=238, loss=0.0685
Epoch=239, loss=0.0629
Epoch=240, loss=0.0670
Epoch=241, loss=0.0617
Epoch=242, loss=0.0624
Epoch=243, loss=0.0706
Epoch=244, loss=0.0605
Epoch=245, loss=0.0661
Epoch=246, loss=0.0616
Epoch=247, loss=0.0578
Epoch=248, loss=0.0482
Epoch=249, loss=0.0540
Epoch=250, loss=0.0586
Epoch=251, loss=0.0581
Epoch=252, loss=0.0657
Epoch=253, loss=0.0604
Epoch=254, loss=0.0583
Epoch=255, loss=0.0524
Epoch=256, loss=0.0572
Epoch=257, loss=0.0560
Epoch=258, loss=0.0616
Epoch=259, loss=0.0580
Epoch=260, loss=0.0617
Epoch=261, loss=0.0572
Epoch=262, loss=0.0515
Epoch=263, loss=0.0581
Epoch=264, loss=0.0564
Epoch=265, loss=0.0560
Epoch=266, loss=0.0575
Epoch=267, loss=0.0532
Epoch=268, loss=0.0597
Early stopping!
Loading 248th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7594+-0.0053, F1Ma=0.7257+-0.0123, acc=0.7594+-0.0053
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7759531706257288, 0.770145337156762, 0.7685441563538558, 0.7712987521905887, 0.8642857074737549, 0.7720000147819519, 0.7848162651062012, 0.8500000238418579, 0.7720000147819519, 0.782882034778595, 0.7594247959580256, 0.005254704634638344, 0.7256654108243084, 0.012264534077316567, 0.7594247959580256, 0.005254704634638344]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6924
Epoch=005, loss=0.6921
Epoch=006, loss=0.6917
Epoch=007, loss=0.6913
Epoch=008, loss=0.6907
Epoch=009, loss=0.6901
Epoch=010, loss=0.6894
Epoch=011, loss=0.6886
Epoch=012, loss=0.6877
Epoch=013, loss=0.6866
Epoch=014, loss=0.6852
Epoch=015, loss=0.6838
Epoch=016, loss=0.6822
Epoch=017, loss=0.6803
Epoch=018, loss=0.6784
Epoch=019, loss=0.6759
Epoch=020, loss=0.6734
Epoch=021, loss=0.6710
Epoch=022, loss=0.6675
Epoch=023, loss=0.6644
Epoch=024, loss=0.6599
Epoch=025, loss=0.6563
Epoch=026, loss=0.6515
Epoch=027, loss=0.6468
Epoch=028, loss=0.6416
Epoch=029, loss=0.6354
Epoch=030, loss=0.6301
Epoch=031, loss=0.6240
Epoch=032, loss=0.6169
Epoch=033, loss=0.6085
Epoch=034, loss=0.6016
Epoch=035, loss=0.5923
Epoch=036, loss=0.5840
Epoch=037, loss=0.5740
Epoch=038, loss=0.5651
Epoch=039, loss=0.5524
Epoch=040, loss=0.5441
Epoch=041, loss=0.5326
Epoch=042, loss=0.5194
Epoch=043, loss=0.5092
Epoch=044, loss=0.4958
Epoch=045, loss=0.4887
Epoch=046, loss=0.4728
Epoch=047, loss=0.4581
Epoch=048, loss=0.4483
Epoch=049, loss=0.4351
Epoch=050, loss=0.4198
Epoch=051, loss=0.4077
Epoch=052, loss=0.3954
Epoch=053, loss=0.3799
Epoch=054, loss=0.3678
Epoch=055, loss=0.3565
Epoch=056, loss=0.3410
Epoch=057, loss=0.3359
Epoch=058, loss=0.3239
Epoch=059, loss=0.3099
Epoch=060, loss=0.3044
Epoch=061, loss=0.2903
Epoch=062, loss=0.2694
Epoch=063, loss=0.2788
Epoch=064, loss=0.2551
Epoch=065, loss=0.2482
Epoch=066, loss=0.2422
Epoch=067, loss=0.2343
Epoch=068, loss=0.2310
Epoch=069, loss=0.2102
Epoch=070, loss=0.2092
Epoch=071, loss=0.1935
Epoch=072, loss=0.1902
Epoch=073, loss=0.1833
Epoch=074, loss=0.1798
Epoch=075, loss=0.1753
Epoch=076, loss=0.1792
Epoch=077, loss=0.1590
Epoch=078, loss=0.1611
Epoch=079, loss=0.1559
Epoch=080, loss=0.1569
Epoch=081, loss=0.1497
Epoch=082, loss=0.1414
Epoch=083, loss=0.1406
Epoch=084, loss=0.1262
Epoch=085, loss=0.1419
Epoch=086, loss=0.1270
Epoch=087, loss=0.1311
Epoch=088, loss=0.1234
Epoch=089, loss=0.1178
Epoch=090, loss=0.1131
Epoch=091, loss=0.1096
Epoch=092, loss=0.1139
Epoch=093, loss=0.1083
Epoch=094, loss=0.1092
Epoch=095, loss=0.1060
Epoch=096, loss=0.1047
Epoch=097, loss=0.0958
Epoch=098, loss=0.1029
Epoch=099, loss=0.1070
Epoch=100, loss=0.1068
Epoch=101, loss=0.0945
Epoch=102, loss=0.0915
Epoch=103, loss=0.1055
Epoch=104, loss=0.0971
Epoch=105, loss=0.0845
Epoch=106, loss=0.0924
Epoch=107, loss=0.0992
Epoch=108, loss=0.0830
Epoch=109, loss=0.0880
Epoch=110, loss=0.0859
Epoch=111, loss=0.0768
Epoch=112, loss=0.0766
Epoch=113, loss=0.0795
Epoch=114, loss=0.0896
Epoch=115, loss=0.0801
Epoch=116, loss=0.0795
Epoch=117, loss=0.0775
Epoch=118, loss=0.0761
Epoch=119, loss=0.0656
Epoch=120, loss=0.0848
Epoch=121, loss=0.0734
Epoch=122, loss=0.0732
Epoch=123, loss=0.0672
Epoch=124, loss=0.0739
Epoch=125, loss=0.0614
Epoch=126, loss=0.0657
Epoch=127, loss=0.0711
Epoch=128, loss=0.0702
Epoch=129, loss=0.0756
Epoch=130, loss=0.0581
Epoch=131, loss=0.0749
Epoch=132, loss=0.0666
Epoch=133, loss=0.0661
Epoch=134, loss=0.0729
Epoch=135, loss=0.0715
Epoch=136, loss=0.0652
Epoch=137, loss=0.0612
Epoch=138, loss=0.0625
Epoch=139, loss=0.0661
Epoch=140, loss=0.0571
Epoch=141, loss=0.0606
Epoch=142, loss=0.0612
Epoch=143, loss=0.0540
Epoch=144, loss=0.0601
Epoch=145, loss=0.0605
Epoch=146, loss=0.0600
Epoch=147, loss=0.0586
Epoch=148, loss=0.0565
Epoch=149, loss=0.0503
Epoch=150, loss=0.0637
Epoch=151, loss=0.0636
Epoch=152, loss=0.0584
Epoch=153, loss=0.0530
Epoch=154, loss=0.0626
Epoch=155, loss=0.0533
Epoch=156, loss=0.0563
Epoch=157, loss=0.0555
Epoch=158, loss=0.0649
Epoch=159, loss=0.0532
Epoch=160, loss=0.0532
Epoch=161, loss=0.0539
Epoch=162, loss=0.0577
Epoch=163, loss=0.0565
Epoch=164, loss=0.0528
Epoch=165, loss=0.0479
Epoch=166, loss=0.0561
Epoch=167, loss=0.0467
Epoch=168, loss=0.0532
Epoch=169, loss=0.0503
Epoch=170, loss=0.0521
Epoch=171, loss=0.0561
Epoch=172, loss=0.0500
Epoch=173, loss=0.0539
Epoch=174, loss=0.0557
Epoch=175, loss=0.0508
Epoch=176, loss=0.0496
Epoch=177, loss=0.0467
Epoch=178, loss=0.0447
Epoch=179, loss=0.0428
Epoch=180, loss=0.0425
Epoch=181, loss=0.0477
Epoch=182, loss=0.0503
Epoch=183, loss=0.0421
Epoch=184, loss=0.0409
Epoch=185, loss=0.0419
Epoch=186, loss=0.0485
Epoch=187, loss=0.0429
Epoch=188, loss=0.0537
Epoch=189, loss=0.0391
Epoch=190, loss=0.0525
Epoch=191, loss=0.0474
Epoch=192, loss=0.0479
Epoch=193, loss=0.0463
Epoch=194, loss=0.0534
Epoch=195, loss=0.0374
Epoch=196, loss=0.0529
Epoch=197, loss=0.0403
Epoch=198, loss=0.0445
Epoch=199, loss=0.0485
Epoch=200, loss=0.0487
Epoch=201, loss=0.0444
Epoch=202, loss=0.0455
Epoch=203, loss=0.0520
Epoch=204, loss=0.0495
Epoch=205, loss=0.0464
Epoch=206, loss=0.0392
Epoch=207, loss=0.0383
Epoch=208, loss=0.0336
Epoch=209, loss=0.0526
Epoch=210, loss=0.0445
Epoch=211, loss=0.0399
Epoch=212, loss=0.0499
Epoch=213, loss=0.0476
Epoch=214, loss=0.0375
Epoch=215, loss=0.0415
Epoch=216, loss=0.0487
Epoch=217, loss=0.0378
Epoch=218, loss=0.0395
Epoch=219, loss=0.0422
Epoch=220, loss=0.0290
Epoch=221, loss=0.0500
Epoch=222, loss=0.0376
Epoch=223, loss=0.0361
Epoch=224, loss=0.0374
Epoch=225, loss=0.0368
Epoch=226, loss=0.0338
Epoch=227, loss=0.0356
Epoch=228, loss=0.0357
Epoch=229, loss=0.0292
Epoch=230, loss=0.0407
Epoch=231, loss=0.0441
Epoch=232, loss=0.0391
Epoch=233, loss=0.0411
Epoch=234, loss=0.0416
Epoch=235, loss=0.0359
Epoch=236, loss=0.0377
Epoch=237, loss=0.0431
Epoch=238, loss=0.0387
Epoch=239, loss=0.0432
Epoch=240, loss=0.0376
Early stopping!
Loading 220th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7887+-0.0096, F1Ma=0.7647+-0.0158, acc=0.7887+-0.0096
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7759531706257288, 0.770145337156762, 0.7685441563538558, 0.7712987521905887, 0.8642857074737549, 0.7720000147819519, 0.7848162651062012, 0.8500000238418579, 0.7720000147819519, 0.782882034778595, 0.7594247959580256, 0.005254704634638344, 0.7256654108243084, 0.012264534077316567, 0.7594247959580256, 0.005254704634638344], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7641984885025149, 0.7641306616056764, 0.7613464924440732, 0.7671901064193413, 0.8857142925262451, 0.8119999766349792, 0.7877175807952881, 0.8928571343421936, 0.8100000023841858, 0.7877175807952881, 0.7887291099883404, 0.009604015194370692, 0.7647056682607795, 0.01583740084592843, 0.7887291099883404, 0.009604015194370688]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6927
Epoch=002, loss=0.6921
Epoch=003, loss=0.6914
Epoch=004, loss=0.6903
Epoch=005, loss=0.6891
Epoch=006, loss=0.6875
Epoch=007, loss=0.6852
Epoch=008, loss=0.6828
Epoch=009, loss=0.6797
Epoch=010, loss=0.6762
Epoch=011, loss=0.6722
Epoch=012, loss=0.6670
Epoch=013, loss=0.6616
Epoch=014, loss=0.6548
Epoch=015, loss=0.6480
Epoch=016, loss=0.6394
Epoch=017, loss=0.6290
Epoch=018, loss=0.6212
Epoch=019, loss=0.6079
Epoch=020, loss=0.5976
Epoch=021, loss=0.5830
Epoch=022, loss=0.5676
Epoch=023, loss=0.5519
Epoch=024, loss=0.5324
Epoch=025, loss=0.5215
Epoch=026, loss=0.4975
Epoch=027, loss=0.4802
Epoch=028, loss=0.4596
Epoch=029, loss=0.4385
Epoch=030, loss=0.4178
Epoch=031, loss=0.3984
Epoch=032, loss=0.3775
Epoch=033, loss=0.3510
Epoch=034, loss=0.3403
Epoch=035, loss=0.3213
Epoch=036, loss=0.2993
Epoch=037, loss=0.2781
Epoch=038, loss=0.2603
Epoch=039, loss=0.2406
Epoch=040, loss=0.2396
Epoch=041, loss=0.2240
Epoch=042, loss=0.1978
Epoch=043, loss=0.2065
Epoch=044, loss=0.1922
Epoch=045, loss=0.1703
Epoch=046, loss=0.1688
Epoch=047, loss=0.1467
Epoch=048, loss=0.1566
Epoch=049, loss=0.1429
Epoch=050, loss=0.1469
Epoch=051, loss=0.1316
Epoch=052, loss=0.1263
Epoch=053, loss=0.1330
Epoch=054, loss=0.1134
Epoch=055, loss=0.1172
Epoch=056, loss=0.1216
Epoch=057, loss=0.0916
Epoch=058, loss=0.1096
Epoch=059, loss=0.1045
Epoch=060, loss=0.0970
Epoch=061, loss=0.1007
Epoch=062, loss=0.0938
Epoch=063, loss=0.0888
Epoch=064, loss=0.0909
Epoch=065, loss=0.0937
Epoch=066, loss=0.0847
Epoch=067, loss=0.0886
Epoch=068, loss=0.0770
Epoch=069, loss=0.0886
Epoch=070, loss=0.0828
Epoch=071, loss=0.0875
Epoch=072, loss=0.0790
Epoch=073, loss=0.0835
Epoch=074, loss=0.0788
Epoch=075, loss=0.0871
Epoch=076, loss=0.0671
Epoch=077, loss=0.0853
Epoch=078, loss=0.0693
Epoch=079, loss=0.0845
Epoch=080, loss=0.0661
Epoch=081, loss=0.0768
Epoch=082, loss=0.0655
Epoch=083, loss=0.0694
Epoch=084, loss=0.0667
Epoch=085, loss=0.0604
Epoch=086, loss=0.0679
Epoch=087, loss=0.0757
Epoch=088, loss=0.0787
Epoch=089, loss=0.0651
Epoch=090, loss=0.0568
Epoch=091, loss=0.0599
Epoch=092, loss=0.0671
Epoch=093, loss=0.0564
Epoch=094, loss=0.0603
Epoch=095, loss=0.0505
Epoch=096, loss=0.0615
Epoch=097, loss=0.0605
Epoch=098, loss=0.0630
Epoch=099, loss=0.0594
Epoch=100, loss=0.0472
Epoch=101, loss=0.0565
Epoch=102, loss=0.0537
Epoch=103, loss=0.0555
Epoch=104, loss=0.0563
Epoch=105, loss=0.0568
Epoch=106, loss=0.0495
Epoch=107, loss=0.0476
Epoch=108, loss=0.0635
Epoch=109, loss=0.0614
Epoch=110, loss=0.0550
Epoch=111, loss=0.0539
Epoch=112, loss=0.0545
Epoch=113, loss=0.0544
Epoch=114, loss=0.0511
Epoch=115, loss=0.0510
Epoch=116, loss=0.0505
Epoch=117, loss=0.0558
Epoch=118, loss=0.0575
Epoch=119, loss=0.0470
Epoch=120, loss=0.0561
Epoch=121, loss=0.0485
Epoch=122, loss=0.0671
Epoch=123, loss=0.0491
Epoch=124, loss=0.0577
Epoch=125, loss=0.0599
Epoch=126, loss=0.0586
Epoch=127, loss=0.0467
Epoch=128, loss=0.0493
Epoch=129, loss=0.0421
Epoch=130, loss=0.0487
Epoch=131, loss=0.0467
Epoch=132, loss=0.0417
Epoch=133, loss=0.0569
Epoch=134, loss=0.0459
Epoch=135, loss=0.0438
Epoch=136, loss=0.0546
Epoch=137, loss=0.0457
Epoch=138, loss=0.0454
Epoch=139, loss=0.0418
Epoch=140, loss=0.0347
Epoch=141, loss=0.0454
Epoch=142, loss=0.0545
Epoch=143, loss=0.0345
Epoch=144, loss=0.0360
Epoch=145, loss=0.0549
Epoch=146, loss=0.0399
Epoch=147, loss=0.0362
Epoch=148, loss=0.0386
Epoch=149, loss=0.0428
Epoch=150, loss=0.0435
Epoch=151, loss=0.0415
Epoch=152, loss=0.0517
Epoch=153, loss=0.0488
Epoch=154, loss=0.0389
Epoch=155, loss=0.0337
Epoch=156, loss=0.0327
Epoch=157, loss=0.0370
Epoch=158, loss=0.0398
Epoch=159, loss=0.0405
Epoch=160, loss=0.0477
Epoch=161, loss=0.0487
Epoch=162, loss=0.0327
Epoch=163, loss=0.0364
Epoch=164, loss=0.0383
Epoch=165, loss=0.0301
Epoch=166, loss=0.0442
Epoch=167, loss=0.0309
Epoch=168, loss=0.0515
Epoch=169, loss=0.0505
Epoch=170, loss=0.0271
Epoch=171, loss=0.0491
Epoch=172, loss=0.0417
Epoch=173, loss=0.0387
Epoch=174, loss=0.0356
Epoch=175, loss=0.0337
Epoch=176, loss=0.0365
Epoch=177, loss=0.0301
Epoch=178, loss=0.0431
Epoch=179, loss=0.0270
Epoch=180, loss=0.0394
Epoch=181, loss=0.0271
Epoch=182, loss=0.0427
Epoch=183, loss=0.0340
Epoch=184, loss=0.0388
Epoch=185, loss=0.0349
Epoch=186, loss=0.0286
Epoch=187, loss=0.0331
Epoch=188, loss=0.0395
Epoch=189, loss=0.0273
Epoch=190, loss=0.0332
Epoch=191, loss=0.0270
Epoch=192, loss=0.0321
Epoch=193, loss=0.0289
Epoch=194, loss=0.0386
Epoch=195, loss=0.0399
Epoch=196, loss=0.0340
Epoch=197, loss=0.0312
Epoch=198, loss=0.0359
Epoch=199, loss=0.0252
Epoch=200, loss=0.0357
Epoch=201, loss=0.0298
Epoch=202, loss=0.0347
Epoch=203, loss=0.0362
Epoch=204, loss=0.0344
Epoch=205, loss=0.0284
Epoch=206, loss=0.0342
Epoch=207, loss=0.0293
Epoch=208, loss=0.0382
Epoch=209, loss=0.0393
Epoch=210, loss=0.0311
Epoch=211, loss=0.0181
Epoch=212, loss=0.0307
Epoch=213, loss=0.0303
Epoch=214, loss=0.0230
Epoch=215, loss=0.0372
Epoch=216, loss=0.0429
Epoch=217, loss=0.0347
Epoch=218, loss=0.0259
Epoch=219, loss=0.0247
Epoch=220, loss=0.0350
Epoch=221, loss=0.0289
Epoch=222, loss=0.0223
Epoch=223, loss=0.0396
Epoch=224, loss=0.0282
Epoch=225, loss=0.0392
Epoch=226, loss=0.0279
Epoch=227, loss=0.0376
Epoch=228, loss=0.0281
Epoch=229, loss=0.0224
Epoch=230, loss=0.0233
Epoch=231, loss=0.0210
Early stopping!
Loading 211th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8025+-0.0067, F1Ma=0.7809+-0.0148, acc=0.8025+-0.0067
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7759531706257288, 0.770145337156762, 0.7685441563538558, 0.7712987521905887, 0.8642857074737549, 0.7720000147819519, 0.7848162651062012, 0.8500000238418579, 0.7720000147819519, 0.782882034778595, 0.7594247959580256, 0.005254704634638344, 0.7256654108243084, 0.012264534077316567, 0.7594247959580256, 0.005254704634638344], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7641984885025149, 0.7641306616056764, 0.7613464924440732, 0.7671901064193413, 0.8857142925262451, 0.8119999766349792, 0.7877175807952881, 0.8928571343421936, 0.8100000023841858, 0.7877175807952881, 0.7887291099883404, 0.009604015194370692, 0.7647056682607795, 0.01583740084592843, 0.7887291099883404, 0.009604015194370688], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7830520921705256, 0.7730339439646632, 0.7917358288115391, 0.7814137614476941, 0.9428571462631226, 0.7900000214576721, 0.8007736802101135, 0.9428571462631226, 0.7879999876022339, 0.8007736802101135, 0.8024873688301593, 0.006679378487039522, 0.7808963528066803, 0.014766322721061551, 0.8024873688301593, 0.006679378487039504]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6915
Epoch=002, loss=0.6887
Epoch=003, loss=0.6847
Epoch=004, loss=0.6797
Epoch=005, loss=0.6728
Epoch=006, loss=0.6644
Epoch=007, loss=0.6537
Epoch=008, loss=0.6412
Epoch=009, loss=0.6274
Epoch=010, loss=0.6112
Epoch=011, loss=0.5927
Epoch=012, loss=0.5702
Epoch=013, loss=0.5475
Epoch=014, loss=0.5222
Epoch=015, loss=0.4965
Epoch=016, loss=0.4683
Epoch=017, loss=0.4412
Epoch=018, loss=0.4072
Epoch=019, loss=0.3841
Epoch=020, loss=0.3548
Epoch=021, loss=0.3233
Epoch=022, loss=0.3141
Epoch=023, loss=0.2826
Epoch=024, loss=0.2632
Epoch=025, loss=0.2558
Epoch=026, loss=0.2318
Epoch=027, loss=0.2219
Epoch=028, loss=0.2065
Epoch=029, loss=0.1984
Epoch=030, loss=0.1766
Epoch=031, loss=0.1614
Epoch=032, loss=0.1598
Epoch=033, loss=0.1574
Epoch=034, loss=0.1353
Epoch=035, loss=0.1390
Epoch=036, loss=0.1308
Epoch=037, loss=0.1382
Epoch=038, loss=0.1128
Epoch=039, loss=0.1290
Epoch=040, loss=0.1132
Epoch=041, loss=0.1053
Epoch=042, loss=0.1179
Epoch=043, loss=0.1175
Epoch=044, loss=0.1171
Epoch=045, loss=0.0961
Epoch=046, loss=0.1001
Epoch=047, loss=0.0908
Epoch=048, loss=0.1137
Epoch=049, loss=0.0970
Epoch=050, loss=0.0886
Epoch=051, loss=0.0979
Epoch=052, loss=0.0912
Epoch=053, loss=0.0854
Epoch=054, loss=0.0850
Epoch=055, loss=0.0845
Epoch=056, loss=0.1030
Epoch=057, loss=0.0726
Epoch=058, loss=0.0853
Epoch=059, loss=0.0786
Epoch=060, loss=0.0653
Epoch=061, loss=0.0737
Epoch=062, loss=0.0796
Epoch=063, loss=0.0668
Epoch=064, loss=0.0883
Epoch=065, loss=0.0665
Epoch=066, loss=0.0790
Epoch=067, loss=0.0802
Epoch=068, loss=0.0653
Epoch=069, loss=0.0632
Epoch=070, loss=0.0602
Epoch=071, loss=0.0586
Epoch=072, loss=0.0695
Epoch=073, loss=0.0641
Epoch=074, loss=0.0701
Epoch=075, loss=0.0574
Epoch=076, loss=0.0729
Epoch=077, loss=0.0627
Epoch=078, loss=0.0696
Epoch=079, loss=0.0665
Epoch=080, loss=0.0692
Epoch=081, loss=0.0579
Epoch=082, loss=0.0696
Epoch=083, loss=0.0497
Epoch=084, loss=0.0549
Epoch=085, loss=0.0638
Epoch=086, loss=0.0572
Epoch=087, loss=0.0545
Epoch=088, loss=0.0533
Epoch=089, loss=0.0403
Epoch=090, loss=0.0568
Epoch=091, loss=0.0540
Epoch=092, loss=0.0489
Epoch=093, loss=0.0537
Epoch=094, loss=0.0458
Epoch=095, loss=0.0441
Epoch=096, loss=0.0510
Epoch=097, loss=0.0487
Epoch=098, loss=0.0558
Epoch=099, loss=0.0525
Epoch=100, loss=0.0449
Epoch=101, loss=0.0438
Epoch=102, loss=0.0483
Epoch=103, loss=0.0489
Epoch=104, loss=0.0632
Epoch=105, loss=0.0395
Epoch=106, loss=0.0519
Epoch=107, loss=0.0563
Epoch=108, loss=0.0623
Epoch=109, loss=0.0495
Epoch=110, loss=0.0529
Epoch=111, loss=0.0531
Epoch=112, loss=0.0462
Epoch=113, loss=0.0689
Epoch=114, loss=0.0455
Epoch=115, loss=0.0506
Epoch=116, loss=0.0500
Epoch=117, loss=0.0467
Epoch=118, loss=0.0417
Epoch=119, loss=0.0410
Epoch=120, loss=0.0373
Epoch=121, loss=0.0465
Epoch=122, loss=0.0492
Epoch=123, loss=0.0383
Epoch=124, loss=0.0371
Epoch=125, loss=0.0390
Epoch=126, loss=0.0421
Epoch=127, loss=0.0345
Epoch=128, loss=0.0522
Epoch=129, loss=0.0307
Epoch=130, loss=0.0395
Epoch=131, loss=0.0357
Epoch=132, loss=0.0392
Epoch=133, loss=0.0282
Epoch=134, loss=0.0372
Epoch=135, loss=0.0333
Epoch=136, loss=0.0447
Epoch=137, loss=0.0345
Epoch=138, loss=0.0410
Epoch=139, loss=0.0308
Epoch=140, loss=0.0292
Epoch=141, loss=0.0339
Epoch=142, loss=0.0338
Epoch=143, loss=0.0323
Epoch=144, loss=0.0345
Epoch=145, loss=0.0248
Epoch=146, loss=0.0334
Epoch=147, loss=0.0358
Epoch=148, loss=0.0358
Epoch=149, loss=0.0275
Epoch=150, loss=0.0353
Epoch=151, loss=0.0260
Epoch=152, loss=0.0410
Epoch=153, loss=0.0314
Epoch=154, loss=0.0385
Epoch=155, loss=0.0262
Epoch=156, loss=0.0414
Epoch=157, loss=0.0357
Epoch=158, loss=0.0355
Epoch=159, loss=0.0463
Epoch=160, loss=0.0229
Epoch=161, loss=0.0351
Epoch=162, loss=0.0238
Epoch=163, loss=0.0273
Epoch=164, loss=0.0299
Epoch=165, loss=0.0351
Epoch=166, loss=0.0304
Epoch=167, loss=0.0298
Epoch=168, loss=0.0278
Epoch=169, loss=0.0238
Epoch=170, loss=0.0330
Epoch=171, loss=0.0208
Epoch=172, loss=0.0328
Epoch=173, loss=0.0317
Epoch=174, loss=0.0147
Epoch=175, loss=0.0207
Epoch=176, loss=0.0224
Epoch=177, loss=0.0233
Epoch=178, loss=0.0301
Epoch=179, loss=0.0248
Epoch=180, loss=0.0285
Epoch=181, loss=0.0273
Epoch=182, loss=0.0260
Epoch=183, loss=0.0221
Epoch=184, loss=0.0421
Epoch=185, loss=0.0233
Epoch=186, loss=0.0217
Epoch=187, loss=0.0202
Epoch=188, loss=0.0313
Epoch=189, loss=0.0181
Epoch=190, loss=0.0166
Epoch=191, loss=0.0237
Epoch=192, loss=0.0265
Epoch=193, loss=0.0173
Epoch=194, loss=0.0188
Early stopping!
Loading 174th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7994+-0.0101, F1Ma=0.7806+-0.0168, acc=0.7994+-0.0101
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7759531706257288, 0.770145337156762, 0.7685441563538558, 0.7712987521905887, 0.8642857074737549, 0.7720000147819519, 0.7848162651062012, 0.8500000238418579, 0.7720000147819519, 0.782882034778595, 0.7594247959580256, 0.005254704634638344, 0.7256654108243084, 0.012264534077316567, 0.7594247959580256, 0.005254704634638344], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7641984885025149, 0.7641306616056764, 0.7613464924440732, 0.7671901064193413, 0.8857142925262451, 0.8119999766349792, 0.7877175807952881, 0.8928571343421936, 0.8100000023841858, 0.7877175807952881, 0.7887291099883404, 0.009604015194370692, 0.7647056682607795, 0.01583740084592843, 0.7887291099883404, 0.009604015194370688], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7830520921705256, 0.7730339439646632, 0.7917358288115391, 0.7814137614476941, 0.9428571462631226, 0.7900000214576721, 0.8007736802101135, 0.9428571462631226, 0.7879999876022339, 0.8007736802101135, 0.8024873688301593, 0.006679378487039522, 0.7808963528066803, 0.014766322721061551, 0.8024873688301593, 0.006679378487039504], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7601618278570543, 0.7470991145642262, 0.7706109192774251, 0.7596201847540498, 0.9571428298950195, 0.8220000267028809, 0.8046421408653259, 0.9571428298950195, 0.8220000267028809, 0.804158627986908, 0.7993781577924601, 0.010085185038714691, 0.780570739441915, 0.016773435859530793, 0.7993781577924601, 0.010085185038714691]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6911
Epoch=002, loss=0.6862
Epoch=003, loss=0.6758
Epoch=004, loss=0.6689
Epoch=005, loss=0.6535
Epoch=006, loss=0.6366
Epoch=007, loss=0.6280
Epoch=008, loss=0.6050
Epoch=009, loss=0.5792
Epoch=010, loss=0.5671
Epoch=011, loss=0.5363
Epoch=012, loss=0.5003
Epoch=013, loss=0.4800
Epoch=014, loss=0.4511
Epoch=015, loss=0.4023
Epoch=016, loss=0.3821
Epoch=017, loss=0.3647
Epoch=018, loss=0.3167
Epoch=019, loss=0.2978
Epoch=020, loss=0.2925
Epoch=021, loss=0.2619
Epoch=022, loss=0.2259
Epoch=023, loss=0.2379
Epoch=024, loss=0.2046
Epoch=025, loss=0.2048
Epoch=026, loss=0.1869
Epoch=027, loss=0.1498
Epoch=028, loss=0.1617
Epoch=029, loss=0.1412
Epoch=030, loss=0.1172
Epoch=031, loss=0.1207
Epoch=032, loss=0.1074
Epoch=033, loss=0.1075
Epoch=034, loss=0.0905
Epoch=035, loss=0.0856
Epoch=036, loss=0.0948
Epoch=037, loss=0.0889
Epoch=038, loss=0.0857
Epoch=039, loss=0.0896
Epoch=040, loss=0.0762
Epoch=041, loss=0.0646
Epoch=042, loss=0.0627
Epoch=043, loss=0.0580
Epoch=044, loss=0.0651
Epoch=045, loss=0.0525
Epoch=046, loss=0.0585
Epoch=047, loss=0.0502
Epoch=048, loss=0.0475
Epoch=049, loss=0.0478
Epoch=050, loss=0.0431
Epoch=051, loss=0.0382
Epoch=052, loss=0.0351
Epoch=053, loss=0.0543
Epoch=054, loss=0.0328
Epoch=055, loss=0.0422
Epoch=056, loss=0.0444
Epoch=057, loss=0.0316
Epoch=058, loss=0.0346
Epoch=059, loss=0.0280
Epoch=060, loss=0.0399
Epoch=061, loss=0.0306
Epoch=062, loss=0.0287
Epoch=063, loss=0.0259
Epoch=064, loss=0.0267
Epoch=065, loss=0.0250
Epoch=066, loss=0.0250
Epoch=067, loss=0.0355
Epoch=068, loss=0.0282
Epoch=069, loss=0.0197
Epoch=070, loss=0.0312
Epoch=071, loss=0.0318
Epoch=072, loss=0.0224
Epoch=073, loss=0.0264
Epoch=074, loss=0.0189
Epoch=075, loss=0.0224
Epoch=076, loss=0.0186
Epoch=077, loss=0.0186
Epoch=078, loss=0.0270
Epoch=079, loss=0.0162
Epoch=080, loss=0.0145
Epoch=081, loss=0.0158
Epoch=082, loss=0.0104
Epoch=083, loss=0.0123
Epoch=084, loss=0.0139
Epoch=085, loss=0.0149
Epoch=086, loss=0.0228
Epoch=087, loss=0.0175
Epoch=088, loss=0.0157
Epoch=089, loss=0.0219
Epoch=090, loss=0.0174
Epoch=091, loss=0.0249
Epoch=092, loss=0.0166
Epoch=093, loss=0.0106
Epoch=094, loss=0.0196
Epoch=095, loss=0.0100
Epoch=096, loss=0.0161
Epoch=097, loss=0.0133
Epoch=098, loss=0.0117
Epoch=099, loss=0.0131
Epoch=100, loss=0.0111
Epoch=101, loss=0.0182
Epoch=102, loss=0.0092
Epoch=103, loss=0.0062
Epoch=104, loss=0.0181
Epoch=105, loss=0.0120
Epoch=106, loss=0.0107
Epoch=107, loss=0.0143
Epoch=108, loss=0.0103
Epoch=109, loss=0.0084
Epoch=110, loss=0.0087
Epoch=111, loss=0.0096
Epoch=112, loss=0.0091
Epoch=113, loss=0.0060
Epoch=114, loss=0.0118
Epoch=115, loss=0.0072
Epoch=116, loss=0.0079
Epoch=117, loss=0.0087
Epoch=118, loss=0.0087
Epoch=119, loss=0.0089
Epoch=120, loss=0.0095
Epoch=121, loss=0.0041
Epoch=122, loss=0.0054
Epoch=123, loss=0.0089
Epoch=124, loss=0.0081
Epoch=125, loss=0.0054
Epoch=126, loss=0.0048
Epoch=127, loss=0.0091
Epoch=128, loss=0.0054
Epoch=129, loss=0.0076
Epoch=130, loss=0.0122
Epoch=131, loss=0.0080
Epoch=132, loss=0.0089
Epoch=133, loss=0.0073
Epoch=134, loss=0.0057
Epoch=135, loss=0.0080
Epoch=136, loss=0.0094
Epoch=137, loss=0.0086
Epoch=138, loss=0.0092
Epoch=139, loss=0.0034
Epoch=140, loss=0.0127
Epoch=141, loss=0.0049
Epoch=142, loss=0.0040
Epoch=143, loss=0.0050
Epoch=144, loss=0.0161
Epoch=145, loss=0.0040
Epoch=146, loss=0.0064
Epoch=147, loss=0.0040
Epoch=148, loss=0.0040
Epoch=149, loss=0.0119
Epoch=150, loss=0.0028
Epoch=151, loss=0.0069
Epoch=152, loss=0.0082
Epoch=153, loss=0.0080
Epoch=154, loss=0.0046
Epoch=155, loss=0.0017
Epoch=156, loss=0.0059
Epoch=157, loss=0.0070
Epoch=158, loss=0.0100
Epoch=159, loss=0.0073
Epoch=160, loss=0.0084
Epoch=161, loss=0.0050
Epoch=162, loss=0.0040
Epoch=163, loss=0.0047
Epoch=164, loss=0.0075
Epoch=165, loss=0.0100
Epoch=166, loss=0.0041
Epoch=167, loss=0.0114
Epoch=168, loss=0.0044
Epoch=169, loss=0.0047
Epoch=170, loss=0.0036
Epoch=171, loss=0.0126
Epoch=172, loss=0.0031
Epoch=173, loss=0.0092
Epoch=174, loss=0.0039
Epoch=175, loss=0.0039
Early stopping!
Loading 155th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8075+-0.0168, F1Ma=0.7907+-0.0223, acc=0.8075+-0.0168
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7744852037598382, 0.7740178331315754, 0.7826676364369584, 0.7877511767136052, 0.7785714268684387, 0.7400000095367432, 0.7001934051513672, 0.7714285850524902, 0.7459999918937683, 0.6997098922729492, 0.6928099494753206, 0.02178750655474496, 0.6298214731363603, 0.04658616018673951, 0.6928099494753206, 0.02178750655474496], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7759531706257288, 0.770145337156762, 0.7685441563538558, 0.7712987521905887, 0.8642857074737549, 0.7720000147819519, 0.7848162651062012, 0.8500000238418579, 0.7720000147819519, 0.782882034778595, 0.7594247959580256, 0.005254704634638344, 0.7256654108243084, 0.012264534077316567, 0.7594247959580256, 0.005254704634638344], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7641984885025149, 0.7641306616056764, 0.7613464924440732, 0.7671901064193413, 0.8857142925262451, 0.8119999766349792, 0.7877175807952881, 0.8928571343421936, 0.8100000023841858, 0.7877175807952881, 0.7887291099883404, 0.009604015194370692, 0.7647056682607795, 0.01583740084592843, 0.7887291099883404, 0.009604015194370688], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7830520921705256, 0.7730339439646632, 0.7917358288115391, 0.7814137614476941, 0.9428571462631226, 0.7900000214576721, 0.8007736802101135, 0.9428571462631226, 0.7879999876022339, 0.8007736802101135, 0.8024873688301593, 0.006679378487039522, 0.7808963528066803, 0.014766322721061551, 0.8024873688301593, 0.006679378487039504], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7601618278570543, 0.7470991145642262, 0.7706109192774251, 0.7596201847540498, 0.9571428298950195, 0.8220000267028809, 0.8046421408653259, 0.9571428298950195, 0.8220000267028809, 0.804158627986908, 0.7993781577924601, 0.010085185038714691, 0.780570739441915, 0.016773435859530793, 0.7993781577924601, 0.010085185038714691], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9140724046059843, 0.9052416990627402, 0.9141141184391979, 0.9060428748999059, 0.9785714149475098, 0.7979999780654907, 0.8181818127632141, 0.9785714149475098, 0.7960000038146973, 0.8172147274017334, 0.8074621064904781, 0.01683466230446569, 0.7907427444024189, 0.02233632852959022, 0.8074621064904781, 0.0168346623044657]]
