My SLURM_ARRAY_TASK_ID:  20
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_20
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_20.csv
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6929
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6928
Epoch=010, loss=0.6928
Epoch=011, loss=0.6927
Epoch=012, loss=0.6927
Epoch=013, loss=0.6926
Epoch=014, loss=0.6925
Epoch=015, loss=0.6925
Epoch=016, loss=0.6924
Epoch=017, loss=0.6923
Epoch=018, loss=0.6922
Epoch=019, loss=0.6921
Epoch=020, loss=0.6920
Epoch=021, loss=0.6919
Epoch=022, loss=0.6919
Epoch=023, loss=0.6917
Epoch=024, loss=0.6915
Epoch=025, loss=0.6914
Epoch=026, loss=0.6913
Epoch=027, loss=0.6911
Epoch=028, loss=0.6909
Epoch=029, loss=0.6908
Epoch=030, loss=0.6906
Epoch=031, loss=0.6904
Epoch=032, loss=0.6901
Epoch=033, loss=0.6900
Epoch=034, loss=0.6898
Epoch=035, loss=0.6895
Epoch=036, loss=0.6892
Epoch=037, loss=0.6890
Epoch=038, loss=0.6887
Epoch=039, loss=0.6884
Epoch=040, loss=0.6879
Epoch=041, loss=0.6877
Epoch=042, loss=0.6873
Epoch=043, loss=0.6869
Epoch=044, loss=0.6864
Epoch=045, loss=0.6860
Epoch=046, loss=0.6856
Epoch=047, loss=0.6850
Epoch=048, loss=0.6847
Epoch=049, loss=0.6841
Epoch=050, loss=0.6835
Epoch=051, loss=0.6832
Epoch=052, loss=0.6826
Epoch=053, loss=0.6820
Epoch=054, loss=0.6814
Epoch=055, loss=0.6806
Epoch=056, loss=0.6797
Epoch=057, loss=0.6790
Epoch=058, loss=0.6782
Epoch=059, loss=0.6777
Epoch=060, loss=0.6765
Epoch=061, loss=0.6757
Epoch=062, loss=0.6752
Epoch=063, loss=0.6737
Epoch=064, loss=0.6733
Epoch=065, loss=0.6719
Epoch=066, loss=0.6713
Epoch=067, loss=0.6703
Epoch=068, loss=0.6686
Epoch=069, loss=0.6678
Epoch=070, loss=0.6665
Epoch=071, loss=0.6650
Epoch=072, loss=0.6638
Epoch=073, loss=0.6624
Epoch=074, loss=0.6610
Epoch=075, loss=0.6601
Epoch=076, loss=0.6586
Epoch=077, loss=0.6565
Epoch=078, loss=0.6552
Epoch=079, loss=0.6538
Epoch=080, loss=0.6520
Epoch=081, loss=0.6497
Epoch=082, loss=0.6490
Epoch=083, loss=0.6464
Epoch=084, loss=0.6445
Epoch=085, loss=0.6431
Epoch=086, loss=0.6410
Epoch=087, loss=0.6389
Epoch=088, loss=0.6373
Epoch=089, loss=0.6355
Epoch=090, loss=0.6324
Epoch=091, loss=0.6303
Epoch=092, loss=0.6278
Epoch=093, loss=0.6248
Epoch=094, loss=0.6243
Epoch=095, loss=0.6208
Epoch=096, loss=0.6186
Epoch=097, loss=0.6175
Epoch=098, loss=0.6135
Epoch=099, loss=0.6113
Epoch=100, loss=0.6093
Epoch=101, loss=0.6060
Epoch=102, loss=0.6025
Epoch=103, loss=0.6008
Epoch=104, loss=0.5971
Epoch=105, loss=0.5949
Epoch=106, loss=0.5904
Epoch=107, loss=0.5867
Epoch=108, loss=0.5846
Epoch=109, loss=0.5835
Epoch=110, loss=0.5800
Epoch=111, loss=0.5772
Epoch=112, loss=0.5702
Epoch=113, loss=0.5741
Epoch=114, loss=0.5679
Epoch=115, loss=0.5639
Epoch=116, loss=0.5607
Epoch=117, loss=0.5550
Epoch=118, loss=0.5537
Epoch=119, loss=0.5467
Epoch=120, loss=0.5465
Epoch=121, loss=0.5430
Epoch=122, loss=0.5372
Epoch=123, loss=0.5337
Epoch=124, loss=0.5327
Epoch=125, loss=0.5288
Epoch=126, loss=0.5269
Epoch=127, loss=0.5223
Epoch=128, loss=0.5192
Epoch=129, loss=0.5119
Epoch=130, loss=0.5057
Epoch=131, loss=0.5053
Epoch=132, loss=0.5034
Epoch=133, loss=0.4956
Epoch=134, loss=0.4920
Epoch=135, loss=0.4935
Epoch=136, loss=0.4846
Epoch=137, loss=0.4828
Epoch=138, loss=0.4788
Epoch=139, loss=0.4734
Epoch=140, loss=0.4697
Epoch=141, loss=0.4654
Epoch=142, loss=0.4584
Epoch=143, loss=0.4594
Epoch=144, loss=0.4549
Epoch=145, loss=0.4528
Epoch=146, loss=0.4487
Epoch=147, loss=0.4441
Epoch=148, loss=0.4388
Epoch=149, loss=0.4351
Epoch=150, loss=0.4296
Epoch=151, loss=0.4332
Epoch=152, loss=0.4275
Epoch=153, loss=0.4205
Epoch=154, loss=0.4116
Epoch=155, loss=0.4090
Epoch=156, loss=0.4145
Epoch=157, loss=0.3990
Epoch=158, loss=0.3978
Epoch=159, loss=0.3902
Epoch=160, loss=0.3920
Epoch=161, loss=0.3923
Epoch=162, loss=0.3830
Epoch=163, loss=0.3824
Epoch=164, loss=0.3765
Epoch=165, loss=0.3719
Epoch=166, loss=0.3688
Epoch=167, loss=0.3688
Epoch=168, loss=0.3628
Epoch=169, loss=0.3575
Epoch=170, loss=0.3547
Epoch=171, loss=0.3512
Epoch=172, loss=0.3494
Epoch=173, loss=0.3454
Epoch=174, loss=0.3361
Epoch=175, loss=0.3337
Epoch=176, loss=0.3350
Epoch=177, loss=0.3382
Epoch=178, loss=0.3298
Epoch=179, loss=0.3257
Epoch=180, loss=0.3183
Epoch=181, loss=0.3243
Epoch=182, loss=0.3158
Epoch=183, loss=0.3156
Epoch=184, loss=0.3109
Epoch=185, loss=0.3069
Epoch=186, loss=0.3080
Epoch=187, loss=0.2956
Epoch=188, loss=0.2992
Epoch=189, loss=0.2976
Epoch=190, loss=0.2962
Epoch=191, loss=0.2910
Epoch=192, loss=0.2788
Epoch=193, loss=0.2836
Epoch=194, loss=0.2818
Epoch=195, loss=0.2825
Epoch=196, loss=0.2694
Epoch=197, loss=0.2720
Epoch=198, loss=0.2701
Epoch=199, loss=0.2683
Epoch=200, loss=0.2645
Epoch=201, loss=0.2600
Epoch=202, loss=0.2532
Epoch=203, loss=0.2530
Epoch=204, loss=0.2575
Epoch=205, loss=0.2538
Epoch=206, loss=0.2485
Epoch=207, loss=0.2508
Epoch=208, loss=0.2469
Epoch=209, loss=0.2499
Epoch=210, loss=0.2407
Epoch=211, loss=0.2436
Epoch=212, loss=0.2355
Epoch=213, loss=0.2325
Epoch=214, loss=0.2341
Epoch=215, loss=0.2345
Epoch=216, loss=0.2286
Epoch=217, loss=0.2269
Epoch=218, loss=0.2238
Epoch=219, loss=0.2246
Epoch=220, loss=0.2228
Epoch=221, loss=0.2172
Epoch=222, loss=0.2222
Epoch=223, loss=0.2073
Epoch=224, loss=0.2089
Epoch=225, loss=0.2147
Epoch=226, loss=0.2061
Epoch=227, loss=0.2076
Epoch=228, loss=0.2103
Epoch=229, loss=0.2117
Epoch=230, loss=0.2068
Epoch=231, loss=0.2019
Epoch=232, loss=0.1985
Epoch=233, loss=0.2030
Epoch=234, loss=0.1948
Epoch=235, loss=0.1916
Epoch=236, loss=0.1945
Epoch=237, loss=0.1885
Epoch=238, loss=0.1827
Epoch=239, loss=0.1936
Epoch=240, loss=0.1898
Epoch=241, loss=0.1982
Epoch=242, loss=0.1984
Epoch=243, loss=0.1820
Epoch=244, loss=0.1818
Epoch=245, loss=0.1783
Epoch=246, loss=0.1834
Epoch=247, loss=0.1779
Epoch=248, loss=0.1718
Epoch=249, loss=0.1824
Epoch=250, loss=0.1733
Epoch=251, loss=0.1833
Epoch=252, loss=0.1839
Epoch=253, loss=0.1740
Epoch=254, loss=0.1745
Epoch=255, loss=0.1689
Epoch=256, loss=0.1685
Epoch=257, loss=0.1718
Epoch=258, loss=0.1711
Epoch=259, loss=0.1714
Epoch=260, loss=0.1627
Epoch=261, loss=0.1661
Epoch=262, loss=0.1583
Epoch=263, loss=0.1546
Epoch=264, loss=0.1533
Epoch=265, loss=0.1547
Epoch=266, loss=0.1557
Epoch=267, loss=0.1583
Epoch=268, loss=0.1547
Epoch=269, loss=0.1559
Epoch=270, loss=0.1563
Epoch=271, loss=0.1525
Epoch=272, loss=0.1596
Epoch=273, loss=0.1516
Epoch=274, loss=0.1594
Epoch=275, loss=0.1470
Epoch=276, loss=0.1442
Epoch=277, loss=0.1498
Epoch=278, loss=0.1418
Epoch=279, loss=0.1448
Epoch=280, loss=0.1410
Epoch=281, loss=0.1471
Epoch=282, loss=0.1361
Epoch=283, loss=0.1337
Epoch=284, loss=0.1441
Epoch=285, loss=0.1395
Epoch=286, loss=0.1446
Epoch=287, loss=0.1398
Epoch=288, loss=0.1426
Epoch=289, loss=0.1365
Epoch=290, loss=0.1413
Epoch=291, loss=0.1272
Epoch=292, loss=0.1425
Epoch=293, loss=0.1371
Epoch=294, loss=0.1393
Epoch=295, loss=0.1357
Epoch=296, loss=0.1365
Epoch=297, loss=0.1325
Epoch=298, loss=0.1361
Epoch=299, loss=0.1227
Epoch=300, loss=0.1320
Epoch=301, loss=0.1224
Epoch=302, loss=0.1362
Epoch=303, loss=0.1302
Epoch=304, loss=0.1269
Epoch=305, loss=0.1315
Epoch=306, loss=0.1221
Epoch=307, loss=0.1242
Epoch=308, loss=0.1225
Epoch=309, loss=0.1306
Epoch=310, loss=0.1293
Epoch=311, loss=0.1169
Epoch=312, loss=0.1219
Epoch=313, loss=0.1232
Epoch=314, loss=0.1209
Epoch=315, loss=0.1146
Epoch=316, loss=0.1160
Epoch=317, loss=0.1215
Epoch=318, loss=0.1278
Epoch=319, loss=0.1180
Epoch=320, loss=0.1215
Epoch=321, loss=0.1260
Epoch=322, loss=0.1178
Epoch=323, loss=0.1219
Epoch=324, loss=0.1250
Epoch=325, loss=0.1201
Epoch=326, loss=0.1170
Epoch=327, loss=0.1312
Epoch=328, loss=0.1185
Epoch=329, loss=0.1166
Epoch=330, loss=0.1193
Epoch=331, loss=0.1165
Epoch=332, loss=0.1155
Epoch=333, loss=0.1099
Epoch=334, loss=0.1139
Epoch=335, loss=0.1134
Epoch=336, loss=0.1099
Epoch=337, loss=0.1091
Epoch=338, loss=0.1107
Epoch=339, loss=0.1133
Epoch=340, loss=0.1126
Epoch=341, loss=0.1102
Epoch=342, loss=0.1163
Epoch=343, loss=0.1136
Epoch=344, loss=0.1103
Epoch=345, loss=0.1033
Epoch=346, loss=0.1154
Epoch=347, loss=0.1101
Epoch=348, loss=0.0999
Epoch=349, loss=0.1024
Epoch=350, loss=0.1064
Epoch=351, loss=0.1039
Epoch=352, loss=0.1089
Epoch=353, loss=0.1025
Epoch=354, loss=0.0943
Epoch=355, loss=0.1058
Epoch=356, loss=0.1082
Epoch=357, loss=0.1011
Epoch=358, loss=0.1111
Epoch=359, loss=0.1007
Epoch=360, loss=0.1101
Epoch=361, loss=0.0970
Epoch=362, loss=0.0978
Epoch=363, loss=0.1082
Epoch=364, loss=0.0987
Epoch=365, loss=0.1041
Epoch=366, loss=0.1037
Epoch=367, loss=0.1033
Epoch=368, loss=0.1026
Epoch=369, loss=0.0948
Epoch=370, loss=0.0976
Epoch=371, loss=0.1041
Epoch=372, loss=0.0932
Epoch=373, loss=0.0943
Epoch=374, loss=0.1042
Epoch=375, loss=0.0872
Epoch=376, loss=0.0902
Epoch=377, loss=0.0927
Epoch=378, loss=0.0962
Epoch=379, loss=0.1002
Epoch=380, loss=0.1041
Epoch=381, loss=0.1036
Epoch=382, loss=0.1060
Epoch=383, loss=0.0929
Epoch=384, loss=0.0875
Epoch=385, loss=0.0933
Epoch=386, loss=0.0899
Epoch=387, loss=0.1042
Epoch=388, loss=0.1052
Epoch=389, loss=0.0942
Epoch=390, loss=0.0855
Epoch=391, loss=0.0900
Epoch=392, loss=0.0925
Epoch=393, loss=0.1043
Epoch=394, loss=0.0931
Epoch=395, loss=0.0920
Epoch=396, loss=0.0996
Epoch=397, loss=0.0839
Epoch=398, loss=0.0862
Epoch=399, loss=0.0967
Epoch=400, loss=0.0910
Epoch=401, loss=0.0918
Epoch=402, loss=0.0992
Epoch=403, loss=0.0957
Epoch=404, loss=0.0898
Epoch=405, loss=0.0938
Epoch=406, loss=0.0837
Epoch=407, loss=0.1103
Epoch=408, loss=0.0861
Epoch=409, loss=0.0885
Epoch=410, loss=0.0896
Epoch=411, loss=0.0895
Epoch=412, loss=0.0875
Epoch=413, loss=0.0819
Epoch=414, loss=0.0875
Epoch=415, loss=0.0781
Epoch=416, loss=0.0908
Epoch=417, loss=0.0962
Epoch=418, loss=0.0792
Epoch=419, loss=0.0834
Epoch=420, loss=0.0875
Epoch=421, loss=0.0837
Epoch=422, loss=0.1003
Epoch=423, loss=0.0793
Epoch=424, loss=0.0789
Epoch=425, loss=0.0810
Epoch=426, loss=0.0831
Epoch=427, loss=0.0960
Epoch=428, loss=0.0967
Epoch=429, loss=0.0847
Epoch=430, loss=0.0850
Epoch=431, loss=0.0793
Epoch=432, loss=0.0914
Epoch=433, loss=0.0857
Epoch=434, loss=0.0798
Epoch=435, loss=0.0868
Early stopping!
Loading 415th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7237+-0.0100, F1Ma=0.6908+-0.0171, acc=0.7237+-0.0100
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6929
Epoch=006, loss=0.6928
Epoch=007, loss=0.6928
Epoch=008, loss=0.6927
Epoch=009, loss=0.6926
Epoch=010, loss=0.6924
Epoch=011, loss=0.6923
Epoch=012, loss=0.6922
Epoch=013, loss=0.6920
Epoch=014, loss=0.6918
Epoch=015, loss=0.6916
Epoch=016, loss=0.6914
Epoch=017, loss=0.6910
Epoch=018, loss=0.6908
Epoch=019, loss=0.6904
Epoch=020, loss=0.6901
Epoch=021, loss=0.6896
Epoch=022, loss=0.6893
Epoch=023, loss=0.6888
Epoch=024, loss=0.6882
Epoch=025, loss=0.6877
Epoch=026, loss=0.6870
Epoch=027, loss=0.6863
Epoch=028, loss=0.6855
Epoch=029, loss=0.6848
Epoch=030, loss=0.6837
Epoch=031, loss=0.6828
Epoch=032, loss=0.6817
Epoch=033, loss=0.6805
Epoch=034, loss=0.6794
Epoch=035, loss=0.6783
Epoch=036, loss=0.6766
Epoch=037, loss=0.6755
Epoch=038, loss=0.6738
Epoch=039, loss=0.6715
Epoch=040, loss=0.6705
Epoch=041, loss=0.6681
Epoch=042, loss=0.6662
Epoch=043, loss=0.6635
Epoch=044, loss=0.6615
Epoch=045, loss=0.6589
Epoch=046, loss=0.6566
Epoch=047, loss=0.6536
Epoch=048, loss=0.6513
Epoch=049, loss=0.6474
Epoch=050, loss=0.6446
Epoch=051, loss=0.6411
Epoch=052, loss=0.6383
Epoch=053, loss=0.6338
Epoch=054, loss=0.6301
Epoch=055, loss=0.6263
Epoch=056, loss=0.6218
Epoch=057, loss=0.6170
Epoch=058, loss=0.6136
Epoch=059, loss=0.6080
Epoch=060, loss=0.6016
Epoch=061, loss=0.5979
Epoch=062, loss=0.5917
Epoch=063, loss=0.5884
Epoch=064, loss=0.5813
Epoch=065, loss=0.5775
Epoch=066, loss=0.5698
Epoch=067, loss=0.5643
Epoch=068, loss=0.5583
Epoch=069, loss=0.5513
Epoch=070, loss=0.5453
Epoch=071, loss=0.5423
Epoch=072, loss=0.5312
Epoch=073, loss=0.5231
Epoch=074, loss=0.5192
Epoch=075, loss=0.5073
Epoch=076, loss=0.5052
Epoch=077, loss=0.4932
Epoch=078, loss=0.4911
Epoch=079, loss=0.4805
Epoch=080, loss=0.4714
Epoch=081, loss=0.4678
Epoch=082, loss=0.4585
Epoch=083, loss=0.4512
Epoch=084, loss=0.4456
Epoch=085, loss=0.4352
Epoch=086, loss=0.4291
Epoch=087, loss=0.4221
Epoch=088, loss=0.4118
Epoch=089, loss=0.4029
Epoch=090, loss=0.4014
Epoch=091, loss=0.3926
Epoch=092, loss=0.3865
Epoch=093, loss=0.3760
Epoch=094, loss=0.3642
Epoch=095, loss=0.3551
Epoch=096, loss=0.3519
Epoch=097, loss=0.3468
Epoch=098, loss=0.3426
Epoch=099, loss=0.3307
Epoch=100, loss=0.3278
Epoch=101, loss=0.3168
Epoch=102, loss=0.3166
Epoch=103, loss=0.3016
Epoch=104, loss=0.3055
Epoch=105, loss=0.2967
Epoch=106, loss=0.2882
Epoch=107, loss=0.2939
Epoch=108, loss=0.2734
Epoch=109, loss=0.2674
Epoch=110, loss=0.2631
Epoch=111, loss=0.2619
Epoch=112, loss=0.2511
Epoch=113, loss=0.2501
Epoch=114, loss=0.2381
Epoch=115, loss=0.2444
Epoch=116, loss=0.2402
Epoch=117, loss=0.2263
Epoch=118, loss=0.2256
Epoch=119, loss=0.2262
Epoch=120, loss=0.2226
Epoch=121, loss=0.2148
Epoch=122, loss=0.2120
Epoch=123, loss=0.2070
Epoch=124, loss=0.2060
Epoch=125, loss=0.1949
Epoch=126, loss=0.2017
Epoch=127, loss=0.1907
Epoch=128, loss=0.1857
Epoch=129, loss=0.1862
Epoch=130, loss=0.1895
Epoch=131, loss=0.1831
Epoch=132, loss=0.1871
Epoch=133, loss=0.1792
Epoch=134, loss=0.1794
Epoch=135, loss=0.1736
Epoch=136, loss=0.1726
Epoch=137, loss=0.1669
Epoch=138, loss=0.1620
Epoch=139, loss=0.1671
Epoch=140, loss=0.1535
Epoch=141, loss=0.1602
Epoch=142, loss=0.1538
Epoch=143, loss=0.1530
Epoch=144, loss=0.1572
Epoch=145, loss=0.1504
Epoch=146, loss=0.1496
Epoch=147, loss=0.1513
Epoch=148, loss=0.1386
Epoch=149, loss=0.1426
Epoch=150, loss=0.1533
Epoch=151, loss=0.1418
Epoch=152, loss=0.1303
Epoch=153, loss=0.1364
Epoch=154, loss=0.1359
Epoch=155, loss=0.1255
Epoch=156, loss=0.1350
Epoch=157, loss=0.1339
Epoch=158, loss=0.1290
Epoch=159, loss=0.1262
Epoch=160, loss=0.1267
Epoch=161, loss=0.1277
Epoch=162, loss=0.1282
Epoch=163, loss=0.1247
Epoch=164, loss=0.1195
Epoch=165, loss=0.1169
Epoch=166, loss=0.1248
Epoch=167, loss=0.1151
Epoch=168, loss=0.1013
Epoch=169, loss=0.1122
Epoch=170, loss=0.1095
Epoch=171, loss=0.1045
Epoch=172, loss=0.1149
Epoch=173, loss=0.1188
Epoch=174, loss=0.1026
Epoch=175, loss=0.1080
Epoch=176, loss=0.1110
Epoch=177, loss=0.1004
Epoch=178, loss=0.1121
Epoch=179, loss=0.0986
Epoch=180, loss=0.1065
Epoch=181, loss=0.0996
Epoch=182, loss=0.1162
Epoch=183, loss=0.1016
Epoch=184, loss=0.1008
Epoch=185, loss=0.1041
Epoch=186, loss=0.1032
Epoch=187, loss=0.0962
Epoch=188, loss=0.0932
Epoch=189, loss=0.0950
Epoch=190, loss=0.1073
Epoch=191, loss=0.0896
Epoch=192, loss=0.0804
Epoch=193, loss=0.0939
Epoch=194, loss=0.0935
Epoch=195, loss=0.0921
Epoch=196, loss=0.0948
Epoch=197, loss=0.0868
Epoch=198, loss=0.0866
Epoch=199, loss=0.0886
Epoch=200, loss=0.0891
Epoch=201, loss=0.0917
Epoch=202, loss=0.0932
Epoch=203, loss=0.0896
Epoch=204, loss=0.0837
Epoch=205, loss=0.0789
Epoch=206, loss=0.0856
Epoch=207, loss=0.0790
Epoch=208, loss=0.0797
Epoch=209, loss=0.0911
Epoch=210, loss=0.0843
Epoch=211, loss=0.0841
Epoch=212, loss=0.0864
Epoch=213, loss=0.0834
Epoch=214, loss=0.0816
Epoch=215, loss=0.0825
Epoch=216, loss=0.0687
Epoch=217, loss=0.0844
Epoch=218, loss=0.0806
Epoch=219, loss=0.0738
Epoch=220, loss=0.0751
Epoch=221, loss=0.0867
Epoch=222, loss=0.0865
Epoch=223, loss=0.0914
Epoch=224, loss=0.0762
Epoch=225, loss=0.0773
Epoch=226, loss=0.0749
Epoch=227, loss=0.0798
Epoch=228, loss=0.0850
Epoch=229, loss=0.0729
Epoch=230, loss=0.0774
Epoch=231, loss=0.0799
Epoch=232, loss=0.0814
Epoch=233, loss=0.0840
Epoch=234, loss=0.0838
Epoch=235, loss=0.0708
Epoch=236, loss=0.0793
Early stopping!
Loading 216th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7864+-0.0135, F1Ma=0.7535+-0.0293, acc=0.7864+-0.0135
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7334168596947772, 0.7500713826961194, 0.7116001569875671, 0.7416331861644319, 0.8785714507102966, 0.7739999890327454, 0.7707930207252502, 0.8928571343421936, 0.7739999890327454, 0.7654739022254944, 0.7863972017100661, 0.013462381140037201, 0.7534608802593724, 0.029255987711256305, 0.7863972017100661, 0.013462381140037161]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6929
Epoch=002, loss=0.6927
Epoch=003, loss=0.6925
Epoch=004, loss=0.6922
Epoch=005, loss=0.6919
Epoch=006, loss=0.6915
Epoch=007, loss=0.6912
Epoch=008, loss=0.6906
Epoch=009, loss=0.6900
Epoch=010, loss=0.6892
Epoch=011, loss=0.6884
Epoch=012, loss=0.6876
Epoch=013, loss=0.6866
Epoch=014, loss=0.6855
Epoch=015, loss=0.6839
Epoch=016, loss=0.6823
Epoch=017, loss=0.6807
Epoch=018, loss=0.6787
Epoch=019, loss=0.6766
Epoch=020, loss=0.6741
Epoch=021, loss=0.6715
Epoch=022, loss=0.6687
Epoch=023, loss=0.6657
Epoch=024, loss=0.6618
Epoch=025, loss=0.6580
Epoch=026, loss=0.6542
Epoch=027, loss=0.6495
Epoch=028, loss=0.6445
Epoch=029, loss=0.6396
Epoch=030, loss=0.6342
Epoch=031, loss=0.6286
Epoch=032, loss=0.6217
Epoch=033, loss=0.6158
Epoch=034, loss=0.6087
Epoch=035, loss=0.6000
Epoch=036, loss=0.5916
Epoch=037, loss=0.5832
Epoch=038, loss=0.5737
Epoch=039, loss=0.5646
Epoch=040, loss=0.5549
Epoch=041, loss=0.5459
Epoch=042, loss=0.5349
Epoch=043, loss=0.5224
Epoch=044, loss=0.5126
Epoch=045, loss=0.4982
Epoch=046, loss=0.4878
Epoch=047, loss=0.4763
Epoch=048, loss=0.4630
Epoch=049, loss=0.4498
Epoch=050, loss=0.4420
Epoch=051, loss=0.4248
Epoch=052, loss=0.4114
Epoch=053, loss=0.4006
Epoch=054, loss=0.3891
Epoch=055, loss=0.3773
Epoch=056, loss=0.3604
Epoch=057, loss=0.3492
Epoch=058, loss=0.3416
Epoch=059, loss=0.3329
Epoch=060, loss=0.3180
Epoch=061, loss=0.3054
Epoch=062, loss=0.2920
Epoch=063, loss=0.2784
Epoch=064, loss=0.2689
Epoch=065, loss=0.2601
Epoch=066, loss=0.2558
Epoch=067, loss=0.2423
Epoch=068, loss=0.2282
Epoch=069, loss=0.2237
Epoch=070, loss=0.2180
Epoch=071, loss=0.2048
Epoch=072, loss=0.2080
Epoch=073, loss=0.1963
Epoch=074, loss=0.1962
Epoch=075, loss=0.1774
Epoch=076, loss=0.1857
Epoch=077, loss=0.1748
Epoch=078, loss=0.1702
Epoch=079, loss=0.1644
Epoch=080, loss=0.1605
Epoch=081, loss=0.1556
Epoch=082, loss=0.1531
Epoch=083, loss=0.1482
Epoch=084, loss=0.1512
Epoch=085, loss=0.1308
Epoch=086, loss=0.1352
Epoch=087, loss=0.1448
Epoch=088, loss=0.1327
Epoch=089, loss=0.1171
Epoch=090, loss=0.1222
Epoch=091, loss=0.1188
Epoch=092, loss=0.1114
Epoch=093, loss=0.1157
Epoch=094, loss=0.1236
Epoch=095, loss=0.1093
Epoch=096, loss=0.1061
Epoch=097, loss=0.1066
Epoch=098, loss=0.1068
Epoch=099, loss=0.1008
Epoch=100, loss=0.1019
Epoch=101, loss=0.1021
Epoch=102, loss=0.1060
Epoch=103, loss=0.1040
Epoch=104, loss=0.0908
Epoch=105, loss=0.0987
Epoch=106, loss=0.0902
Epoch=107, loss=0.0901
Epoch=108, loss=0.0790
Epoch=109, loss=0.0936
Epoch=110, loss=0.0917
Epoch=111, loss=0.0860
Epoch=112, loss=0.0866
Epoch=113, loss=0.0853
Epoch=114, loss=0.0778
Epoch=115, loss=0.0858
Epoch=116, loss=0.0800
Epoch=117, loss=0.0773
Epoch=118, loss=0.0735
Epoch=119, loss=0.0663
Epoch=120, loss=0.0778
Epoch=121, loss=0.0750
Epoch=122, loss=0.0695
Epoch=123, loss=0.0645
Epoch=124, loss=0.0666
Epoch=125, loss=0.0757
Epoch=126, loss=0.0689
Epoch=127, loss=0.0655
Epoch=128, loss=0.0759
Epoch=129, loss=0.0705
Epoch=130, loss=0.0668
Epoch=131, loss=0.0717
Epoch=132, loss=0.0762
Epoch=133, loss=0.0692
Epoch=134, loss=0.0639
Epoch=135, loss=0.0690
Epoch=136, loss=0.0675
Epoch=137, loss=0.0621
Epoch=138, loss=0.0549
Epoch=139, loss=0.0595
Epoch=140, loss=0.0537
Epoch=141, loss=0.0624
Epoch=142, loss=0.0564
Epoch=143, loss=0.0639
Epoch=144, loss=0.0546
Epoch=145, loss=0.0606
Epoch=146, loss=0.0664
Epoch=147, loss=0.0608
Epoch=148, loss=0.0595
Epoch=149, loss=0.0669
Epoch=150, loss=0.0555
Epoch=151, loss=0.0550
Epoch=152, loss=0.0568
Epoch=153, loss=0.0670
Epoch=154, loss=0.0496
Epoch=155, loss=0.0475
Epoch=156, loss=0.0536
Epoch=157, loss=0.0558
Epoch=158, loss=0.0634
Epoch=159, loss=0.0534
Epoch=160, loss=0.0534
Epoch=161, loss=0.0466
Epoch=162, loss=0.0564
Epoch=163, loss=0.0495
Epoch=164, loss=0.0469
Epoch=165, loss=0.0541
Epoch=166, loss=0.0544
Epoch=167, loss=0.0557
Epoch=168, loss=0.0485
Epoch=169, loss=0.0520
Epoch=170, loss=0.0514
Epoch=171, loss=0.0501
Epoch=172, loss=0.0540
Epoch=173, loss=0.0449
Epoch=174, loss=0.0585
Epoch=175, loss=0.0529
Epoch=176, loss=0.0391
Epoch=177, loss=0.0510
Epoch=178, loss=0.0448
Epoch=179, loss=0.0471
Epoch=180, loss=0.0510
Epoch=181, loss=0.0440
Epoch=182, loss=0.0445
Epoch=183, loss=0.0507
Epoch=184, loss=0.0364
Epoch=185, loss=0.0457
Epoch=186, loss=0.0441
Epoch=187, loss=0.0541
Epoch=188, loss=0.0421
Epoch=189, loss=0.0470
Epoch=190, loss=0.0451
Epoch=191, loss=0.0490
Epoch=192, loss=0.0465
Epoch=193, loss=0.0468
Epoch=194, loss=0.0462
Epoch=195, loss=0.0416
Epoch=196, loss=0.0445
Epoch=197, loss=0.0347
Epoch=198, loss=0.0412
Epoch=199, loss=0.0488
Epoch=200, loss=0.0385
Epoch=201, loss=0.0434
Epoch=202, loss=0.0434
Epoch=203, loss=0.0461
Epoch=204, loss=0.0432
Epoch=205, loss=0.0385
Epoch=206, loss=0.0413
Epoch=207, loss=0.0364
Epoch=208, loss=0.0352
Epoch=209, loss=0.0361
Epoch=210, loss=0.0408
Epoch=211, loss=0.0383
Epoch=212, loss=0.0421
Epoch=213, loss=0.0382
Epoch=214, loss=0.0340
Epoch=215, loss=0.0342
Epoch=216, loss=0.0286
Epoch=217, loss=0.0484
Epoch=218, loss=0.0397
Epoch=219, loss=0.0398
Epoch=220, loss=0.0293
Epoch=221, loss=0.0427
Epoch=222, loss=0.0459
Epoch=223, loss=0.0355
Epoch=224, loss=0.0418
Epoch=225, loss=0.0346
Epoch=226, loss=0.0358
Epoch=227, loss=0.0372
Epoch=228, loss=0.0315
Epoch=229, loss=0.0342
Epoch=230, loss=0.0342
Epoch=231, loss=0.0345
Epoch=232, loss=0.0454
Epoch=233, loss=0.0402
Epoch=234, loss=0.0380
Epoch=235, loss=0.0412
Epoch=236, loss=0.0370
Early stopping!
Loading 216th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7854+-0.0144, F1Ma=0.7463+-0.0213, acc=0.7854+-0.0144
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7334168596947772, 0.7500713826961194, 0.7116001569875671, 0.7416331861644319, 0.8785714507102966, 0.7739999890327454, 0.7707930207252502, 0.8928571343421936, 0.7739999890327454, 0.7654739022254944, 0.7863972017100661, 0.013462381140037201, 0.7534608802593724, 0.029255987711256305, 0.7863972017100661, 0.013462381140037161], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.772350301934094, 0.7683906879843225, 0.7699376010427431, 0.7639988094097883, 0.9285714030265808, 0.777999997138977, 0.7790135145187378, 0.9285714030265808, 0.7760000228881836, 0.7790135145187378, 0.7853867081228139, 0.014358867107615428, 0.7463065650219333, 0.021256217135074203, 0.7853867081228139, 0.01435886710761546]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6927
Epoch=002, loss=0.6921
Epoch=003, loss=0.6913
Epoch=004, loss=0.6903
Epoch=005, loss=0.6889
Epoch=006, loss=0.6872
Epoch=007, loss=0.6850
Epoch=008, loss=0.6826
Epoch=009, loss=0.6792
Epoch=010, loss=0.6755
Epoch=011, loss=0.6714
Epoch=012, loss=0.6656
Epoch=013, loss=0.6605
Epoch=014, loss=0.6526
Epoch=015, loss=0.6448
Epoch=016, loss=0.6377
Epoch=017, loss=0.6267
Epoch=018, loss=0.6167
Epoch=019, loss=0.6039
Epoch=020, loss=0.5911
Epoch=021, loss=0.5753
Epoch=022, loss=0.5594
Epoch=023, loss=0.5480
Epoch=024, loss=0.5279
Epoch=025, loss=0.5095
Epoch=026, loss=0.4863
Epoch=027, loss=0.4677
Epoch=028, loss=0.4466
Epoch=029, loss=0.4279
Epoch=030, loss=0.4082
Epoch=031, loss=0.3804
Epoch=032, loss=0.3650
Epoch=033, loss=0.3510
Epoch=034, loss=0.3165
Epoch=035, loss=0.3018
Epoch=036, loss=0.2986
Epoch=037, loss=0.2725
Epoch=038, loss=0.2523
Epoch=039, loss=0.2340
Epoch=040, loss=0.2235
Epoch=041, loss=0.2074
Epoch=042, loss=0.2158
Epoch=043, loss=0.1829
Epoch=044, loss=0.1759
Epoch=045, loss=0.1668
Epoch=046, loss=0.1646
Epoch=047, loss=0.1568
Epoch=048, loss=0.1510
Epoch=049, loss=0.1282
Epoch=050, loss=0.1347
Epoch=051, loss=0.1224
Epoch=052, loss=0.1295
Epoch=053, loss=0.1178
Epoch=054, loss=0.1148
Epoch=055, loss=0.1204
Epoch=056, loss=0.1004
Epoch=057, loss=0.1022
Epoch=058, loss=0.1067
Epoch=059, loss=0.1003
Epoch=060, loss=0.0862
Epoch=061, loss=0.0912
Epoch=062, loss=0.0896
Epoch=063, loss=0.0820
Epoch=064, loss=0.0857
Epoch=065, loss=0.0889
Epoch=066, loss=0.0922
Epoch=067, loss=0.0930
Epoch=068, loss=0.0778
Epoch=069, loss=0.0794
Epoch=070, loss=0.0847
Epoch=071, loss=0.0750
Epoch=072, loss=0.0958
Epoch=073, loss=0.0878
Epoch=074, loss=0.0834
Epoch=075, loss=0.0716
Epoch=076, loss=0.0742
Epoch=077, loss=0.0755
Epoch=078, loss=0.0831
Epoch=079, loss=0.0644
Epoch=080, loss=0.0622
Epoch=081, loss=0.0747
Epoch=082, loss=0.0788
Epoch=083, loss=0.0694
Epoch=084, loss=0.0667
Epoch=085, loss=0.0734
Epoch=086, loss=0.0622
Epoch=087, loss=0.0505
Epoch=088, loss=0.0817
Epoch=089, loss=0.0673
Epoch=090, loss=0.0742
Epoch=091, loss=0.0651
Epoch=092, loss=0.0698
Epoch=093, loss=0.0481
Epoch=094, loss=0.0576
Epoch=095, loss=0.0534
Epoch=096, loss=0.0685
Epoch=097, loss=0.0669
Epoch=098, loss=0.0568
Epoch=099, loss=0.0820
Epoch=100, loss=0.0685
Epoch=101, loss=0.0509
Epoch=102, loss=0.0625
Epoch=103, loss=0.0474
Epoch=104, loss=0.0593
Epoch=105, loss=0.0621
Epoch=106, loss=0.0566
Epoch=107, loss=0.0542
Epoch=108, loss=0.0566
Epoch=109, loss=0.0621
Epoch=110, loss=0.0584
Epoch=111, loss=0.0502
Epoch=112, loss=0.0553
Epoch=113, loss=0.0408
Epoch=114, loss=0.0609
Epoch=115, loss=0.0479
Epoch=116, loss=0.0552
Epoch=117, loss=0.0523
Epoch=118, loss=0.0486
Epoch=119, loss=0.0612
Epoch=120, loss=0.0594
Epoch=121, loss=0.0374
Epoch=122, loss=0.0527
Epoch=123, loss=0.0634
Epoch=124, loss=0.0618
Epoch=125, loss=0.0572
Epoch=126, loss=0.0506
Epoch=127, loss=0.0729
Epoch=128, loss=0.0547
Epoch=129, loss=0.0543
Epoch=130, loss=0.0484
Epoch=131, loss=0.0368
Epoch=132, loss=0.0525
Epoch=133, loss=0.0413
Epoch=134, loss=0.0417
Epoch=135, loss=0.0422
Epoch=136, loss=0.0455
Epoch=137, loss=0.0381
Epoch=138, loss=0.0443
Epoch=139, loss=0.0516
Epoch=140, loss=0.0494
Epoch=141, loss=0.0507
Epoch=142, loss=0.0457
Epoch=143, loss=0.0439
Epoch=144, loss=0.0447
Epoch=145, loss=0.0532
Epoch=146, loss=0.0477
Epoch=147, loss=0.0449
Epoch=148, loss=0.0411
Epoch=149, loss=0.0398
Epoch=150, loss=0.0355
Epoch=151, loss=0.0421
Epoch=152, loss=0.0399
Epoch=153, loss=0.0378
Epoch=154, loss=0.0355
Epoch=155, loss=0.0328
Epoch=156, loss=0.0469
Epoch=157, loss=0.0471
Epoch=158, loss=0.0471
Epoch=159, loss=0.0314
Epoch=160, loss=0.0449
Epoch=161, loss=0.0442
Epoch=162, loss=0.0400
Epoch=163, loss=0.0443
Epoch=164, loss=0.0392
Epoch=165, loss=0.0409
Epoch=166, loss=0.0406
Epoch=167, loss=0.0470
Epoch=168, loss=0.0309
Epoch=169, loss=0.0299
Epoch=170, loss=0.0398
Epoch=171, loss=0.0363
Epoch=172, loss=0.0447
Epoch=173, loss=0.0323
Epoch=174, loss=0.0294
Epoch=175, loss=0.0420
Epoch=176, loss=0.0485
Epoch=177, loss=0.0469
Epoch=178, loss=0.0388
Epoch=179, loss=0.0456
Epoch=180, loss=0.0438
Epoch=181, loss=0.0292
Epoch=182, loss=0.0408
Epoch=183, loss=0.0297
Epoch=184, loss=0.0355
Epoch=185, loss=0.0403
Epoch=186, loss=0.0447
Epoch=187, loss=0.0383
Epoch=188, loss=0.0283
Epoch=189, loss=0.0416
Epoch=190, loss=0.0428
Epoch=191, loss=0.0405
Epoch=192, loss=0.0376
Epoch=193, loss=0.0337
Epoch=194, loss=0.0345
Epoch=195, loss=0.0388
Epoch=196, loss=0.0408
Epoch=197, loss=0.0439
Epoch=198, loss=0.0320
Epoch=199, loss=0.0347
Epoch=200, loss=0.0322
Epoch=201, loss=0.0355
Epoch=202, loss=0.0335
Epoch=203, loss=0.0369
Epoch=204, loss=0.0356
Epoch=205, loss=0.0240
Epoch=206, loss=0.0255
Epoch=207, loss=0.0360
Epoch=208, loss=0.0403
Epoch=209, loss=0.0345
Epoch=210, loss=0.0266
Epoch=211, loss=0.0325
Epoch=212, loss=0.0281
Epoch=213, loss=0.0326
Epoch=214, loss=0.0310
Epoch=215, loss=0.0300
Epoch=216, loss=0.0292
Epoch=217, loss=0.0340
Epoch=218, loss=0.0285
Epoch=219, loss=0.0331
Epoch=220, loss=0.0289
Epoch=221, loss=0.0330
Epoch=222, loss=0.0292
Epoch=223, loss=0.0244
Epoch=224, loss=0.0425
Epoch=225, loss=0.0362
Early stopping!
Loading 205th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8026+-0.0084, F1Ma=0.7747+-0.0319, acc=0.8026+-0.0084
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7334168596947772, 0.7500713826961194, 0.7116001569875671, 0.7416331861644319, 0.8785714507102966, 0.7739999890327454, 0.7707930207252502, 0.8928571343421936, 0.7739999890327454, 0.7654739022254944, 0.7863972017100661, 0.013462381140037201, 0.7534608802593724, 0.029255987711256305, 0.7863972017100661, 0.013462381140037161], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.772350301934094, 0.7683906879843225, 0.7699376010427431, 0.7639988094097883, 0.9285714030265808, 0.777999997138977, 0.7790135145187378, 0.9285714030265808, 0.7760000228881836, 0.7790135145187378, 0.7853867081228139, 0.014358867107615428, 0.7463065650219333, 0.021256217135074203, 0.7853867081228139, 0.01435886710761546], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7718977433584033, 0.7636265006393573, 0.7709835847174764, 0.7643869838817905, 0.8857142925262451, 0.7940000295639038, 0.7751450538635254, 0.8857142925262451, 0.7919999957084656, 0.7746614813804626, 0.8025650991061019, 0.008414997965160865, 0.7746758103262945, 0.03187087520366088, 0.8025650991061019, 0.008414997965160865]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6916
Epoch=002, loss=0.6891
Epoch=003, loss=0.6855
Epoch=004, loss=0.6804
Epoch=005, loss=0.6741
Epoch=006, loss=0.6660
Epoch=007, loss=0.6566
Epoch=008, loss=0.6434
Epoch=009, loss=0.6285
Epoch=010, loss=0.6175
Epoch=011, loss=0.5969
Epoch=012, loss=0.5757
Epoch=013, loss=0.5551
Epoch=014, loss=0.5263
Epoch=015, loss=0.5098
Epoch=016, loss=0.4770
Epoch=017, loss=0.4480
Epoch=018, loss=0.4254
Epoch=019, loss=0.4025
Epoch=020, loss=0.3709
Epoch=021, loss=0.3435
Epoch=022, loss=0.3112
Epoch=023, loss=0.2964
Epoch=024, loss=0.2720
Epoch=025, loss=0.2440
Epoch=026, loss=0.2503
Epoch=027, loss=0.2213
Epoch=028, loss=0.1977
Epoch=029, loss=0.1896
Epoch=030, loss=0.1729
Epoch=031, loss=0.1771
Epoch=032, loss=0.1612
Epoch=033, loss=0.1548
Epoch=034, loss=0.1439
Epoch=035, loss=0.1295
Epoch=036, loss=0.1512
Epoch=037, loss=0.1256
Epoch=038, loss=0.1350
Epoch=039, loss=0.1359
Epoch=040, loss=0.1137
Epoch=041, loss=0.1332
Epoch=042, loss=0.1152
Epoch=043, loss=0.1220
Epoch=044, loss=0.1154
Epoch=045, loss=0.1047
Epoch=046, loss=0.1042
Epoch=047, loss=0.0967
Epoch=048, loss=0.0919
Epoch=049, loss=0.0987
Epoch=050, loss=0.0971
Epoch=051, loss=0.0908
Epoch=052, loss=0.0803
Epoch=053, loss=0.0986
Epoch=054, loss=0.0845
Epoch=055, loss=0.0907
Epoch=056, loss=0.0801
Epoch=057, loss=0.0706
Epoch=058, loss=0.0967
Epoch=059, loss=0.0842
Epoch=060, loss=0.0986
Epoch=061, loss=0.0726
Epoch=062, loss=0.0683
Epoch=063, loss=0.0620
Epoch=064, loss=0.0557
Epoch=065, loss=0.0667
Epoch=066, loss=0.0752
Epoch=067, loss=0.0775
Epoch=068, loss=0.0572
Epoch=069, loss=0.0683
Epoch=070, loss=0.0894
Epoch=071, loss=0.0930
Epoch=072, loss=0.0625
Epoch=073, loss=0.0649
Epoch=074, loss=0.0615
Epoch=075, loss=0.0771
Epoch=076, loss=0.0656
Epoch=077, loss=0.0866
Epoch=078, loss=0.0557
Epoch=079, loss=0.0615
Epoch=080, loss=0.0581
Epoch=081, loss=0.0550
Epoch=082, loss=0.0496
Epoch=083, loss=0.0587
Epoch=084, loss=0.0593
Epoch=085, loss=0.0685
Epoch=086, loss=0.0627
Epoch=087, loss=0.0640
Epoch=088, loss=0.0466
Epoch=089, loss=0.0577
Epoch=090, loss=0.0569
Epoch=091, loss=0.0499
Epoch=092, loss=0.0622
Epoch=093, loss=0.0591
Epoch=094, loss=0.0615
Epoch=095, loss=0.0460
Epoch=096, loss=0.0523
Epoch=097, loss=0.0577
Epoch=098, loss=0.0452
Epoch=099, loss=0.0463
Epoch=100, loss=0.0476
Epoch=101, loss=0.0427
Epoch=102, loss=0.0549
Epoch=103, loss=0.0648
Epoch=104, loss=0.0465
Epoch=105, loss=0.0460
Epoch=106, loss=0.0573
Epoch=107, loss=0.0478
Epoch=108, loss=0.0438
Epoch=109, loss=0.0536
Epoch=110, loss=0.0292
Epoch=111, loss=0.0439
Epoch=112, loss=0.0496
Epoch=113, loss=0.0416
Epoch=114, loss=0.0446
Epoch=115, loss=0.0340
Epoch=116, loss=0.0413
Epoch=117, loss=0.0540
Epoch=118, loss=0.0413
Epoch=119, loss=0.0390
Epoch=120, loss=0.0392
Epoch=121, loss=0.0517
Epoch=122, loss=0.0374
Epoch=123, loss=0.0445
Epoch=124, loss=0.0437
Epoch=125, loss=0.0494
Epoch=126, loss=0.0433
Epoch=127, loss=0.0402
Epoch=128, loss=0.0379
Epoch=129, loss=0.0496
Epoch=130, loss=0.0303
Early stopping!
Loading 110th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8061+-0.0108, F1Ma=0.7895+-0.0113, acc=0.8061+-0.0108
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7334168596947772, 0.7500713826961194, 0.7116001569875671, 0.7416331861644319, 0.8785714507102966, 0.7739999890327454, 0.7707930207252502, 0.8928571343421936, 0.7739999890327454, 0.7654739022254944, 0.7863972017100661, 0.013462381140037201, 0.7534608802593724, 0.029255987711256305, 0.7863972017100661, 0.013462381140037161], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.772350301934094, 0.7683906879843225, 0.7699376010427431, 0.7639988094097883, 0.9285714030265808, 0.777999997138977, 0.7790135145187378, 0.9285714030265808, 0.7760000228881836, 0.7790135145187378, 0.7853867081228139, 0.014358867107615428, 0.7463065650219333, 0.021256217135074203, 0.7853867081228139, 0.01435886710761546], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7718977433584033, 0.7636265006393573, 0.7709835847174764, 0.7643869838817905, 0.8857142925262451, 0.7940000295639038, 0.7751450538635254, 0.8857142925262451, 0.7919999957084656, 0.7746614813804626, 0.8025650991061019, 0.008414997965160865, 0.7746758103262945, 0.03187087520366088, 0.8025650991061019, 0.008414997965160865], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9299557187159422, 0.9212241188751742, 0.926082620108091, 0.9138373982761621, 0.9642857313156128, 0.8100000023841858, 0.8012572526931763, 0.9642857313156128, 0.8100000023841858, 0.8007736802101135, 0.8061406917994558, 0.010841632084521224, 0.7894597860372189, 0.011276802211277156, 0.8061406917994558, 0.01084163208452126]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6907
Epoch=002, loss=0.6852
Epoch=003, loss=0.6748
Epoch=004, loss=0.6663
Epoch=005, loss=0.6517
Epoch=006, loss=0.6349
Epoch=007, loss=0.6187
Epoch=008, loss=0.6025
Epoch=009, loss=0.5738
Epoch=010, loss=0.5488
Epoch=011, loss=0.5238
Epoch=012, loss=0.5113
Epoch=013, loss=0.4586
Epoch=014, loss=0.4320
Epoch=015, loss=0.4189
Epoch=016, loss=0.3694
Epoch=017, loss=0.3480
Epoch=018, loss=0.3375
Epoch=019, loss=0.3109
Epoch=020, loss=0.2540
Epoch=021, loss=0.2550
Epoch=022, loss=0.2451
Epoch=023, loss=0.2236
Epoch=024, loss=0.2186
Epoch=025, loss=0.1899
Epoch=026, loss=0.1790
Epoch=027, loss=0.1664
Epoch=028, loss=0.1265
Epoch=029, loss=0.1505
Epoch=030, loss=0.1346
Epoch=031, loss=0.1153
Epoch=032, loss=0.1248
Epoch=033, loss=0.0957
Epoch=034, loss=0.1024
Epoch=035, loss=0.0967
Epoch=036, loss=0.0780
Epoch=037, loss=0.0914
Epoch=038, loss=0.0918
Epoch=039, loss=0.1041
Epoch=040, loss=0.0675
Epoch=041, loss=0.0897
Epoch=042, loss=0.0743
Epoch=043, loss=0.0974
Epoch=044, loss=0.0713
Epoch=045, loss=0.0975
Epoch=046, loss=0.0477
Epoch=047, loss=0.0964
Epoch=048, loss=0.0519
Epoch=049, loss=0.0887
Epoch=050, loss=0.0638
Epoch=051, loss=0.0545
Epoch=052, loss=0.0505
Epoch=053, loss=0.0526
Epoch=054, loss=0.0595
Epoch=055, loss=0.0508
Epoch=056, loss=0.0518
Epoch=057, loss=0.0485
Epoch=058, loss=0.0384
Epoch=059, loss=0.0485
Epoch=060, loss=0.0390
Epoch=061, loss=0.0426
Epoch=062, loss=0.0352
Epoch=063, loss=0.0214
Epoch=064, loss=0.0356
Epoch=065, loss=0.0543
Epoch=066, loss=0.0362
Epoch=067, loss=0.0474
Epoch=068, loss=0.0249
Epoch=069, loss=0.0350
Epoch=070, loss=0.0459
Epoch=071, loss=0.0265
Epoch=072, loss=0.0385
Epoch=073, loss=0.0248
Epoch=074, loss=0.0256
Epoch=075, loss=0.0459
Epoch=076, loss=0.0236
Epoch=077, loss=0.0229
Epoch=078, loss=0.0317
Epoch=079, loss=0.0232
Epoch=080, loss=0.0236
Epoch=081, loss=0.0255
Epoch=082, loss=0.0251
Epoch=083, loss=0.0199
Epoch=084, loss=0.0154
Epoch=085, loss=0.0184
Epoch=086, loss=0.0283
Epoch=087, loss=0.0206
Epoch=088, loss=0.0188
Epoch=089, loss=0.0194
Epoch=090, loss=0.0130
Epoch=091, loss=0.0135
Epoch=092, loss=0.0224
Epoch=093, loss=0.0189
Epoch=094, loss=0.0168
Epoch=095, loss=0.0204
Epoch=096, loss=0.0190
Epoch=097, loss=0.0191
Epoch=098, loss=0.0166
Epoch=099, loss=0.0212
Epoch=100, loss=0.0180
Epoch=101, loss=0.0209
Epoch=102, loss=0.0120
Epoch=103, loss=0.0102
Epoch=104, loss=0.0148
Epoch=105, loss=0.0208
Epoch=106, loss=0.0161
Epoch=107, loss=0.0178
Epoch=108, loss=0.0133
Epoch=109, loss=0.0076
Epoch=110, loss=0.0201
Epoch=111, loss=0.0181
Epoch=112, loss=0.0082
Epoch=113, loss=0.0156
Epoch=114, loss=0.0172
Epoch=115, loss=0.0113
Epoch=116, loss=0.0117
Epoch=117, loss=0.0108
Epoch=118, loss=0.0131
Epoch=119, loss=0.0085
Epoch=120, loss=0.0174
Epoch=121, loss=0.0114
Epoch=122, loss=0.0043
Epoch=123, loss=0.0097
Epoch=124, loss=0.0091
Epoch=125, loss=0.0091
Epoch=126, loss=0.0068
Epoch=127, loss=0.0097
Epoch=128, loss=0.0068
Epoch=129, loss=0.0132
Epoch=130, loss=0.0134
Epoch=131, loss=0.0085
Epoch=132, loss=0.0081
Epoch=133, loss=0.0057
Epoch=134, loss=0.0118
Epoch=135, loss=0.0077
Epoch=136, loss=0.0060
Epoch=137, loss=0.0079
Epoch=138, loss=0.0097
Epoch=139, loss=0.0186
Epoch=140, loss=0.0052
Epoch=141, loss=0.0049
Epoch=142, loss=0.0081
Early stopping!
Loading 122th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8002+-0.0108, F1Ma=0.7778+-0.0120, acc=0.8002+-0.0108
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.8462923807912404, 0.833788198803851, 0.8381731832109718, 0.8276577179362867, 0.8071428537368774, 0.7360000014305115, 0.7296905517578125, 0.7928571701049805, 0.7360000014305115, 0.7238878011703491, 0.7237465993004275, 0.010010017897865662, 0.6907670974351298, 0.017106334866143588, 0.7237465993004276, 0.01001001789786567], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7334168596947772, 0.7500713826961194, 0.7116001569875671, 0.7416331861644319, 0.8785714507102966, 0.7739999890327454, 0.7707930207252502, 0.8928571343421936, 0.7739999890327454, 0.7654739022254944, 0.7863972017100661, 0.013462381140037201, 0.7534608802593724, 0.029255987711256305, 0.7863972017100661, 0.013462381140037161], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.772350301934094, 0.7683906879843225, 0.7699376010427431, 0.7639988094097883, 0.9285714030265808, 0.777999997138977, 0.7790135145187378, 0.9285714030265808, 0.7760000228881836, 0.7790135145187378, 0.7853867081228139, 0.014358867107615428, 0.7463065650219333, 0.021256217135074203, 0.7853867081228139, 0.01435886710761546], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7718977433584033, 0.7636265006393573, 0.7709835847174764, 0.7643869838817905, 0.8857142925262451, 0.7940000295639038, 0.7751450538635254, 0.8857142925262451, 0.7919999957084656, 0.7746614813804626, 0.8025650991061019, 0.008414997965160865, 0.7746758103262945, 0.03187087520366088, 0.8025650991061019, 0.008414997965160865], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9299557187159422, 0.9212241188751742, 0.926082620108091, 0.9138373982761621, 0.9642857313156128, 0.8100000023841858, 0.8012572526931763, 0.9642857313156128, 0.8100000023841858, 0.8007736802101135, 0.8061406917994558, 0.010841632084521224, 0.7894597860372189, 0.011276802211277156, 0.8061406917994558, 0.01084163208452126], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7648914385678108, 0.7809794899607735, 0.7583147600718685, 0.7800170372715094, 0.9142857193946838, 0.8080000281333923, 0.7940038442611694, 0.9357143044471741, 0.8080000281333923, 0.7969052195549011, 0.800155460551885, 0.010780155248443342, 0.7777916302411616, 0.011958725840567477, 0.800155460551885, 0.010780155248443342]]
