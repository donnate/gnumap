My SLURM_ARRAY_TASK_ID:  3
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_3
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_3.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6931
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6929
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6928
Epoch=010, loss=0.6927
Epoch=011, loss=0.6927
Epoch=012, loss=0.6926
Epoch=013, loss=0.6925
Epoch=014, loss=0.6924
Epoch=015, loss=0.6924
Epoch=016, loss=0.6923
Epoch=017, loss=0.6922
Epoch=018, loss=0.6921
Epoch=019, loss=0.6920
Epoch=020, loss=0.6919
Epoch=021, loss=0.6918
Epoch=022, loss=0.6917
Epoch=023, loss=0.6916
Epoch=024, loss=0.6914
Epoch=025, loss=0.6913
Epoch=026, loss=0.6911
Epoch=027, loss=0.6909
Epoch=028, loss=0.6906
Epoch=029, loss=0.6905
Epoch=030, loss=0.6902
Epoch=031, loss=0.6901
Epoch=032, loss=0.6898
Epoch=033, loss=0.6896
Epoch=034, loss=0.6894
Epoch=035, loss=0.6890
Epoch=036, loss=0.6887
Epoch=037, loss=0.6884
Epoch=038, loss=0.6880
Epoch=039, loss=0.6878
Epoch=040, loss=0.6874
Epoch=041, loss=0.6870
Epoch=042, loss=0.6867
Epoch=043, loss=0.6863
Epoch=044, loss=0.6857
Epoch=045, loss=0.6853
Epoch=046, loss=0.6849
Epoch=047, loss=0.6844
Epoch=048, loss=0.6838
Epoch=049, loss=0.6832
Epoch=050, loss=0.6828
Epoch=051, loss=0.6823
Epoch=052, loss=0.6815
Epoch=053, loss=0.6810
Epoch=054, loss=0.6803
Epoch=055, loss=0.6796
Epoch=056, loss=0.6789
Epoch=057, loss=0.6781
Epoch=058, loss=0.6770
Epoch=059, loss=0.6763
Epoch=060, loss=0.6757
Epoch=061, loss=0.6752
Epoch=062, loss=0.6737
Epoch=063, loss=0.6727
Epoch=064, loss=0.6716
Epoch=065, loss=0.6714
Epoch=066, loss=0.6696
Epoch=067, loss=0.6690
Epoch=068, loss=0.6674
Epoch=069, loss=0.6666
Epoch=070, loss=0.6649
Epoch=071, loss=0.6639
Epoch=072, loss=0.6632
Epoch=073, loss=0.6609
Epoch=074, loss=0.6597
Epoch=075, loss=0.6587
Epoch=076, loss=0.6570
Epoch=077, loss=0.6562
Epoch=078, loss=0.6539
Epoch=079, loss=0.6518
Epoch=080, loss=0.6505
Epoch=081, loss=0.6491
Epoch=082, loss=0.6474
Epoch=083, loss=0.6456
Epoch=084, loss=0.6440
Epoch=085, loss=0.6422
Epoch=086, loss=0.6402
Epoch=087, loss=0.6388
Epoch=088, loss=0.6369
Epoch=089, loss=0.6351
Epoch=090, loss=0.6316
Epoch=091, loss=0.6303
Epoch=092, loss=0.6283
Epoch=093, loss=0.6252
Epoch=094, loss=0.6239
Epoch=095, loss=0.6222
Epoch=096, loss=0.6194
Epoch=097, loss=0.6174
Epoch=098, loss=0.6152
Epoch=099, loss=0.6129
Epoch=100, loss=0.6102
Epoch=101, loss=0.6057
Epoch=102, loss=0.6057
Epoch=103, loss=0.6023
Epoch=104, loss=0.6011
Epoch=105, loss=0.5947
Epoch=106, loss=0.5931
Epoch=107, loss=0.5936
Epoch=108, loss=0.5881
Epoch=109, loss=0.5848
Epoch=110, loss=0.5831
Epoch=111, loss=0.5793
Epoch=112, loss=0.5756
Epoch=113, loss=0.5735
Epoch=114, loss=0.5681
Epoch=115, loss=0.5666
Epoch=116, loss=0.5642
Epoch=117, loss=0.5592
Epoch=118, loss=0.5592
Epoch=119, loss=0.5552
Epoch=120, loss=0.5555
Epoch=121, loss=0.5497
Epoch=122, loss=0.5435
Epoch=123, loss=0.5424
Epoch=124, loss=0.5383
Epoch=125, loss=0.5352
Epoch=126, loss=0.5326
Epoch=127, loss=0.5306
Epoch=128, loss=0.5243
Epoch=129, loss=0.5209
Epoch=130, loss=0.5177
Epoch=131, loss=0.5124
Epoch=132, loss=0.5109
Epoch=133, loss=0.5075
Epoch=134, loss=0.5031
Epoch=135, loss=0.5017
Epoch=136, loss=0.4936
Epoch=137, loss=0.4877
Epoch=138, loss=0.4913
Epoch=139, loss=0.4845
Epoch=140, loss=0.4793
Epoch=141, loss=0.4742
Epoch=142, loss=0.4762
Epoch=143, loss=0.4713
Epoch=144, loss=0.4666
Epoch=145, loss=0.4587
Epoch=146, loss=0.4616
Epoch=147, loss=0.4552
Epoch=148, loss=0.4509
Epoch=149, loss=0.4430
Epoch=150, loss=0.4482
Epoch=151, loss=0.4426
Epoch=152, loss=0.4367
Epoch=153, loss=0.4326
Epoch=154, loss=0.4285
Epoch=155, loss=0.4281
Epoch=156, loss=0.4206
Epoch=157, loss=0.4172
Epoch=158, loss=0.4093
Epoch=159, loss=0.4110
Epoch=160, loss=0.4019
Epoch=161, loss=0.4010
Epoch=162, loss=0.3955
Epoch=163, loss=0.3940
Epoch=164, loss=0.3953
Epoch=165, loss=0.3881
Epoch=166, loss=0.3891
Epoch=167, loss=0.3848
Epoch=168, loss=0.3767
Epoch=169, loss=0.3734
Epoch=170, loss=0.3673
Epoch=171, loss=0.3674
Epoch=172, loss=0.3603
Epoch=173, loss=0.3634
Epoch=174, loss=0.3609
Epoch=175, loss=0.3543
Epoch=176, loss=0.3461
Epoch=177, loss=0.3474
Epoch=178, loss=0.3455
Epoch=179, loss=0.3404
Epoch=180, loss=0.3389
Epoch=181, loss=0.3376
Epoch=182, loss=0.3358
Epoch=183, loss=0.3269
Epoch=184, loss=0.3228
Epoch=185, loss=0.3198
Epoch=186, loss=0.3207
Epoch=187, loss=0.3181
Epoch=188, loss=0.3115
Epoch=189, loss=0.3098
Epoch=190, loss=0.2979
Epoch=191, loss=0.3004
Epoch=192, loss=0.2952
Epoch=193, loss=0.2947
Epoch=194, loss=0.2877
Epoch=195, loss=0.2887
Epoch=196, loss=0.2909
Epoch=197, loss=0.2848
Epoch=198, loss=0.2842
Epoch=199, loss=0.2782
Epoch=200, loss=0.2799
Epoch=201, loss=0.2737
Epoch=202, loss=0.2798
Epoch=203, loss=0.2685
Epoch=204, loss=0.2663
Epoch=205, loss=0.2603
Epoch=206, loss=0.2649
Epoch=207, loss=0.2572
Epoch=208, loss=0.2649
Epoch=209, loss=0.2508
Epoch=210, loss=0.2513
Epoch=211, loss=0.2468
Epoch=212, loss=0.2535
Epoch=213, loss=0.2495
Epoch=214, loss=0.2465
Epoch=215, loss=0.2364
Epoch=216, loss=0.2438
Epoch=217, loss=0.2348
Epoch=218, loss=0.2356
Epoch=219, loss=0.2363
Epoch=220, loss=0.2319
Epoch=221, loss=0.2233
Epoch=222, loss=0.2275
Epoch=223, loss=0.2294
Epoch=224, loss=0.2221
Epoch=225, loss=0.2236
Epoch=226, loss=0.2206
Epoch=227, loss=0.2159
Epoch=228, loss=0.2046
Epoch=229, loss=0.2155
Epoch=230, loss=0.2121
Epoch=231, loss=0.2038
Epoch=232, loss=0.2014
Epoch=233, loss=0.2082
Epoch=234, loss=0.2032
Epoch=235, loss=0.2010
Epoch=236, loss=0.1963
Epoch=237, loss=0.1968
Epoch=238, loss=0.1961
Epoch=239, loss=0.2068
Epoch=240, loss=0.1966
Epoch=241, loss=0.1974
Epoch=242, loss=0.1855
Epoch=243, loss=0.1838
Epoch=244, loss=0.1953
Epoch=245, loss=0.1855
Epoch=246, loss=0.1796
Epoch=247, loss=0.1831
Epoch=248, loss=0.1776
Epoch=249, loss=0.1835
Epoch=250, loss=0.1745
Epoch=251, loss=0.1752
Epoch=252, loss=0.1763
Epoch=253, loss=0.1679
Epoch=254, loss=0.1727
Epoch=255, loss=0.1752
Epoch=256, loss=0.1697
Epoch=257, loss=0.1706
Epoch=258, loss=0.1763
Epoch=259, loss=0.1716
Epoch=260, loss=0.1662
Epoch=261, loss=0.1685
Epoch=262, loss=0.1683
Epoch=263, loss=0.1613
Epoch=264, loss=0.1633
Epoch=265, loss=0.1590
Epoch=266, loss=0.1577
Epoch=267, loss=0.1578
Epoch=268, loss=0.1533
Epoch=269, loss=0.1601
Epoch=270, loss=0.1569
Epoch=271, loss=0.1585
Epoch=272, loss=0.1550
Epoch=273, loss=0.1519
Epoch=274, loss=0.1543
Epoch=275, loss=0.1510
Epoch=276, loss=0.1521
Epoch=277, loss=0.1515
Epoch=278, loss=0.1472
Epoch=279, loss=0.1366
Epoch=280, loss=0.1528
Epoch=281, loss=0.1472
Epoch=282, loss=0.1474
Epoch=283, loss=0.1412
Epoch=284, loss=0.1437
Epoch=285, loss=0.1397
Epoch=286, loss=0.1496
Epoch=287, loss=0.1388
Epoch=288, loss=0.1438
Epoch=289, loss=0.1319
Epoch=290, loss=0.1420
Epoch=291, loss=0.1296
Epoch=292, loss=0.1312
Epoch=293, loss=0.1339
Epoch=294, loss=0.1356
Epoch=295, loss=0.1301
Epoch=296, loss=0.1316
Epoch=297, loss=0.1298
Epoch=298, loss=0.1338
Epoch=299, loss=0.1293
Epoch=300, loss=0.1269
Epoch=301, loss=0.1345
Epoch=302, loss=0.1321
Epoch=303, loss=0.1295
Epoch=304, loss=0.1290
Epoch=305, loss=0.1293
Epoch=306, loss=0.1252
Epoch=307, loss=0.1226
Epoch=308, loss=0.1212
Epoch=309, loss=0.1242
Epoch=310, loss=0.1179
Epoch=311, loss=0.1252
Epoch=312, loss=0.1208
Epoch=313, loss=0.1177
Epoch=314, loss=0.1230
Epoch=315, loss=0.1167
Epoch=316, loss=0.1152
Epoch=317, loss=0.1153
Epoch=318, loss=0.1118
Epoch=319, loss=0.1129
Epoch=320, loss=0.1181
Epoch=321, loss=0.1189
Epoch=322, loss=0.1137
Epoch=323, loss=0.1059
Epoch=324, loss=0.1239
Epoch=325, loss=0.1113
Epoch=326, loss=0.1121
Epoch=327, loss=0.1100
Epoch=328, loss=0.1068
Epoch=329, loss=0.1169
Epoch=330, loss=0.1049
Epoch=331, loss=0.1069
Epoch=332, loss=0.1010
Epoch=333, loss=0.1165
Epoch=334, loss=0.1094
Epoch=335, loss=0.1075
Epoch=336, loss=0.1066
Epoch=337, loss=0.1017
Epoch=338, loss=0.1093
Epoch=339, loss=0.0959
Epoch=340, loss=0.1180
Epoch=341, loss=0.1060
Epoch=342, loss=0.1071
Epoch=343, loss=0.1105
Epoch=344, loss=0.1036
Epoch=345, loss=0.0945
Epoch=346, loss=0.1056
Epoch=347, loss=0.1015
Epoch=348, loss=0.0988
Epoch=349, loss=0.0938
Epoch=350, loss=0.0921
Epoch=351, loss=0.1002
Epoch=352, loss=0.1105
Epoch=353, loss=0.0981
Epoch=354, loss=0.1024
Epoch=355, loss=0.0931
Epoch=356, loss=0.0988
Epoch=357, loss=0.0964
Epoch=358, loss=0.0978
Epoch=359, loss=0.0916
Epoch=360, loss=0.1032
Epoch=361, loss=0.0997
Epoch=362, loss=0.0996
Epoch=363, loss=0.0955
Epoch=364, loss=0.0957
Epoch=365, loss=0.0966
Epoch=366, loss=0.0955
Epoch=367, loss=0.0884
Epoch=368, loss=0.0917
Epoch=369, loss=0.0954
Epoch=370, loss=0.0937
Epoch=371, loss=0.0866
Epoch=372, loss=0.0962
Epoch=373, loss=0.0930
Epoch=374, loss=0.0919
Epoch=375, loss=0.0870
Epoch=376, loss=0.0876
Epoch=377, loss=0.0971
Epoch=378, loss=0.0936
Epoch=379, loss=0.0835
Epoch=380, loss=0.0832
Epoch=381, loss=0.0872
Epoch=382, loss=0.0899
Epoch=383, loss=0.0909
Epoch=384, loss=0.0853
Epoch=385, loss=0.0939
Epoch=386, loss=0.0797
Epoch=387, loss=0.0987
Epoch=388, loss=0.0935
Epoch=389, loss=0.0873
Epoch=390, loss=0.0815
Epoch=391, loss=0.0837
Epoch=392, loss=0.0869
Epoch=393, loss=0.0732
Epoch=394, loss=0.0863
Epoch=395, loss=0.0923
Epoch=396, loss=0.0837
Epoch=397, loss=0.0826
Epoch=398, loss=0.0874
Epoch=399, loss=0.0716
Epoch=400, loss=0.0916
Epoch=401, loss=0.0892
Epoch=402, loss=0.0857
Epoch=403, loss=0.0798
Epoch=404, loss=0.0816
Epoch=405, loss=0.0774
Epoch=406, loss=0.0876
Epoch=407, loss=0.0830
Epoch=408, loss=0.0874
Epoch=409, loss=0.0782
Epoch=410, loss=0.0826
Epoch=411, loss=0.0859
Epoch=412, loss=0.0818
Epoch=413, loss=0.0830
Epoch=414, loss=0.0852
Epoch=415, loss=0.0799
Epoch=416, loss=0.0842
Epoch=417, loss=0.0740
Epoch=418, loss=0.0816
Epoch=419, loss=0.0854
Early stopping!
Loading 399th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7080+-0.0140, F1Ma=0.6459+-0.0211, acc=0.7080+-0.0140
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6928
Epoch=007, loss=0.6927
Epoch=008, loss=0.6926
Epoch=009, loss=0.6925
Epoch=010, loss=0.6923
Epoch=011, loss=0.6922
Epoch=012, loss=0.6920
Epoch=013, loss=0.6918
Epoch=014, loss=0.6917
Epoch=015, loss=0.6914
Epoch=016, loss=0.6912
Epoch=017, loss=0.6909
Epoch=018, loss=0.6907
Epoch=019, loss=0.6903
Epoch=020, loss=0.6899
Epoch=021, loss=0.6896
Epoch=022, loss=0.6891
Epoch=023, loss=0.6885
Epoch=024, loss=0.6881
Epoch=025, loss=0.6875
Epoch=026, loss=0.6870
Epoch=027, loss=0.6862
Epoch=028, loss=0.6856
Epoch=029, loss=0.6850
Epoch=030, loss=0.6839
Epoch=031, loss=0.6831
Epoch=032, loss=0.6820
Epoch=033, loss=0.6810
Epoch=034, loss=0.6802
Epoch=035, loss=0.6786
Epoch=036, loss=0.6774
Epoch=037, loss=0.6763
Epoch=038, loss=0.6748
Epoch=039, loss=0.6732
Epoch=040, loss=0.6716
Epoch=041, loss=0.6698
Epoch=042, loss=0.6680
Epoch=043, loss=0.6660
Epoch=044, loss=0.6639
Epoch=045, loss=0.6617
Epoch=046, loss=0.6593
Epoch=047, loss=0.6573
Epoch=048, loss=0.6541
Epoch=049, loss=0.6517
Epoch=050, loss=0.6492
Epoch=051, loss=0.6461
Epoch=052, loss=0.6424
Epoch=053, loss=0.6397
Epoch=054, loss=0.6355
Epoch=055, loss=0.6323
Epoch=056, loss=0.6284
Epoch=057, loss=0.6260
Epoch=058, loss=0.6214
Epoch=059, loss=0.6171
Epoch=060, loss=0.6125
Epoch=061, loss=0.6087
Epoch=062, loss=0.6051
Epoch=063, loss=0.5984
Epoch=064, loss=0.5949
Epoch=065, loss=0.5896
Epoch=066, loss=0.5839
Epoch=067, loss=0.5780
Epoch=068, loss=0.5743
Epoch=069, loss=0.5671
Epoch=070, loss=0.5621
Epoch=071, loss=0.5539
Epoch=072, loss=0.5527
Epoch=073, loss=0.5434
Epoch=074, loss=0.5404
Epoch=075, loss=0.5319
Epoch=076, loss=0.5274
Epoch=077, loss=0.5182
Epoch=078, loss=0.5139
Epoch=079, loss=0.5067
Epoch=080, loss=0.4993
Epoch=081, loss=0.4936
Epoch=082, loss=0.4853
Epoch=083, loss=0.4766
Epoch=084, loss=0.4697
Epoch=085, loss=0.4637
Epoch=086, loss=0.4556
Epoch=087, loss=0.4495
Epoch=088, loss=0.4445
Epoch=089, loss=0.4403
Epoch=090, loss=0.4267
Epoch=091, loss=0.4200
Epoch=092, loss=0.4148
Epoch=093, loss=0.4080
Epoch=094, loss=0.3999
Epoch=095, loss=0.3927
Epoch=096, loss=0.3912
Epoch=097, loss=0.3868
Epoch=098, loss=0.3727
Epoch=099, loss=0.3705
Epoch=100, loss=0.3628
Epoch=101, loss=0.3520
Epoch=102, loss=0.3500
Epoch=103, loss=0.3378
Epoch=104, loss=0.3315
Epoch=105, loss=0.3326
Epoch=106, loss=0.3232
Epoch=107, loss=0.3182
Epoch=108, loss=0.3153
Epoch=109, loss=0.3126
Epoch=110, loss=0.2969
Epoch=111, loss=0.2917
Epoch=112, loss=0.2897
Epoch=113, loss=0.2838
Epoch=114, loss=0.2769
Epoch=115, loss=0.2775
Epoch=116, loss=0.2623
Epoch=117, loss=0.2570
Epoch=118, loss=0.2609
Epoch=119, loss=0.2476
Epoch=120, loss=0.2631
Epoch=121, loss=0.2497
Epoch=122, loss=0.2392
Epoch=123, loss=0.2377
Epoch=124, loss=0.2289
Epoch=125, loss=0.2297
Epoch=126, loss=0.2228
Epoch=127, loss=0.2188
Epoch=128, loss=0.2192
Epoch=129, loss=0.2065
Epoch=130, loss=0.2097
Epoch=131, loss=0.2057
Epoch=132, loss=0.1965
Epoch=133, loss=0.1941
Epoch=134, loss=0.1953
Epoch=135, loss=0.1852
Epoch=136, loss=0.1944
Epoch=137, loss=0.1805
Epoch=138, loss=0.1768
Epoch=139, loss=0.1852
Epoch=140, loss=0.1667
Epoch=141, loss=0.1685
Epoch=142, loss=0.1719
Epoch=143, loss=0.1757
Epoch=144, loss=0.1722
Epoch=145, loss=0.1642
Epoch=146, loss=0.1535
Epoch=147, loss=0.1558
Epoch=148, loss=0.1584
Epoch=149, loss=0.1548
Epoch=150, loss=0.1552
Epoch=151, loss=0.1523
Epoch=152, loss=0.1486
Epoch=153, loss=0.1390
Epoch=154, loss=0.1384
Epoch=155, loss=0.1472
Epoch=156, loss=0.1328
Epoch=157, loss=0.1430
Epoch=158, loss=0.1333
Epoch=159, loss=0.1391
Epoch=160, loss=0.1311
Epoch=161, loss=0.1430
Epoch=162, loss=0.1246
Epoch=163, loss=0.1275
Epoch=164, loss=0.1261
Epoch=165, loss=0.1278
Epoch=166, loss=0.1244
Epoch=167, loss=0.1209
Epoch=168, loss=0.1301
Epoch=169, loss=0.1216
Epoch=170, loss=0.1191
Epoch=171, loss=0.1211
Epoch=172, loss=0.1157
Epoch=173, loss=0.1226
Epoch=174, loss=0.1095
Epoch=175, loss=0.1159
Epoch=176, loss=0.1082
Epoch=177, loss=0.1087
Epoch=178, loss=0.1112
Epoch=179, loss=0.1100
Epoch=180, loss=0.1072
Epoch=181, loss=0.0990
Epoch=182, loss=0.1062
Epoch=183, loss=0.1138
Epoch=184, loss=0.1004
Epoch=185, loss=0.1011
Epoch=186, loss=0.1118
Epoch=187, loss=0.0957
Epoch=188, loss=0.0953
Epoch=189, loss=0.0984
Epoch=190, loss=0.1034
Epoch=191, loss=0.0941
Epoch=192, loss=0.1040
Epoch=193, loss=0.0933
Epoch=194, loss=0.0887
Epoch=195, loss=0.0909
Epoch=196, loss=0.0845
Epoch=197, loss=0.0839
Epoch=198, loss=0.0880
Epoch=199, loss=0.0887
Epoch=200, loss=0.0977
Epoch=201, loss=0.0877
Epoch=202, loss=0.0926
Epoch=203, loss=0.0803
Epoch=204, loss=0.0934
Epoch=205, loss=0.0873
Epoch=206, loss=0.0849
Epoch=207, loss=0.0825
Epoch=208, loss=0.0878
Epoch=209, loss=0.0787
Epoch=210, loss=0.0854
Epoch=211, loss=0.0843
Epoch=212, loss=0.0973
Epoch=213, loss=0.0818
Epoch=214, loss=0.0805
Epoch=215, loss=0.0857
Epoch=216, loss=0.0874
Epoch=217, loss=0.0836
Epoch=218, loss=0.0774
Epoch=219, loss=0.0777
Epoch=220, loss=0.0766
Epoch=221, loss=0.0797
Epoch=222, loss=0.0787
Epoch=223, loss=0.0767
Epoch=224, loss=0.0744
Epoch=225, loss=0.0746
Epoch=226, loss=0.0669
Epoch=227, loss=0.0722
Epoch=228, loss=0.0703
Epoch=229, loss=0.0661
Epoch=230, loss=0.0698
Epoch=231, loss=0.0723
Epoch=232, loss=0.0762
Epoch=233, loss=0.0750
Epoch=234, loss=0.0728
Epoch=235, loss=0.0632
Epoch=236, loss=0.0624
Epoch=237, loss=0.0689
Epoch=238, loss=0.0704
Epoch=239, loss=0.0697
Epoch=240, loss=0.0665
Epoch=241, loss=0.0682
Epoch=242, loss=0.0663
Epoch=243, loss=0.0627
Epoch=244, loss=0.0729
Epoch=245, loss=0.0685
Epoch=246, loss=0.0656
Epoch=247, loss=0.0681
Epoch=248, loss=0.0617
Epoch=249, loss=0.0682
Epoch=250, loss=0.0574
Epoch=251, loss=0.0690
Epoch=252, loss=0.0602
Epoch=253, loss=0.0538
Epoch=254, loss=0.0648
Epoch=255, loss=0.0589
Epoch=256, loss=0.0639
Epoch=257, loss=0.0644
Epoch=258, loss=0.0669
Epoch=259, loss=0.0684
Epoch=260, loss=0.0606
Epoch=261, loss=0.0576
Epoch=262, loss=0.0595
Epoch=263, loss=0.0588
Epoch=264, loss=0.0564
Epoch=265, loss=0.0656
Epoch=266, loss=0.0598
Epoch=267, loss=0.0563
Epoch=268, loss=0.0547
Epoch=269, loss=0.0542
Epoch=270, loss=0.0556
Epoch=271, loss=0.0560
Epoch=272, loss=0.0575
Epoch=273, loss=0.0511
Epoch=274, loss=0.0586
Epoch=275, loss=0.0552
Epoch=276, loss=0.0576
Epoch=277, loss=0.0611
Epoch=278, loss=0.0515
Epoch=279, loss=0.0563
Epoch=280, loss=0.0542
Epoch=281, loss=0.0495
Epoch=282, loss=0.0621
Epoch=283, loss=0.0526
Epoch=284, loss=0.0523
Epoch=285, loss=0.0533
Epoch=286, loss=0.0507
Epoch=287, loss=0.0497
Epoch=288, loss=0.0500
Epoch=289, loss=0.0572
Epoch=290, loss=0.0513
Epoch=291, loss=0.0509
Epoch=292, loss=0.0521
Epoch=293, loss=0.0632
Epoch=294, loss=0.0505
Epoch=295, loss=0.0427
Epoch=296, loss=0.0514
Epoch=297, loss=0.0473
Epoch=298, loss=0.0478
Epoch=299, loss=0.0561
Epoch=300, loss=0.0416
Epoch=301, loss=0.0497
Epoch=302, loss=0.0475
Epoch=303, loss=0.0437
Epoch=304, loss=0.0463
Epoch=305, loss=0.0453
Epoch=306, loss=0.0512
Epoch=307, loss=0.0394
Epoch=308, loss=0.0471
Epoch=309, loss=0.0484
Epoch=310, loss=0.0461
Epoch=311, loss=0.0536
Epoch=312, loss=0.0443
Epoch=313, loss=0.0415
Epoch=314, loss=0.0456
Epoch=315, loss=0.0470
Epoch=316, loss=0.0524
Epoch=317, loss=0.0394
Epoch=318, loss=0.0402
Epoch=319, loss=0.0505
Epoch=320, loss=0.0431
Epoch=321, loss=0.0437
Epoch=322, loss=0.0486
Epoch=323, loss=0.0422
Epoch=324, loss=0.0470
Epoch=325, loss=0.0459
Epoch=326, loss=0.0469
Epoch=327, loss=0.0412
Epoch=328, loss=0.0414
Epoch=329, loss=0.0431
Epoch=330, loss=0.0473
Epoch=331, loss=0.0365
Epoch=332, loss=0.0350
Epoch=333, loss=0.0377
Epoch=334, loss=0.0472
Epoch=335, loss=0.0380
Epoch=336, loss=0.0477
Epoch=337, loss=0.0456
Epoch=338, loss=0.0419
Epoch=339, loss=0.0409
Epoch=340, loss=0.0420
Epoch=341, loss=0.0411
Epoch=342, loss=0.0359
Epoch=343, loss=0.0380
Epoch=344, loss=0.0466
Epoch=345, loss=0.0360
Epoch=346, loss=0.0476
Epoch=347, loss=0.0429
Epoch=348, loss=0.0407
Epoch=349, loss=0.0385
Epoch=350, loss=0.0381
Epoch=351, loss=0.0370
Epoch=352, loss=0.0326
Epoch=353, loss=0.0376
Epoch=354, loss=0.0381
Epoch=355, loss=0.0473
Epoch=356, loss=0.0351
Epoch=357, loss=0.0359
Epoch=358, loss=0.0352
Epoch=359, loss=0.0395
Epoch=360, loss=0.0366
Epoch=361, loss=0.0338
Epoch=362, loss=0.0358
Epoch=363, loss=0.0387
Epoch=364, loss=0.0504
Epoch=365, loss=0.0402
Epoch=366, loss=0.0418
Epoch=367, loss=0.0375
Epoch=368, loss=0.0369
Epoch=369, loss=0.0366
Epoch=370, loss=0.0359
Epoch=371, loss=0.0361
Epoch=372, loss=0.0403
Early stopping!
Loading 352th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7675+-0.0150, F1Ma=0.7384+-0.0269, acc=0.7675+-0.0150
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7706708878657605, 0.7747211268998493, 0.7905368182652874, 0.7841401831452868, 0.7785714268684387, 0.7559999823570251, 0.7364603281021118, 0.7785714268684387, 0.7519999742507935, 0.738394558429718, 0.7675087446560436, 0.01498683261394303, 0.7384228739075238, 0.026897566319932065, 0.7675087446560436, 0.014986832613943065]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6929
Epoch=003, loss=0.6927
Epoch=004, loss=0.6925
Epoch=005, loss=0.6922
Epoch=006, loss=0.6919
Epoch=007, loss=0.6915
Epoch=008, loss=0.6911
Epoch=009, loss=0.6905
Epoch=010, loss=0.6899
Epoch=011, loss=0.6892
Epoch=012, loss=0.6883
Epoch=013, loss=0.6873
Epoch=014, loss=0.6863
Epoch=015, loss=0.6849
Epoch=016, loss=0.6835
Epoch=017, loss=0.6818
Epoch=018, loss=0.6801
Epoch=019, loss=0.6781
Epoch=020, loss=0.6760
Epoch=021, loss=0.6738
Epoch=022, loss=0.6710
Epoch=023, loss=0.6677
Epoch=024, loss=0.6646
Epoch=025, loss=0.6607
Epoch=026, loss=0.6567
Epoch=027, loss=0.6530
Epoch=028, loss=0.6480
Epoch=029, loss=0.6429
Epoch=030, loss=0.6380
Epoch=031, loss=0.6319
Epoch=032, loss=0.6255
Epoch=033, loss=0.6189
Epoch=034, loss=0.6118
Epoch=035, loss=0.6063
Epoch=036, loss=0.5975
Epoch=037, loss=0.5886
Epoch=038, loss=0.5796
Epoch=039, loss=0.5686
Epoch=040, loss=0.5617
Epoch=041, loss=0.5505
Epoch=042, loss=0.5400
Epoch=043, loss=0.5293
Epoch=044, loss=0.5178
Epoch=045, loss=0.5050
Epoch=046, loss=0.4967
Epoch=047, loss=0.4783
Epoch=048, loss=0.4726
Epoch=049, loss=0.4578
Epoch=050, loss=0.4451
Epoch=051, loss=0.4278
Epoch=052, loss=0.4166
Epoch=053, loss=0.4072
Epoch=054, loss=0.3938
Epoch=055, loss=0.3802
Epoch=056, loss=0.3678
Epoch=057, loss=0.3552
Epoch=058, loss=0.3413
Epoch=059, loss=0.3305
Epoch=060, loss=0.3191
Epoch=061, loss=0.3092
Epoch=062, loss=0.2943
Epoch=063, loss=0.2836
Epoch=064, loss=0.2775
Epoch=065, loss=0.2695
Epoch=066, loss=0.2542
Epoch=067, loss=0.2450
Epoch=068, loss=0.2302
Epoch=069, loss=0.2271
Epoch=070, loss=0.2185
Epoch=071, loss=0.2060
Epoch=072, loss=0.1989
Epoch=073, loss=0.1956
Epoch=074, loss=0.1823
Epoch=075, loss=0.1867
Epoch=076, loss=0.1728
Epoch=077, loss=0.1671
Epoch=078, loss=0.1647
Epoch=079, loss=0.1553
Epoch=080, loss=0.1547
Epoch=081, loss=0.1489
Epoch=082, loss=0.1359
Epoch=083, loss=0.1416
Epoch=084, loss=0.1333
Epoch=085, loss=0.1279
Epoch=086, loss=0.1344
Epoch=087, loss=0.1303
Epoch=088, loss=0.1239
Epoch=089, loss=0.1318
Epoch=090, loss=0.1157
Epoch=091, loss=0.1166
Epoch=092, loss=0.1099
Epoch=093, loss=0.1056
Epoch=094, loss=0.1016
Epoch=095, loss=0.1065
Epoch=096, loss=0.1003
Epoch=097, loss=0.1004
Epoch=098, loss=0.1021
Epoch=099, loss=0.0873
Epoch=100, loss=0.0897
Epoch=101, loss=0.0857
Epoch=102, loss=0.0887
Epoch=103, loss=0.1059
Epoch=104, loss=0.0917
Epoch=105, loss=0.0946
Epoch=106, loss=0.0900
Epoch=107, loss=0.1002
Epoch=108, loss=0.0853
Epoch=109, loss=0.0775
Epoch=110, loss=0.0868
Epoch=111, loss=0.0938
Epoch=112, loss=0.0798
Epoch=113, loss=0.0801
Epoch=114, loss=0.0770
Epoch=115, loss=0.0752
Epoch=116, loss=0.0763
Epoch=117, loss=0.0832
Epoch=118, loss=0.0813
Epoch=119, loss=0.0753
Epoch=120, loss=0.0776
Epoch=121, loss=0.0665
Epoch=122, loss=0.0694
Epoch=123, loss=0.0777
Epoch=124, loss=0.0738
Epoch=125, loss=0.0828
Epoch=126, loss=0.0684
Epoch=127, loss=0.0757
Epoch=128, loss=0.0585
Epoch=129, loss=0.0677
Epoch=130, loss=0.0728
Epoch=131, loss=0.0649
Epoch=132, loss=0.0630
Epoch=133, loss=0.0615
Epoch=134, loss=0.0699
Epoch=135, loss=0.0638
Epoch=136, loss=0.0579
Epoch=137, loss=0.0608
Epoch=138, loss=0.0611
Epoch=139, loss=0.0552
Epoch=140, loss=0.0719
Epoch=141, loss=0.0556
Epoch=142, loss=0.0652
Epoch=143, loss=0.0516
Epoch=144, loss=0.0702
Epoch=145, loss=0.0625
Epoch=146, loss=0.0610
Epoch=147, loss=0.0517
Epoch=148, loss=0.0598
Epoch=149, loss=0.0579
Epoch=150, loss=0.0523
Epoch=151, loss=0.0559
Epoch=152, loss=0.0521
Epoch=153, loss=0.0610
Epoch=154, loss=0.0601
Epoch=155, loss=0.0556
Epoch=156, loss=0.0525
Epoch=157, loss=0.0601
Epoch=158, loss=0.0665
Epoch=159, loss=0.0523
Epoch=160, loss=0.0734
Epoch=161, loss=0.0565
Epoch=162, loss=0.0510
Epoch=163, loss=0.0459
Epoch=164, loss=0.0625
Epoch=165, loss=0.0521
Epoch=166, loss=0.0572
Epoch=167, loss=0.0562
Epoch=168, loss=0.0479
Epoch=169, loss=0.0486
Epoch=170, loss=0.0479
Epoch=171, loss=0.0524
Epoch=172, loss=0.0505
Epoch=173, loss=0.0535
Epoch=174, loss=0.0612
Epoch=175, loss=0.0534
Epoch=176, loss=0.0583
Epoch=177, loss=0.0399
Epoch=178, loss=0.0590
Epoch=179, loss=0.0442
Epoch=180, loss=0.0524
Epoch=181, loss=0.0523
Epoch=182, loss=0.0409
Epoch=183, loss=0.0518
Epoch=184, loss=0.0610
Epoch=185, loss=0.0421
Epoch=186, loss=0.0516
Epoch=187, loss=0.0476
Epoch=188, loss=0.0433
Epoch=189, loss=0.0443
Epoch=190, loss=0.0453
Epoch=191, loss=0.0451
Epoch=192, loss=0.0527
Epoch=193, loss=0.0515
Epoch=194, loss=0.0537
Epoch=195, loss=0.0372
Epoch=196, loss=0.0457
Epoch=197, loss=0.0409
Epoch=198, loss=0.0359
Epoch=199, loss=0.0412
Epoch=200, loss=0.0454
Epoch=201, loss=0.0408
Epoch=202, loss=0.0532
Epoch=203, loss=0.0414
Epoch=204, loss=0.0438
Epoch=205, loss=0.0363
Epoch=206, loss=0.0449
Epoch=207, loss=0.0374
Epoch=208, loss=0.0371
Epoch=209, loss=0.0356
Epoch=210, loss=0.0440
Epoch=211, loss=0.0354
Epoch=212, loss=0.0377
Epoch=213, loss=0.0416
Epoch=214, loss=0.0322
Epoch=215, loss=0.0364
Epoch=216, loss=0.0484
Epoch=217, loss=0.0352
Epoch=218, loss=0.0356
Epoch=219, loss=0.0388
Epoch=220, loss=0.0439
Epoch=221, loss=0.0346
Epoch=222, loss=0.0467
Epoch=223, loss=0.0386
Epoch=224, loss=0.0313
Epoch=225, loss=0.0471
Epoch=226, loss=0.0442
Epoch=227, loss=0.0374
Epoch=228, loss=0.0368
Epoch=229, loss=0.0339
Epoch=230, loss=0.0345
Epoch=231, loss=0.0407
Epoch=232, loss=0.0359
Epoch=233, loss=0.0360
Epoch=234, loss=0.0460
Epoch=235, loss=0.0353
Epoch=236, loss=0.0448
Epoch=237, loss=0.0364
Epoch=238, loss=0.0369
Epoch=239, loss=0.0366
Epoch=240, loss=0.0365
Epoch=241, loss=0.0330
Epoch=242, loss=0.0311
Epoch=243, loss=0.0387
Epoch=244, loss=0.0296
Epoch=245, loss=0.0387
Epoch=246, loss=0.0353
Epoch=247, loss=0.0317
Epoch=248, loss=0.0276
Epoch=249, loss=0.0427
Epoch=250, loss=0.0335
Epoch=251, loss=0.0364
Epoch=252, loss=0.0354
Epoch=253, loss=0.0358
Epoch=254, loss=0.0275
Epoch=255, loss=0.0394
Epoch=256, loss=0.0253
Epoch=257, loss=0.0338
Epoch=258, loss=0.0335
Epoch=259, loss=0.0302
Epoch=260, loss=0.0376
Epoch=261, loss=0.0315
Epoch=262, loss=0.0255
Epoch=263, loss=0.0345
Epoch=264, loss=0.0279
Epoch=265, loss=0.0276
Epoch=266, loss=0.0357
Epoch=267, loss=0.0341
Epoch=268, loss=0.0295
Epoch=269, loss=0.0324
Epoch=270, loss=0.0241
Epoch=271, loss=0.0275
Epoch=272, loss=0.0251
Epoch=273, loss=0.0260
Epoch=274, loss=0.0365
Epoch=275, loss=0.0315
Epoch=276, loss=0.0297
Epoch=277, loss=0.0247
Epoch=278, loss=0.0280
Epoch=279, loss=0.0343
Epoch=280, loss=0.0282
Epoch=281, loss=0.0326
Epoch=282, loss=0.0296
Epoch=283, loss=0.0327
Epoch=284, loss=0.0209
Epoch=285, loss=0.0325
Epoch=286, loss=0.0308
Epoch=287, loss=0.0297
Epoch=288, loss=0.0266
Epoch=289, loss=0.0244
Epoch=290, loss=0.0278
Epoch=291, loss=0.0299
Epoch=292, loss=0.0254
Epoch=293, loss=0.0281
Epoch=294, loss=0.0259
Epoch=295, loss=0.0266
Epoch=296, loss=0.0226
Epoch=297, loss=0.0189
Epoch=298, loss=0.0258
Epoch=299, loss=0.0203
Epoch=300, loss=0.0218
Epoch=301, loss=0.0231
Epoch=302, loss=0.0290
Epoch=303, loss=0.0227
Epoch=304, loss=0.0280
Epoch=305, loss=0.0238
Epoch=306, loss=0.0279
Epoch=307, loss=0.0202
Epoch=308, loss=0.0213
Epoch=309, loss=0.0302
Epoch=310, loss=0.0254
Epoch=311, loss=0.0197
Epoch=312, loss=0.0214
Epoch=313, loss=0.0200
Epoch=314, loss=0.0291
Epoch=315, loss=0.0185
Epoch=316, loss=0.0217
Epoch=317, loss=0.0278
Epoch=318, loss=0.0183
Epoch=319, loss=0.0291
Epoch=320, loss=0.0307
Epoch=321, loss=0.0240
Epoch=322, loss=0.0330
Epoch=323, loss=0.0278
Epoch=324, loss=0.0246
Epoch=325, loss=0.0212
Epoch=326, loss=0.0267
Epoch=327, loss=0.0211
Epoch=328, loss=0.0328
Epoch=329, loss=0.0214
Epoch=330, loss=0.0251
Epoch=331, loss=0.0245
Epoch=332, loss=0.0259
Epoch=333, loss=0.0167
Epoch=334, loss=0.0224
Epoch=335, loss=0.0267
Epoch=336, loss=0.0190
Epoch=337, loss=0.0198
Epoch=338, loss=0.0191
Epoch=339, loss=0.0194
Epoch=340, loss=0.0296
Epoch=341, loss=0.0297
Epoch=342, loss=0.0221
Epoch=343, loss=0.0259
Epoch=344, loss=0.0193
Epoch=345, loss=0.0172
Epoch=346, loss=0.0276
Epoch=347, loss=0.0217
Epoch=348, loss=0.0214
Epoch=349, loss=0.0205
Epoch=350, loss=0.0193
Epoch=351, loss=0.0296
Epoch=352, loss=0.0321
Epoch=353, loss=0.0224
Early stopping!
Loading 333th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7932+-0.0119, F1Ma=0.7704+-0.0157, acc=0.7932+-0.0119
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7706708878657605, 0.7747211268998493, 0.7905368182652874, 0.7841401831452868, 0.7785714268684387, 0.7559999823570251, 0.7364603281021118, 0.7785714268684387, 0.7519999742507935, 0.738394558429718, 0.7675087446560436, 0.01498683261394303, 0.7384228739075238, 0.026897566319932065, 0.7675087446560436, 0.014986832613943065], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.766898399693697, 0.7660551836804512, 0.7957469331614632, 0.7910504704017394, 0.8785714507102966, 0.7979999780654907, 0.7780464291572571, 0.8785714507102966, 0.800000011920929, 0.7751450538635254, 0.7932374659930043, 0.0118929862369962, 0.7703762662665241, 0.01568878731581493, 0.7932374659930043, 0.0118929862369962]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6926
Epoch=002, loss=0.6919
Epoch=003, loss=0.6910
Epoch=004, loss=0.6899
Epoch=005, loss=0.6885
Epoch=006, loss=0.6866
Epoch=007, loss=0.6840
Epoch=008, loss=0.6815
Epoch=009, loss=0.6780
Epoch=010, loss=0.6740
Epoch=011, loss=0.6690
Epoch=012, loss=0.6639
Epoch=013, loss=0.6579
Epoch=014, loss=0.6511
Epoch=015, loss=0.6419
Epoch=016, loss=0.6337
Epoch=017, loss=0.6225
Epoch=018, loss=0.6118
Epoch=019, loss=0.5990
Epoch=020, loss=0.5863
Epoch=021, loss=0.5704
Epoch=022, loss=0.5557
Epoch=023, loss=0.5382
Epoch=024, loss=0.5197
Epoch=025, loss=0.4998
Epoch=026, loss=0.4834
Epoch=027, loss=0.4647
Epoch=028, loss=0.4389
Epoch=029, loss=0.4152
Epoch=030, loss=0.3983
Epoch=031, loss=0.3817
Epoch=032, loss=0.3600
Epoch=033, loss=0.3407
Epoch=034, loss=0.3246
Epoch=035, loss=0.3005
Epoch=036, loss=0.2802
Epoch=037, loss=0.2611
Epoch=038, loss=0.2521
Epoch=039, loss=0.2390
Epoch=040, loss=0.2263
Epoch=041, loss=0.2066
Epoch=042, loss=0.1898
Epoch=043, loss=0.1981
Epoch=044, loss=0.1792
Epoch=045, loss=0.1627
Epoch=046, loss=0.1602
Epoch=047, loss=0.1575
Epoch=048, loss=0.1500
Epoch=049, loss=0.1515
Epoch=050, loss=0.1332
Epoch=051, loss=0.1477
Epoch=052, loss=0.1186
Epoch=053, loss=0.1267
Epoch=054, loss=0.1260
Epoch=055, loss=0.1151
Epoch=056, loss=0.1114
Epoch=057, loss=0.1095
Epoch=058, loss=0.1003
Epoch=059, loss=0.1006
Epoch=060, loss=0.1134
Epoch=061, loss=0.0966
Epoch=062, loss=0.1144
Epoch=063, loss=0.0926
Epoch=064, loss=0.0871
Epoch=065, loss=0.0881
Epoch=066, loss=0.0878
Epoch=067, loss=0.1094
Epoch=068, loss=0.0875
Epoch=069, loss=0.0872
Epoch=070, loss=0.0828
Epoch=071, loss=0.0928
Epoch=072, loss=0.0912
Epoch=073, loss=0.0840
Epoch=074, loss=0.0735
Epoch=075, loss=0.0906
Epoch=076, loss=0.0764
Epoch=077, loss=0.0809
Epoch=078, loss=0.0772
Epoch=079, loss=0.0822
Epoch=080, loss=0.0704
Epoch=081, loss=0.0850
Epoch=082, loss=0.0742
Epoch=083, loss=0.0661
Epoch=084, loss=0.0815
Epoch=085, loss=0.0728
Epoch=086, loss=0.0553
Epoch=087, loss=0.0775
Epoch=088, loss=0.0611
Epoch=089, loss=0.0631
Epoch=090, loss=0.0744
Epoch=091, loss=0.0562
Epoch=092, loss=0.0669
Epoch=093, loss=0.0664
Epoch=094, loss=0.0681
Epoch=095, loss=0.0626
Epoch=096, loss=0.0563
Epoch=097, loss=0.0603
Epoch=098, loss=0.0589
Epoch=099, loss=0.0610
Epoch=100, loss=0.0733
Epoch=101, loss=0.0605
Epoch=102, loss=0.0522
Epoch=103, loss=0.0674
Epoch=104, loss=0.0475
Epoch=105, loss=0.0610
Epoch=106, loss=0.0794
Epoch=107, loss=0.0571
Epoch=108, loss=0.0499
Epoch=109, loss=0.0581
Epoch=110, loss=0.0685
Epoch=111, loss=0.0540
Epoch=112, loss=0.0586
Epoch=113, loss=0.0752
Epoch=114, loss=0.0540
Epoch=115, loss=0.0707
Epoch=116, loss=0.0585
Epoch=117, loss=0.0488
Epoch=118, loss=0.0567
Epoch=119, loss=0.0496
Epoch=120, loss=0.0464
Epoch=121, loss=0.0382
Epoch=122, loss=0.0594
Epoch=123, loss=0.0608
Epoch=124, loss=0.0505
Epoch=125, loss=0.0480
Epoch=126, loss=0.0563
Epoch=127, loss=0.0456
Epoch=128, loss=0.0536
Epoch=129, loss=0.0481
Epoch=130, loss=0.0473
Epoch=131, loss=0.0472
Epoch=132, loss=0.0518
Epoch=133, loss=0.0477
Epoch=134, loss=0.0444
Epoch=135, loss=0.0483
Epoch=136, loss=0.0446
Epoch=137, loss=0.0403
Epoch=138, loss=0.0467
Epoch=139, loss=0.0537
Epoch=140, loss=0.0539
Epoch=141, loss=0.0526
Early stopping!
Loading 121th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8005+-0.0159, F1Ma=0.7752+-0.0227, acc=0.8005+-0.0159
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7706708878657605, 0.7747211268998493, 0.7905368182652874, 0.7841401831452868, 0.7785714268684387, 0.7559999823570251, 0.7364603281021118, 0.7785714268684387, 0.7519999742507935, 0.738394558429718, 0.7675087446560436, 0.01498683261394303, 0.7384228739075238, 0.026897566319932065, 0.7675087446560436, 0.014986832613943065], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.766898399693697, 0.7660551836804512, 0.7957469331614632, 0.7910504704017394, 0.8785714507102966, 0.7979999780654907, 0.7780464291572571, 0.8785714507102966, 0.800000011920929, 0.7751450538635254, 0.7932374659930043, 0.0118929862369962, 0.7703762662665241, 0.01568878731581493, 0.7932374659930043, 0.0118929862369962], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7464093693302957, 0.7559516057254446, 0.7705029003092944, 0.7740068939103921, 0.9071428775787354, 0.800000011920929, 0.804158627986908, 0.9142857193946838, 0.800000011920929, 0.8031914830207825, 0.8004663816556548, 0.015895033699023675, 0.7751813672084095, 0.022655773482811538, 0.8004663816556548, 0.01589503369902371]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6918
Epoch=002, loss=0.6895
Epoch=003, loss=0.6861
Epoch=004, loss=0.6811
Epoch=005, loss=0.6759
Epoch=006, loss=0.6686
Epoch=007, loss=0.6587
Epoch=008, loss=0.6485
Epoch=009, loss=0.6328
Epoch=010, loss=0.6196
Epoch=011, loss=0.6031
Epoch=012, loss=0.5840
Epoch=013, loss=0.5624
Epoch=014, loss=0.5389
Epoch=015, loss=0.5095
Epoch=016, loss=0.4828
Epoch=017, loss=0.4635
Epoch=018, loss=0.4293
Epoch=019, loss=0.4020
Epoch=020, loss=0.3730
Epoch=021, loss=0.3522
Epoch=022, loss=0.3171
Epoch=023, loss=0.3002
Epoch=024, loss=0.2688
Epoch=025, loss=0.2578
Epoch=026, loss=0.2463
Epoch=027, loss=0.2267
Epoch=028, loss=0.2111
Epoch=029, loss=0.1855
Epoch=030, loss=0.1802
Epoch=031, loss=0.1849
Epoch=032, loss=0.1616
Epoch=033, loss=0.1576
Epoch=034, loss=0.1573
Epoch=035, loss=0.1379
Epoch=036, loss=0.1507
Epoch=037, loss=0.1406
Epoch=038, loss=0.1270
Epoch=039, loss=0.1289
Epoch=040, loss=0.1106
Epoch=041, loss=0.1110
Epoch=042, loss=0.1074
Epoch=043, loss=0.0983
Epoch=044, loss=0.0973
Epoch=045, loss=0.1208
Epoch=046, loss=0.0907
Epoch=047, loss=0.0994
Epoch=048, loss=0.0874
Epoch=049, loss=0.0806
Epoch=050, loss=0.0889
Epoch=051, loss=0.0783
Epoch=052, loss=0.0839
Epoch=053, loss=0.1051
Epoch=054, loss=0.0858
Epoch=055, loss=0.0745
Epoch=056, loss=0.0897
Epoch=057, loss=0.0819
Epoch=058, loss=0.0827
Epoch=059, loss=0.0631
Epoch=060, loss=0.0751
Epoch=061, loss=0.0689
Epoch=062, loss=0.0890
Epoch=063, loss=0.0710
Epoch=064, loss=0.0842
Epoch=065, loss=0.0745
Epoch=066, loss=0.0794
Epoch=067, loss=0.0572
Epoch=068, loss=0.0704
Epoch=069, loss=0.0754
Epoch=070, loss=0.0724
Epoch=071, loss=0.0601
Epoch=072, loss=0.0657
Epoch=073, loss=0.0648
Epoch=074, loss=0.0712
Epoch=075, loss=0.0525
Epoch=076, loss=0.0845
Epoch=077, loss=0.0698
Epoch=078, loss=0.0742
Epoch=079, loss=0.0605
Epoch=080, loss=0.0821
Epoch=081, loss=0.0567
Epoch=082, loss=0.0695
Epoch=083, loss=0.0549
Epoch=084, loss=0.0525
Epoch=085, loss=0.0476
Epoch=086, loss=0.0633
Epoch=087, loss=0.0584
Epoch=088, loss=0.0636
Epoch=089, loss=0.0532
Epoch=090, loss=0.0567
Epoch=091, loss=0.0554
Epoch=092, loss=0.0745
Epoch=093, loss=0.0465
Epoch=094, loss=0.0534
Epoch=095, loss=0.0630
Epoch=096, loss=0.0690
Epoch=097, loss=0.0551
Epoch=098, loss=0.0527
Epoch=099, loss=0.0606
Epoch=100, loss=0.0697
Epoch=101, loss=0.0477
Epoch=102, loss=0.0466
Epoch=103, loss=0.0419
Epoch=104, loss=0.0499
Epoch=105, loss=0.0579
Epoch=106, loss=0.0530
Epoch=107, loss=0.0449
Epoch=108, loss=0.0431
Epoch=109, loss=0.0498
Epoch=110, loss=0.0425
Epoch=111, loss=0.0404
Epoch=112, loss=0.0445
Epoch=113, loss=0.0363
Epoch=114, loss=0.0421
Epoch=115, loss=0.0416
Epoch=116, loss=0.0371
Epoch=117, loss=0.0380
Epoch=118, loss=0.0369
Epoch=119, loss=0.0528
Epoch=120, loss=0.0392
Epoch=121, loss=0.0443
Epoch=122, loss=0.0399
Epoch=123, loss=0.0400
Epoch=124, loss=0.0498
Epoch=125, loss=0.0328
Epoch=126, loss=0.0383
Epoch=127, loss=0.0409
Epoch=128, loss=0.0270
Epoch=129, loss=0.0363
Epoch=130, loss=0.0373
Epoch=131, loss=0.0402
Epoch=132, loss=0.0323
Epoch=133, loss=0.0439
Epoch=134, loss=0.0327
Epoch=135, loss=0.0475
Epoch=136, loss=0.0326
Epoch=137, loss=0.0311
Epoch=138, loss=0.0354
Epoch=139, loss=0.0323
Epoch=140, loss=0.0340
Epoch=141, loss=0.0333
Epoch=142, loss=0.0301
Epoch=143, loss=0.0408
Epoch=144, loss=0.0360
Epoch=145, loss=0.0318
Epoch=146, loss=0.0359
Epoch=147, loss=0.0462
Epoch=148, loss=0.0374
Early stopping!
Loading 128th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8094+-0.0133, F1Ma=0.7956+-0.0099, acc=0.8094+-0.0133
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7706708878657605, 0.7747211268998493, 0.7905368182652874, 0.7841401831452868, 0.7785714268684387, 0.7559999823570251, 0.7364603281021118, 0.7785714268684387, 0.7519999742507935, 0.738394558429718, 0.7675087446560436, 0.01498683261394303, 0.7384228739075238, 0.026897566319932065, 0.7675087446560436, 0.014986832613943065], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.766898399693697, 0.7660551836804512, 0.7957469331614632, 0.7910504704017394, 0.8785714507102966, 0.7979999780654907, 0.7780464291572571, 0.8785714507102966, 0.800000011920929, 0.7751450538635254, 0.7932374659930043, 0.0118929862369962, 0.7703762662665241, 0.01568878731581493, 0.7932374659930043, 0.0118929862369962], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7464093693302957, 0.7559516057254446, 0.7705029003092944, 0.7740068939103921, 0.9071428775787354, 0.800000011920929, 0.804158627986908, 0.9142857193946838, 0.800000011920929, 0.8031914830207825, 0.8004663816556548, 0.015895033699023675, 0.7751813672084095, 0.022655773482811538, 0.8004663816556548, 0.01589503369902371], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9203770214332694, 0.9145352867960344, 0.9239114388486618, 0.9185030519850398, 0.9571428298950195, 0.8180000185966492, 0.8080270886421204, 0.949999988079071, 0.8159999847412109, 0.8085106611251831, 0.80940536338904, 0.013322524856978499, 0.795599133463867, 0.009920639376087049, 0.80940536338904, 0.013322524856978487]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6906
Epoch=002, loss=0.6858
Epoch=003, loss=0.6744
Epoch=004, loss=0.6677
Epoch=005, loss=0.6523
Epoch=006, loss=0.6390
Epoch=007, loss=0.6212
Epoch=008, loss=0.5958
Epoch=009, loss=0.5829
Epoch=010, loss=0.5505
Epoch=011, loss=0.5184
Epoch=012, loss=0.5036
Epoch=013, loss=0.4821
Epoch=014, loss=0.4346
Epoch=015, loss=0.4033
Epoch=016, loss=0.3936
Epoch=017, loss=0.3423
Epoch=018, loss=0.3089
Epoch=019, loss=0.3010
Epoch=020, loss=0.2881
Epoch=021, loss=0.2601
Epoch=022, loss=0.2576
Epoch=023, loss=0.2227
Epoch=024, loss=0.2083
Epoch=025, loss=0.1726
Epoch=026, loss=0.1775
Epoch=027, loss=0.1804
Epoch=028, loss=0.1363
Epoch=029, loss=0.1355
Epoch=030, loss=0.1382
Epoch=031, loss=0.1137
Epoch=032, loss=0.1302
Epoch=033, loss=0.1116
Epoch=034, loss=0.0882
Epoch=035, loss=0.0964
Epoch=036, loss=0.0817
Epoch=037, loss=0.0962
Epoch=038, loss=0.0770
Epoch=039, loss=0.0738
Epoch=040, loss=0.0684
Epoch=041, loss=0.0727
Epoch=042, loss=0.0660
Epoch=043, loss=0.0694
Epoch=044, loss=0.0625
Epoch=045, loss=0.0683
Epoch=046, loss=0.0603
Epoch=047, loss=0.0689
Epoch=048, loss=0.0671
Epoch=049, loss=0.0454
Epoch=050, loss=0.0481
Epoch=051, loss=0.0504
Epoch=052, loss=0.0532
Epoch=053, loss=0.0366
Epoch=054, loss=0.0461
Epoch=055, loss=0.0322
Epoch=056, loss=0.0417
Epoch=057, loss=0.0360
Epoch=058, loss=0.0532
Epoch=059, loss=0.0355
Epoch=060, loss=0.0305
Epoch=061, loss=0.0228
Epoch=062, loss=0.0403
Epoch=063, loss=0.0385
Epoch=064, loss=0.0316
Epoch=065, loss=0.0361
Epoch=066, loss=0.0335
Epoch=067, loss=0.0385
Epoch=068, loss=0.0365
Epoch=069, loss=0.0356
Epoch=070, loss=0.0344
Epoch=071, loss=0.0174
Epoch=072, loss=0.0236
Epoch=073, loss=0.0238
Epoch=074, loss=0.0285
Epoch=075, loss=0.0250
Epoch=076, loss=0.0245
Epoch=077, loss=0.0192
Epoch=078, loss=0.0216
Epoch=079, loss=0.0211
Epoch=080, loss=0.0213
Epoch=081, loss=0.0237
Epoch=082, loss=0.0225
Epoch=083, loss=0.0218
Epoch=084, loss=0.0220
Epoch=085, loss=0.0243
Epoch=086, loss=0.0223
Epoch=087, loss=0.0218
Epoch=088, loss=0.0136
Epoch=089, loss=0.0213
Epoch=090, loss=0.0263
Epoch=091, loss=0.0163
Epoch=092, loss=0.0248
Epoch=093, loss=0.0112
Epoch=094, loss=0.0164
Epoch=095, loss=0.0155
Epoch=096, loss=0.0184
Epoch=097, loss=0.0101
Epoch=098, loss=0.0094
Epoch=099, loss=0.0231
Epoch=100, loss=0.0150
Epoch=101, loss=0.0139
Epoch=102, loss=0.0164
Epoch=103, loss=0.0115
Epoch=104, loss=0.0100
Epoch=105, loss=0.0148
Epoch=106, loss=0.0166
Epoch=107, loss=0.0107
Epoch=108, loss=0.0093
Epoch=109, loss=0.0080
Epoch=110, loss=0.0104
Epoch=111, loss=0.0088
Epoch=112, loss=0.0166
Epoch=113, loss=0.0108
Epoch=114, loss=0.0123
Epoch=115, loss=0.0118
Epoch=116, loss=0.0088
Epoch=117, loss=0.0112
Epoch=118, loss=0.0108
Epoch=119, loss=0.0094
Epoch=120, loss=0.0132
Epoch=121, loss=0.0092
Epoch=122, loss=0.0069
Epoch=123, loss=0.0150
Epoch=124, loss=0.0084
Epoch=125, loss=0.0064
Epoch=126, loss=0.0088
Epoch=127, loss=0.0120
Epoch=128, loss=0.0088
Epoch=129, loss=0.0081
Epoch=130, loss=0.0106
Epoch=131, loss=0.0061
Epoch=132, loss=0.0137
Epoch=133, loss=0.0141
Epoch=134, loss=0.0064
Epoch=135, loss=0.0115
Epoch=136, loss=0.0142
Epoch=137, loss=0.0087
Epoch=138, loss=0.0094
Epoch=139, loss=0.0061
Epoch=140, loss=0.0131
Epoch=141, loss=0.0113
Epoch=142, loss=0.0077
Epoch=143, loss=0.0164
Epoch=144, loss=0.0071
Epoch=145, loss=0.0036
Epoch=146, loss=0.0077
Epoch=147, loss=0.0089
Epoch=148, loss=0.0067
Epoch=149, loss=0.0066
Epoch=150, loss=0.0036
Epoch=151, loss=0.0075
Epoch=152, loss=0.0074
Epoch=153, loss=0.0062
Epoch=154, loss=0.0076
Epoch=155, loss=0.0068
Epoch=156, loss=0.0093
Epoch=157, loss=0.0033
Epoch=158, loss=0.0076
Epoch=159, loss=0.0092
Epoch=160, loss=0.0076
Epoch=161, loss=0.0049
Epoch=162, loss=0.0068
Epoch=163, loss=0.0068
Epoch=164, loss=0.0061
Epoch=165, loss=0.0052
Epoch=166, loss=0.0101
Epoch=167, loss=0.0048
Epoch=168, loss=0.0044
Epoch=169, loss=0.0093
Epoch=170, loss=0.0063
Epoch=171, loss=0.0076
Epoch=172, loss=0.0050
Epoch=173, loss=0.0046
Epoch=174, loss=0.0024
Epoch=175, loss=0.0108
Epoch=176, loss=0.0115
Epoch=177, loss=0.0167
Epoch=178, loss=0.0039
Epoch=179, loss=0.0021
Epoch=180, loss=0.0052
Epoch=181, loss=0.0133
Epoch=182, loss=0.0057
Epoch=183, loss=0.0081
Epoch=184, loss=0.0095
Epoch=185, loss=0.0082
Epoch=186, loss=0.0036
Epoch=187, loss=0.0019
Epoch=188, loss=0.0041
Epoch=189, loss=0.0029
Epoch=190, loss=0.0036
Epoch=191, loss=0.0023
Epoch=192, loss=0.0071
Epoch=193, loss=0.0065
Epoch=194, loss=0.0026
Epoch=195, loss=0.0048
Epoch=196, loss=0.0040
Epoch=197, loss=0.0063
Epoch=198, loss=0.0073
Epoch=199, loss=0.0027
Epoch=200, loss=0.0029
Epoch=201, loss=0.0032
Epoch=202, loss=0.0073
Epoch=203, loss=0.0041
Epoch=204, loss=0.0044
Epoch=205, loss=0.0069
Epoch=206, loss=0.0024
Epoch=207, loss=0.0028
Early stopping!
Loading 187th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7971+-0.0108, F1Ma=0.7846+-0.0126, acc=0.7971+-0.0108
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7446577931326477, 0.7609601895393513, 0.7563236104259908, 0.7709522105715672, 0.7214285731315613, 0.7139999866485596, 0.6948742866516113, 0.7142857313156128, 0.7200000286102295, 0.698259174823761, 0.7079673532841042, 0.014027246171673542, 0.6459079644218416, 0.021112865461074427, 0.7079673532841042, 0.014027246171673547], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7706708878657605, 0.7747211268998493, 0.7905368182652874, 0.7841401831452868, 0.7785714268684387, 0.7559999823570251, 0.7364603281021118, 0.7785714268684387, 0.7519999742507935, 0.738394558429718, 0.7675087446560436, 0.01498683261394303, 0.7384228739075238, 0.026897566319932065, 0.7675087446560436, 0.014986832613943065], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.766898399693697, 0.7660551836804512, 0.7957469331614632, 0.7910504704017394, 0.8785714507102966, 0.7979999780654907, 0.7780464291572571, 0.8785714507102966, 0.800000011920929, 0.7751450538635254, 0.7932374659930043, 0.0118929862369962, 0.7703762662665241, 0.01568878731581493, 0.7932374659930043, 0.0118929862369962], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7464093693302957, 0.7559516057254446, 0.7705029003092944, 0.7740068939103921, 0.9071428775787354, 0.800000011920929, 0.804158627986908, 0.9142857193946838, 0.800000011920929, 0.8031914830207825, 0.8004663816556548, 0.015895033699023675, 0.7751813672084095, 0.022655773482811538, 0.8004663816556548, 0.01589503369902371], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9203770214332694, 0.9145352867960344, 0.9239114388486618, 0.9185030519850398, 0.9571428298950195, 0.8180000185966492, 0.8080270886421204, 0.949999988079071, 0.8159999847412109, 0.8085106611251831, 0.80940536338904, 0.013322524856978499, 0.795599133463867, 0.009920639376087049, 0.80940536338904, 0.013322524856978487], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9113471733694289, 0.9035787766177373, 0.9109419614084233, 0.8980904538192694, 0.949999988079071, 0.8240000009536743, 0.8162475824356079, 0.9714285731315613, 0.8240000009536743, 0.8157640099525452, 0.7971239797901283, 0.010815407465791562, 0.7845617384180157, 0.012564541050057526, 0.7971239797901283, 0.010815407465791562]]
