My SLURM_ARRAY_TASK_ID:  19
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_19
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_19.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6931
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6929
Epoch=010, loss=0.6929
Epoch=011, loss=0.6928
Epoch=012, loss=0.6928
Epoch=013, loss=0.6927
Epoch=014, loss=0.6927
Epoch=015, loss=0.6926
Epoch=016, loss=0.6925
Epoch=017, loss=0.6925
Epoch=018, loss=0.6924
Epoch=019, loss=0.6923
Epoch=020, loss=0.6923
Epoch=021, loss=0.6922
Epoch=022, loss=0.6921
Epoch=023, loss=0.6920
Epoch=024, loss=0.6919
Epoch=025, loss=0.6918
Epoch=026, loss=0.6917
Epoch=027, loss=0.6916
Epoch=028, loss=0.6914
Epoch=029, loss=0.6913
Epoch=030, loss=0.6912
Epoch=031, loss=0.6910
Epoch=032, loss=0.6909
Epoch=033, loss=0.6907
Epoch=034, loss=0.6905
Epoch=035, loss=0.6902
Epoch=036, loss=0.6901
Epoch=037, loss=0.6898
Epoch=038, loss=0.6896
Epoch=039, loss=0.6894
Epoch=040, loss=0.6891
Epoch=041, loss=0.6889
Epoch=042, loss=0.6885
Epoch=043, loss=0.6882
Epoch=044, loss=0.6878
Epoch=045, loss=0.6876
Epoch=046, loss=0.6871
Epoch=047, loss=0.6867
Epoch=048, loss=0.6863
Epoch=049, loss=0.6860
Epoch=050, loss=0.6856
Epoch=051, loss=0.6849
Epoch=052, loss=0.6844
Epoch=053, loss=0.6841
Epoch=054, loss=0.6834
Epoch=055, loss=0.6828
Epoch=056, loss=0.6822
Epoch=057, loss=0.6817
Epoch=058, loss=0.6812
Epoch=059, loss=0.6803
Epoch=060, loss=0.6797
Epoch=061, loss=0.6792
Epoch=062, loss=0.6780
Epoch=063, loss=0.6775
Epoch=064, loss=0.6766
Epoch=065, loss=0.6757
Epoch=066, loss=0.6749
Epoch=067, loss=0.6736
Epoch=068, loss=0.6730
Epoch=069, loss=0.6719
Epoch=070, loss=0.6708
Epoch=071, loss=0.6695
Epoch=072, loss=0.6683
Epoch=073, loss=0.6674
Epoch=074, loss=0.6661
Epoch=075, loss=0.6646
Epoch=076, loss=0.6635
Epoch=077, loss=0.6625
Epoch=078, loss=0.6610
Epoch=079, loss=0.6591
Epoch=080, loss=0.6575
Epoch=081, loss=0.6563
Epoch=082, loss=0.6544
Epoch=083, loss=0.6525
Epoch=084, loss=0.6508
Epoch=085, loss=0.6494
Epoch=086, loss=0.6475
Epoch=087, loss=0.6456
Epoch=088, loss=0.6441
Epoch=089, loss=0.6420
Epoch=090, loss=0.6395
Epoch=091, loss=0.6383
Epoch=092, loss=0.6364
Epoch=093, loss=0.6348
Epoch=094, loss=0.6326
Epoch=095, loss=0.6290
Epoch=096, loss=0.6273
Epoch=097, loss=0.6253
Epoch=098, loss=0.6214
Epoch=099, loss=0.6199
Epoch=100, loss=0.6179
Epoch=101, loss=0.6155
Epoch=102, loss=0.6132
Epoch=103, loss=0.6095
Epoch=104, loss=0.6077
Epoch=105, loss=0.6053
Epoch=106, loss=0.6020
Epoch=107, loss=0.5998
Epoch=108, loss=0.5963
Epoch=109, loss=0.5937
Epoch=110, loss=0.5896
Epoch=111, loss=0.5870
Epoch=112, loss=0.5843
Epoch=113, loss=0.5823
Epoch=114, loss=0.5770
Epoch=115, loss=0.5738
Epoch=116, loss=0.5721
Epoch=117, loss=0.5668
Epoch=118, loss=0.5637
Epoch=119, loss=0.5617
Epoch=120, loss=0.5561
Epoch=121, loss=0.5567
Epoch=122, loss=0.5498
Epoch=123, loss=0.5471
Epoch=124, loss=0.5453
Epoch=125, loss=0.5412
Epoch=126, loss=0.5372
Epoch=127, loss=0.5322
Epoch=128, loss=0.5322
Epoch=129, loss=0.5232
Epoch=130, loss=0.5232
Epoch=131, loss=0.5184
Epoch=132, loss=0.5130
Epoch=133, loss=0.5112
Epoch=134, loss=0.5090
Epoch=135, loss=0.5025
Epoch=136, loss=0.5010
Epoch=137, loss=0.4962
Epoch=138, loss=0.4931
Epoch=139, loss=0.4835
Epoch=140, loss=0.4852
Epoch=141, loss=0.4786
Epoch=142, loss=0.4769
Epoch=143, loss=0.4734
Epoch=144, loss=0.4708
Epoch=145, loss=0.4625
Epoch=146, loss=0.4614
Epoch=147, loss=0.4543
Epoch=148, loss=0.4538
Epoch=149, loss=0.4506
Epoch=150, loss=0.4467
Epoch=151, loss=0.4426
Epoch=152, loss=0.4339
Epoch=153, loss=0.4354
Epoch=154, loss=0.4292
Epoch=155, loss=0.4263
Epoch=156, loss=0.4207
Epoch=157, loss=0.4199
Epoch=158, loss=0.4096
Epoch=159, loss=0.4041
Epoch=160, loss=0.4055
Epoch=161, loss=0.4047
Epoch=162, loss=0.3957
Epoch=163, loss=0.3927
Epoch=164, loss=0.3933
Epoch=165, loss=0.3809
Epoch=166, loss=0.3812
Epoch=167, loss=0.3802
Epoch=168, loss=0.3702
Epoch=169, loss=0.3665
Epoch=170, loss=0.3713
Epoch=171, loss=0.3604
Epoch=172, loss=0.3613
Epoch=173, loss=0.3545
Epoch=174, loss=0.3522
Epoch=175, loss=0.3480
Epoch=176, loss=0.3431
Epoch=177, loss=0.3406
Epoch=178, loss=0.3403
Epoch=179, loss=0.3334
Epoch=180, loss=0.3386
Epoch=181, loss=0.3304
Epoch=182, loss=0.3244
Epoch=183, loss=0.3205
Epoch=184, loss=0.3172
Epoch=185, loss=0.3171
Epoch=186, loss=0.3123
Epoch=187, loss=0.3118
Epoch=188, loss=0.3119
Epoch=189, loss=0.3042
Epoch=190, loss=0.2983
Epoch=191, loss=0.2957
Epoch=192, loss=0.2914
Epoch=193, loss=0.2912
Epoch=194, loss=0.2858
Epoch=195, loss=0.2851
Epoch=196, loss=0.2768
Epoch=197, loss=0.2791
Epoch=198, loss=0.2693
Epoch=199, loss=0.2733
Epoch=200, loss=0.2679
Epoch=201, loss=0.2646
Epoch=202, loss=0.2672
Epoch=203, loss=0.2644
Epoch=204, loss=0.2576
Epoch=205, loss=0.2571
Epoch=206, loss=0.2509
Epoch=207, loss=0.2565
Epoch=208, loss=0.2585
Epoch=209, loss=0.2447
Epoch=210, loss=0.2457
Epoch=211, loss=0.2419
Epoch=212, loss=0.2400
Epoch=213, loss=0.2346
Epoch=214, loss=0.2347
Epoch=215, loss=0.2321
Epoch=216, loss=0.2332
Epoch=217, loss=0.2266
Epoch=218, loss=0.2337
Epoch=219, loss=0.2223
Epoch=220, loss=0.2200
Epoch=221, loss=0.2194
Epoch=222, loss=0.2176
Epoch=223, loss=0.2126
Epoch=224, loss=0.2147
Epoch=225, loss=0.2154
Epoch=226, loss=0.2231
Epoch=227, loss=0.2014
Epoch=228, loss=0.2030
Epoch=229, loss=0.2119
Epoch=230, loss=0.2069
Epoch=231, loss=0.2018
Epoch=232, loss=0.2042
Epoch=233, loss=0.2010
Epoch=234, loss=0.1973
Epoch=235, loss=0.2018
Epoch=236, loss=0.1983
Epoch=237, loss=0.1900
Epoch=238, loss=0.1924
Epoch=239, loss=0.1950
Epoch=240, loss=0.1836
Epoch=241, loss=0.1836
Epoch=242, loss=0.1861
Epoch=243, loss=0.1806
Epoch=244, loss=0.1950
Epoch=245, loss=0.1869
Epoch=246, loss=0.1812
Epoch=247, loss=0.1799
Epoch=248, loss=0.1750
Epoch=249, loss=0.1810
Epoch=250, loss=0.1771
Epoch=251, loss=0.1737
Epoch=252, loss=0.1776
Epoch=253, loss=0.1700
Epoch=254, loss=0.1738
Epoch=255, loss=0.1683
Epoch=256, loss=0.1571
Epoch=257, loss=0.1628
Epoch=258, loss=0.1723
Epoch=259, loss=0.1629
Epoch=260, loss=0.1750
Epoch=261, loss=0.1587
Epoch=262, loss=0.1659
Epoch=263, loss=0.1541
Epoch=264, loss=0.1531
Epoch=265, loss=0.1476
Epoch=266, loss=0.1507
Epoch=267, loss=0.1629
Epoch=268, loss=0.1584
Epoch=269, loss=0.1501
Epoch=270, loss=0.1511
Epoch=271, loss=0.1510
Epoch=272, loss=0.1502
Epoch=273, loss=0.1468
Epoch=274, loss=0.1440
Epoch=275, loss=0.1478
Epoch=276, loss=0.1385
Epoch=277, loss=0.1470
Epoch=278, loss=0.1462
Epoch=279, loss=0.1523
Epoch=280, loss=0.1521
Epoch=281, loss=0.1392
Epoch=282, loss=0.1377
Epoch=283, loss=0.1454
Epoch=284, loss=0.1407
Epoch=285, loss=0.1389
Epoch=286, loss=0.1282
Epoch=287, loss=0.1209
Epoch=288, loss=0.1300
Epoch=289, loss=0.1323
Epoch=290, loss=0.1345
Epoch=291, loss=0.1253
Epoch=292, loss=0.1420
Epoch=293, loss=0.1394
Epoch=294, loss=0.1300
Epoch=295, loss=0.1289
Epoch=296, loss=0.1244
Epoch=297, loss=0.1334
Epoch=298, loss=0.1316
Epoch=299, loss=0.1282
Epoch=300, loss=0.1335
Epoch=301, loss=0.1194
Epoch=302, loss=0.1199
Epoch=303, loss=0.1284
Epoch=304, loss=0.1223
Epoch=305, loss=0.1227
Epoch=306, loss=0.1261
Epoch=307, loss=0.1223
Epoch=308, loss=0.1237
Epoch=309, loss=0.1279
Epoch=310, loss=0.1138
Epoch=311, loss=0.1303
Epoch=312, loss=0.1201
Epoch=313, loss=0.1144
Epoch=314, loss=0.1200
Epoch=315, loss=0.1282
Epoch=316, loss=0.1190
Epoch=317, loss=0.1129
Epoch=318, loss=0.1125
Epoch=319, loss=0.1137
Epoch=320, loss=0.1196
Epoch=321, loss=0.1076
Epoch=322, loss=0.1043
Epoch=323, loss=0.1109
Epoch=324, loss=0.1132
Epoch=325, loss=0.1096
Epoch=326, loss=0.1222
Epoch=327, loss=0.1027
Epoch=328, loss=0.1103
Epoch=329, loss=0.1070
Epoch=330, loss=0.1173
Epoch=331, loss=0.1072
Epoch=332, loss=0.1207
Epoch=333, loss=0.1032
Epoch=334, loss=0.1037
Epoch=335, loss=0.1206
Epoch=336, loss=0.1034
Epoch=337, loss=0.1047
Epoch=338, loss=0.1083
Epoch=339, loss=0.1059
Epoch=340, loss=0.0922
Epoch=341, loss=0.0999
Epoch=342, loss=0.0969
Epoch=343, loss=0.1026
Epoch=344, loss=0.0962
Epoch=345, loss=0.1047
Epoch=346, loss=0.0982
Epoch=347, loss=0.1008
Epoch=348, loss=0.0971
Epoch=349, loss=0.0948
Epoch=350, loss=0.1005
Epoch=351, loss=0.1082
Epoch=352, loss=0.1024
Epoch=353, loss=0.0970
Epoch=354, loss=0.0946
Epoch=355, loss=0.1048
Epoch=356, loss=0.1018
Epoch=357, loss=0.0976
Epoch=358, loss=0.0946
Epoch=359, loss=0.0963
Epoch=360, loss=0.0901
Epoch=361, loss=0.0891
Epoch=362, loss=0.0978
Epoch=363, loss=0.0970
Epoch=364, loss=0.1007
Epoch=365, loss=0.0865
Epoch=366, loss=0.0933
Epoch=367, loss=0.0901
Epoch=368, loss=0.0925
Epoch=369, loss=0.0950
Epoch=370, loss=0.0873
Epoch=371, loss=0.0830
Epoch=372, loss=0.0945
Epoch=373, loss=0.0768
Epoch=374, loss=0.0974
Epoch=375, loss=0.0894
Epoch=376, loss=0.0868
Epoch=377, loss=0.0807
Epoch=378, loss=0.0807
Epoch=379, loss=0.0867
Epoch=380, loss=0.0844
Epoch=381, loss=0.0907
Epoch=382, loss=0.0903
Epoch=383, loss=0.0855
Epoch=384, loss=0.0861
Epoch=385, loss=0.0831
Epoch=386, loss=0.0924
Epoch=387, loss=0.0859
Epoch=388, loss=0.0886
Epoch=389, loss=0.0890
Epoch=390, loss=0.0804
Epoch=391, loss=0.0910
Epoch=392, loss=0.0809
Epoch=393, loss=0.0924
Early stopping!
Loading 373th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.6326+-0.0121, F1Ma=0.5534+-0.0129, acc=0.6326+-0.0121
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6925
Epoch=009, loss=0.6924
Epoch=010, loss=0.6923
Epoch=011, loss=0.6921
Epoch=012, loss=0.6919
Epoch=013, loss=0.6918
Epoch=014, loss=0.6915
Epoch=015, loss=0.6913
Epoch=016, loss=0.6910
Epoch=017, loss=0.6907
Epoch=018, loss=0.6904
Epoch=019, loss=0.6900
Epoch=020, loss=0.6897
Epoch=021, loss=0.6893
Epoch=022, loss=0.6888
Epoch=023, loss=0.6882
Epoch=024, loss=0.6879
Epoch=025, loss=0.6871
Epoch=026, loss=0.6865
Epoch=027, loss=0.6858
Epoch=028, loss=0.6850
Epoch=029, loss=0.6840
Epoch=030, loss=0.6831
Epoch=031, loss=0.6821
Epoch=032, loss=0.6813
Epoch=033, loss=0.6799
Epoch=034, loss=0.6788
Epoch=035, loss=0.6776
Epoch=036, loss=0.6760
Epoch=037, loss=0.6748
Epoch=038, loss=0.6733
Epoch=039, loss=0.6714
Epoch=040, loss=0.6695
Epoch=041, loss=0.6677
Epoch=042, loss=0.6657
Epoch=043, loss=0.6629
Epoch=044, loss=0.6601
Epoch=045, loss=0.6587
Epoch=046, loss=0.6562
Epoch=047, loss=0.6536
Epoch=048, loss=0.6516
Epoch=049, loss=0.6481
Epoch=050, loss=0.6445
Epoch=051, loss=0.6412
Epoch=052, loss=0.6381
Epoch=053, loss=0.6344
Epoch=054, loss=0.6309
Epoch=055, loss=0.6270
Epoch=056, loss=0.6233
Epoch=057, loss=0.6185
Epoch=058, loss=0.6152
Epoch=059, loss=0.6099
Epoch=060, loss=0.6052
Epoch=061, loss=0.6022
Epoch=062, loss=0.5968
Epoch=063, loss=0.5888
Epoch=064, loss=0.5842
Epoch=065, loss=0.5810
Epoch=066, loss=0.5769
Epoch=067, loss=0.5685
Epoch=068, loss=0.5630
Epoch=069, loss=0.5589
Epoch=070, loss=0.5493
Epoch=071, loss=0.5428
Epoch=072, loss=0.5400
Epoch=073, loss=0.5315
Epoch=074, loss=0.5257
Epoch=075, loss=0.5160
Epoch=076, loss=0.5106
Epoch=077, loss=0.5010
Epoch=078, loss=0.4983
Epoch=079, loss=0.4921
Epoch=080, loss=0.4836
Epoch=081, loss=0.4798
Epoch=082, loss=0.4709
Epoch=083, loss=0.4660
Epoch=084, loss=0.4523
Epoch=085, loss=0.4475
Epoch=086, loss=0.4376
Epoch=087, loss=0.4302
Epoch=088, loss=0.4249
Epoch=089, loss=0.4155
Epoch=090, loss=0.4104
Epoch=091, loss=0.4037
Epoch=092, loss=0.4022
Epoch=093, loss=0.3887
Epoch=094, loss=0.3874
Epoch=095, loss=0.3746
Epoch=096, loss=0.3693
Epoch=097, loss=0.3597
Epoch=098, loss=0.3514
Epoch=099, loss=0.3461
Epoch=100, loss=0.3426
Epoch=101, loss=0.3301
Epoch=102, loss=0.3246
Epoch=103, loss=0.3241
Epoch=104, loss=0.3126
Epoch=105, loss=0.3066
Epoch=106, loss=0.2968
Epoch=107, loss=0.2936
Epoch=108, loss=0.2849
Epoch=109, loss=0.2831
Epoch=110, loss=0.2804
Epoch=111, loss=0.2729
Epoch=112, loss=0.2704
Epoch=113, loss=0.2592
Epoch=114, loss=0.2597
Epoch=115, loss=0.2478
Epoch=116, loss=0.2438
Epoch=117, loss=0.2425
Epoch=118, loss=0.2369
Epoch=119, loss=0.2344
Epoch=120, loss=0.2178
Epoch=121, loss=0.2305
Epoch=122, loss=0.2163
Epoch=123, loss=0.2210
Epoch=124, loss=0.2143
Epoch=125, loss=0.2145
Epoch=126, loss=0.2146
Epoch=127, loss=0.1962
Epoch=128, loss=0.2017
Epoch=129, loss=0.1994
Epoch=130, loss=0.1968
Epoch=131, loss=0.1858
Epoch=132, loss=0.1844
Epoch=133, loss=0.1794
Epoch=134, loss=0.1707
Epoch=135, loss=0.1717
Epoch=136, loss=0.1726
Epoch=137, loss=0.1642
Epoch=138, loss=0.1671
Epoch=139, loss=0.1628
Epoch=140, loss=0.1657
Epoch=141, loss=0.1565
Epoch=142, loss=0.1576
Epoch=143, loss=0.1531
Epoch=144, loss=0.1528
Epoch=145, loss=0.1497
Epoch=146, loss=0.1459
Epoch=147, loss=0.1444
Epoch=148, loss=0.1350
Epoch=149, loss=0.1372
Epoch=150, loss=0.1291
Epoch=151, loss=0.1410
Epoch=152, loss=0.1435
Epoch=153, loss=0.1384
Epoch=154, loss=0.1331
Epoch=155, loss=0.1285
Epoch=156, loss=0.1309
Epoch=157, loss=0.1302
Epoch=158, loss=0.1242
Epoch=159, loss=0.1235
Epoch=160, loss=0.1136
Epoch=161, loss=0.1274
Epoch=162, loss=0.1187
Epoch=163, loss=0.1142
Epoch=164, loss=0.1152
Epoch=165, loss=0.1121
Epoch=166, loss=0.1165
Epoch=167, loss=0.1186
Epoch=168, loss=0.1151
Epoch=169, loss=0.1119
Epoch=170, loss=0.1099
Epoch=171, loss=0.1165
Epoch=172, loss=0.1009
Epoch=173, loss=0.1011
Epoch=174, loss=0.1096
Epoch=175, loss=0.1067
Epoch=176, loss=0.1086
Epoch=177, loss=0.1113
Epoch=178, loss=0.1019
Epoch=179, loss=0.0972
Epoch=180, loss=0.1025
Epoch=181, loss=0.0971
Epoch=182, loss=0.0913
Epoch=183, loss=0.0967
Epoch=184, loss=0.0945
Epoch=185, loss=0.0991
Epoch=186, loss=0.0907
Epoch=187, loss=0.1017
Epoch=188, loss=0.1032
Epoch=189, loss=0.0977
Epoch=190, loss=0.0962
Epoch=191, loss=0.0858
Epoch=192, loss=0.0944
Epoch=193, loss=0.0848
Epoch=194, loss=0.0886
Epoch=195, loss=0.0820
Epoch=196, loss=0.0796
Epoch=197, loss=0.0925
Epoch=198, loss=0.0927
Epoch=199, loss=0.0883
Epoch=200, loss=0.0833
Epoch=201, loss=0.0800
Epoch=202, loss=0.0824
Epoch=203, loss=0.0861
Epoch=204, loss=0.0749
Epoch=205, loss=0.0813
Epoch=206, loss=0.0740
Epoch=207, loss=0.0910
Epoch=208, loss=0.0801
Epoch=209, loss=0.0761
Epoch=210, loss=0.0774
Epoch=211, loss=0.0802
Epoch=212, loss=0.0775
Epoch=213, loss=0.0730
Epoch=214, loss=0.0754
Epoch=215, loss=0.0763
Epoch=216, loss=0.0781
Epoch=217, loss=0.0786
Epoch=218, loss=0.0800
Epoch=219, loss=0.0690
Epoch=220, loss=0.0764
Epoch=221, loss=0.0772
Epoch=222, loss=0.0787
Epoch=223, loss=0.0736
Epoch=224, loss=0.0684
Epoch=225, loss=0.0706
Epoch=226, loss=0.0701
Epoch=227, loss=0.0666
Epoch=228, loss=0.0730
Epoch=229, loss=0.0685
Epoch=230, loss=0.0727
Epoch=231, loss=0.0669
Epoch=232, loss=0.0689
Epoch=233, loss=0.0596
Epoch=234, loss=0.0671
Epoch=235, loss=0.0743
Epoch=236, loss=0.0684
Epoch=237, loss=0.0597
Epoch=238, loss=0.0619
Epoch=239, loss=0.0635
Epoch=240, loss=0.0681
Epoch=241, loss=0.0633
Epoch=242, loss=0.0807
Epoch=243, loss=0.0725
Epoch=244, loss=0.0663
Epoch=245, loss=0.0705
Epoch=246, loss=0.0628
Epoch=247, loss=0.0560
Epoch=248, loss=0.0618
Epoch=249, loss=0.0598
Epoch=250, loss=0.0641
Epoch=251, loss=0.0631
Epoch=252, loss=0.0618
Epoch=253, loss=0.0613
Epoch=254, loss=0.0584
Epoch=255, loss=0.0544
Epoch=256, loss=0.0729
Epoch=257, loss=0.0575
Epoch=258, loss=0.0607
Epoch=259, loss=0.0679
Epoch=260, loss=0.0599
Epoch=261, loss=0.0611
Epoch=262, loss=0.0632
Epoch=263, loss=0.0565
Epoch=264, loss=0.0676
Epoch=265, loss=0.0664
Epoch=266, loss=0.0593
Epoch=267, loss=0.0589
Epoch=268, loss=0.0558
Epoch=269, loss=0.0559
Epoch=270, loss=0.0552
Epoch=271, loss=0.0632
Epoch=272, loss=0.0508
Epoch=273, loss=0.0527
Epoch=274, loss=0.0565
Epoch=275, loss=0.0543
Epoch=276, loss=0.0602
Epoch=277, loss=0.0575
Epoch=278, loss=0.0534
Epoch=279, loss=0.0677
Epoch=280, loss=0.0520
Epoch=281, loss=0.0596
Epoch=282, loss=0.0552
Epoch=283, loss=0.0468
Epoch=284, loss=0.0520
Epoch=285, loss=0.0531
Epoch=286, loss=0.0542
Epoch=287, loss=0.0487
Epoch=288, loss=0.0433
Epoch=289, loss=0.0394
Epoch=290, loss=0.0547
Epoch=291, loss=0.0527
Epoch=292, loss=0.0556
Epoch=293, loss=0.0625
Epoch=294, loss=0.0525
Epoch=295, loss=0.0468
Epoch=296, loss=0.0476
Epoch=297, loss=0.0400
Epoch=298, loss=0.0538
Epoch=299, loss=0.0526
Epoch=300, loss=0.0539
Epoch=301, loss=0.0473
Epoch=302, loss=0.0413
Epoch=303, loss=0.0529
Epoch=304, loss=0.0546
Epoch=305, loss=0.0518
Epoch=306, loss=0.0492
Epoch=307, loss=0.0561
Epoch=308, loss=0.0556
Epoch=309, loss=0.0517
Early stopping!
Loading 289th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7527+-0.0155, F1Ma=0.7184+-0.0229, acc=0.7527+-0.0155
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7921226260719813, 0.789892820789674, 0.7881315959082416, 0.7834073395875671, 0.8500000238418579, 0.7400000095367432, 0.7717601656913757, 0.8500000238418579, 0.7360000014305115, 0.7693423628807068, 0.7526622619510299, 0.015529723251775002, 0.7183572529573103, 0.02289161198999102, 0.7526622619510299, 0.015529723251774997]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6925
Epoch=004, loss=0.6923
Epoch=005, loss=0.6919
Epoch=006, loss=0.6915
Epoch=007, loss=0.6910
Epoch=008, loss=0.6905
Epoch=009, loss=0.6898
Epoch=010, loss=0.6891
Epoch=011, loss=0.6883
Epoch=012, loss=0.6872
Epoch=013, loss=0.6861
Epoch=014, loss=0.6848
Epoch=015, loss=0.6834
Epoch=016, loss=0.6818
Epoch=017, loss=0.6800
Epoch=018, loss=0.6781
Epoch=019, loss=0.6758
Epoch=020, loss=0.6733
Epoch=021, loss=0.6704
Epoch=022, loss=0.6674
Epoch=023, loss=0.6642
Epoch=024, loss=0.6612
Epoch=025, loss=0.6568
Epoch=026, loss=0.6518
Epoch=027, loss=0.6471
Epoch=028, loss=0.6420
Epoch=029, loss=0.6359
Epoch=030, loss=0.6312
Epoch=031, loss=0.6242
Epoch=032, loss=0.6175
Epoch=033, loss=0.6102
Epoch=034, loss=0.6020
Epoch=035, loss=0.5938
Epoch=036, loss=0.5845
Epoch=037, loss=0.5781
Epoch=038, loss=0.5667
Epoch=039, loss=0.5576
Epoch=040, loss=0.5467
Epoch=041, loss=0.5378
Epoch=042, loss=0.5234
Epoch=043, loss=0.5161
Epoch=044, loss=0.5007
Epoch=045, loss=0.4905
Epoch=046, loss=0.4794
Epoch=047, loss=0.4617
Epoch=048, loss=0.4543
Epoch=049, loss=0.4401
Epoch=050, loss=0.4224
Epoch=051, loss=0.4085
Epoch=052, loss=0.4006
Epoch=053, loss=0.3850
Epoch=054, loss=0.3734
Epoch=055, loss=0.3593
Epoch=056, loss=0.3499
Epoch=057, loss=0.3325
Epoch=058, loss=0.3211
Epoch=059, loss=0.3069
Epoch=060, loss=0.2985
Epoch=061, loss=0.2885
Epoch=062, loss=0.2758
Epoch=063, loss=0.2717
Epoch=064, loss=0.2565
Epoch=065, loss=0.2540
Epoch=066, loss=0.2300
Epoch=067, loss=0.2306
Epoch=068, loss=0.2248
Epoch=069, loss=0.2262
Epoch=070, loss=0.1974
Epoch=071, loss=0.2014
Epoch=072, loss=0.1886
Epoch=073, loss=0.1837
Epoch=074, loss=0.1770
Epoch=075, loss=0.1729
Epoch=076, loss=0.1731
Epoch=077, loss=0.1616
Epoch=078, loss=0.1642
Epoch=079, loss=0.1577
Epoch=080, loss=0.1473
Epoch=081, loss=0.1446
Epoch=082, loss=0.1447
Epoch=083, loss=0.1420
Epoch=084, loss=0.1371
Epoch=085, loss=0.1389
Epoch=086, loss=0.1281
Epoch=087, loss=0.1162
Epoch=088, loss=0.1186
Epoch=089, loss=0.1219
Epoch=090, loss=0.1215
Epoch=091, loss=0.1088
Epoch=092, loss=0.1064
Epoch=093, loss=0.1158
Epoch=094, loss=0.1043
Epoch=095, loss=0.1157
Epoch=096, loss=0.1002
Epoch=097, loss=0.1151
Epoch=098, loss=0.1004
Epoch=099, loss=0.1038
Epoch=100, loss=0.0997
Epoch=101, loss=0.1023
Epoch=102, loss=0.1007
Epoch=103, loss=0.0970
Epoch=104, loss=0.0864
Epoch=105, loss=0.0906
Epoch=106, loss=0.0943
Epoch=107, loss=0.0949
Epoch=108, loss=0.0780
Epoch=109, loss=0.0888
Epoch=110, loss=0.0906
Epoch=111, loss=0.0806
Epoch=112, loss=0.0904
Epoch=113, loss=0.0889
Epoch=114, loss=0.0787
Epoch=115, loss=0.0815
Epoch=116, loss=0.0813
Epoch=117, loss=0.0762
Epoch=118, loss=0.0735
Epoch=119, loss=0.0804
Epoch=120, loss=0.0832
Epoch=121, loss=0.0738
Epoch=122, loss=0.0796
Epoch=123, loss=0.0684
Epoch=124, loss=0.0712
Epoch=125, loss=0.0595
Epoch=126, loss=0.0749
Epoch=127, loss=0.0781
Epoch=128, loss=0.0745
Epoch=129, loss=0.0716
Epoch=130, loss=0.0750
Epoch=131, loss=0.0689
Epoch=132, loss=0.0747
Epoch=133, loss=0.0666
Epoch=134, loss=0.0725
Epoch=135, loss=0.0655
Epoch=136, loss=0.0637
Epoch=137, loss=0.0630
Epoch=138, loss=0.0625
Epoch=139, loss=0.0646
Epoch=140, loss=0.0603
Epoch=141, loss=0.0622
Epoch=142, loss=0.0665
Epoch=143, loss=0.0571
Epoch=144, loss=0.0771
Epoch=145, loss=0.0748
Epoch=146, loss=0.0655
Epoch=147, loss=0.0705
Epoch=148, loss=0.0599
Epoch=149, loss=0.0677
Epoch=150, loss=0.0523
Epoch=151, loss=0.0634
Epoch=152, loss=0.0552
Epoch=153, loss=0.0624
Epoch=154, loss=0.0633
Epoch=155, loss=0.0649
Epoch=156, loss=0.0617
Epoch=157, loss=0.0601
Epoch=158, loss=0.0537
Epoch=159, loss=0.0639
Epoch=160, loss=0.0598
Epoch=161, loss=0.0488
Epoch=162, loss=0.0464
Epoch=163, loss=0.0663
Epoch=164, loss=0.0730
Epoch=165, loss=0.0588
Epoch=166, loss=0.0472
Epoch=167, loss=0.0464
Epoch=168, loss=0.0604
Epoch=169, loss=0.0559
Epoch=170, loss=0.0579
Epoch=171, loss=0.0542
Epoch=172, loss=0.0473
Epoch=173, loss=0.0547
Epoch=174, loss=0.0443
Epoch=175, loss=0.0600
Epoch=176, loss=0.0508
Epoch=177, loss=0.0469
Epoch=178, loss=0.0525
Epoch=179, loss=0.0417
Epoch=180, loss=0.0468
Epoch=181, loss=0.0553
Epoch=182, loss=0.0456
Epoch=183, loss=0.0530
Epoch=184, loss=0.0493
Epoch=185, loss=0.0505
Epoch=186, loss=0.0445
Epoch=187, loss=0.0535
Epoch=188, loss=0.0460
Epoch=189, loss=0.0446
Epoch=190, loss=0.0413
Epoch=191, loss=0.0402
Epoch=192, loss=0.0461
Epoch=193, loss=0.0427
Epoch=194, loss=0.0411
Epoch=195, loss=0.0486
Epoch=196, loss=0.0478
Epoch=197, loss=0.0478
Epoch=198, loss=0.0501
Epoch=199, loss=0.0504
Epoch=200, loss=0.0345
Epoch=201, loss=0.0501
Epoch=202, loss=0.0493
Epoch=203, loss=0.0502
Epoch=204, loss=0.0456
Epoch=205, loss=0.0466
Epoch=206, loss=0.0331
Epoch=207, loss=0.0465
Epoch=208, loss=0.0358
Epoch=209, loss=0.0416
Epoch=210, loss=0.0302
Epoch=211, loss=0.0437
Epoch=212, loss=0.0307
Epoch=213, loss=0.0444
Epoch=214, loss=0.0461
Epoch=215, loss=0.0416
Epoch=216, loss=0.0426
Epoch=217, loss=0.0430
Epoch=218, loss=0.0375
Epoch=219, loss=0.0353
Epoch=220, loss=0.0447
Epoch=221, loss=0.0482
Epoch=222, loss=0.0422
Epoch=223, loss=0.0513
Epoch=224, loss=0.0334
Epoch=225, loss=0.0379
Epoch=226, loss=0.0441
Epoch=227, loss=0.0409
Epoch=228, loss=0.0434
Epoch=229, loss=0.0419
Epoch=230, loss=0.0363
Early stopping!
Loading 210th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7868+-0.0088, F1Ma=0.7395+-0.0170, acc=0.7868+-0.0088
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7921226260719813, 0.789892820789674, 0.7881315959082416, 0.7834073395875671, 0.8500000238418579, 0.7400000095367432, 0.7717601656913757, 0.8500000238418579, 0.7360000014305115, 0.7693423628807068, 0.7526622619510299, 0.015529723251775002, 0.7183572529573103, 0.02289161198999102, 0.7526622619510299, 0.015529723251774997], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7782807033849028, 0.7700521198879904, 0.7684145335920989, 0.7571882858659942, 0.9214285612106323, 0.7559999823570251, 0.7862669229507446, 0.9214285612106323, 0.7540000081062317, 0.7838491201400757, 0.7867858530897786, 0.008761826214356382, 0.7394707749868877, 0.016964031684690437, 0.7867858530897784, 0.008761826214356392]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6925
Epoch=002, loss=0.6918
Epoch=003, loss=0.6909
Epoch=004, loss=0.6896
Epoch=005, loss=0.6879
Epoch=006, loss=0.6861
Epoch=007, loss=0.6836
Epoch=008, loss=0.6806
Epoch=009, loss=0.6771
Epoch=010, loss=0.6728
Epoch=011, loss=0.6681
Epoch=012, loss=0.6626
Epoch=013, loss=0.6568
Epoch=014, loss=0.6482
Epoch=015, loss=0.6406
Epoch=016, loss=0.6313
Epoch=017, loss=0.6215
Epoch=018, loss=0.6097
Epoch=019, loss=0.5975
Epoch=020, loss=0.5841
Epoch=021, loss=0.5675
Epoch=022, loss=0.5527
Epoch=023, loss=0.5349
Epoch=024, loss=0.5180
Epoch=025, loss=0.4985
Epoch=026, loss=0.4806
Epoch=027, loss=0.4581
Epoch=028, loss=0.4406
Epoch=029, loss=0.4170
Epoch=030, loss=0.4012
Epoch=031, loss=0.3771
Epoch=032, loss=0.3665
Epoch=033, loss=0.3306
Epoch=034, loss=0.3169
Epoch=035, loss=0.3010
Epoch=036, loss=0.2799
Epoch=037, loss=0.2653
Epoch=038, loss=0.2491
Epoch=039, loss=0.2348
Epoch=040, loss=0.2168
Epoch=041, loss=0.2135
Epoch=042, loss=0.1993
Epoch=043, loss=0.1903
Epoch=044, loss=0.1666
Epoch=045, loss=0.1694
Epoch=046, loss=0.1591
Epoch=047, loss=0.1490
Epoch=048, loss=0.1568
Epoch=049, loss=0.1446
Epoch=050, loss=0.1303
Epoch=051, loss=0.1189
Epoch=052, loss=0.1225
Epoch=053, loss=0.1258
Epoch=054, loss=0.1089
Epoch=055, loss=0.1123
Epoch=056, loss=0.1091
Epoch=057, loss=0.1125
Epoch=058, loss=0.1185
Epoch=059, loss=0.1098
Epoch=060, loss=0.0962
Epoch=061, loss=0.1012
Epoch=062, loss=0.0901
Epoch=063, loss=0.0985
Epoch=064, loss=0.0710
Epoch=065, loss=0.0958
Epoch=066, loss=0.0911
Epoch=067, loss=0.0891
Epoch=068, loss=0.0727
Epoch=069, loss=0.0782
Epoch=070, loss=0.0740
Epoch=071, loss=0.0807
Epoch=072, loss=0.0821
Epoch=073, loss=0.0875
Epoch=074, loss=0.0748
Epoch=075, loss=0.0715
Epoch=076, loss=0.0771
Epoch=077, loss=0.0829
Epoch=078, loss=0.0805
Epoch=079, loss=0.0692
Epoch=080, loss=0.0720
Epoch=081, loss=0.0689
Epoch=082, loss=0.0721
Epoch=083, loss=0.0634
Epoch=084, loss=0.0568
Epoch=085, loss=0.0669
Epoch=086, loss=0.0677
Epoch=087, loss=0.0610
Epoch=088, loss=0.0599
Epoch=089, loss=0.0691
Epoch=090, loss=0.0502
Epoch=091, loss=0.0594
Epoch=092, loss=0.0679
Epoch=093, loss=0.0520
Epoch=094, loss=0.0596
Epoch=095, loss=0.0660
Epoch=096, loss=0.0587
Epoch=097, loss=0.0573
Epoch=098, loss=0.0500
Epoch=099, loss=0.0559
Epoch=100, loss=0.0554
Epoch=101, loss=0.0497
Epoch=102, loss=0.0654
Epoch=103, loss=0.0612
Epoch=104, loss=0.0545
Epoch=105, loss=0.0544
Epoch=106, loss=0.0620
Epoch=107, loss=0.0635
Epoch=108, loss=0.0517
Epoch=109, loss=0.0525
Epoch=110, loss=0.0553
Epoch=111, loss=0.0563
Epoch=112, loss=0.0535
Epoch=113, loss=0.0434
Epoch=114, loss=0.0486
Epoch=115, loss=0.0506
Epoch=116, loss=0.0599
Epoch=117, loss=0.0499
Epoch=118, loss=0.0367
Epoch=119, loss=0.0528
Epoch=120, loss=0.0507
Epoch=121, loss=0.0602
Epoch=122, loss=0.0467
Epoch=123, loss=0.0579
Epoch=124, loss=0.0475
Epoch=125, loss=0.0498
Epoch=126, loss=0.0550
Epoch=127, loss=0.0509
Epoch=128, loss=0.0468
Epoch=129, loss=0.0674
Epoch=130, loss=0.0447
Epoch=131, loss=0.0431
Epoch=132, loss=0.0457
Epoch=133, loss=0.0446
Epoch=134, loss=0.0601
Epoch=135, loss=0.0428
Epoch=136, loss=0.0354
Epoch=137, loss=0.0511
Epoch=138, loss=0.0289
Epoch=139, loss=0.0470
Epoch=140, loss=0.0536
Epoch=141, loss=0.0405
Epoch=142, loss=0.0338
Epoch=143, loss=0.0356
Epoch=144, loss=0.0483
Epoch=145, loss=0.0388
Epoch=146, loss=0.0434
Epoch=147, loss=0.0520
Epoch=148, loss=0.0534
Epoch=149, loss=0.0439
Epoch=150, loss=0.0362
Epoch=151, loss=0.0328
Epoch=152, loss=0.0242
Epoch=153, loss=0.0510
Epoch=154, loss=0.0522
Epoch=155, loss=0.0372
Epoch=156, loss=0.0439
Epoch=157, loss=0.0397
Epoch=158, loss=0.0442
Epoch=159, loss=0.0438
Epoch=160, loss=0.0325
Epoch=161, loss=0.0386
Epoch=162, loss=0.0487
Epoch=163, loss=0.0427
Epoch=164, loss=0.0524
Epoch=165, loss=0.0389
Epoch=166, loss=0.0362
Epoch=167, loss=0.0261
Epoch=168, loss=0.0275
Epoch=169, loss=0.0403
Epoch=170, loss=0.0367
Epoch=171, loss=0.0437
Epoch=172, loss=0.0367
Early stopping!
Loading 152th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7949+-0.0120, F1Ma=0.7651+-0.0220, acc=0.7949+-0.0120
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7921226260719813, 0.789892820789674, 0.7881315959082416, 0.7834073395875671, 0.8500000238418579, 0.7400000095367432, 0.7717601656913757, 0.8500000238418579, 0.7360000014305115, 0.7693423628807068, 0.7526622619510299, 0.015529723251775002, 0.7183572529573103, 0.02289161198999102, 0.7526622619510299, 0.015529723251774997], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7782807033849028, 0.7700521198879904, 0.7684145335920989, 0.7571882858659942, 0.9214285612106323, 0.7559999823570251, 0.7862669229507446, 0.9214285612106323, 0.7540000081062317, 0.7838491201400757, 0.7867858530897786, 0.008761826214356382, 0.7394707749868877, 0.016964031684690437, 0.7867858530897784, 0.008761826214356392], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847838839797789, 0.7744436319365973, 0.7787519488422168, 0.7624614234184541, 0.9357143044471741, 0.7720000147819519, 0.8002901077270508, 0.9357143044471741, 0.7720000147819519, 0.7998065948486328, 0.7948698017877964, 0.0119800487556573, 0.765123726020702, 0.02196395511049696, 0.7948698017877963, 0.011980048755657271]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6917
Epoch=002, loss=0.6891
Epoch=003, loss=0.6858
Epoch=004, loss=0.6806
Epoch=005, loss=0.6749
Epoch=006, loss=0.6672
Epoch=007, loss=0.6577
Epoch=008, loss=0.6455
Epoch=009, loss=0.6323
Epoch=010, loss=0.6183
Epoch=011, loss=0.5989
Epoch=012, loss=0.5791
Epoch=013, loss=0.5578
Epoch=014, loss=0.5293
Epoch=015, loss=0.5062
Epoch=016, loss=0.4836
Epoch=017, loss=0.4510
Epoch=018, loss=0.4197
Epoch=019, loss=0.3871
Epoch=020, loss=0.3661
Epoch=021, loss=0.3439
Epoch=022, loss=0.3102
Epoch=023, loss=0.2910
Epoch=024, loss=0.2872
Epoch=025, loss=0.2527
Epoch=026, loss=0.2237
Epoch=027, loss=0.2213
Epoch=028, loss=0.1979
Epoch=029, loss=0.1904
Epoch=030, loss=0.1910
Epoch=031, loss=0.1810
Epoch=032, loss=0.1541
Epoch=033, loss=0.1702
Epoch=034, loss=0.1545
Epoch=035, loss=0.1489
Epoch=036, loss=0.1477
Epoch=037, loss=0.1459
Epoch=038, loss=0.1248
Epoch=039, loss=0.1316
Epoch=040, loss=0.1169
Epoch=041, loss=0.1110
Epoch=042, loss=0.1004
Epoch=043, loss=0.1193
Epoch=044, loss=0.0957
Epoch=045, loss=0.0858
Epoch=046, loss=0.1109
Epoch=047, loss=0.0947
Epoch=048, loss=0.0922
Epoch=049, loss=0.0981
Epoch=050, loss=0.0901
Epoch=051, loss=0.1010
Epoch=052, loss=0.1047
Epoch=053, loss=0.0947
Epoch=054, loss=0.0877
Epoch=055, loss=0.0854
Epoch=056, loss=0.1041
Epoch=057, loss=0.0796
Epoch=058, loss=0.0941
Epoch=059, loss=0.0774
Epoch=060, loss=0.0718
Epoch=061, loss=0.0623
Epoch=062, loss=0.0868
Epoch=063, loss=0.0726
Epoch=064, loss=0.0813
Epoch=065, loss=0.0641
Epoch=066, loss=0.0719
Epoch=067, loss=0.0866
Epoch=068, loss=0.0783
Epoch=069, loss=0.0673
Epoch=070, loss=0.0808
Epoch=071, loss=0.0797
Epoch=072, loss=0.0762
Epoch=073, loss=0.0625
Epoch=074, loss=0.0683
Epoch=075, loss=0.0555
Epoch=076, loss=0.0685
Epoch=077, loss=0.0642
Epoch=078, loss=0.0820
Epoch=079, loss=0.0521
Epoch=080, loss=0.0515
Epoch=081, loss=0.0722
Epoch=082, loss=0.0628
Epoch=083, loss=0.0696
Epoch=084, loss=0.0636
Epoch=085, loss=0.0577
Epoch=086, loss=0.0523
Epoch=087, loss=0.0586
Epoch=088, loss=0.0519
Epoch=089, loss=0.0593
Epoch=090, loss=0.0519
Epoch=091, loss=0.0556
Epoch=092, loss=0.0624
Epoch=093, loss=0.0499
Epoch=094, loss=0.0553
Epoch=095, loss=0.0521
Epoch=096, loss=0.0495
Epoch=097, loss=0.0609
Epoch=098, loss=0.0439
Epoch=099, loss=0.0431
Epoch=100, loss=0.0558
Epoch=101, loss=0.0395
Epoch=102, loss=0.0515
Epoch=103, loss=0.0492
Epoch=104, loss=0.0589
Epoch=105, loss=0.0615
Epoch=106, loss=0.0436
Epoch=107, loss=0.0559
Epoch=108, loss=0.0412
Epoch=109, loss=0.0382
Epoch=110, loss=0.0467
Epoch=111, loss=0.0471
Epoch=112, loss=0.0575
Epoch=113, loss=0.0435
Epoch=114, loss=0.0513
Epoch=115, loss=0.0399
Epoch=116, loss=0.0380
Epoch=117, loss=0.0390
Epoch=118, loss=0.0396
Epoch=119, loss=0.0481
Epoch=120, loss=0.0444
Epoch=121, loss=0.0393
Epoch=122, loss=0.0451
Epoch=123, loss=0.0359
Epoch=124, loss=0.0411
Epoch=125, loss=0.0459
Epoch=126, loss=0.0361
Epoch=127, loss=0.0487
Epoch=128, loss=0.0321
Epoch=129, loss=0.0406
Epoch=130, loss=0.0384
Epoch=131, loss=0.0335
Epoch=132, loss=0.0408
Epoch=133, loss=0.0492
Epoch=134, loss=0.0347
Epoch=135, loss=0.0415
Epoch=136, loss=0.0404
Epoch=137, loss=0.0350
Epoch=138, loss=0.0351
Epoch=139, loss=0.0367
Epoch=140, loss=0.0464
Epoch=141, loss=0.0406
Epoch=142, loss=0.0385
Epoch=143, loss=0.0418
Epoch=144, loss=0.0323
Epoch=145, loss=0.0433
Epoch=146, loss=0.0366
Epoch=147, loss=0.0276
Epoch=148, loss=0.0260
Epoch=149, loss=0.0410
Epoch=150, loss=0.0358
Epoch=151, loss=0.0295
Epoch=152, loss=0.0315
Epoch=153, loss=0.0273
Epoch=154, loss=0.0329
Epoch=155, loss=0.0246
Epoch=156, loss=0.0386
Epoch=157, loss=0.0300
Epoch=158, loss=0.0358
Epoch=159, loss=0.0357
Epoch=160, loss=0.0294
Epoch=161, loss=0.0206
Epoch=162, loss=0.0305
Epoch=163, loss=0.0294
Epoch=164, loss=0.0253
Epoch=165, loss=0.0290
Epoch=166, loss=0.0374
Epoch=167, loss=0.0285
Epoch=168, loss=0.0291
Epoch=169, loss=0.0244
Epoch=170, loss=0.0306
Epoch=171, loss=0.0340
Epoch=172, loss=0.0239
Epoch=173, loss=0.0257
Epoch=174, loss=0.0268
Epoch=175, loss=0.0283
Epoch=176, loss=0.0302
Epoch=177, loss=0.0217
Epoch=178, loss=0.0204
Epoch=179, loss=0.0251
Epoch=180, loss=0.0258
Epoch=181, loss=0.0165
Epoch=182, loss=0.0175
Epoch=183, loss=0.0270
Epoch=184, loss=0.0326
Epoch=185, loss=0.0293
Epoch=186, loss=0.0263
Epoch=187, loss=0.0287
Epoch=188, loss=0.0153
Epoch=189, loss=0.0302
Epoch=190, loss=0.0221
Epoch=191, loss=0.0193
Epoch=192, loss=0.0289
Epoch=193, loss=0.0203
Epoch=194, loss=0.0160
Epoch=195, loss=0.0216
Epoch=196, loss=0.0293
Epoch=197, loss=0.0249
Epoch=198, loss=0.0297
Epoch=199, loss=0.0346
Epoch=200, loss=0.0452
Epoch=201, loss=0.0289
Epoch=202, loss=0.0321
Epoch=203, loss=0.0188
Epoch=204, loss=0.0280
Epoch=205, loss=0.0461
Epoch=206, loss=0.0254
Epoch=207, loss=0.0514
Epoch=208, loss=0.0377
Early stopping!
Loading 188th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8022+-0.0116, F1Ma=0.7843+-0.0205, acc=0.8022+-0.0116
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7921226260719813, 0.789892820789674, 0.7881315959082416, 0.7834073395875671, 0.8500000238418579, 0.7400000095367432, 0.7717601656913757, 0.8500000238418579, 0.7360000014305115, 0.7693423628807068, 0.7526622619510299, 0.015529723251775002, 0.7183572529573103, 0.02289161198999102, 0.7526622619510299, 0.015529723251774997], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7782807033849028, 0.7700521198879904, 0.7684145335920989, 0.7571882858659942, 0.9214285612106323, 0.7559999823570251, 0.7862669229507446, 0.9214285612106323, 0.7540000081062317, 0.7838491201400757, 0.7867858530897786, 0.008761826214356382, 0.7394707749868877, 0.016964031684690437, 0.7867858530897784, 0.008761826214356392], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847838839797789, 0.7744436319365973, 0.7787519488422168, 0.7624614234184541, 0.9357143044471741, 0.7720000147819519, 0.8002901077270508, 0.9357143044471741, 0.7720000147819519, 0.7998065948486328, 0.7948698017877964, 0.0119800487556573, 0.765123726020702, 0.02196395511049696, 0.7948698017877963, 0.011980048755657271], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7331607300593224, 0.7535372300394935, 0.7249981096680578, 0.7432186713567327, 0.9357143044471741, 0.7860000133514404, 0.7969052195549011, 0.9357143044471741, 0.7860000133514404, 0.7964216470718384, 0.8021764477263895, 0.011563276655508182, 0.7842707846555835, 0.020452962658112386, 0.8021764477263893, 0.011563276655508221]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6915
Epoch=002, loss=0.6874
Epoch=003, loss=0.6773
Epoch=004, loss=0.6717
Epoch=005, loss=0.6552
Epoch=006, loss=0.6462
Epoch=007, loss=0.6309
Epoch=008, loss=0.6033
Epoch=009, loss=0.5866
Epoch=010, loss=0.5714
Epoch=011, loss=0.5342
Epoch=012, loss=0.5105
Epoch=013, loss=0.4866
Epoch=014, loss=0.4469
Epoch=015, loss=0.4080
Epoch=016, loss=0.4113
Epoch=017, loss=0.3910
Epoch=018, loss=0.3215
Epoch=019, loss=0.3193
Epoch=020, loss=0.2984
Epoch=021, loss=0.2525
Epoch=022, loss=0.2671
Epoch=023, loss=0.2228
Epoch=024, loss=0.2073
Epoch=025, loss=0.2191
Epoch=026, loss=0.1752
Epoch=027, loss=0.1660
Epoch=028, loss=0.1459
Epoch=029, loss=0.1464
Epoch=030, loss=0.1417
Epoch=031, loss=0.1355
Epoch=032, loss=0.1365
Epoch=033, loss=0.1364
Epoch=034, loss=0.1019
Epoch=035, loss=0.1064
Epoch=036, loss=0.0845
Epoch=037, loss=0.0963
Epoch=038, loss=0.0936
Epoch=039, loss=0.0870
Epoch=040, loss=0.0826
Epoch=041, loss=0.0858
Epoch=042, loss=0.0702
Epoch=043, loss=0.0843
Epoch=044, loss=0.0674
Epoch=045, loss=0.0845
Epoch=046, loss=0.0598
Epoch=047, loss=0.0756
Epoch=048, loss=0.0471
Epoch=049, loss=0.0606
Epoch=050, loss=0.0492
Epoch=051, loss=0.0403
Epoch=052, loss=0.0699
Epoch=053, loss=0.0429
Epoch=054, loss=0.0485
Epoch=055, loss=0.0476
Epoch=056, loss=0.0385
Epoch=057, loss=0.0533
Epoch=058, loss=0.0376
Epoch=059, loss=0.0375
Epoch=060, loss=0.0397
Epoch=061, loss=0.0348
Epoch=062, loss=0.0308
Epoch=063, loss=0.0383
Epoch=064, loss=0.0283
Epoch=065, loss=0.0372
Epoch=066, loss=0.0248
Epoch=067, loss=0.0270
Epoch=068, loss=0.0302
Epoch=069, loss=0.0321
Epoch=070, loss=0.0294
Epoch=071, loss=0.0255
Epoch=072, loss=0.0284
Epoch=073, loss=0.0256
Epoch=074, loss=0.0259
Epoch=075, loss=0.0230
Epoch=076, loss=0.0158
Epoch=077, loss=0.0204
Epoch=078, loss=0.0184
Epoch=079, loss=0.0222
Epoch=080, loss=0.0236
Epoch=081, loss=0.0194
Epoch=082, loss=0.0203
Epoch=083, loss=0.0258
Epoch=084, loss=0.0215
Epoch=085, loss=0.0183
Epoch=086, loss=0.0198
Epoch=087, loss=0.0230
Epoch=088, loss=0.0178
Epoch=089, loss=0.0142
Epoch=090, loss=0.0157
Epoch=091, loss=0.0139
Epoch=092, loss=0.0184
Epoch=093, loss=0.0101
Epoch=094, loss=0.0208
Epoch=095, loss=0.0125
Epoch=096, loss=0.0168
Epoch=097, loss=0.0122
Epoch=098, loss=0.0160
Epoch=099, loss=0.0187
Epoch=100, loss=0.0134
Epoch=101, loss=0.0152
Epoch=102, loss=0.0087
Epoch=103, loss=0.0085
Epoch=104, loss=0.0088
Epoch=105, loss=0.0103
Epoch=106, loss=0.0087
Epoch=107, loss=0.0081
Epoch=108, loss=0.0112
Epoch=109, loss=0.0138
Epoch=110, loss=0.0087
Epoch=111, loss=0.0149
Epoch=112, loss=0.0123
Epoch=113, loss=0.0107
Epoch=114, loss=0.0090
Epoch=115, loss=0.0112
Epoch=116, loss=0.0183
Epoch=117, loss=0.0150
Epoch=118, loss=0.0125
Epoch=119, loss=0.0072
Epoch=120, loss=0.0077
Epoch=121, loss=0.0114
Epoch=122, loss=0.0072
Epoch=123, loss=0.0159
Epoch=124, loss=0.0101
Epoch=125, loss=0.0097
Epoch=126, loss=0.0074
Epoch=127, loss=0.0059
Epoch=128, loss=0.0064
Epoch=129, loss=0.0047
Epoch=130, loss=0.0073
Epoch=131, loss=0.0091
Epoch=132, loss=0.0069
Epoch=133, loss=0.0143
Epoch=134, loss=0.0064
Epoch=135, loss=0.0059
Epoch=136, loss=0.0089
Epoch=137, loss=0.0059
Epoch=138, loss=0.0089
Epoch=139, loss=0.0062
Epoch=140, loss=0.0064
Epoch=141, loss=0.0098
Epoch=142, loss=0.0036
Epoch=143, loss=0.0043
Epoch=144, loss=0.0064
Epoch=145, loss=0.0102
Epoch=146, loss=0.0082
Epoch=147, loss=0.0056
Epoch=148, loss=0.0146
Epoch=149, loss=0.0040
Epoch=150, loss=0.0078
Epoch=151, loss=0.0053
Epoch=152, loss=0.0067
Epoch=153, loss=0.0063
Epoch=154, loss=0.0076
Epoch=155, loss=0.0041
Epoch=156, loss=0.0029
Epoch=157, loss=0.0038
Epoch=158, loss=0.0040
Epoch=159, loss=0.0042
Epoch=160, loss=0.0123
Epoch=161, loss=0.0038
Epoch=162, loss=0.0058
Epoch=163, loss=0.0064
Epoch=164, loss=0.0036
Epoch=165, loss=0.0041
Epoch=166, loss=0.0065
Epoch=167, loss=0.0034
Epoch=168, loss=0.0051
Epoch=169, loss=0.0040
Epoch=170, loss=0.0071
Epoch=171, loss=0.0103
Epoch=172, loss=0.0058
Epoch=173, loss=0.0048
Epoch=174, loss=0.0042
Epoch=175, loss=0.0036
Epoch=176, loss=0.0023
Epoch=177, loss=0.0106
Epoch=178, loss=0.0033
Epoch=179, loss=0.0037
Epoch=180, loss=0.0034
Epoch=181, loss=0.0060
Epoch=182, loss=0.0031
Epoch=183, loss=0.0027
Epoch=184, loss=0.0038
Epoch=185, loss=0.0056
Epoch=186, loss=0.0032
Epoch=187, loss=0.0031
Epoch=188, loss=0.0060
Epoch=189, loss=0.0041
Epoch=190, loss=0.0053
Epoch=191, loss=0.0027
Epoch=192, loss=0.0053
Epoch=193, loss=0.0124
Epoch=194, loss=0.0021
Epoch=195, loss=0.0055
Epoch=196, loss=0.0048
Epoch=197, loss=0.0053
Epoch=198, loss=0.0022
Epoch=199, loss=0.0045
Epoch=200, loss=0.0027
Epoch=201, loss=0.0066
Epoch=202, loss=0.0047
Epoch=203, loss=0.0070
Epoch=204, loss=0.0031
Epoch=205, loss=0.0013
Epoch=206, loss=0.0056
Epoch=207, loss=0.0054
Epoch=208, loss=0.0074
Epoch=209, loss=0.0039
Epoch=210, loss=0.0027
Epoch=211, loss=0.0039
Epoch=212, loss=0.0022
Epoch=213, loss=0.0037
Epoch=214, loss=0.0035
Epoch=215, loss=0.0049
Epoch=216, loss=0.0032
Epoch=217, loss=0.0030
Epoch=218, loss=0.0013
Epoch=219, loss=0.0023
Epoch=220, loss=0.0023
Epoch=221, loss=0.0015
Epoch=222, loss=0.0028
Epoch=223, loss=0.0024
Epoch=224, loss=0.0022
Epoch=225, loss=0.0031
Epoch=226, loss=0.0012
Epoch=227, loss=0.0036
Epoch=228, loss=0.0035
Epoch=229, loss=0.0020
Epoch=230, loss=0.0022
Epoch=231, loss=0.0051
Epoch=232, loss=0.0022
Epoch=233, loss=0.0016
Epoch=234, loss=0.0015
Epoch=235, loss=0.0049
Epoch=236, loss=0.0011
Epoch=237, loss=0.0027
Epoch=238, loss=0.0035
Epoch=239, loss=0.0016
Epoch=240, loss=0.0023
Epoch=241, loss=0.0015
Epoch=242, loss=0.0010
Epoch=243, loss=0.0019
Epoch=244, loss=0.0018
Epoch=245, loss=0.0043
Epoch=246, loss=0.0022
Epoch=247, loss=0.0027
Epoch=248, loss=0.0014
Epoch=249, loss=0.0049
Epoch=250, loss=0.0056
Epoch=251, loss=0.0024
Epoch=252, loss=0.0014
Epoch=253, loss=0.0017
Epoch=254, loss=0.0012
Epoch=255, loss=0.0008
Epoch=256, loss=0.0019
Epoch=257, loss=0.0023
Epoch=258, loss=0.0019
Epoch=259, loss=0.0019
Epoch=260, loss=0.0033
Epoch=261, loss=0.0020
Epoch=262, loss=0.0013
Epoch=263, loss=0.0018
Epoch=264, loss=0.0009
Epoch=265, loss=0.0040
Epoch=266, loss=0.0012
Epoch=267, loss=0.0021
Epoch=268, loss=0.0037
Epoch=269, loss=0.0015
Epoch=270, loss=0.0018
Epoch=271, loss=0.0014
Epoch=272, loss=0.0013
Epoch=273, loss=0.0012
Epoch=274, loss=0.0050
Epoch=275, loss=0.0006
Epoch=276, loss=0.0041
Epoch=277, loss=0.0022
Epoch=278, loss=0.0023
Epoch=279, loss=0.0020
Epoch=280, loss=0.0010
Epoch=281, loss=0.0006
Epoch=282, loss=0.0039
Epoch=283, loss=0.0052
Epoch=284, loss=0.0019
Epoch=285, loss=0.0038
Epoch=286, loss=0.0019
Epoch=287, loss=0.0011
Epoch=288, loss=0.0018
Epoch=289, loss=0.0021
Epoch=290, loss=0.0017
Epoch=291, loss=0.0025
Epoch=292, loss=0.0032
Epoch=293, loss=0.0019
Epoch=294, loss=0.0015
Epoch=295, loss=0.0005
Epoch=296, loss=0.0039
Epoch=297, loss=0.0029
Epoch=298, loss=0.0017
Epoch=299, loss=0.0007
Epoch=300, loss=0.0010
Epoch=301, loss=0.0037
Epoch=302, loss=0.0009
Epoch=303, loss=0.0012
Epoch=304, loss=0.0010
Epoch=305, loss=0.0066
Epoch=306, loss=0.0035
Epoch=307, loss=0.0016
Epoch=308, loss=0.0045
Epoch=309, loss=0.0010
Epoch=310, loss=0.0026
Epoch=311, loss=0.0011
Epoch=312, loss=0.0026
Epoch=313, loss=0.0011
Epoch=314, loss=0.0012
Epoch=315, loss=0.0009
Early stopping!
Loading 295th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7953+-0.0151, F1Ma=0.7702+-0.0288, acc=0.7953+-0.0151
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7287841105693614, 0.747090367515227, 0.7154762376273274, 0.7329889905045243, 0.7357142567634583, 0.5879999995231628, 0.6237910985946655, 0.7357142567634583, 0.5839999914169312, 0.625241756439209, 0.6325689856198989, 0.012098487103957486, 0.5534350691005903, 0.01290978090767024, 0.6325689856198989, 0.012098487103957486], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7921226260719813, 0.789892820789674, 0.7881315959082416, 0.7834073395875671, 0.8500000238418579, 0.7400000095367432, 0.7717601656913757, 0.8500000238418579, 0.7360000014305115, 0.7693423628807068, 0.7526622619510299, 0.015529723251775002, 0.7183572529573103, 0.02289161198999102, 0.7526622619510299, 0.015529723251774997], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7782807033849028, 0.7700521198879904, 0.7684145335920989, 0.7571882858659942, 0.9214285612106323, 0.7559999823570251, 0.7862669229507446, 0.9214285612106323, 0.7540000081062317, 0.7838491201400757, 0.7867858530897786, 0.008761826214356382, 0.7394707749868877, 0.016964031684690437, 0.7867858530897784, 0.008761826214356392], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7847838839797789, 0.7744436319365973, 0.7787519488422168, 0.7624614234184541, 0.9357143044471741, 0.7720000147819519, 0.8002901077270508, 0.9357143044471741, 0.7720000147819519, 0.7998065948486328, 0.7948698017877964, 0.0119800487556573, 0.765123726020702, 0.02196395511049696, 0.7948698017877963, 0.011980048755657271], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7331607300593224, 0.7535372300394935, 0.7249981096680578, 0.7432186713567327, 0.9357143044471741, 0.7860000133514404, 0.7969052195549011, 0.9357143044471741, 0.7860000133514404, 0.7964216470718384, 0.8021764477263895, 0.011563276655508182, 0.7842707846555835, 0.020452962658112386, 0.8021764477263893, 0.011563276655508221], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7763663341896473, 0.7880219348587962, 0.7665998149275012, 0.7815528686254414, 0.949999988079071, 0.7839999794960022, 0.8051257133483887, 0.9571428298950195, 0.7839999794960022, 0.8051257133483887, 0.7952584531675088, 0.015131271882197291, 0.770154287367826, 0.0288347813397229, 0.7952584531675088, 0.015131271882197308]]
