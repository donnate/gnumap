My SLURM_ARRAY_TASK_ID:  10
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_10
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_10.csv
=== train DGI model ===
Epoch=000, loss=0.6930
Epoch=001, loss=0.6930
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6927
Epoch=008, loss=0.6926
Epoch=009, loss=0.6926
Epoch=010, loss=0.6925
Epoch=011, loss=0.6924
Epoch=012, loss=0.6923
Epoch=013, loss=0.6922
Epoch=014, loss=0.6921
Epoch=015, loss=0.6920
Epoch=016, loss=0.6919
Epoch=017, loss=0.6918
Epoch=018, loss=0.6916
Epoch=019, loss=0.6915
Epoch=020, loss=0.6914
Epoch=021, loss=0.6912
Epoch=022, loss=0.6910
Epoch=023, loss=0.6908
Epoch=024, loss=0.6907
Epoch=025, loss=0.6905
Epoch=026, loss=0.6902
Epoch=027, loss=0.6900
Epoch=028, loss=0.6898
Epoch=029, loss=0.6895
Epoch=030, loss=0.6893
Epoch=031, loss=0.6890
Epoch=032, loss=0.6886
Epoch=033, loss=0.6884
Epoch=034, loss=0.6880
Epoch=035, loss=0.6875
Epoch=036, loss=0.6871
Epoch=037, loss=0.6868
Epoch=038, loss=0.6863
Epoch=039, loss=0.6859
Epoch=040, loss=0.6855
Epoch=041, loss=0.6850
Epoch=042, loss=0.6846
Epoch=043, loss=0.6839
Epoch=044, loss=0.6836
Epoch=045, loss=0.6829
Epoch=046, loss=0.6820
Epoch=047, loss=0.6815
Epoch=048, loss=0.6806
Epoch=049, loss=0.6800
Epoch=050, loss=0.6796
Epoch=051, loss=0.6787
Epoch=052, loss=0.6778
Epoch=053, loss=0.6773
Epoch=054, loss=0.6761
Epoch=055, loss=0.6756
Epoch=056, loss=0.6741
Epoch=057, loss=0.6737
Epoch=058, loss=0.6729
Epoch=059, loss=0.6717
Epoch=060, loss=0.6704
Epoch=061, loss=0.6694
Epoch=062, loss=0.6683
Epoch=063, loss=0.6670
Epoch=064, loss=0.6651
Epoch=065, loss=0.6646
Epoch=066, loss=0.6631
Epoch=067, loss=0.6623
Epoch=068, loss=0.6607
Epoch=069, loss=0.6590
Epoch=070, loss=0.6574
Epoch=071, loss=0.6559
Epoch=072, loss=0.6543
Epoch=073, loss=0.6527
Epoch=074, loss=0.6514
Epoch=075, loss=0.6495
Epoch=076, loss=0.6482
Epoch=077, loss=0.6458
Epoch=078, loss=0.6441
Epoch=079, loss=0.6432
Epoch=080, loss=0.6406
Epoch=081, loss=0.6385
Epoch=082, loss=0.6361
Epoch=083, loss=0.6345
Epoch=084, loss=0.6324
Epoch=085, loss=0.6287
Epoch=086, loss=0.6279
Epoch=087, loss=0.6249
Epoch=088, loss=0.6220
Epoch=089, loss=0.6203
Epoch=090, loss=0.6179
Epoch=091, loss=0.6156
Epoch=092, loss=0.6131
Epoch=093, loss=0.6098
Epoch=094, loss=0.6080
Epoch=095, loss=0.6054
Epoch=096, loss=0.6027
Epoch=097, loss=0.5983
Epoch=098, loss=0.5965
Epoch=099, loss=0.5931
Epoch=100, loss=0.5906
Epoch=101, loss=0.5873
Epoch=102, loss=0.5839
Epoch=103, loss=0.5803
Epoch=104, loss=0.5771
Epoch=105, loss=0.5723
Epoch=106, loss=0.5700
Epoch=107, loss=0.5687
Epoch=108, loss=0.5650
Epoch=109, loss=0.5600
Epoch=110, loss=0.5564
Epoch=111, loss=0.5533
Epoch=112, loss=0.5478
Epoch=113, loss=0.5485
Epoch=114, loss=0.5427
Epoch=115, loss=0.5409
Epoch=116, loss=0.5368
Epoch=117, loss=0.5314
Epoch=118, loss=0.5294
Epoch=119, loss=0.5240
Epoch=120, loss=0.5187
Epoch=121, loss=0.5192
Epoch=122, loss=0.5133
Epoch=123, loss=0.5104
Epoch=124, loss=0.5046
Epoch=125, loss=0.4962
Epoch=126, loss=0.4987
Epoch=127, loss=0.4937
Epoch=128, loss=0.4884
Epoch=129, loss=0.4847
Epoch=130, loss=0.4868
Epoch=131, loss=0.4777
Epoch=132, loss=0.4754
Epoch=133, loss=0.4666
Epoch=134, loss=0.4671
Epoch=135, loss=0.4592
Epoch=136, loss=0.4594
Epoch=137, loss=0.4535
Epoch=138, loss=0.4493
Epoch=139, loss=0.4479
Epoch=140, loss=0.4440
Epoch=141, loss=0.4355
Epoch=142, loss=0.4394
Epoch=143, loss=0.4265
Epoch=144, loss=0.4263
Epoch=145, loss=0.4211
Epoch=146, loss=0.4105
Epoch=147, loss=0.4129
Epoch=148, loss=0.4138
Epoch=149, loss=0.4090
Epoch=150, loss=0.3997
Epoch=151, loss=0.3974
Epoch=152, loss=0.3909
Epoch=153, loss=0.3901
Epoch=154, loss=0.3885
Epoch=155, loss=0.3787
Epoch=156, loss=0.3746
Epoch=157, loss=0.3774
Epoch=158, loss=0.3697
Epoch=159, loss=0.3676
Epoch=160, loss=0.3611
Epoch=161, loss=0.3599
Epoch=162, loss=0.3581
Epoch=163, loss=0.3489
Epoch=164, loss=0.3463
Epoch=165, loss=0.3454
Epoch=166, loss=0.3345
Epoch=167, loss=0.3396
Epoch=168, loss=0.3391
Epoch=169, loss=0.3354
Epoch=170, loss=0.3346
Epoch=171, loss=0.3233
Epoch=172, loss=0.3155
Epoch=173, loss=0.3250
Epoch=174, loss=0.3123
Epoch=175, loss=0.3098
Epoch=176, loss=0.3089
Epoch=177, loss=0.3080
Epoch=178, loss=0.2987
Epoch=179, loss=0.2951
Epoch=180, loss=0.2951
Epoch=181, loss=0.2912
Epoch=182, loss=0.2886
Epoch=183, loss=0.2944
Epoch=184, loss=0.2916
Epoch=185, loss=0.2790
Epoch=186, loss=0.2838
Epoch=187, loss=0.2746
Epoch=188, loss=0.2694
Epoch=189, loss=0.2780
Epoch=190, loss=0.2629
Epoch=191, loss=0.2685
Epoch=192, loss=0.2602
Epoch=193, loss=0.2557
Epoch=194, loss=0.2624
Epoch=195, loss=0.2637
Epoch=196, loss=0.2591
Epoch=197, loss=0.2540
Epoch=198, loss=0.2530
Epoch=199, loss=0.2439
Epoch=200, loss=0.2423
Epoch=201, loss=0.2424
Epoch=202, loss=0.2364
Epoch=203, loss=0.2418
Epoch=204, loss=0.2263
Epoch=205, loss=0.2409
Epoch=206, loss=0.2318
Epoch=207, loss=0.2266
Epoch=208, loss=0.2214
Epoch=209, loss=0.2300
Epoch=210, loss=0.2295
Epoch=211, loss=0.2163
Epoch=212, loss=0.2235
Epoch=213, loss=0.2186
Epoch=214, loss=0.2209
Epoch=215, loss=0.2196
Epoch=216, loss=0.2205
Epoch=217, loss=0.2083
Epoch=218, loss=0.2167
Epoch=219, loss=0.2185
Epoch=220, loss=0.2006
Epoch=221, loss=0.2007
Epoch=222, loss=0.2072
Epoch=223, loss=0.1964
Epoch=224, loss=0.2024
Epoch=225, loss=0.1878
Epoch=226, loss=0.2020
Epoch=227, loss=0.2004
Epoch=228, loss=0.1959
Epoch=229, loss=0.1988
Epoch=230, loss=0.1887
Epoch=231, loss=0.1862
Epoch=232, loss=0.1889
Epoch=233, loss=0.1811
Epoch=234, loss=0.1791
Epoch=235, loss=0.1774
Epoch=236, loss=0.1862
Epoch=237, loss=0.1886
Epoch=238, loss=0.1775
Epoch=239, loss=0.1779
Epoch=240, loss=0.1754
Epoch=241, loss=0.1840
Epoch=242, loss=0.1839
Epoch=243, loss=0.1726
Epoch=244, loss=0.1705
Epoch=245, loss=0.1813
Epoch=246, loss=0.1710
Epoch=247, loss=0.1748
Epoch=248, loss=0.1617
Epoch=249, loss=0.1637
Epoch=250, loss=0.1664
Epoch=251, loss=0.1585
Epoch=252, loss=0.1610
Epoch=253, loss=0.1637
Epoch=254, loss=0.1629
Epoch=255, loss=0.1512
Epoch=256, loss=0.1517
Epoch=257, loss=0.1473
Epoch=258, loss=0.1677
Epoch=259, loss=0.1581
Epoch=260, loss=0.1585
Epoch=261, loss=0.1573
Epoch=262, loss=0.1537
Epoch=263, loss=0.1465
Epoch=264, loss=0.1527
Epoch=265, loss=0.1493
Epoch=266, loss=0.1507
Epoch=267, loss=0.1486
Epoch=268, loss=0.1495
Epoch=269, loss=0.1465
Epoch=270, loss=0.1539
Epoch=271, loss=0.1386
Epoch=272, loss=0.1363
Epoch=273, loss=0.1416
Epoch=274, loss=0.1429
Epoch=275, loss=0.1380
Epoch=276, loss=0.1433
Epoch=277, loss=0.1446
Epoch=278, loss=0.1357
Epoch=279, loss=0.1399
Epoch=280, loss=0.1295
Epoch=281, loss=0.1370
Epoch=282, loss=0.1302
Epoch=283, loss=0.1342
Epoch=284, loss=0.1374
Epoch=285, loss=0.1417
Epoch=286, loss=0.1384
Epoch=287, loss=0.1362
Epoch=288, loss=0.1314
Epoch=289, loss=0.1257
Epoch=290, loss=0.1287
Epoch=291, loss=0.1322
Epoch=292, loss=0.1307
Epoch=293, loss=0.1319
Epoch=294, loss=0.1200
Epoch=295, loss=0.1326
Epoch=296, loss=0.1354
Epoch=297, loss=0.1345
Epoch=298, loss=0.1270
Epoch=299, loss=0.1259
Epoch=300, loss=0.1228
Epoch=301, loss=0.1330
Epoch=302, loss=0.1247
Epoch=303, loss=0.1204
Epoch=304, loss=0.1242
Epoch=305, loss=0.1307
Epoch=306, loss=0.1213
Epoch=307, loss=0.1240
Epoch=308, loss=0.1301
Epoch=309, loss=0.1196
Epoch=310, loss=0.1194
Epoch=311, loss=0.1149
Epoch=312, loss=0.1147
Epoch=313, loss=0.1267
Epoch=314, loss=0.1144
Epoch=315, loss=0.1111
Epoch=316, loss=0.0996
Epoch=317, loss=0.1106
Epoch=318, loss=0.1208
Epoch=319, loss=0.1110
Epoch=320, loss=0.1149
Epoch=321, loss=0.1057
Epoch=322, loss=0.1117
Epoch=323, loss=0.1142
Epoch=324, loss=0.1082
Epoch=325, loss=0.1054
Epoch=326, loss=0.1148
Epoch=327, loss=0.1127
Epoch=328, loss=0.1124
Epoch=329, loss=0.1150
Epoch=330, loss=0.0998
Epoch=331, loss=0.1079
Epoch=332, loss=0.1110
Epoch=333, loss=0.1095
Epoch=334, loss=0.1118
Epoch=335, loss=0.1086
Epoch=336, loss=0.1130
Early stopping!
Loading 316th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7319+-0.0193, F1Ma=0.6635+-0.0334, acc=0.7319+-0.0193
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6930
Epoch=003, loss=0.6930
Epoch=004, loss=0.6929
Epoch=005, loss=0.6928
Epoch=006, loss=0.6927
Epoch=007, loss=0.6926
Epoch=008, loss=0.6925
Epoch=009, loss=0.6924
Epoch=010, loss=0.6922
Epoch=011, loss=0.6921
Epoch=012, loss=0.6918
Epoch=013, loss=0.6917
Epoch=014, loss=0.6915
Epoch=015, loss=0.6911
Epoch=016, loss=0.6909
Epoch=017, loss=0.6905
Epoch=018, loss=0.6902
Epoch=019, loss=0.6898
Epoch=020, loss=0.6894
Epoch=021, loss=0.6889
Epoch=022, loss=0.6884
Epoch=023, loss=0.6878
Epoch=024, loss=0.6872
Epoch=025, loss=0.6866
Epoch=026, loss=0.6858
Epoch=027, loss=0.6852
Epoch=028, loss=0.6845
Epoch=029, loss=0.6833
Epoch=030, loss=0.6825
Epoch=031, loss=0.6816
Epoch=032, loss=0.6806
Epoch=033, loss=0.6796
Epoch=034, loss=0.6779
Epoch=035, loss=0.6766
Epoch=036, loss=0.6752
Epoch=037, loss=0.6738
Epoch=038, loss=0.6720
Epoch=039, loss=0.6705
Epoch=040, loss=0.6679
Epoch=041, loss=0.6662
Epoch=042, loss=0.6651
Epoch=043, loss=0.6627
Epoch=044, loss=0.6602
Epoch=045, loss=0.6581
Epoch=046, loss=0.6563
Epoch=047, loss=0.6526
Epoch=048, loss=0.6500
Epoch=049, loss=0.6482
Epoch=050, loss=0.6447
Epoch=051, loss=0.6405
Epoch=052, loss=0.6377
Epoch=053, loss=0.6343
Epoch=054, loss=0.6319
Epoch=055, loss=0.6273
Epoch=056, loss=0.6233
Epoch=057, loss=0.6209
Epoch=058, loss=0.6147
Epoch=059, loss=0.6138
Epoch=060, loss=0.6083
Epoch=061, loss=0.6041
Epoch=062, loss=0.5992
Epoch=063, loss=0.5937
Epoch=064, loss=0.5899
Epoch=065, loss=0.5849
Epoch=066, loss=0.5800
Epoch=067, loss=0.5751
Epoch=068, loss=0.5698
Epoch=069, loss=0.5635
Epoch=070, loss=0.5572
Epoch=071, loss=0.5531
Epoch=072, loss=0.5452
Epoch=073, loss=0.5418
Epoch=074, loss=0.5378
Epoch=075, loss=0.5294
Epoch=076, loss=0.5271
Epoch=077, loss=0.5163
Epoch=078, loss=0.5109
Epoch=079, loss=0.5036
Epoch=080, loss=0.4977
Epoch=081, loss=0.4907
Epoch=082, loss=0.4882
Epoch=083, loss=0.4781
Epoch=084, loss=0.4688
Epoch=085, loss=0.4653
Epoch=086, loss=0.4570
Epoch=087, loss=0.4468
Epoch=088, loss=0.4479
Epoch=089, loss=0.4377
Epoch=090, loss=0.4314
Epoch=091, loss=0.4308
Epoch=092, loss=0.4168
Epoch=093, loss=0.4092
Epoch=094, loss=0.4033
Epoch=095, loss=0.3956
Epoch=096, loss=0.3952
Epoch=097, loss=0.3824
Epoch=098, loss=0.3704
Epoch=099, loss=0.3634
Epoch=100, loss=0.3603
Epoch=101, loss=0.3574
Epoch=102, loss=0.3495
Epoch=103, loss=0.3463
Epoch=104, loss=0.3355
Epoch=105, loss=0.3305
Epoch=106, loss=0.3276
Epoch=107, loss=0.3172
Epoch=108, loss=0.3208
Epoch=109, loss=0.3002
Epoch=110, loss=0.2934
Epoch=111, loss=0.2894
Epoch=112, loss=0.2950
Epoch=113, loss=0.2836
Epoch=114, loss=0.2765
Epoch=115, loss=0.2735
Epoch=116, loss=0.2741
Epoch=117, loss=0.2662
Epoch=118, loss=0.2575
Epoch=119, loss=0.2516
Epoch=120, loss=0.2494
Epoch=121, loss=0.2489
Epoch=122, loss=0.2374
Epoch=123, loss=0.2337
Epoch=124, loss=0.2347
Epoch=125, loss=0.2295
Epoch=126, loss=0.2185
Epoch=127, loss=0.2159
Epoch=128, loss=0.2168
Epoch=129, loss=0.2182
Epoch=130, loss=0.2107
Epoch=131, loss=0.2063
Epoch=132, loss=0.2084
Epoch=133, loss=0.1940
Epoch=134, loss=0.1892
Epoch=135, loss=0.1837
Epoch=136, loss=0.1865
Epoch=137, loss=0.1855
Epoch=138, loss=0.1841
Epoch=139, loss=0.1834
Epoch=140, loss=0.1807
Epoch=141, loss=0.1743
Epoch=142, loss=0.1664
Epoch=143, loss=0.1722
Epoch=144, loss=0.1652
Epoch=145, loss=0.1645
Epoch=146, loss=0.1635
Epoch=147, loss=0.1646
Epoch=148, loss=0.1564
Epoch=149, loss=0.1560
Epoch=150, loss=0.1485
Epoch=151, loss=0.1503
Epoch=152, loss=0.1423
Epoch=153, loss=0.1446
Epoch=154, loss=0.1467
Epoch=155, loss=0.1386
Epoch=156, loss=0.1438
Epoch=157, loss=0.1382
Epoch=158, loss=0.1403
Epoch=159, loss=0.1388
Epoch=160, loss=0.1453
Epoch=161, loss=0.1285
Epoch=162, loss=0.1325
Epoch=163, loss=0.1193
Epoch=164, loss=0.1263
Epoch=165, loss=0.1203
Epoch=166, loss=0.1221
Epoch=167, loss=0.1197
Epoch=168, loss=0.1198
Epoch=169, loss=0.1253
Epoch=170, loss=0.1120
Epoch=171, loss=0.1176
Epoch=172, loss=0.1307
Epoch=173, loss=0.1165
Epoch=174, loss=0.1268
Epoch=175, loss=0.1176
Epoch=176, loss=0.1067
Epoch=177, loss=0.1174
Epoch=178, loss=0.1137
Epoch=179, loss=0.1075
Epoch=180, loss=0.1050
Epoch=181, loss=0.1090
Epoch=182, loss=0.1083
Epoch=183, loss=0.1061
Epoch=184, loss=0.1012
Epoch=185, loss=0.1040
Epoch=186, loss=0.1021
Epoch=187, loss=0.1025
Epoch=188, loss=0.0954
Epoch=189, loss=0.1051
Epoch=190, loss=0.0994
Epoch=191, loss=0.0990
Epoch=192, loss=0.1033
Epoch=193, loss=0.0967
Epoch=194, loss=0.0991
Epoch=195, loss=0.1041
Epoch=196, loss=0.0888
Epoch=197, loss=0.0951
Epoch=198, loss=0.0859
Epoch=199, loss=0.0956
Epoch=200, loss=0.0972
Epoch=201, loss=0.0850
Epoch=202, loss=0.0883
Epoch=203, loss=0.0838
Epoch=204, loss=0.0822
Epoch=205, loss=0.0837
Epoch=206, loss=0.0898
Epoch=207, loss=0.0801
Epoch=208, loss=0.0825
Epoch=209, loss=0.0859
Epoch=210, loss=0.0851
Epoch=211, loss=0.0787
Epoch=212, loss=0.0799
Epoch=213, loss=0.0785
Epoch=214, loss=0.0883
Epoch=215, loss=0.0886
Epoch=216, loss=0.0823
Epoch=217, loss=0.0823
Epoch=218, loss=0.0795
Epoch=219, loss=0.0756
Epoch=220, loss=0.0719
Epoch=221, loss=0.0754
Epoch=222, loss=0.0861
Epoch=223, loss=0.0824
Epoch=224, loss=0.0854
Epoch=225, loss=0.0767
Epoch=226, loss=0.0719
Epoch=227, loss=0.0708
Epoch=228, loss=0.0719
Epoch=229, loss=0.0711
Epoch=230, loss=0.0768
Epoch=231, loss=0.0735
Epoch=232, loss=0.0703
Epoch=233, loss=0.0747
Epoch=234, loss=0.0778
Epoch=235, loss=0.0735
Epoch=236, loss=0.0807
Epoch=237, loss=0.0750
Epoch=238, loss=0.0782
Epoch=239, loss=0.0779
Epoch=240, loss=0.0653
Epoch=241, loss=0.0732
Epoch=242, loss=0.0716
Epoch=243, loss=0.0642
Epoch=244, loss=0.0630
Epoch=245, loss=0.0670
Epoch=246, loss=0.0673
Epoch=247, loss=0.0687
Epoch=248, loss=0.0677
Epoch=249, loss=0.0628
Epoch=250, loss=0.0635
Epoch=251, loss=0.0637
Epoch=252, loss=0.0721
Epoch=253, loss=0.0675
Epoch=254, loss=0.0664
Epoch=255, loss=0.0627
Epoch=256, loss=0.0639
Epoch=257, loss=0.0673
Epoch=258, loss=0.0750
Epoch=259, loss=0.0647
Epoch=260, loss=0.0686
Epoch=261, loss=0.0664
Epoch=262, loss=0.0670
Epoch=263, loss=0.0566
Epoch=264, loss=0.0589
Epoch=265, loss=0.0631
Epoch=266, loss=0.0551
Epoch=267, loss=0.0594
Epoch=268, loss=0.0640
Epoch=269, loss=0.0619
Epoch=270, loss=0.0587
Epoch=271, loss=0.0624
Epoch=272, loss=0.0575
Epoch=273, loss=0.0571
Epoch=274, loss=0.0582
Epoch=275, loss=0.0621
Epoch=276, loss=0.0539
Epoch=277, loss=0.0634
Epoch=278, loss=0.0564
Epoch=279, loss=0.0579
Epoch=280, loss=0.0603
Epoch=281, loss=0.0561
Epoch=282, loss=0.0604
Epoch=283, loss=0.0553
Epoch=284, loss=0.0524
Epoch=285, loss=0.0668
Epoch=286, loss=0.0579
Epoch=287, loss=0.0641
Epoch=288, loss=0.0544
Epoch=289, loss=0.0519
Epoch=290, loss=0.0463
Epoch=291, loss=0.0555
Epoch=292, loss=0.0492
Epoch=293, loss=0.0544
Epoch=294, loss=0.0533
Epoch=295, loss=0.0491
Epoch=296, loss=0.0462
Epoch=297, loss=0.0653
Epoch=298, loss=0.0476
Epoch=299, loss=0.0520
Epoch=300, loss=0.0500
Epoch=301, loss=0.0617
Epoch=302, loss=0.0559
Epoch=303, loss=0.0533
Epoch=304, loss=0.0495
Epoch=305, loss=0.0501
Epoch=306, loss=0.0523
Epoch=307, loss=0.0446
Epoch=308, loss=0.0502
Epoch=309, loss=0.0564
Epoch=310, loss=0.0470
Epoch=311, loss=0.0480
Epoch=312, loss=0.0488
Epoch=313, loss=0.0389
Epoch=314, loss=0.0463
Epoch=315, loss=0.0512
Epoch=316, loss=0.0397
Epoch=317, loss=0.0465
Epoch=318, loss=0.0450
Epoch=319, loss=0.0413
Epoch=320, loss=0.0579
Epoch=321, loss=0.0464
Epoch=322, loss=0.0508
Epoch=323, loss=0.0490
Epoch=324, loss=0.0467
Epoch=325, loss=0.0457
Epoch=326, loss=0.0520
Epoch=327, loss=0.0448
Epoch=328, loss=0.0483
Epoch=329, loss=0.0437
Epoch=330, loss=0.0514
Epoch=331, loss=0.0484
Epoch=332, loss=0.0499
Epoch=333, loss=0.0417
Early stopping!
Loading 313th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7765+-0.0188, F1Ma=0.7327+-0.0340, acc=0.7765+-0.0188
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7750462910006005, 0.7888659356120821, 0.789620457352311, 0.8088043715245196, 0.7928571701049805, 0.75, 0.7277562618255615, 0.8071428537368774, 0.7459999918937683, 0.7258220314979553, 0.7765254566653712, 0.01880365906158857, 0.732724467311201, 0.0339654146542452, 0.7765254566653712, 0.01880365906158857]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6924
Epoch=005, loss=0.6921
Epoch=006, loss=0.6918
Epoch=007, loss=0.6914
Epoch=008, loss=0.6909
Epoch=009, loss=0.6904
Epoch=010, loss=0.6897
Epoch=011, loss=0.6890
Epoch=012, loss=0.6881
Epoch=013, loss=0.6871
Epoch=014, loss=0.6859
Epoch=015, loss=0.6847
Epoch=016, loss=0.6832
Epoch=017, loss=0.6816
Epoch=018, loss=0.6797
Epoch=019, loss=0.6779
Epoch=020, loss=0.6757
Epoch=021, loss=0.6729
Epoch=022, loss=0.6702
Epoch=023, loss=0.6676
Epoch=024, loss=0.6641
Epoch=025, loss=0.6598
Epoch=026, loss=0.6562
Epoch=027, loss=0.6522
Epoch=028, loss=0.6472
Epoch=029, loss=0.6426
Epoch=030, loss=0.6368
Epoch=031, loss=0.6304
Epoch=032, loss=0.6246
Epoch=033, loss=0.6182
Epoch=034, loss=0.6112
Epoch=035, loss=0.6036
Epoch=036, loss=0.5943
Epoch=037, loss=0.5873
Epoch=038, loss=0.5766
Epoch=039, loss=0.5672
Epoch=040, loss=0.5585
Epoch=041, loss=0.5470
Epoch=042, loss=0.5365
Epoch=043, loss=0.5248
Epoch=044, loss=0.5137
Epoch=045, loss=0.5016
Epoch=046, loss=0.4891
Epoch=047, loss=0.4814
Epoch=048, loss=0.4645
Epoch=049, loss=0.4542
Epoch=050, loss=0.4440
Epoch=051, loss=0.4273
Epoch=052, loss=0.4151
Epoch=053, loss=0.3996
Epoch=054, loss=0.3901
Epoch=055, loss=0.3722
Epoch=056, loss=0.3586
Epoch=057, loss=0.3505
Epoch=058, loss=0.3415
Epoch=059, loss=0.3260
Epoch=060, loss=0.3127
Epoch=061, loss=0.2969
Epoch=062, loss=0.2901
Epoch=063, loss=0.2781
Epoch=064, loss=0.2643
Epoch=065, loss=0.2622
Epoch=066, loss=0.2436
Epoch=067, loss=0.2446
Epoch=068, loss=0.2258
Epoch=069, loss=0.2207
Epoch=070, loss=0.2115
Epoch=071, loss=0.2053
Epoch=072, loss=0.1964
Epoch=073, loss=0.1943
Epoch=074, loss=0.1874
Epoch=075, loss=0.1784
Epoch=076, loss=0.1788
Epoch=077, loss=0.1693
Epoch=078, loss=0.1671
Epoch=079, loss=0.1587
Epoch=080, loss=0.1590
Epoch=081, loss=0.1429
Epoch=082, loss=0.1438
Epoch=083, loss=0.1396
Epoch=084, loss=0.1315
Epoch=085, loss=0.1341
Epoch=086, loss=0.1306
Epoch=087, loss=0.1314
Epoch=088, loss=0.1233
Epoch=089, loss=0.1259
Epoch=090, loss=0.1217
Epoch=091, loss=0.1233
Epoch=092, loss=0.1111
Epoch=093, loss=0.1119
Epoch=094, loss=0.1051
Epoch=095, loss=0.1119
Epoch=096, loss=0.1040
Epoch=097, loss=0.1082
Epoch=098, loss=0.1021
Epoch=099, loss=0.0972
Epoch=100, loss=0.1070
Epoch=101, loss=0.0867
Epoch=102, loss=0.0947
Epoch=103, loss=0.0975
Epoch=104, loss=0.0815
Epoch=105, loss=0.0878
Epoch=106, loss=0.0941
Epoch=107, loss=0.1019
Epoch=108, loss=0.0913
Epoch=109, loss=0.0750
Epoch=110, loss=0.0800
Epoch=111, loss=0.0855
Epoch=112, loss=0.0830
Epoch=113, loss=0.0852
Epoch=114, loss=0.0792
Epoch=115, loss=0.0798
Epoch=116, loss=0.0731
Epoch=117, loss=0.0778
Epoch=118, loss=0.0735
Epoch=119, loss=0.0647
Epoch=120, loss=0.0729
Epoch=121, loss=0.0711
Epoch=122, loss=0.0712
Epoch=123, loss=0.0759
Epoch=124, loss=0.0660
Epoch=125, loss=0.0706
Epoch=126, loss=0.0651
Epoch=127, loss=0.0654
Epoch=128, loss=0.0667
Epoch=129, loss=0.0586
Epoch=130, loss=0.0655
Epoch=131, loss=0.0641
Epoch=132, loss=0.0686
Epoch=133, loss=0.0549
Epoch=134, loss=0.0627
Epoch=135, loss=0.0563
Epoch=136, loss=0.0592
Epoch=137, loss=0.0605
Epoch=138, loss=0.0718
Epoch=139, loss=0.0605
Epoch=140, loss=0.0675
Epoch=141, loss=0.0567
Epoch=142, loss=0.0643
Epoch=143, loss=0.0653
Epoch=144, loss=0.0615
Epoch=145, loss=0.0566
Epoch=146, loss=0.0566
Epoch=147, loss=0.0652
Epoch=148, loss=0.0705
Epoch=149, loss=0.0614
Epoch=150, loss=0.0595
Epoch=151, loss=0.0646
Epoch=152, loss=0.0515
Epoch=153, loss=0.0503
Epoch=154, loss=0.0526
Epoch=155, loss=0.0593
Epoch=156, loss=0.0636
Epoch=157, loss=0.0589
Epoch=158, loss=0.0535
Epoch=159, loss=0.0500
Epoch=160, loss=0.0614
Epoch=161, loss=0.0611
Epoch=162, loss=0.0538
Epoch=163, loss=0.0568
Epoch=164, loss=0.0597
Epoch=165, loss=0.0562
Epoch=166, loss=0.0484
Epoch=167, loss=0.0461
Epoch=168, loss=0.0463
Epoch=169, loss=0.0516
Epoch=170, loss=0.0559
Epoch=171, loss=0.0596
Epoch=172, loss=0.0441
Epoch=173, loss=0.0533
Epoch=174, loss=0.0523
Epoch=175, loss=0.0466
Epoch=176, loss=0.0411
Epoch=177, loss=0.0489
Epoch=178, loss=0.0529
Epoch=179, loss=0.0495
Epoch=180, loss=0.0492
Epoch=181, loss=0.0440
Epoch=182, loss=0.0450
Epoch=183, loss=0.0559
Epoch=184, loss=0.0491
Epoch=185, loss=0.0494
Epoch=186, loss=0.0437
Epoch=187, loss=0.0432
Epoch=188, loss=0.0408
Epoch=189, loss=0.0472
Epoch=190, loss=0.0431
Epoch=191, loss=0.0554
Epoch=192, loss=0.0478
Epoch=193, loss=0.0471
Epoch=194, loss=0.0437
Epoch=195, loss=0.0444
Epoch=196, loss=0.0390
Epoch=197, loss=0.0413
Epoch=198, loss=0.0378
Epoch=199, loss=0.0383
Epoch=200, loss=0.0462
Epoch=201, loss=0.0370
Epoch=202, loss=0.0425
Epoch=203, loss=0.0351
Epoch=204, loss=0.0362
Epoch=205, loss=0.0341
Epoch=206, loss=0.0456
Epoch=207, loss=0.0317
Epoch=208, loss=0.0379
Epoch=209, loss=0.0317
Epoch=210, loss=0.0383
Epoch=211, loss=0.0341
Epoch=212, loss=0.0306
Epoch=213, loss=0.0345
Epoch=214, loss=0.0376
Epoch=215, loss=0.0393
Epoch=216, loss=0.0399
Epoch=217, loss=0.0378
Epoch=218, loss=0.0329
Epoch=219, loss=0.0381
Epoch=220, loss=0.0396
Epoch=221, loss=0.0332
Epoch=222, loss=0.0377
Epoch=223, loss=0.0284
Epoch=224, loss=0.0402
Epoch=225, loss=0.0408
Epoch=226, loss=0.0435
Epoch=227, loss=0.0330
Epoch=228, loss=0.0371
Epoch=229, loss=0.0345
Epoch=230, loss=0.0462
Epoch=231, loss=0.0414
Epoch=232, loss=0.0333
Epoch=233, loss=0.0320
Epoch=234, loss=0.0360
Epoch=235, loss=0.0396
Epoch=236, loss=0.0367
Epoch=237, loss=0.0397
Epoch=238, loss=0.0360
Epoch=239, loss=0.0328
Epoch=240, loss=0.0330
Epoch=241, loss=0.0360
Epoch=242, loss=0.0288
Epoch=243, loss=0.0400
Early stopping!
Loading 223th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7820+-0.0084, F1Ma=0.7516+-0.0115, acc=0.7820+-0.0084
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7750462910006005, 0.7888659356120821, 0.789620457352311, 0.8088043715245196, 0.7928571701049805, 0.75, 0.7277562618255615, 0.8071428537368774, 0.7459999918937683, 0.7258220314979553, 0.7765254566653712, 0.01880365906158857, 0.732724467311201, 0.0339654146542452, 0.7765254566653712, 0.01880365906158857], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7780724087763448, 0.7778637617669651, 0.791570199727072, 0.7998515120386043, 0.8500000238418579, 0.7979999780654907, 0.7567698359489441, 0.8642857074737549, 0.800000011920929, 0.7606382966041565, 0.7819665759813447, 0.008432928942162767, 0.7515999669076999, 0.011501742216137026, 0.7819665759813447, 0.008432928942162778]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6927
Epoch=002, loss=0.6922
Epoch=003, loss=0.6913
Epoch=004, loss=0.6904
Epoch=005, loss=0.6890
Epoch=006, loss=0.6874
Epoch=007, loss=0.6853
Epoch=008, loss=0.6827
Epoch=009, loss=0.6798
Epoch=010, loss=0.6758
Epoch=011, loss=0.6712
Epoch=012, loss=0.6670
Epoch=013, loss=0.6608
Epoch=014, loss=0.6546
Epoch=015, loss=0.6465
Epoch=016, loss=0.6378
Epoch=017, loss=0.6286
Epoch=018, loss=0.6171
Epoch=019, loss=0.6064
Epoch=020, loss=0.5932
Epoch=021, loss=0.5801
Epoch=022, loss=0.5636
Epoch=023, loss=0.5469
Epoch=024, loss=0.5307
Epoch=025, loss=0.5120
Epoch=026, loss=0.4930
Epoch=027, loss=0.4707
Epoch=028, loss=0.4516
Epoch=029, loss=0.4337
Epoch=030, loss=0.4129
Epoch=031, loss=0.3940
Epoch=032, loss=0.3753
Epoch=033, loss=0.3529
Epoch=034, loss=0.3340
Epoch=035, loss=0.3185
Epoch=036, loss=0.3004
Epoch=037, loss=0.2752
Epoch=038, loss=0.2628
Epoch=039, loss=0.2468
Epoch=040, loss=0.2376
Epoch=041, loss=0.2216
Epoch=042, loss=0.2089
Epoch=043, loss=0.1950
Epoch=044, loss=0.1851
Epoch=045, loss=0.1638
Epoch=046, loss=0.1603
Epoch=047, loss=0.1579
Epoch=048, loss=0.1540
Epoch=049, loss=0.1446
Epoch=050, loss=0.1363
Epoch=051, loss=0.1353
Epoch=052, loss=0.1156
Epoch=053, loss=0.1156
Epoch=054, loss=0.1298
Epoch=055, loss=0.1075
Epoch=056, loss=0.1110
Epoch=057, loss=0.1025
Epoch=058, loss=0.1145
Epoch=059, loss=0.1076
Epoch=060, loss=0.1028
Epoch=061, loss=0.0870
Epoch=062, loss=0.0955
Epoch=063, loss=0.0969
Epoch=064, loss=0.0938
Epoch=065, loss=0.0930
Epoch=066, loss=0.0993
Epoch=067, loss=0.0750
Epoch=068, loss=0.0918
Epoch=069, loss=0.0870
Epoch=070, loss=0.0874
Epoch=071, loss=0.0887
Epoch=072, loss=0.0755
Epoch=073, loss=0.0754
Epoch=074, loss=0.0778
Epoch=075, loss=0.0718
Epoch=076, loss=0.0718
Epoch=077, loss=0.0775
Epoch=078, loss=0.0636
Epoch=079, loss=0.0719
Epoch=080, loss=0.0620
Epoch=081, loss=0.0733
Epoch=082, loss=0.0581
Epoch=083, loss=0.0739
Epoch=084, loss=0.0580
Epoch=085, loss=0.0827
Epoch=086, loss=0.0718
Epoch=087, loss=0.0609
Epoch=088, loss=0.0634
Epoch=089, loss=0.0746
Epoch=090, loss=0.0666
Epoch=091, loss=0.0553
Epoch=092, loss=0.0797
Epoch=093, loss=0.0586
Epoch=094, loss=0.0700
Epoch=095, loss=0.0734
Epoch=096, loss=0.0626
Epoch=097, loss=0.0558
Epoch=098, loss=0.0569
Epoch=099, loss=0.0601
Epoch=100, loss=0.0747
Epoch=101, loss=0.0594
Epoch=102, loss=0.0633
Epoch=103, loss=0.0655
Epoch=104, loss=0.0429
Epoch=105, loss=0.0528
Epoch=106, loss=0.0701
Epoch=107, loss=0.0635
Epoch=108, loss=0.0696
Epoch=109, loss=0.0550
Epoch=110, loss=0.0494
Epoch=111, loss=0.0554
Epoch=112, loss=0.0546
Epoch=113, loss=0.0484
Epoch=114, loss=0.0498
Epoch=115, loss=0.0585
Epoch=116, loss=0.0493
Epoch=117, loss=0.0608
Epoch=118, loss=0.0388
Epoch=119, loss=0.0510
Epoch=120, loss=0.0529
Epoch=121, loss=0.0501
Epoch=122, loss=0.0577
Epoch=123, loss=0.0528
Epoch=124, loss=0.0447
Epoch=125, loss=0.0570
Epoch=126, loss=0.0471
Epoch=127, loss=0.0514
Epoch=128, loss=0.0532
Epoch=129, loss=0.0597
Epoch=130, loss=0.0501
Epoch=131, loss=0.0457
Epoch=132, loss=0.0426
Epoch=133, loss=0.0378
Epoch=134, loss=0.0531
Epoch=135, loss=0.0517
Epoch=136, loss=0.0509
Epoch=137, loss=0.0463
Epoch=138, loss=0.0469
Epoch=139, loss=0.0325
Epoch=140, loss=0.0403
Epoch=141, loss=0.0406
Epoch=142, loss=0.0407
Epoch=143, loss=0.0461
Epoch=144, loss=0.0355
Epoch=145, loss=0.0383
Epoch=146, loss=0.0417
Epoch=147, loss=0.0376
Epoch=148, loss=0.0430
Epoch=149, loss=0.0459
Epoch=150, loss=0.0363
Epoch=151, loss=0.0455
Epoch=152, loss=0.0303
Epoch=153, loss=0.0393
Epoch=154, loss=0.0360
Epoch=155, loss=0.0414
Epoch=156, loss=0.0438
Epoch=157, loss=0.0464
Epoch=158, loss=0.0464
Epoch=159, loss=0.0450
Epoch=160, loss=0.0361
Epoch=161, loss=0.0366
Epoch=162, loss=0.0305
Epoch=163, loss=0.0392
Epoch=164, loss=0.0362
Epoch=165, loss=0.0318
Epoch=166, loss=0.0436
Epoch=167, loss=0.0449
Epoch=168, loss=0.0472
Epoch=169, loss=0.0405
Epoch=170, loss=0.0318
Epoch=171, loss=0.0335
Epoch=172, loss=0.0380
Early stopping!
Loading 152th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8094+-0.0112, F1Ma=0.7889+-0.0110, acc=0.8094+-0.0112
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7750462910006005, 0.7888659356120821, 0.789620457352311, 0.8088043715245196, 0.7928571701049805, 0.75, 0.7277562618255615, 0.8071428537368774, 0.7459999918937683, 0.7258220314979553, 0.7765254566653712, 0.01880365906158857, 0.732724467311201, 0.0339654146542452, 0.7765254566653712, 0.01880365906158857], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7780724087763448, 0.7778637617669651, 0.791570199727072, 0.7998515120386043, 0.8500000238418579, 0.7979999780654907, 0.7567698359489441, 0.8642857074737549, 0.800000011920929, 0.7606382966041565, 0.7819665759813447, 0.008432928942162767, 0.7515999669076999, 0.011501742216137026, 0.7819665759813447, 0.008432928942162778], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7742413617934615, 0.772128262020954, 0.7819457096666175, 0.7877850807400211, 0.9285714030265808, 0.8100000023841858, 0.7640231847763062, 0.9285714030265808, 0.8059999942779541, 0.7654739022254944, 0.80940536338904, 0.011185059901285018, 0.7889469382851293, 0.010997748103694737, 0.80940536338904, 0.011185059901285066]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6916
Epoch=002, loss=0.6889
Epoch=003, loss=0.6852
Epoch=004, loss=0.6800
Epoch=005, loss=0.6740
Epoch=006, loss=0.6656
Epoch=007, loss=0.6560
Epoch=008, loss=0.6433
Epoch=009, loss=0.6303
Epoch=010, loss=0.6153
Epoch=011, loss=0.5964
Epoch=012, loss=0.5759
Epoch=013, loss=0.5610
Epoch=014, loss=0.5304
Epoch=015, loss=0.5043
Epoch=016, loss=0.4851
Epoch=017, loss=0.4496
Epoch=018, loss=0.4286
Epoch=019, loss=0.4008
Epoch=020, loss=0.3662
Epoch=021, loss=0.3467
Epoch=022, loss=0.3250
Epoch=023, loss=0.2970
Epoch=024, loss=0.2792
Epoch=025, loss=0.2644
Epoch=026, loss=0.2407
Epoch=027, loss=0.2207
Epoch=028, loss=0.2067
Epoch=029, loss=0.2064
Epoch=030, loss=0.2012
Epoch=031, loss=0.1546
Epoch=032, loss=0.1666
Epoch=033, loss=0.1394
Epoch=034, loss=0.1596
Epoch=035, loss=0.1415
Epoch=036, loss=0.1395
Epoch=037, loss=0.1328
Epoch=038, loss=0.1278
Epoch=039, loss=0.1288
Epoch=040, loss=0.1176
Epoch=041, loss=0.1196
Epoch=042, loss=0.0966
Epoch=043, loss=0.1023
Epoch=044, loss=0.1003
Epoch=045, loss=0.1137
Epoch=046, loss=0.1175
Epoch=047, loss=0.0953
Epoch=048, loss=0.0863
Epoch=049, loss=0.0977
Epoch=050, loss=0.0973
Epoch=051, loss=0.0985
Epoch=052, loss=0.0929
Epoch=053, loss=0.0818
Epoch=054, loss=0.0916
Epoch=055, loss=0.0886
Epoch=056, loss=0.0854
Epoch=057, loss=0.0709
Epoch=058, loss=0.0717
Epoch=059, loss=0.0803
Epoch=060, loss=0.0688
Epoch=061, loss=0.0891
Epoch=062, loss=0.0685
Epoch=063, loss=0.0826
Epoch=064, loss=0.0740
Epoch=065, loss=0.0688
Epoch=066, loss=0.0675
Epoch=067, loss=0.0746
Epoch=068, loss=0.0567
Epoch=069, loss=0.0663
Epoch=070, loss=0.0597
Epoch=071, loss=0.0712
Epoch=072, loss=0.0694
Epoch=073, loss=0.0723
Epoch=074, loss=0.0571
Epoch=075, loss=0.0548
Epoch=076, loss=0.0651
Epoch=077, loss=0.0686
Epoch=078, loss=0.0499
Epoch=079, loss=0.0598
Epoch=080, loss=0.0561
Epoch=081, loss=0.0558
Epoch=082, loss=0.0551
Epoch=083, loss=0.0601
Epoch=084, loss=0.0550
Epoch=085, loss=0.0620
Epoch=086, loss=0.0513
Epoch=087, loss=0.0511
Epoch=088, loss=0.0505
Epoch=089, loss=0.0506
Epoch=090, loss=0.0450
Epoch=091, loss=0.0435
Epoch=092, loss=0.0544
Epoch=093, loss=0.0561
Epoch=094, loss=0.0462
Epoch=095, loss=0.0408
Epoch=096, loss=0.0444
Epoch=097, loss=0.0493
Epoch=098, loss=0.0341
Epoch=099, loss=0.0485
Epoch=100, loss=0.0462
Epoch=101, loss=0.0560
Epoch=102, loss=0.0447
Epoch=103, loss=0.0344
Epoch=104, loss=0.0403
Epoch=105, loss=0.0472
Epoch=106, loss=0.0342
Epoch=107, loss=0.0467
Epoch=108, loss=0.0424
Epoch=109, loss=0.0480
Epoch=110, loss=0.0441
Epoch=111, loss=0.0533
Epoch=112, loss=0.0470
Epoch=113, loss=0.0441
Epoch=114, loss=0.0334
Epoch=115, loss=0.0316
Epoch=116, loss=0.0398
Epoch=117, loss=0.0355
Epoch=118, loss=0.0325
Epoch=119, loss=0.0432
Epoch=120, loss=0.0390
Epoch=121, loss=0.0520
Epoch=122, loss=0.0260
Epoch=123, loss=0.0396
Epoch=124, loss=0.0351
Epoch=125, loss=0.0514
Epoch=126, loss=0.0429
Epoch=127, loss=0.0319
Epoch=128, loss=0.0395
Epoch=129, loss=0.0271
Epoch=130, loss=0.0373
Epoch=131, loss=0.0308
Epoch=132, loss=0.0304
Epoch=133, loss=0.0318
Epoch=134, loss=0.0342
Epoch=135, loss=0.0294
Epoch=136, loss=0.0411
Epoch=137, loss=0.0261
Epoch=138, loss=0.0416
Epoch=139, loss=0.0315
Epoch=140, loss=0.0300
Epoch=141, loss=0.0473
Epoch=142, loss=0.0237
Epoch=143, loss=0.0324
Epoch=144, loss=0.0400
Epoch=145, loss=0.0305
Epoch=146, loss=0.0383
Epoch=147, loss=0.0295
Epoch=148, loss=0.0276
Epoch=149, loss=0.0255
Epoch=150, loss=0.0261
Epoch=151, loss=0.0384
Epoch=152, loss=0.0313
Epoch=153, loss=0.0307
Epoch=154, loss=0.0287
Epoch=155, loss=0.0283
Epoch=156, loss=0.0248
Epoch=157, loss=0.0285
Epoch=158, loss=0.0276
Epoch=159, loss=0.0273
Epoch=160, loss=0.0312
Epoch=161, loss=0.0213
Epoch=162, loss=0.0292
Epoch=163, loss=0.0253
Epoch=164, loss=0.0210
Epoch=165, loss=0.0230
Epoch=166, loss=0.0224
Epoch=167, loss=0.0200
Epoch=168, loss=0.0282
Epoch=169, loss=0.0225
Epoch=170, loss=0.0275
Epoch=171, loss=0.0240
Epoch=172, loss=0.0183
Epoch=173, loss=0.0209
Epoch=174, loss=0.0250
Epoch=175, loss=0.0239
Epoch=176, loss=0.0205
Epoch=177, loss=0.0164
Epoch=178, loss=0.0247
Epoch=179, loss=0.0187
Epoch=180, loss=0.0350
Epoch=181, loss=0.0216
Epoch=182, loss=0.0235
Epoch=183, loss=0.0214
Epoch=184, loss=0.0235
Epoch=185, loss=0.0214
Epoch=186, loss=0.0241
Epoch=187, loss=0.0164
Epoch=188, loss=0.0248
Epoch=189, loss=0.0184
Epoch=190, loss=0.0167
Epoch=191, loss=0.0259
Epoch=192, loss=0.0148
Epoch=193, loss=0.0145
Epoch=194, loss=0.0186
Epoch=195, loss=0.0187
Epoch=196, loss=0.0243
Epoch=197, loss=0.0261
Epoch=198, loss=0.0172
Epoch=199, loss=0.0186
Epoch=200, loss=0.0219
Epoch=201, loss=0.0167
Epoch=202, loss=0.0289
Epoch=203, loss=0.0262
Epoch=204, loss=0.0226
Epoch=205, loss=0.0243
Epoch=206, loss=0.0221
Epoch=207, loss=0.0179
Epoch=208, loss=0.0162
Epoch=209, loss=0.0134
Epoch=210, loss=0.0128
Epoch=211, loss=0.0248
Epoch=212, loss=0.0210
Epoch=213, loss=0.0228
Epoch=214, loss=0.0176
Epoch=215, loss=0.0140
Epoch=216, loss=0.0168
Epoch=217, loss=0.0135
Epoch=218, loss=0.0225
Epoch=219, loss=0.0136
Epoch=220, loss=0.0194
Epoch=221, loss=0.0119
Epoch=222, loss=0.0232
Epoch=223, loss=0.0129
Epoch=224, loss=0.0153
Epoch=225, loss=0.0194
Epoch=226, loss=0.0110
Epoch=227, loss=0.0223
Epoch=228, loss=0.0164
Epoch=229, loss=0.0085
Epoch=230, loss=0.0140
Epoch=231, loss=0.0129
Epoch=232, loss=0.0206
Epoch=233, loss=0.0153
Epoch=234, loss=0.0155
Epoch=235, loss=0.0093
Epoch=236, loss=0.0159
Epoch=237, loss=0.0198
Epoch=238, loss=0.0173
Epoch=239, loss=0.0087
Epoch=240, loss=0.0210
Epoch=241, loss=0.0095
Epoch=242, loss=0.0169
Epoch=243, loss=0.0255
Epoch=244, loss=0.0121
Epoch=245, loss=0.0089
Epoch=246, loss=0.0152
Epoch=247, loss=0.0186
Epoch=248, loss=0.0127
Epoch=249, loss=0.0197
Early stopping!
Loading 229th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8060+-0.0100, F1Ma=0.7846+-0.0162, acc=0.8060+-0.0100
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7750462910006005, 0.7888659356120821, 0.789620457352311, 0.8088043715245196, 0.7928571701049805, 0.75, 0.7277562618255615, 0.8071428537368774, 0.7459999918937683, 0.7258220314979553, 0.7765254566653712, 0.01880365906158857, 0.732724467311201, 0.0339654146542452, 0.7765254566653712, 0.01880365906158857], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7780724087763448, 0.7778637617669651, 0.791570199727072, 0.7998515120386043, 0.8500000238418579, 0.7979999780654907, 0.7567698359489441, 0.8642857074737549, 0.800000011920929, 0.7606382966041565, 0.7819665759813447, 0.008432928942162767, 0.7515999669076999, 0.011501742216137026, 0.7819665759813447, 0.008432928942162778], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7742413617934615, 0.772128262020954, 0.7819457096666175, 0.7877850807400211, 0.9285714030265808, 0.8100000023841858, 0.7640231847763062, 0.9285714030265808, 0.8059999942779541, 0.7654739022254944, 0.80940536338904, 0.011185059901285018, 0.7889469382851293, 0.010997748103694737, 0.80940536338904, 0.011185059901285066], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7685777641148828, 0.7804419861978129, 0.782698241811262, 0.8006515517013103, 0.9642857313156128, 0.8080000281333923, 0.780464231967926, 0.9642857313156128, 0.8100000023841858, 0.780464231967926, 0.8059852312475708, 0.009994916634253967, 0.7846370764362177, 0.016212256150106866, 0.8059852312475708, 0.009994916634253967]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6914
Epoch=002, loss=0.6868
Epoch=003, loss=0.6765
Epoch=004, loss=0.6709
Epoch=005, loss=0.6541
Epoch=006, loss=0.6435
Epoch=007, loss=0.6296
Epoch=008, loss=0.6035
Epoch=009, loss=0.5885
Epoch=010, loss=0.5688
Epoch=011, loss=0.5287
Epoch=012, loss=0.5071
Epoch=013, loss=0.4900
Epoch=014, loss=0.4461
Epoch=015, loss=0.4127
Epoch=016, loss=0.4050
Epoch=017, loss=0.3563
Epoch=018, loss=0.3296
Epoch=019, loss=0.3035
Epoch=020, loss=0.2749
Epoch=021, loss=0.2633
Epoch=022, loss=0.2169
Epoch=023, loss=0.2372
Epoch=024, loss=0.1921
Epoch=025, loss=0.1618
Epoch=026, loss=0.1508
Epoch=027, loss=0.1648
Epoch=028, loss=0.1287
Epoch=029, loss=0.1307
Epoch=030, loss=0.1341
Epoch=031, loss=0.0991
Epoch=032, loss=0.0968
Epoch=033, loss=0.0999
Epoch=034, loss=0.0851
Epoch=035, loss=0.0841
Epoch=036, loss=0.0825
Epoch=037, loss=0.0745
Epoch=038, loss=0.0766
Epoch=039, loss=0.0679
Epoch=040, loss=0.0559
Epoch=041, loss=0.0596
Epoch=042, loss=0.0569
Epoch=043, loss=0.0620
Epoch=044, loss=0.0558
Epoch=045, loss=0.0444
Epoch=046, loss=0.0488
Epoch=047, loss=0.0539
Epoch=048, loss=0.0480
Epoch=049, loss=0.0436
Epoch=050, loss=0.0408
Epoch=051, loss=0.0480
Epoch=052, loss=0.0415
Epoch=053, loss=0.0338
Epoch=054, loss=0.0254
Epoch=055, loss=0.0348
Epoch=056, loss=0.0371
Epoch=057, loss=0.0286
Epoch=058, loss=0.0300
Epoch=059, loss=0.0235
Epoch=060, loss=0.0237
Epoch=061, loss=0.0320
Epoch=062, loss=0.0307
Epoch=063, loss=0.0273
Epoch=064, loss=0.0307
Epoch=065, loss=0.0212
Epoch=066, loss=0.0210
Epoch=067, loss=0.0203
Epoch=068, loss=0.0221
Epoch=069, loss=0.0169
Epoch=070, loss=0.0187
Epoch=071, loss=0.0232
Epoch=072, loss=0.0197
Epoch=073, loss=0.0209
Epoch=074, loss=0.0206
Epoch=075, loss=0.0192
Epoch=076, loss=0.0116
Epoch=077, loss=0.0188
Epoch=078, loss=0.0270
Epoch=079, loss=0.0124
Epoch=080, loss=0.0136
Epoch=081, loss=0.0118
Epoch=082, loss=0.0143
Epoch=083, loss=0.0167
Epoch=084, loss=0.0184
Epoch=085, loss=0.0137
Epoch=086, loss=0.0105
Epoch=087, loss=0.0180
Epoch=088, loss=0.0115
Epoch=089, loss=0.0201
Epoch=090, loss=0.0146
Epoch=091, loss=0.0085
Epoch=092, loss=0.0093
Epoch=093, loss=0.0150
Epoch=094, loss=0.0100
Epoch=095, loss=0.0174
Epoch=096, loss=0.0124
Epoch=097, loss=0.0180
Epoch=098, loss=0.0158
Epoch=099, loss=0.0097
Epoch=100, loss=0.0132
Epoch=101, loss=0.0090
Epoch=102, loss=0.0155
Epoch=103, loss=0.0127
Epoch=104, loss=0.0164
Epoch=105, loss=0.0081
Epoch=106, loss=0.0058
Epoch=107, loss=0.0109
Epoch=108, loss=0.0074
Epoch=109, loss=0.0121
Epoch=110, loss=0.0209
Epoch=111, loss=0.0067
Epoch=112, loss=0.0061
Epoch=113, loss=0.0066
Epoch=114, loss=0.0080
Epoch=115, loss=0.0105
Epoch=116, loss=0.0133
Epoch=117, loss=0.0121
Epoch=118, loss=0.0094
Epoch=119, loss=0.0080
Epoch=120, loss=0.0093
Epoch=121, loss=0.0056
Epoch=122, loss=0.0064
Epoch=123, loss=0.0138
Epoch=124, loss=0.0103
Epoch=125, loss=0.0062
Epoch=126, loss=0.0088
Epoch=127, loss=0.0060
Epoch=128, loss=0.0044
Epoch=129, loss=0.0107
Epoch=130, loss=0.0054
Epoch=131, loss=0.0115
Epoch=132, loss=0.0087
Epoch=133, loss=0.0066
Epoch=134, loss=0.0075
Epoch=135, loss=0.0056
Epoch=136, loss=0.0042
Epoch=137, loss=0.0082
Epoch=138, loss=0.0096
Epoch=139, loss=0.0114
Epoch=140, loss=0.0059
Epoch=141, loss=0.0167
Epoch=142, loss=0.0055
Epoch=143, loss=0.0077
Epoch=144, loss=0.0072
Epoch=145, loss=0.0040
Epoch=146, loss=0.0106
Epoch=147, loss=0.0062
Epoch=148, loss=0.0074
Epoch=149, loss=0.0083
Epoch=150, loss=0.0029
Epoch=151, loss=0.0115
Epoch=152, loss=0.0111
Epoch=153, loss=0.0055
Epoch=154, loss=0.0090
Epoch=155, loss=0.0026
Epoch=156, loss=0.0082
Epoch=157, loss=0.0091
Epoch=158, loss=0.0065
Epoch=159, loss=0.0082
Epoch=160, loss=0.0023
Epoch=161, loss=0.0063
Epoch=162, loss=0.0085
Epoch=163, loss=0.0020
Epoch=164, loss=0.0031
Epoch=165, loss=0.0048
Epoch=166, loss=0.0025
Epoch=167, loss=0.0037
Epoch=168, loss=0.0072
Epoch=169, loss=0.0047
Epoch=170, loss=0.0051
Epoch=171, loss=0.0051
Epoch=172, loss=0.0042
Epoch=173, loss=0.0023
Epoch=174, loss=0.0042
Epoch=175, loss=0.0042
Epoch=176, loss=0.0031
Epoch=177, loss=0.0046
Epoch=178, loss=0.0033
Epoch=179, loss=0.0038
Epoch=180, loss=0.0069
Epoch=181, loss=0.0023
Epoch=182, loss=0.0047
Epoch=183, loss=0.0044
Early stopping!
Loading 163th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8048+-0.0079, F1Ma=0.7882+-0.0139, acc=0.8048+-0.0079
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7929249488038612, 0.792338720514959, 0.7975166439226729, 0.8022415351298978, 0.7642857432365417, 0.7599999904632568, 0.747582197189331, 0.7714285850524902, 0.7559999823570251, 0.7470986247062683, 0.7319082782743879, 0.01928024246429325, 0.6634797821504391, 0.0334399821641841, 0.7319082782743879, 0.019280242464293277], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7750462910006005, 0.7888659356120821, 0.789620457352311, 0.8088043715245196, 0.7928571701049805, 0.75, 0.7277562618255615, 0.8071428537368774, 0.7459999918937683, 0.7258220314979553, 0.7765254566653712, 0.01880365906158857, 0.732724467311201, 0.0339654146542452, 0.7765254566653712, 0.01880365906158857], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7780724087763448, 0.7778637617669651, 0.791570199727072, 0.7998515120386043, 0.8500000238418579, 0.7979999780654907, 0.7567698359489441, 0.8642857074737549, 0.800000011920929, 0.7606382966041565, 0.7819665759813447, 0.008432928942162767, 0.7515999669076999, 0.011501742216137026, 0.7819665759813447, 0.008432928942162778], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7742413617934615, 0.772128262020954, 0.7819457096666175, 0.7877850807400211, 0.9285714030265808, 0.8100000023841858, 0.7640231847763062, 0.9285714030265808, 0.8059999942779541, 0.7654739022254944, 0.80940536338904, 0.011185059901285018, 0.7889469382851293, 0.010997748103694737, 0.80940536338904, 0.011185059901285066], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7685777641148828, 0.7804419861978129, 0.782698241811262, 0.8006515517013103, 0.9642857313156128, 0.8080000281333923, 0.780464231967926, 0.9642857313156128, 0.8100000023841858, 0.780464231967926, 0.8059852312475708, 0.009994916634253967, 0.7846370764362177, 0.016212256150106866, 0.8059852312475708, 0.009994916634253967], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.917405192813635, 0.9077752809376016, 0.9106143038717598, 0.8945950853767628, 0.9571428298950195, 0.8339999914169312, 0.792553186416626, 0.949999988079071, 0.8339999914169312, 0.7906189560890198, 0.8048192771084336, 0.007851912195366928, 0.7881840487973326, 0.01393885229878336, 0.8048192771084338, 0.00785191219536692]]
