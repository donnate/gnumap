My SLURM_ARRAY_TASK_ID:  12
My SLURM_ARRAY_JOB_ID:  4522289
DGI
Cora
result file is 4522289_12
Found it
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
==============================================================
Number of nodes: 2708
Number of edges: 10556
Average node degree: 3.90
Number of training nodes: 140
Training node label rate: 0.05
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
/scratch/midway3/cdonnat/gnumap/experiments/results/DGI_results_Cora_4522289_12.csv
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6931
Epoch=002, loss=0.6931
Epoch=003, loss=0.6930
Epoch=004, loss=0.6930
Epoch=005, loss=0.6930
Epoch=006, loss=0.6930
Epoch=007, loss=0.6929
Epoch=008, loss=0.6929
Epoch=009, loss=0.6928
Epoch=010, loss=0.6928
Epoch=011, loss=0.6927
Epoch=012, loss=0.6927
Epoch=013, loss=0.6926
Epoch=014, loss=0.6926
Epoch=015, loss=0.6925
Epoch=016, loss=0.6924
Epoch=017, loss=0.6923
Epoch=018, loss=0.6923
Epoch=019, loss=0.6922
Epoch=020, loss=0.6921
Epoch=021, loss=0.6920
Epoch=022, loss=0.6919
Epoch=023, loss=0.6917
Epoch=024, loss=0.6917
Epoch=025, loss=0.6915
Epoch=026, loss=0.6913
Epoch=027, loss=0.6913
Epoch=028, loss=0.6911
Epoch=029, loss=0.6909
Epoch=030, loss=0.6907
Epoch=031, loss=0.6905
Epoch=032, loss=0.6902
Epoch=033, loss=0.6901
Epoch=034, loss=0.6899
Epoch=035, loss=0.6897
Epoch=036, loss=0.6894
Epoch=037, loss=0.6892
Epoch=038, loss=0.6889
Epoch=039, loss=0.6886
Epoch=040, loss=0.6883
Epoch=041, loss=0.6880
Epoch=042, loss=0.6876
Epoch=043, loss=0.6872
Epoch=044, loss=0.6869
Epoch=045, loss=0.6864
Epoch=046, loss=0.6860
Epoch=047, loss=0.6855
Epoch=048, loss=0.6852
Epoch=049, loss=0.6848
Epoch=050, loss=0.6842
Epoch=051, loss=0.6837
Epoch=052, loss=0.6832
Epoch=053, loss=0.6828
Epoch=054, loss=0.6820
Epoch=055, loss=0.6816
Epoch=056, loss=0.6807
Epoch=057, loss=0.6802
Epoch=058, loss=0.6795
Epoch=059, loss=0.6788
Epoch=060, loss=0.6778
Epoch=061, loss=0.6769
Epoch=062, loss=0.6762
Epoch=063, loss=0.6760
Epoch=064, loss=0.6753
Epoch=065, loss=0.6740
Epoch=066, loss=0.6730
Epoch=067, loss=0.6721
Epoch=068, loss=0.6713
Epoch=069, loss=0.6707
Epoch=070, loss=0.6691
Epoch=071, loss=0.6677
Epoch=072, loss=0.6668
Epoch=073, loss=0.6650
Epoch=074, loss=0.6640
Epoch=075, loss=0.6629
Epoch=076, loss=0.6622
Epoch=077, loss=0.6600
Epoch=078, loss=0.6588
Epoch=079, loss=0.6576
Epoch=080, loss=0.6560
Epoch=081, loss=0.6546
Epoch=082, loss=0.6533
Epoch=083, loss=0.6513
Epoch=084, loss=0.6488
Epoch=085, loss=0.6475
Epoch=086, loss=0.6474
Epoch=087, loss=0.6445
Epoch=088, loss=0.6433
Epoch=089, loss=0.6411
Epoch=090, loss=0.6389
Epoch=091, loss=0.6378
Epoch=092, loss=0.6356
Epoch=093, loss=0.6342
Epoch=094, loss=0.6307
Epoch=095, loss=0.6308
Epoch=096, loss=0.6268
Epoch=097, loss=0.6250
Epoch=098, loss=0.6233
Epoch=099, loss=0.6209
Epoch=100, loss=0.6176
Epoch=101, loss=0.6183
Epoch=102, loss=0.6139
Epoch=103, loss=0.6104
Epoch=104, loss=0.6100
Epoch=105, loss=0.6057
Epoch=106, loss=0.6036
Epoch=107, loss=0.6021
Epoch=108, loss=0.5979
Epoch=109, loss=0.5955
Epoch=110, loss=0.5921
Epoch=111, loss=0.5918
Epoch=112, loss=0.5863
Epoch=113, loss=0.5852
Epoch=114, loss=0.5802
Epoch=115, loss=0.5803
Epoch=116, loss=0.5761
Epoch=117, loss=0.5717
Epoch=118, loss=0.5711
Epoch=119, loss=0.5677
Epoch=120, loss=0.5634
Epoch=121, loss=0.5612
Epoch=122, loss=0.5570
Epoch=123, loss=0.5543
Epoch=124, loss=0.5516
Epoch=125, loss=0.5466
Epoch=126, loss=0.5450
Epoch=127, loss=0.5395
Epoch=128, loss=0.5351
Epoch=129, loss=0.5345
Epoch=130, loss=0.5281
Epoch=131, loss=0.5274
Epoch=132, loss=0.5237
Epoch=133, loss=0.5198
Epoch=134, loss=0.5150
Epoch=135, loss=0.5122
Epoch=136, loss=0.5123
Epoch=137, loss=0.5045
Epoch=138, loss=0.4999
Epoch=139, loss=0.4958
Epoch=140, loss=0.4942
Epoch=141, loss=0.4904
Epoch=142, loss=0.4871
Epoch=143, loss=0.4820
Epoch=144, loss=0.4794
Epoch=145, loss=0.4732
Epoch=146, loss=0.4724
Epoch=147, loss=0.4676
Epoch=148, loss=0.4626
Epoch=149, loss=0.4635
Epoch=150, loss=0.4582
Epoch=151, loss=0.4537
Epoch=152, loss=0.4499
Epoch=153, loss=0.4462
Epoch=154, loss=0.4481
Epoch=155, loss=0.4352
Epoch=156, loss=0.4367
Epoch=157, loss=0.4324
Epoch=158, loss=0.4282
Epoch=159, loss=0.4230
Epoch=160, loss=0.4205
Epoch=161, loss=0.4149
Epoch=162, loss=0.4166
Epoch=163, loss=0.4121
Epoch=164, loss=0.4038
Epoch=165, loss=0.4022
Epoch=166, loss=0.3990
Epoch=167, loss=0.3953
Epoch=168, loss=0.3900
Epoch=169, loss=0.3887
Epoch=170, loss=0.3808
Epoch=171, loss=0.3795
Epoch=172, loss=0.3748
Epoch=173, loss=0.3758
Epoch=174, loss=0.3716
Epoch=175, loss=0.3646
Epoch=176, loss=0.3672
Epoch=177, loss=0.3584
Epoch=178, loss=0.3541
Epoch=179, loss=0.3545
Epoch=180, loss=0.3451
Epoch=181, loss=0.3468
Epoch=182, loss=0.3412
Epoch=183, loss=0.3405
Epoch=184, loss=0.3335
Epoch=185, loss=0.3345
Epoch=186, loss=0.3276
Epoch=187, loss=0.3259
Epoch=188, loss=0.3292
Epoch=189, loss=0.3159
Epoch=190, loss=0.3145
Epoch=191, loss=0.3108
Epoch=192, loss=0.3133
Epoch=193, loss=0.3032
Epoch=194, loss=0.3115
Epoch=195, loss=0.3068
Epoch=196, loss=0.2979
Epoch=197, loss=0.2912
Epoch=198, loss=0.2947
Epoch=199, loss=0.2957
Epoch=200, loss=0.2856
Epoch=201, loss=0.2832
Epoch=202, loss=0.2825
Epoch=203, loss=0.2776
Epoch=204, loss=0.2753
Epoch=205, loss=0.2754
Epoch=206, loss=0.2753
Epoch=207, loss=0.2669
Epoch=208, loss=0.2667
Epoch=209, loss=0.2656
Epoch=210, loss=0.2622
Epoch=211, loss=0.2598
Epoch=212, loss=0.2531
Epoch=213, loss=0.2508
Epoch=214, loss=0.2484
Epoch=215, loss=0.2551
Epoch=216, loss=0.2442
Epoch=217, loss=0.2447
Epoch=218, loss=0.2474
Epoch=219, loss=0.2411
Epoch=220, loss=0.2383
Epoch=221, loss=0.2442
Epoch=222, loss=0.2344
Epoch=223, loss=0.2401
Epoch=224, loss=0.2316
Epoch=225, loss=0.2228
Epoch=226, loss=0.2221
Epoch=227, loss=0.2318
Epoch=228, loss=0.2154
Epoch=229, loss=0.2224
Epoch=230, loss=0.2224
Epoch=231, loss=0.2145
Epoch=232, loss=0.2108
Epoch=233, loss=0.2181
Epoch=234, loss=0.2169
Epoch=235, loss=0.2136
Epoch=236, loss=0.1980
Epoch=237, loss=0.2087
Epoch=238, loss=0.1974
Epoch=239, loss=0.2043
Epoch=240, loss=0.2018
Epoch=241, loss=0.1985
Epoch=242, loss=0.1966
Epoch=243, loss=0.1986
Epoch=244, loss=0.1951
Epoch=245, loss=0.1965
Epoch=246, loss=0.1912
Epoch=247, loss=0.1842
Epoch=248, loss=0.1916
Epoch=249, loss=0.1912
Epoch=250, loss=0.1844
Epoch=251, loss=0.1912
Epoch=252, loss=0.1824
Epoch=253, loss=0.1814
Epoch=254, loss=0.1807
Epoch=255, loss=0.1859
Epoch=256, loss=0.1761
Epoch=257, loss=0.1750
Epoch=258, loss=0.1759
Epoch=259, loss=0.1690
Epoch=260, loss=0.1721
Epoch=261, loss=0.1697
Epoch=262, loss=0.1698
Epoch=263, loss=0.1634
Epoch=264, loss=0.1709
Epoch=265, loss=0.1677
Epoch=266, loss=0.1633
Epoch=267, loss=0.1684
Epoch=268, loss=0.1653
Epoch=269, loss=0.1599
Epoch=270, loss=0.1696
Epoch=271, loss=0.1604
Epoch=272, loss=0.1600
Epoch=273, loss=0.1559
Epoch=274, loss=0.1572
Epoch=275, loss=0.1520
Epoch=276, loss=0.1570
Epoch=277, loss=0.1584
Epoch=278, loss=0.1508
Epoch=279, loss=0.1525
Epoch=280, loss=0.1458
Epoch=281, loss=0.1475
Epoch=282, loss=0.1450
Epoch=283, loss=0.1448
Epoch=284, loss=0.1537
Epoch=285, loss=0.1491
Epoch=286, loss=0.1410
Epoch=287, loss=0.1521
Epoch=288, loss=0.1386
Epoch=289, loss=0.1394
Epoch=290, loss=0.1487
Epoch=291, loss=0.1369
Epoch=292, loss=0.1436
Epoch=293, loss=0.1392
Epoch=294, loss=0.1388
Epoch=295, loss=0.1432
Epoch=296, loss=0.1339
Epoch=297, loss=0.1398
Epoch=298, loss=0.1321
Epoch=299, loss=0.1368
Epoch=300, loss=0.1354
Epoch=301, loss=0.1329
Epoch=302, loss=0.1255
Epoch=303, loss=0.1324
Epoch=304, loss=0.1345
Epoch=305, loss=0.1362
Epoch=306, loss=0.1414
Epoch=307, loss=0.1301
Epoch=308, loss=0.1279
Epoch=309, loss=0.1208
Epoch=310, loss=0.1277
Epoch=311, loss=0.1275
Epoch=312, loss=0.1254
Epoch=313, loss=0.1277
Epoch=314, loss=0.1328
Epoch=315, loss=0.1246
Epoch=316, loss=0.1194
Epoch=317, loss=0.1230
Epoch=318, loss=0.1130
Epoch=319, loss=0.1191
Epoch=320, loss=0.1180
Epoch=321, loss=0.1210
Epoch=322, loss=0.1193
Epoch=323, loss=0.1213
Epoch=324, loss=0.1189
Epoch=325, loss=0.1137
Epoch=326, loss=0.1228
Epoch=327, loss=0.1199
Epoch=328, loss=0.1204
Epoch=329, loss=0.1160
Epoch=330, loss=0.1131
Epoch=331, loss=0.1213
Epoch=332, loss=0.1233
Epoch=333, loss=0.1161
Epoch=334, loss=0.1114
Epoch=335, loss=0.1086
Epoch=336, loss=0.1127
Epoch=337, loss=0.1084
Epoch=338, loss=0.1008
Epoch=339, loss=0.1085
Epoch=340, loss=0.1131
Epoch=341, loss=0.1096
Epoch=342, loss=0.1157
Epoch=343, loss=0.1070
Epoch=344, loss=0.1147
Epoch=345, loss=0.1127
Epoch=346, loss=0.1050
Epoch=347, loss=0.1029
Epoch=348, loss=0.1147
Epoch=349, loss=0.1064
Epoch=350, loss=0.1019
Epoch=351, loss=0.1035
Epoch=352, loss=0.1101
Epoch=353, loss=0.1015
Epoch=354, loss=0.1036
Epoch=355, loss=0.0977
Epoch=356, loss=0.1063
Epoch=357, loss=0.0932
Epoch=358, loss=0.1007
Epoch=359, loss=0.1096
Epoch=360, loss=0.1009
Epoch=361, loss=0.1059
Epoch=362, loss=0.1022
Epoch=363, loss=0.1043
Epoch=364, loss=0.1085
Epoch=365, loss=0.0891
Epoch=366, loss=0.1125
Epoch=367, loss=0.1043
Epoch=368, loss=0.0923
Epoch=369, loss=0.0921
Epoch=370, loss=0.0981
Epoch=371, loss=0.1006
Epoch=372, loss=0.0949
Epoch=373, loss=0.0996
Epoch=374, loss=0.0906
Epoch=375, loss=0.0946
Epoch=376, loss=0.0965
Epoch=377, loss=0.0947
Epoch=378, loss=0.0940
Epoch=379, loss=0.0954
Epoch=380, loss=0.0980
Epoch=381, loss=0.0891
Epoch=382, loss=0.0930
Epoch=383, loss=0.0897
Epoch=384, loss=0.0861
Epoch=385, loss=0.0845
Epoch=386, loss=0.0893
Epoch=387, loss=0.0867
Epoch=388, loss=0.0854
Epoch=389, loss=0.0879
Epoch=390, loss=0.0936
Epoch=391, loss=0.0965
Epoch=392, loss=0.0875
Epoch=393, loss=0.0904
Epoch=394, loss=0.0924
Epoch=395, loss=0.0933
Epoch=396, loss=0.0840
Epoch=397, loss=0.0850
Epoch=398, loss=0.0866
Epoch=399, loss=0.0780
Epoch=400, loss=0.0800
Epoch=401, loss=0.0836
Epoch=402, loss=0.0915
Epoch=403, loss=0.0833
Epoch=404, loss=0.0851
Epoch=405, loss=0.0844
Epoch=406, loss=0.0825
Epoch=407, loss=0.0864
Epoch=408, loss=0.0781
Epoch=409, loss=0.0861
Epoch=410, loss=0.0877
Epoch=411, loss=0.0822
Epoch=412, loss=0.0823
Epoch=413, loss=0.0839
Epoch=414, loss=0.0874
Epoch=415, loss=0.0791
Epoch=416, loss=0.0792
Epoch=417, loss=0.0824
Epoch=418, loss=0.0863
Epoch=419, loss=0.0834
Early stopping!
Loading 399th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7149+-0.0116, F1Ma=0.6640+-0.0267, acc=0.7149+-0.0116
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6930
Epoch=002, loss=0.6930
Epoch=003, loss=0.6929
Epoch=004, loss=0.6928
Epoch=005, loss=0.6927
Epoch=006, loss=0.6926
Epoch=007, loss=0.6924
Epoch=008, loss=0.6923
Epoch=009, loss=0.6921
Epoch=010, loss=0.6920
Epoch=011, loss=0.6918
Epoch=012, loss=0.6916
Epoch=013, loss=0.6914
Epoch=014, loss=0.6911
Epoch=015, loss=0.6908
Epoch=016, loss=0.6904
Epoch=017, loss=0.6901
Epoch=018, loss=0.6898
Epoch=019, loss=0.6892
Epoch=020, loss=0.6889
Epoch=021, loss=0.6883
Epoch=022, loss=0.6878
Epoch=023, loss=0.6873
Epoch=024, loss=0.6866
Epoch=025, loss=0.6859
Epoch=026, loss=0.6851
Epoch=027, loss=0.6843
Epoch=028, loss=0.6834
Epoch=029, loss=0.6824
Epoch=030, loss=0.6815
Epoch=031, loss=0.6803
Epoch=032, loss=0.6793
Epoch=033, loss=0.6780
Epoch=034, loss=0.6770
Epoch=035, loss=0.6753
Epoch=036, loss=0.6737
Epoch=037, loss=0.6722
Epoch=038, loss=0.6703
Epoch=039, loss=0.6689
Epoch=040, loss=0.6671
Epoch=041, loss=0.6647
Epoch=042, loss=0.6627
Epoch=043, loss=0.6602
Epoch=044, loss=0.6582
Epoch=045, loss=0.6556
Epoch=046, loss=0.6525
Epoch=047, loss=0.6495
Epoch=048, loss=0.6471
Epoch=049, loss=0.6442
Epoch=050, loss=0.6396
Epoch=051, loss=0.6376
Epoch=052, loss=0.6333
Epoch=053, loss=0.6310
Epoch=054, loss=0.6271
Epoch=055, loss=0.6210
Epoch=056, loss=0.6195
Epoch=057, loss=0.6139
Epoch=058, loss=0.6099
Epoch=059, loss=0.6037
Epoch=060, loss=0.5996
Epoch=061, loss=0.5938
Epoch=062, loss=0.5896
Epoch=063, loss=0.5848
Epoch=064, loss=0.5790
Epoch=065, loss=0.5736
Epoch=066, loss=0.5690
Epoch=067, loss=0.5619
Epoch=068, loss=0.5542
Epoch=069, loss=0.5478
Epoch=070, loss=0.5415
Epoch=071, loss=0.5377
Epoch=072, loss=0.5315
Epoch=073, loss=0.5241
Epoch=074, loss=0.5171
Epoch=075, loss=0.5096
Epoch=076, loss=0.5016
Epoch=077, loss=0.4927
Epoch=078, loss=0.4891
Epoch=079, loss=0.4804
Epoch=080, loss=0.4725
Epoch=081, loss=0.4645
Epoch=082, loss=0.4592
Epoch=083, loss=0.4526
Epoch=084, loss=0.4467
Epoch=085, loss=0.4378
Epoch=086, loss=0.4281
Epoch=087, loss=0.4210
Epoch=088, loss=0.4105
Epoch=089, loss=0.4023
Epoch=090, loss=0.4031
Epoch=091, loss=0.3908
Epoch=092, loss=0.3815
Epoch=093, loss=0.3816
Epoch=094, loss=0.3709
Epoch=095, loss=0.3586
Epoch=096, loss=0.3581
Epoch=097, loss=0.3469
Epoch=098, loss=0.3411
Epoch=099, loss=0.3371
Epoch=100, loss=0.3265
Epoch=101, loss=0.3222
Epoch=102, loss=0.3155
Epoch=103, loss=0.3111
Epoch=104, loss=0.3044
Epoch=105, loss=0.2975
Epoch=106, loss=0.3001
Epoch=107, loss=0.2888
Epoch=108, loss=0.2843
Epoch=109, loss=0.2785
Epoch=110, loss=0.2774
Epoch=111, loss=0.2578
Epoch=112, loss=0.2578
Epoch=113, loss=0.2591
Epoch=114, loss=0.2461
Epoch=115, loss=0.2439
Epoch=116, loss=0.2418
Epoch=117, loss=0.2376
Epoch=118, loss=0.2243
Epoch=119, loss=0.2329
Epoch=120, loss=0.2205
Epoch=121, loss=0.2158
Epoch=122, loss=0.2136
Epoch=123, loss=0.2134
Epoch=124, loss=0.2133
Epoch=125, loss=0.2095
Epoch=126, loss=0.1988
Epoch=127, loss=0.1944
Epoch=128, loss=0.1941
Epoch=129, loss=0.1910
Epoch=130, loss=0.1907
Epoch=131, loss=0.1825
Epoch=132, loss=0.1874
Epoch=133, loss=0.1742
Epoch=134, loss=0.1794
Epoch=135, loss=0.1778
Epoch=136, loss=0.1654
Epoch=137, loss=0.1707
Epoch=138, loss=0.1578
Epoch=139, loss=0.1647
Epoch=140, loss=0.1637
Epoch=141, loss=0.1546
Epoch=142, loss=0.1560
Epoch=143, loss=0.1464
Epoch=144, loss=0.1490
Epoch=145, loss=0.1608
Epoch=146, loss=0.1545
Epoch=147, loss=0.1505
Epoch=148, loss=0.1420
Epoch=149, loss=0.1385
Epoch=150, loss=0.1545
Epoch=151, loss=0.1374
Epoch=152, loss=0.1375
Epoch=153, loss=0.1377
Epoch=154, loss=0.1222
Epoch=155, loss=0.1261
Epoch=156, loss=0.1320
Epoch=157, loss=0.1314
Epoch=158, loss=0.1369
Epoch=159, loss=0.1375
Epoch=160, loss=0.1317
Epoch=161, loss=0.1165
Epoch=162, loss=0.1222
Epoch=163, loss=0.1206
Epoch=164, loss=0.1262
Epoch=165, loss=0.1230
Epoch=166, loss=0.1119
Epoch=167, loss=0.1174
Epoch=168, loss=0.1246
Epoch=169, loss=0.1099
Epoch=170, loss=0.1104
Epoch=171, loss=0.1108
Epoch=172, loss=0.1113
Epoch=173, loss=0.1069
Epoch=174, loss=0.0939
Epoch=175, loss=0.1102
Epoch=176, loss=0.1119
Epoch=177, loss=0.1116
Epoch=178, loss=0.1078
Epoch=179, loss=0.1003
Epoch=180, loss=0.1059
Epoch=181, loss=0.0973
Epoch=182, loss=0.1037
Epoch=183, loss=0.1018
Epoch=184, loss=0.1034
Epoch=185, loss=0.0965
Epoch=186, loss=0.0957
Epoch=187, loss=0.0893
Epoch=188, loss=0.0957
Epoch=189, loss=0.1003
Epoch=190, loss=0.0832
Epoch=191, loss=0.1003
Epoch=192, loss=0.0823
Epoch=193, loss=0.1001
Epoch=194, loss=0.0988
Epoch=195, loss=0.0922
Epoch=196, loss=0.0925
Epoch=197, loss=0.1022
Epoch=198, loss=0.0966
Epoch=199, loss=0.0834
Epoch=200, loss=0.0879
Epoch=201, loss=0.0941
Epoch=202, loss=0.0864
Epoch=203, loss=0.0889
Epoch=204, loss=0.0854
Epoch=205, loss=0.0826
Epoch=206, loss=0.0840
Epoch=207, loss=0.0857
Epoch=208, loss=0.0791
Epoch=209, loss=0.0888
Epoch=210, loss=0.0834
Epoch=211, loss=0.0820
Epoch=212, loss=0.0837
Epoch=213, loss=0.0831
Epoch=214, loss=0.0819
Epoch=215, loss=0.0825
Epoch=216, loss=0.0763
Epoch=217, loss=0.0762
Epoch=218, loss=0.0664
Epoch=219, loss=0.0699
Epoch=220, loss=0.0698
Epoch=221, loss=0.0661
Epoch=222, loss=0.0799
Epoch=223, loss=0.0813
Epoch=224, loss=0.0821
Epoch=225, loss=0.0767
Epoch=226, loss=0.0755
Epoch=227, loss=0.0813
Epoch=228, loss=0.0668
Epoch=229, loss=0.0754
Epoch=230, loss=0.0667
Epoch=231, loss=0.0677
Epoch=232, loss=0.0744
Epoch=233, loss=0.0711
Epoch=234, loss=0.0708
Epoch=235, loss=0.0819
Epoch=236, loss=0.0736
Epoch=237, loss=0.0689
Epoch=238, loss=0.0832
Epoch=239, loss=0.0673
Epoch=240, loss=0.0733
Epoch=241, loss=0.0809
Early stopping!
Loading 221th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7963+-0.0095, F1Ma=0.7667+-0.0144, acc=0.7963+-0.0095
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7864059307688398, 0.7885904075577486, 0.7768796200612829, 0.7840126902256769, 0.8142856955528259, 0.7559999823570251, 0.7698259353637695, 0.8142856955528259, 0.7599999904632568, 0.7698259353637695, 0.7963466770307034, 0.009519975681240475, 0.7666528951980054, 0.01437795079682381, 0.7963466770307035, 0.009519975681240474]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6930
Epoch=002, loss=0.6928
Epoch=003, loss=0.6926
Epoch=004, loss=0.6924
Epoch=005, loss=0.6921
Epoch=006, loss=0.6917
Epoch=007, loss=0.6913
Epoch=008, loss=0.6907
Epoch=009, loss=0.6901
Epoch=010, loss=0.6893
Epoch=011, loss=0.6884
Epoch=012, loss=0.6873
Epoch=013, loss=0.6864
Epoch=014, loss=0.6850
Epoch=015, loss=0.6837
Epoch=016, loss=0.6820
Epoch=017, loss=0.6803
Epoch=018, loss=0.6781
Epoch=019, loss=0.6756
Epoch=020, loss=0.6732
Epoch=021, loss=0.6710
Epoch=022, loss=0.6675
Epoch=023, loss=0.6641
Epoch=024, loss=0.6602
Epoch=025, loss=0.6559
Epoch=026, loss=0.6528
Epoch=027, loss=0.6470
Epoch=028, loss=0.6417
Epoch=029, loss=0.6366
Epoch=030, loss=0.6308
Epoch=031, loss=0.6247
Epoch=032, loss=0.6185
Epoch=033, loss=0.6114
Epoch=034, loss=0.6031
Epoch=035, loss=0.5947
Epoch=036, loss=0.5868
Epoch=037, loss=0.5778
Epoch=038, loss=0.5676
Epoch=039, loss=0.5584
Epoch=040, loss=0.5483
Epoch=041, loss=0.5394
Epoch=042, loss=0.5281
Epoch=043, loss=0.5151
Epoch=044, loss=0.5087
Epoch=045, loss=0.4917
Epoch=046, loss=0.4797
Epoch=047, loss=0.4662
Epoch=048, loss=0.4584
Epoch=049, loss=0.4424
Epoch=050, loss=0.4318
Epoch=051, loss=0.4198
Epoch=052, loss=0.4041
Epoch=053, loss=0.3901
Epoch=054, loss=0.3787
Epoch=055, loss=0.3687
Epoch=056, loss=0.3580
Epoch=057, loss=0.3407
Epoch=058, loss=0.3321
Epoch=059, loss=0.3187
Epoch=060, loss=0.3095
Epoch=061, loss=0.2947
Epoch=062, loss=0.2817
Epoch=063, loss=0.2718
Epoch=064, loss=0.2631
Epoch=065, loss=0.2582
Epoch=066, loss=0.2441
Epoch=067, loss=0.2391
Epoch=068, loss=0.2344
Epoch=069, loss=0.2217
Epoch=070, loss=0.2185
Epoch=071, loss=0.2020
Epoch=072, loss=0.1894
Epoch=073, loss=0.1986
Epoch=074, loss=0.1854
Epoch=075, loss=0.1811
Epoch=076, loss=0.1717
Epoch=077, loss=0.1627
Epoch=078, loss=0.1631
Epoch=079, loss=0.1561
Epoch=080, loss=0.1458
Epoch=081, loss=0.1456
Epoch=082, loss=0.1424
Epoch=083, loss=0.1448
Epoch=084, loss=0.1445
Epoch=085, loss=0.1387
Epoch=086, loss=0.1264
Epoch=087, loss=0.1269
Epoch=088, loss=0.1293
Epoch=089, loss=0.1139
Epoch=090, loss=0.1176
Epoch=091, loss=0.1272
Epoch=092, loss=0.1107
Epoch=093, loss=0.1144
Epoch=094, loss=0.1171
Epoch=095, loss=0.1125
Epoch=096, loss=0.1046
Epoch=097, loss=0.1002
Epoch=098, loss=0.1151
Epoch=099, loss=0.1045
Epoch=100, loss=0.0959
Epoch=101, loss=0.0877
Epoch=102, loss=0.1024
Epoch=103, loss=0.0990
Epoch=104, loss=0.0989
Epoch=105, loss=0.0958
Epoch=106, loss=0.0980
Epoch=107, loss=0.0948
Epoch=108, loss=0.0833
Epoch=109, loss=0.0869
Epoch=110, loss=0.0982
Epoch=111, loss=0.0852
Epoch=112, loss=0.0816
Epoch=113, loss=0.0917
Epoch=114, loss=0.0814
Epoch=115, loss=0.0849
Epoch=116, loss=0.0812
Epoch=117, loss=0.0920
Epoch=118, loss=0.0756
Epoch=119, loss=0.0797
Epoch=120, loss=0.0849
Epoch=121, loss=0.0771
Epoch=122, loss=0.0780
Epoch=123, loss=0.0851
Epoch=124, loss=0.0773
Epoch=125, loss=0.0745
Epoch=126, loss=0.0825
Epoch=127, loss=0.0727
Epoch=128, loss=0.0723
Epoch=129, loss=0.0748
Epoch=130, loss=0.0675
Epoch=131, loss=0.0760
Epoch=132, loss=0.0743
Epoch=133, loss=0.0770
Epoch=134, loss=0.0684
Epoch=135, loss=0.0727
Epoch=136, loss=0.0625
Epoch=137, loss=0.0616
Epoch=138, loss=0.0672
Epoch=139, loss=0.0596
Epoch=140, loss=0.0592
Epoch=141, loss=0.0622
Epoch=142, loss=0.0584
Epoch=143, loss=0.0724
Epoch=144, loss=0.0636
Epoch=145, loss=0.0703
Epoch=146, loss=0.0559
Epoch=147, loss=0.0713
Epoch=148, loss=0.0596
Epoch=149, loss=0.0564
Epoch=150, loss=0.0697
Epoch=151, loss=0.0591
Epoch=152, loss=0.0664
Epoch=153, loss=0.0584
Epoch=154, loss=0.0639
Epoch=155, loss=0.0621
Epoch=156, loss=0.0640
Epoch=157, loss=0.0569
Epoch=158, loss=0.0589
Epoch=159, loss=0.0687
Epoch=160, loss=0.0609
Epoch=161, loss=0.0526
Epoch=162, loss=0.0626
Epoch=163, loss=0.0594
Epoch=164, loss=0.0724
Epoch=165, loss=0.0679
Epoch=166, loss=0.0553
Epoch=167, loss=0.0507
Epoch=168, loss=0.0556
Epoch=169, loss=0.0495
Epoch=170, loss=0.0549
Epoch=171, loss=0.0539
Epoch=172, loss=0.0558
Epoch=173, loss=0.0516
Epoch=174, loss=0.0473
Epoch=175, loss=0.0484
Epoch=176, loss=0.0583
Epoch=177, loss=0.0429
Epoch=178, loss=0.0634
Epoch=179, loss=0.0550
Epoch=180, loss=0.0530
Epoch=181, loss=0.0505
Epoch=182, loss=0.0617
Epoch=183, loss=0.0590
Epoch=184, loss=0.0493
Epoch=185, loss=0.0518
Epoch=186, loss=0.0481
Epoch=187, loss=0.0518
Epoch=188, loss=0.0471
Epoch=189, loss=0.0514
Epoch=190, loss=0.0587
Epoch=191, loss=0.0567
Epoch=192, loss=0.0453
Epoch=193, loss=0.0558
Epoch=194, loss=0.0512
Epoch=195, loss=0.0515
Epoch=196, loss=0.0538
Epoch=197, loss=0.0562
Early stopping!
Loading 177th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7709+-0.0112, F1Ma=0.7484+-0.0085, acc=0.7709+-0.0112
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7864059307688398, 0.7885904075577486, 0.7768796200612829, 0.7840126902256769, 0.8142856955528259, 0.7559999823570251, 0.7698259353637695, 0.8142856955528259, 0.7599999904632568, 0.7698259353637695, 0.7963466770307034, 0.009519975681240475, 0.7666528951980054, 0.01437795079682381, 0.7963466770307035, 0.009519975681240474], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7577810485318742, 0.7626664023568217, 0.7320805533451675, 0.7423180398098799, 0.800000011920929, 0.7480000257492065, 0.7325918674468994, 0.8357142806053162, 0.7480000257492065, 0.7340425252914429, 0.7709288767975127, 0.011233571303863809, 0.7483653969656846, 0.008488464987760702, 0.7709288767975127, 0.01123357130386379]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6928
Epoch=002, loss=0.6922
Epoch=003, loss=0.6914
Epoch=004, loss=0.6903
Epoch=005, loss=0.6890
Epoch=006, loss=0.6873
Epoch=007, loss=0.6853
Epoch=008, loss=0.6826
Epoch=009, loss=0.6797
Epoch=010, loss=0.6762
Epoch=011, loss=0.6718
Epoch=012, loss=0.6669
Epoch=013, loss=0.6611
Epoch=014, loss=0.6540
Epoch=015, loss=0.6474
Epoch=016, loss=0.6389
Epoch=017, loss=0.6293
Epoch=018, loss=0.6182
Epoch=019, loss=0.6061
Epoch=020, loss=0.5952
Epoch=021, loss=0.5801
Epoch=022, loss=0.5662
Epoch=023, loss=0.5465
Epoch=024, loss=0.5339
Epoch=025, loss=0.5122
Epoch=026, loss=0.4933
Epoch=027, loss=0.4722
Epoch=028, loss=0.4504
Epoch=029, loss=0.4326
Epoch=030, loss=0.4114
Epoch=031, loss=0.3918
Epoch=032, loss=0.3708
Epoch=033, loss=0.3516
Epoch=034, loss=0.3232
Epoch=035, loss=0.3064
Epoch=036, loss=0.2930
Epoch=037, loss=0.2689
Epoch=038, loss=0.2648
Epoch=039, loss=0.2372
Epoch=040, loss=0.2352
Epoch=041, loss=0.2135
Epoch=042, loss=0.2089
Epoch=043, loss=0.1830
Epoch=044, loss=0.1720
Epoch=045, loss=0.1702
Epoch=046, loss=0.1725
Epoch=047, loss=0.1486
Epoch=048, loss=0.1375
Epoch=049, loss=0.1474
Epoch=050, loss=0.1234
Epoch=051, loss=0.1302
Epoch=052, loss=0.1297
Epoch=053, loss=0.1196
Epoch=054, loss=0.1161
Epoch=055, loss=0.1081
Epoch=056, loss=0.1152
Epoch=057, loss=0.1181
Epoch=058, loss=0.1042
Epoch=059, loss=0.1018
Epoch=060, loss=0.0947
Epoch=061, loss=0.0936
Epoch=062, loss=0.0947
Epoch=063, loss=0.0983
Epoch=064, loss=0.0904
Epoch=065, loss=0.0966
Epoch=066, loss=0.0953
Epoch=067, loss=0.0899
Epoch=068, loss=0.0852
Epoch=069, loss=0.0922
Epoch=070, loss=0.0854
Epoch=071, loss=0.0898
Epoch=072, loss=0.0763
Epoch=073, loss=0.0785
Epoch=074, loss=0.0763
Epoch=075, loss=0.0759
Epoch=076, loss=0.0694
Epoch=077, loss=0.0694
Epoch=078, loss=0.0806
Epoch=079, loss=0.0771
Epoch=080, loss=0.0668
Epoch=081, loss=0.0668
Epoch=082, loss=0.0800
Epoch=083, loss=0.0814
Epoch=084, loss=0.0655
Epoch=085, loss=0.0803
Epoch=086, loss=0.0618
Epoch=087, loss=0.0619
Epoch=088, loss=0.0598
Epoch=089, loss=0.0591
Epoch=090, loss=0.0699
Epoch=091, loss=0.0607
Epoch=092, loss=0.0527
Epoch=093, loss=0.0539
Epoch=094, loss=0.0614
Epoch=095, loss=0.0616
Epoch=096, loss=0.0560
Epoch=097, loss=0.0637
Epoch=098, loss=0.0528
Epoch=099, loss=0.0727
Epoch=100, loss=0.0664
Epoch=101, loss=0.0446
Epoch=102, loss=0.0653
Epoch=103, loss=0.0633
Epoch=104, loss=0.0488
Epoch=105, loss=0.0592
Epoch=106, loss=0.0498
Epoch=107, loss=0.0509
Epoch=108, loss=0.0642
Epoch=109, loss=0.0506
Epoch=110, loss=0.0566
Epoch=111, loss=0.0513
Epoch=112, loss=0.0500
Epoch=113, loss=0.0490
Epoch=114, loss=0.0436
Epoch=115, loss=0.0545
Epoch=116, loss=0.0484
Epoch=117, loss=0.0542
Epoch=118, loss=0.0500
Epoch=119, loss=0.0550
Epoch=120, loss=0.0462
Epoch=121, loss=0.0477
Epoch=122, loss=0.0482
Epoch=123, loss=0.0448
Epoch=124, loss=0.0383
Epoch=125, loss=0.0410
Epoch=126, loss=0.0393
Epoch=127, loss=0.0518
Epoch=128, loss=0.0522
Epoch=129, loss=0.0451
Epoch=130, loss=0.0386
Epoch=131, loss=0.0621
Epoch=132, loss=0.0419
Epoch=133, loss=0.0421
Epoch=134, loss=0.0510
Epoch=135, loss=0.0325
Epoch=136, loss=0.0519
Epoch=137, loss=0.0505
Epoch=138, loss=0.0406
Epoch=139, loss=0.0430
Epoch=140, loss=0.0408
Epoch=141, loss=0.0389
Epoch=142, loss=0.0312
Epoch=143, loss=0.0525
Epoch=144, loss=0.0388
Epoch=145, loss=0.0314
Epoch=146, loss=0.0421
Epoch=147, loss=0.0488
Epoch=148, loss=0.0346
Epoch=149, loss=0.0440
Epoch=150, loss=0.0458
Epoch=151, loss=0.0512
Epoch=152, loss=0.0403
Epoch=153, loss=0.0342
Epoch=154, loss=0.0431
Epoch=155, loss=0.0345
Epoch=156, loss=0.0393
Epoch=157, loss=0.0523
Epoch=158, loss=0.0403
Epoch=159, loss=0.0374
Epoch=160, loss=0.0340
Epoch=161, loss=0.0422
Epoch=162, loss=0.0503
Early stopping!
Loading 142th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8037+-0.0055, F1Ma=0.7810+-0.0059, acc=0.8037+-0.0055
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7864059307688398, 0.7885904075577486, 0.7768796200612829, 0.7840126902256769, 0.8142856955528259, 0.7559999823570251, 0.7698259353637695, 0.8142856955528259, 0.7599999904632568, 0.7698259353637695, 0.7963466770307034, 0.009519975681240475, 0.7666528951980054, 0.01437795079682381, 0.7963466770307035, 0.009519975681240474], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7577810485318742, 0.7626664023568217, 0.7320805533451675, 0.7423180398098799, 0.800000011920929, 0.7480000257492065, 0.7325918674468994, 0.8357142806053162, 0.7480000257492065, 0.7340425252914429, 0.7709288767975127, 0.011233571303863809, 0.7483653969656846, 0.008488464987760702, 0.7709288767975127, 0.01123357130386379], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7696013145373204, 0.7711684226060884, 0.7682993133594259, 0.7724073225979581, 0.8285714387893677, 0.800000011920929, 0.7674081325531006, 0.8357142806053162, 0.8019999861717224, 0.768858790397644, 0.8036533229692966, 0.005515016486612288, 0.7809599050633389, 0.00592642938985102, 0.8036533229692966, 0.005515016486612288]]
=== train DGI model ===
Epoch=000, loss=0.6932
Epoch=001, loss=0.6921
Epoch=002, loss=0.6898
Epoch=003, loss=0.6868
Epoch=004, loss=0.6818
Epoch=005, loss=0.6765
Epoch=006, loss=0.6684
Epoch=007, loss=0.6588
Epoch=008, loss=0.6486
Epoch=009, loss=0.6354
Epoch=010, loss=0.6188
Epoch=011, loss=0.6022
Epoch=012, loss=0.5829
Epoch=013, loss=0.5570
Epoch=014, loss=0.5345
Epoch=015, loss=0.5112
Epoch=016, loss=0.4818
Epoch=017, loss=0.4621
Epoch=018, loss=0.4289
Epoch=019, loss=0.4054
Epoch=020, loss=0.3748
Epoch=021, loss=0.3348
Epoch=022, loss=0.3312
Epoch=023, loss=0.2995
Epoch=024, loss=0.2770
Epoch=025, loss=0.2583
Epoch=026, loss=0.2617
Epoch=027, loss=0.2224
Epoch=028, loss=0.2143
Epoch=029, loss=0.1967
Epoch=030, loss=0.1880
Epoch=031, loss=0.1697
Epoch=032, loss=0.1818
Epoch=033, loss=0.1548
Epoch=034, loss=0.1421
Epoch=035, loss=0.1450
Epoch=036, loss=0.1409
Epoch=037, loss=0.1436
Epoch=038, loss=0.1395
Epoch=039, loss=0.1285
Epoch=040, loss=0.1226
Epoch=041, loss=0.1424
Epoch=042, loss=0.1177
Epoch=043, loss=0.1105
Epoch=044, loss=0.0810
Epoch=045, loss=0.1286
Epoch=046, loss=0.1155
Epoch=047, loss=0.1138
Epoch=048, loss=0.0934
Epoch=049, loss=0.1047
Epoch=050, loss=0.0864
Epoch=051, loss=0.1040
Epoch=052, loss=0.0898
Epoch=053, loss=0.1047
Epoch=054, loss=0.0790
Epoch=055, loss=0.0995
Epoch=056, loss=0.0862
Epoch=057, loss=0.0737
Epoch=058, loss=0.0830
Epoch=059, loss=0.0732
Epoch=060, loss=0.0747
Epoch=061, loss=0.0783
Epoch=062, loss=0.0755
Epoch=063, loss=0.0710
Epoch=064, loss=0.0694
Epoch=065, loss=0.0734
Epoch=066, loss=0.0708
Epoch=067, loss=0.0672
Epoch=068, loss=0.0565
Epoch=069, loss=0.0798
Epoch=070, loss=0.0721
Epoch=071, loss=0.0781
Epoch=072, loss=0.0678
Epoch=073, loss=0.0697
Epoch=074, loss=0.0760
Epoch=075, loss=0.0652
Epoch=076, loss=0.0835
Epoch=077, loss=0.0561
Epoch=078, loss=0.0544
Epoch=079, loss=0.0552
Epoch=080, loss=0.0590
Epoch=081, loss=0.0475
Epoch=082, loss=0.0493
Epoch=083, loss=0.0511
Epoch=084, loss=0.0647
Epoch=085, loss=0.0570
Epoch=086, loss=0.0477
Epoch=087, loss=0.0560
Epoch=088, loss=0.0445
Epoch=089, loss=0.0637
Epoch=090, loss=0.0564
Epoch=091, loss=0.0591
Epoch=092, loss=0.0575
Epoch=093, loss=0.0561
Epoch=094, loss=0.0381
Epoch=095, loss=0.0315
Epoch=096, loss=0.0562
Epoch=097, loss=0.0548
Epoch=098, loss=0.0525
Epoch=099, loss=0.0634
Epoch=100, loss=0.0543
Epoch=101, loss=0.0449
Epoch=102, loss=0.0533
Epoch=103, loss=0.0469
Epoch=104, loss=0.0385
Epoch=105, loss=0.0523
Epoch=106, loss=0.0461
Epoch=107, loss=0.0408
Epoch=108, loss=0.0375
Epoch=109, loss=0.0352
Epoch=110, loss=0.0486
Epoch=111, loss=0.0470
Epoch=112, loss=0.0339
Epoch=113, loss=0.0385
Epoch=114, loss=0.0347
Epoch=115, loss=0.0422
Early stopping!
Loading 95th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.7964+-0.0082, F1Ma=0.7740+-0.0103, acc=0.7964+-0.0082
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7864059307688398, 0.7885904075577486, 0.7768796200612829, 0.7840126902256769, 0.8142856955528259, 0.7559999823570251, 0.7698259353637695, 0.8142856955528259, 0.7599999904632568, 0.7698259353637695, 0.7963466770307034, 0.009519975681240475, 0.7666528951980054, 0.01437795079682381, 0.7963466770307035, 0.009519975681240474], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7577810485318742, 0.7626664023568217, 0.7320805533451675, 0.7423180398098799, 0.800000011920929, 0.7480000257492065, 0.7325918674468994, 0.8357142806053162, 0.7480000257492065, 0.7340425252914429, 0.7709288767975127, 0.011233571303863809, 0.7483653969656846, 0.008488464987760702, 0.7709288767975127, 0.01123357130386379], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7696013145373204, 0.7711684226060884, 0.7682993133594259, 0.7724073225979581, 0.8285714387893677, 0.800000011920929, 0.7674081325531006, 0.8357142806053162, 0.8019999861717224, 0.768858790397644, 0.8036533229692966, 0.005515016486612288, 0.7809599050633389, 0.00592642938985102, 0.8036533229692966, 0.005515016486612288], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.919626356558666, 0.9126578648760372, 0.9164401268862813, 0.9060598862322137, 0.8642857074737549, 0.7979999780654907, 0.7693423628807068, 0.8500000238418579, 0.7960000038146973, 0.7693423628807068, 0.796424407306646, 0.008223995437976885, 0.7739742329543556, 0.010310065332013967, 0.796424407306646, 0.008223995437976885]]
=== train DGI model ===
Epoch=000, loss=0.6931
Epoch=001, loss=0.6907
Epoch=002, loss=0.6859
Epoch=003, loss=0.6750
Epoch=004, loss=0.6673
Epoch=005, loss=0.6512
Epoch=006, loss=0.6377
Epoch=007, loss=0.6260
Epoch=008, loss=0.5973
Epoch=009, loss=0.5769
Epoch=010, loss=0.5605
Epoch=011, loss=0.5227
Epoch=012, loss=0.4948
Epoch=013, loss=0.4734
Epoch=014, loss=0.4463
Epoch=015, loss=0.3891
Epoch=016, loss=0.3632
Epoch=017, loss=0.3531
Epoch=018, loss=0.3388
Epoch=019, loss=0.3067
Epoch=020, loss=0.2785
Epoch=021, loss=0.2793
Epoch=022, loss=0.2216
Epoch=023, loss=0.2463
Epoch=024, loss=0.2069
Epoch=025, loss=0.2006
Epoch=026, loss=0.2023
Epoch=027, loss=0.1597
Epoch=028, loss=0.1549
Epoch=029, loss=0.1370
Epoch=030, loss=0.1438
Epoch=031, loss=0.1268
Epoch=032, loss=0.1292
Epoch=033, loss=0.1101
Epoch=034, loss=0.1034
Epoch=035, loss=0.1018
Epoch=036, loss=0.1014
Epoch=037, loss=0.0892
Epoch=038, loss=0.0805
Epoch=039, loss=0.0957
Epoch=040, loss=0.0754
Epoch=041, loss=0.0708
Epoch=042, loss=0.0712
Epoch=043, loss=0.0738
Epoch=044, loss=0.0696
Epoch=045, loss=0.0638
Epoch=046, loss=0.0593
Epoch=047, loss=0.0514
Epoch=048, loss=0.0571
Epoch=049, loss=0.0580
Epoch=050, loss=0.0542
Epoch=051, loss=0.0423
Epoch=052, loss=0.0420
Epoch=053, loss=0.0428
Epoch=054, loss=0.0425
Epoch=055, loss=0.0392
Epoch=056, loss=0.0467
Epoch=057, loss=0.0403
Epoch=058, loss=0.0425
Epoch=059, loss=0.0435
Epoch=060, loss=0.0406
Epoch=061, loss=0.0277
Epoch=062, loss=0.0358
Epoch=063, loss=0.0292
Epoch=064, loss=0.0316
Epoch=065, loss=0.0313
Epoch=066, loss=0.0354
Epoch=067, loss=0.0431
Epoch=068, loss=0.0278
Epoch=069, loss=0.0286
Epoch=070, loss=0.0287
Epoch=071, loss=0.0203
Epoch=072, loss=0.0186
Epoch=073, loss=0.0232
Epoch=074, loss=0.0328
Epoch=075, loss=0.0251
Epoch=076, loss=0.0266
Epoch=077, loss=0.0362
Epoch=078, loss=0.0213
Epoch=079, loss=0.0222
Epoch=080, loss=0.0242
Epoch=081, loss=0.0258
Epoch=082, loss=0.0175
Epoch=083, loss=0.0262
Epoch=084, loss=0.0227
Epoch=085, loss=0.0181
Epoch=086, loss=0.0281
Epoch=087, loss=0.0223
Epoch=088, loss=0.0171
Epoch=089, loss=0.0128
Epoch=090, loss=0.0183
Epoch=091, loss=0.0195
Epoch=092, loss=0.0185
Epoch=093, loss=0.0212
Epoch=094, loss=0.0200
Epoch=095, loss=0.0178
Epoch=096, loss=0.0113
Epoch=097, loss=0.0134
Epoch=098, loss=0.0146
Epoch=099, loss=0.0138
Epoch=100, loss=0.0134
Epoch=101, loss=0.0122
Epoch=102, loss=0.0171
Epoch=103, loss=0.0122
Epoch=104, loss=0.0088
Epoch=105, loss=0.0121
Epoch=106, loss=0.0091
Epoch=107, loss=0.0140
Epoch=108, loss=0.0099
Epoch=109, loss=0.0103
Epoch=110, loss=0.0085
Epoch=111, loss=0.0142
Epoch=112, loss=0.0093
Epoch=113, loss=0.0098
Epoch=114, loss=0.0094
Epoch=115, loss=0.0096
Epoch=116, loss=0.0078
Epoch=117, loss=0.0107
Epoch=118, loss=0.0084
Epoch=119, loss=0.0129
Epoch=120, loss=0.0135
Epoch=121, loss=0.0135
Epoch=122, loss=0.0114
Epoch=123, loss=0.0147
Epoch=124, loss=0.0056
Epoch=125, loss=0.0095
Epoch=126, loss=0.0093
Epoch=127, loss=0.0102
Epoch=128, loss=0.0212
Epoch=129, loss=0.0062
Epoch=130, loss=0.0033
Epoch=131, loss=0.0117
Epoch=132, loss=0.0102
Epoch=133, loss=0.0112
Epoch=134, loss=0.0128
Epoch=135, loss=0.0065
Epoch=136, loss=0.0125
Epoch=137, loss=0.0097
Epoch=138, loss=0.0048
Epoch=139, loss=0.0076
Epoch=140, loss=0.0136
Epoch=141, loss=0.0102
Epoch=142, loss=0.0065
Epoch=143, loss=0.0104
Epoch=144, loss=0.0100
Epoch=145, loss=0.0060
Epoch=146, loss=0.0069
Epoch=147, loss=0.0064
Epoch=148, loss=0.0079
Epoch=149, loss=0.0041
Epoch=150, loss=0.0070
Early stopping!
Loading 130th epoch
Early stopping!
Start to test process.
done with the edge prediction
done with the node prediction
done with the second node prediction
(E) | label_classification: F1Mi=0.8084+-0.0172, F1Ma=0.7922+-0.0204, acc=0.8084+-0.0172
[['DGI', 'heat', 16, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7082457309410557, 0.7501127180259546, 0.7482383906614002, 0.7821711153724482, 0.7428571581840515, 0.6539999842643738, 0.648452639579773, 0.7571428418159485, 0.6499999761581421, 0.6470019221305847, 0.7148853478429847, 0.011572678119629564, 0.6640083851737362, 0.026710903642298136, 0.7148853478429849, 0.01157267811962956], ['DGI', 'heat', 32, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7864059307688398, 0.7885904075577486, 0.7768796200612829, 0.7840126902256769, 0.8142856955528259, 0.7559999823570251, 0.7698259353637695, 0.8142856955528259, 0.7599999904632568, 0.7698259353637695, 0.7963466770307034, 0.009519975681240475, 0.7666528951980054, 0.01437795079682381, 0.7963466770307035, 0.009519975681240474], ['DGI', 'heat', 64, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7577810485318742, 0.7626664023568217, 0.7320805533451675, 0.7423180398098799, 0.800000011920929, 0.7480000257492065, 0.7325918674468994, 0.8357142806053162, 0.7480000257492065, 0.7340425252914429, 0.7709288767975127, 0.011233571303863809, 0.7483653969656846, 0.008488464987760702, 0.7709288767975127, 0.01123357130386379], ['DGI', 'heat', 128, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.7696013145373204, 0.7711684226060884, 0.7682993133594259, 0.7724073225979581, 0.8285714387893677, 0.800000011920929, 0.7674081325531006, 0.8357142806053162, 0.8019999861717224, 0.768858790397644, 0.8036533229692966, 0.005515016486612288, 0.7809599050633389, 0.00592642938985102, 0.8036533229692966, 0.005515016486612288], ['DGI', 'heat', 256, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.919626356558666, 0.9126578648760372, 0.9164401268862813, 0.9060598862322137, 0.8642857074737549, 0.7979999780654907, 0.7693423628807068, 0.8500000238418579, 0.7960000038146973, 0.7693423628807068, 0.796424407306646, 0.008223995437976885, 0.7739742329543556, 0.010310065332013967, 0.796424407306646, 0.008223995437976885], ['DGI', 'heat', 512, 15, 2, 'normalize', 0.1, 0.2, 0.4, 0.001, 0.5, 0.2, 0.5, 0.0001, 512, 512, 0.9200226400923357, 0.911605551175007, 0.9164581300476364, 0.902682232152142, 0.8500000238418579, 0.8019999861717224, 0.7799806594848633, 0.8500000238418579, 0.8019999861717224, 0.7799806594848633, 0.8083948698017878, 0.01719579234460342, 0.7922176509972351, 0.020366310655381636, 0.8083948698017878, 0.017195792344603444]]
